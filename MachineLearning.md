# MachineLearning

[**LoRA: Low-Rank Adaptation of Large Language Models**](3/LoRA%20Low-Rank%20Adaptation%20of%20Large%20Language%20Models%2032d19804c7aa47d9817b679b375a0cea)

GPT-3 같은 대규모 언어 모델을 효율적으로 미세 조정하는 새로운 기술입니다. 이 방법은 원래 모델의 가중치를 고정하고, 각 레이어에 더 작은 학습 가능한 행렬을 추가함으로써, 학습 가능한 파라미터의 수와 메모리 요구 사항을 대폭 줄입니다. LoRA는 적은 수의 파라미터와 빠른 학습에도 불구하고 전체 미세 조정과 동등하거나 그 이상의 성능을 발휘합니다. 이는 파라미터 수를 크게 줄이면서도 효율성과 모델 품질을 유지하는 혁신적인 방법을 제시합니다.

[**MindAgent: Emergent Gaming Interaction**](3/MindAgent%20Emergent%20Gaming%20Interaction%20905e94bd105a49f2afce82a3465abe5e)

멀티 에이전트 상호 작용을 위한 MINDAGENT 시스템에 대해 소개합니다. 이 시스템은 대규모 언어 모델(LLM)을 활용하여, 인간-AI 협업에서 복잡한 작업 계획을 가능하게 합니다. 새로운 게임 벤치마크인 CUISINEWORLD는 여러 AI 에이전트가 협력하여 요리를 만드는 가상 주방 게임으로, 고압력 환경에서 다중 에이전트 조정을 시험하는 데 사용됩니다. 실험 결과, LLM은 이미 2~4명의 에이전트를 위한 작업을 관리할 수 있는 능력을 보여주었습니다. 이 연구는 인간과 AI의 상호 작용이 필요한 게임 환경에서 LLM의 잠재력을 탐구하며, MINDAGENT 인프라를 통해 멀티 에이전트 계획을 효과적으로 조정하고 예약하는 방법을 제시합니다.

[**SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective Depth Up-Scaling**](3/SOLAR%2010%207B%20Scaling%20Large%20Language%20Models%20with%20Sim%205b46306be3fa42b0a2e5a06d93dfa01b)

깊이 업스케일링(DUS)이라는 새로운 방법을 통해 대규모 언어 모델을 효율적으로 확장하는 방법을 제시합니다. DUS는 기존의 훈련 및 추론 프레임워크와 호환되면서도 특별한 변경 없이 트랜스포머 기반 아키텍처를 확장할 수 있는 간단하면서도 효과적인 접근법입니다. 이 연구를 통해 107억 개의 파라미터를 갖는 LLM인 SOLAR 10.7B를 개발하였으며, 이는 다양한 벤치마크에서 기존 모델들을 능가하는 성능을 보여줍니다. 본 연구의 목표는 SOLAR 10.7B를 Apache 2.0 라이선스로 출시하여 전 세계 연구자 및 개발자들이 이용할 수 있도록 함으로써 NLP 분야의 협업과 혁신을 촉진하는 것입니다.

[V-IRL: Grounding Virtual Intelligence in Real Life](3/V-IRL%20Grounding%20Virtual%20Intelligence%20in%20Real%20Life%2023940ab7c9334637b5a4aa1e5aa55595)