# MVDream: Multi-view Diffusion for 3D Generation

[https://arxiv.org/abs/2308.16512](https://arxiv.org/abs/2308.16512)

[https://mv-dream.github.io/](https://mv-dream.github.io/)

- Aug 2023

### 1 INTRODUCTION

3D 콘텐츠 제작은 게임 및 미디어 산업에서 매우 중요하지만 시간이 많이 걸리고 숙련된 디자이너가 필요합니다. 현재 3D 오브젝트를 생성하는 방법에는 템플릿 기반 생성, 3D 생성 모델, 2D 리프팅 방법 등이 있습니다. 하지만 이러한 방식은 다양하고 복잡한 오브젝트를 생성하는 데 한계가 있습니다.

최근에는 드림퓨전(Dreamfusion), Magic3D와 같은 2D 리프팅 방식에서 2D 모델을 사용하여 3D 생성을 지원하고 있습니다. 텍스트 입력으로부터 상세한 3D 에셋을 생성할 수는 있지만, 여러 뷰에서 일관성에 문제가 발생하여 생성된 콘텐츠에 아티팩트가 발생하는 경우가 많습니다.

2D 리프팅 기술의 주요 과제는 멀티뷰 지식과 3D 인식이 부족하다는 점입니다. 이로 인해 제한된 시점으로 인해 시스템이 콘텐츠를 여러 번 재생성하는 멀티페이스 야누스 문제와 같은 문제가 발생합니다.

![3D 생성을 위한 2D 리프팅 방법의 전형적인 다중 뷰 일관성 문제. 왼쪽: "나무로 조각된 머리가 대두인 독수리"는 독수리가 두 얼굴을 가지고 있다. 오른쪽: "닭고기가 와플로 서서히 변하는 닭고기와 와플 위에 메이플 시럽이 들어있는 DSLR 사진".](MVDream%20Multi-view%20Diffusion%20for%203D%20Generation%20332f41c2a6ea43108193758c2324a1e2/Untitled.png)

3D 생성을 위한 2D 리프팅 방법의 전형적인 다중 뷰 일관성 문제. 왼쪽: "나무로 조각된 머리가 대두인 독수리"는 독수리가 두 얼굴을 가지고 있다. 오른쪽: "닭고기가 와플로 서서히 변하는 닭고기와 와플 위에 메이플 시럽이 들어있는 DSLR 사진".

이러한 문제를 해결하기 위해 멀티뷰 확산 모델이라는 새로운 방법이 도입되었습니다. 이 방법은 일관된 멀티뷰 이미지를 생성합니다. 이 모델은 멀티뷰 이미지와 실제 이미지를 학습함으로써 일관성과 적응성을 향상시킵니다. MVDream이라는 이름의 이 모델은 앞서 언급한 문제 없이 3D 모델을 생성할 수 있으며 다양성 측면에서 다른 상위 방법과 비슷하거나 능가합니다.

### 2 RELATED WORK AND BACKGROUND

2.1 3D 제너레이티브 모델:

- 3D 생성은 매우 중요하므로 이 작업을 위해 딥 제너레이티브 모델을 적용해야 합니다.
- 텍스처 3D 생성에는 VAE가 사용되어 왔지만 주로 단순한 모델에 초점을 맞추고 있습니다.
- GAN은 이미지 합성에서 향상된 결과를 보여주었으며, 일부 연구에서는 2D 데이터에서 3D를 인식하는 GAN 훈련을 모색하고 있습니다.
- 확산 모델은 일반적인 이미지 합성의 발전으로 인해 최근 3D 생성에 중점을 두고 있습니다.
단일 이미지에서 직접 물체 모양을 재구성하는 연구가 진행 중입니다.

2.2 오브젝트 신규 뷰 합성을 위한 확산 모델:

- 재구성 없이 새로운 3D 뷰를 합성하는 연구가 집중되고 있습니다.
- 뷰 조건부 확산 모델, 뷰 일관성 향상 등 다양한 방법이 도입되었습니다.
- 일반적인 한계는 다양한 이미지 입력에 일반화할 수 없다는 점입니다.
- Liu 등이 개발한 모델과 같은 일부 모델은 광범위한 3D 데이터 세트에서 미세 조정되었지만 사실적인 기하학적 일관성을 유지하는 데 여전히 어려움을 겪고 있습니다.

2.3 3D 생성을 위한 2D 확산 해제:

- 3D 생성 모델이 직면한 어려움으로 인해 3D 생성에 2D 확산 모델을 사용하는 연구가 진행되었습니다.
- 핵심 기술은 스코어 증류 샘플링(SDS)으로, 디퓨전 프리어가 3D 표현의 최적화를 감독합니다.
이 방법은 3D 데이터 훈련 없이도 사실적인 오브젝트를 생성할 수 있지만 멀티뷰 일관성 문제에 직면합니다.
- MVDream은 생성 견고성을 개선하고 개별 파라미터 튜닝 없이도 만족스러운 결과를 생성할 수 있습니다.
- 피사체 중심 3D 모델 생성의 개념은 더 빠른 훈련과 더 나은 기하학적 일관성을 제공하는 MVDreamBooth를 통해 탐구되었습니다.

### 3 METHODOLOGY

3.1 왜 멀티뷰 디퓨전이 필요한가?

- 2D 확산 모델에서 시점 인식을 향상하면 멀티뷰 일관성 문제를 해결할 수 있습니다.
- 비디오 확산 모델은 모든 각도에서 관찰하여 3D 오브젝트를 인식하는 접근 방식에 영감을 받았습니다.
- 3D 생성 작업에는 멀티뷰 확산을 직접 훈련하는 것이 필수적입니다.

3.2 텍스트-멀티뷰 확산 모델:

- 이 모델은 3D 데이터 세트를 사용하여 일관된 멀티뷰 이미지를 렌더링합니다.
- 동일한 텍스트 프롬프트에서 일관된 이미지를 생성하고, 카메라 포즈 제어를 통합하고, 원본 확산 모델의 품질을 유지하는 등의 과제가 있습니다.
- 멀티뷰 일관된 이미지 생성은 3D 주의력을 사용하여 일관성을 보장합니다.
- 카메라 임베딩이 추가되어 서로 다른 뷰를 구분합니다.
- 훈련 고려 사항에는 시점 선택, 뷰 수, 이미지 해상도, 원본 데이터 세트와의 공동 훈련이 포함됩니다.
    
    ![전체 다중 뷰 확산 모델의 설명. 훈련 중에는 실제 3D 모델에서 다중 뷰 이미지가 렌더링되어 확산 모델을 훈련시키며, 원래 텍스트-이미지 UNet의 구조를 유지하면서 두 가지 작은 변경을 한다: (1) 크로스 뷰 연결을 위해 2D에서 3D로 자기 주의 블록 변경 (2) 각 뷰에 대한 카메라 임베딩을 시간 임베딩에 추가. 테스트 중에는 동일한 파이프라인이 반대 방향으로 사용된다. 다중 뷰 확산 모델은 점수 증류 샘플링(SDS)을 통해 3D 표현을 최적화하기 위한 3D 사전으로 사용된다.](MVDream%20Multi-view%20Diffusion%20for%203D%20Generation%20332f41c2a6ea43108193758c2324a1e2/Untitled%201.png)
    
    전체 다중 뷰 확산 모델의 설명. 훈련 중에는 실제 3D 모델에서 다중 뷰 이미지가 렌더링되어 확산 모델을 훈련시키며, 원래 텍스트-이미지 UNet의 구조를 유지하면서 두 가지 작은 변경을 한다: (1) 크로스 뷰 연결을 위해 2D에서 3D로 자기 주의 블록 변경 (2) 각 뷰에 대한 카메라 임베딩을 시간 임베딩에 추가. 테스트 중에는 동일한 파이프라인이 반대 방향으로 사용된다. 다중 뷰 확산 모델은 점수 증류 샘플링(SDS)을 통해 3D 표현을 최적화하기 위한 3D 사전으로 사용된다.
    
    ![MVDream의 훈련 파이프라인 설명. 왼쪽: 다중 뷰 확산 (MVDiffusion)의 훈련, 2D 주의 (상단) 및 3D 다중 뷰 주의 (하단)의 두 모드로 혼합 훈련된다. 세부 사항은 Sec. 3.2.3 참조. 오른쪽: MVDreamBooth의 훈련, 사전 훈련된 MVDiffusion 모델을 취하고, 2D 주의 모드와 보존 손실로 세부 조정한다. 세부 사항은 Sec. 3.4 참조.](MVDream%20Multi-view%20Diffusion%20for%203D%20Generation%20332f41c2a6ea43108193758c2324a1e2/Untitled%202.png)
    
    MVDream의 훈련 파이프라인 설명. 왼쪽: 다중 뷰 확산 (MVDiffusion)의 훈련, 2D 주의 (상단) 및 3D 다중 뷰 주의 (하단)의 두 모드로 혼합 훈련된다. 세부 사항은 Sec. 3.2.3 참조. 오른쪽: MVDreamBooth의 훈련, 사전 훈련된 MVDiffusion 모델을 취하고, 2D 주의 모드와 보존 손실로 세부 조정한다. 세부 사항은 Sec. 3.4 참조.
    

3.3 텍스트에서 3D로 생성:

- 3D 생성에 확산 모델을 사용하는 방법에는 3D 재구성을 위해 다중 뷰 이미지를 사용하거나 3D 최적화를 위해 모델을 선행으로 사용하는 두 가지 방법이 고려됩니다.
- 후자의 접근 방식은 기존 SDS 파이프라인을 수정하는 데 중점을 둡니다.
- 콘텐츠 풍부도와 텍스처 품질을 개선하기 위해 몇 가지 기법이 제안됩니다.
- 포인트 조명과 소프트 셰이딩은 지오메트리를 규칙화하는 데 사용됩니다.

3.4 3D 세대를 위한 멀티뷰 드림부스:

- 멀티뷰 확산에서 사전 훈련된 네트워크가 3D 애플리케이션용 드림부스 모델로 확장됩니다.
- 모델은 튜닝 후에도 멀티뷰 기능을 유지합니다.
- 이미지 미세 조정 손실과 파라미터 보존 손실이라는 두 가지 유형의 손실이 고려됩니다.
- 최종 3D 모델은 야누스 문제를 완화하고 더 나은 디테일과 품질을 갖춘 모델을 생성합니다.

### 4 IMPLEMENTATION DETAILS

4.1 데이터 준비 및 확산 모델 훈련:

- 기본 3D 렌더링 데이터 세트는 공개 Objaverse 데이터 세트를 사용했습니다.
- 데이터 세트는 오브젝트 이름과 렌더링된 이미지 간의 관련성을 보장하기 위해 CLIP 점수를 사용하여 필터링되었으며, 그 결과 약 35만 개의 오브젝트가 생성되었습니다.
- 오브젝트는 정규화되고 다양한 카메라 설정과 HDRI 조명으로 렌더링되었습니다.
- 훈련 과정에서 데이터 배치는 3D 데이터 세트에서 70%의 확률로, LAION 데이터 세트의 aes V2 하위 집합에서 30%의 확률로 샘플링되었습니다.
- 모델은 512x512 해상도의 Stable Diffusion v2.1 기본 모델에서 미세 조정되었습니다.
- 훈련은 32개의 엔비디아 테슬라 A100 GPU에서 약 3일이 소요되었습니다.

4.2 SDS 최적화:

- 멀티뷰 디퓨전 가이던스는 쓰리스튜디오(thr) 라이브러리에서 구현되었습니다.
- 3D 표현은 쓰리스튜디오의 암시적 볼륨 구현을 사용했습니다.
- 카메라 뷰는 3D 데이터세트 렌더링 프로세스와 유사하게 샘플링되었습니다.
- 3D 모델은 AdamW 옵티마이저를 사용하여 10,000단계로 최적화되었습니다.
- 최적화 과정에서 리스케일링, 소프트 셰이딩, 배경 대체와 같은 다양한 기법이 적용되었습니다.

### 5 EXPERIMENTS

5.1 멀티뷰 이미지 생성:

- 이 연구에서는 멀티뷰 확산 모델의 이미지 생성 품질을 평가했습니다.
- 크로스뷰 일관성을 모델링하기 위해 다양한 주의 모듈을 비교했습니다.
- 그 결과 2D 셀프 어텐션을 재사용하는 것이 생성 품질 저하 없이 최고의 일관성을 달성하는 것으로 나타났습니다.
    
    ![다른 주의 모듈의 효과. 90도를 범위로 하는 8개의 연속적인 방위각으로 훈련된 512×512 모델에서 실험을 진행했다. 훈련 및 테스트에 동일한 랜덤 시드 사용.](MVDream%20Multi-view%20Diffusion%20for%203D%20Generation%20332f41c2a6ea43108193758c2324a1e2/Untitled%203.png)
    
    다른 주의 모듈의 효과. 90도를 범위로 하는 8개의 연속적인 방위각으로 훈련된 512×512 모델에서 실험을 진행했다. 훈련 및 테스트에 동일한 랜덤 시드 사용.
    
- FID, IS, CLIP 점수와 같은 메트릭을 사용한 정량적 비교에서는 생성 품질과 텍스트-이미지 일관성이 우수한 것으로 나타났습니다.
    
    ![훈련 세트 및 테스트 세트의 프롬프트를 사용하여 우리의 다중 뷰 확산 모델로 생성된 예제 이미지. 상위 네 개의 예제에서 상단과 하단 행은 각각 훈련 및 생성된 이미지이다. 하단 네 개의 예제는 보이지 않는 프롬프트를 사용하여 생성된 이미지이다.](MVDream%20Multi-view%20Diffusion%20for%203D%20Generation%20332f41c2a6ea43108193758c2324a1e2/Untitled%204.png)
    
    훈련 세트 및 테스트 세트의 프롬프트를 사용하여 우리의 다중 뷰 확산 모델로 생성된 예제 이미지. 상위 네 개의 예제에서 상단과 하단 행은 각각 훈련 및 생성된 이미지이다. 하단 네 개의 예제는 보이지 않는 프롬프트를 사용하여 생성된 이미지이다.
    
- 이 모델은 미세 조정 후 다양한 텍스트 입력에 일반화할 수 있었습니다.

5.2 멀티뷰 점수 증류를 통한 3D 생성:

- 멀티뷰 확산 모델을 SDS를 사용한 3D 생성에 적용했습니다.
- 이 연구에서는 이 모델을 쓰리스튜디오 프레임워크를 사용하여 기존의 텍스트-3D 변환 방법과 비교했습니다.
- 그 결과 대부분의 기준선에는 멀티뷰 일관성 문제가 있는 것으로 나타났습니다.
- 제안된 방법은 고품질 3D 에셋을 더 안정적으로 생성했습니다.
- 멀티뷰 점수 증류에 적용된 다양한 기법을 비교하여 타임 어닐링, 네거티브 프롬프트, CFG 리스케일링 및 셰이딩의 이점을 보여주었습니다.
    
    ![기본선 및 우리의 방법 사이의 텍스트-3D 생성 비교. 더 많은 결과는 부록 참조.](MVDream%20Multi-view%20Diffusion%20for%203D%20Generation%20332f41c2a6ea43108193758c2324a1e2/Untitled%205.png)
    
    기본선 및 우리의 방법 사이의 텍스트-3D 생성 비교. 더 많은 결과는 부록 참조.
    
    ![다중 뷰 SDS에서 우리가 적용하는 다른 기술의 효과. 입력 텍스트는 "스웨터를 입은 개구리의 DSLR 사진"이다.](MVDream%20Multi-view%20Diffusion%20for%203D%20Generation%20332f41c2a6ea43108193758c2324a1e2/Untitled%206.png)
    
    다중 뷰 SDS에서 우리가 적용하는 다른 기술의 효과. 입력 텍스트는 "스웨터를 입은 개구리의 DSLR 사진"이다.
    
- 사용자 연구에 따르면 78%의 사용자가 기준선보다 제안된 모델을 선호했습니다.

5.3 멀티뷰 드림부스:

- 이 연구에서는 MVDream과 드림부스3D에서 생성된 3D 모델을 비교했습니다.
- 그 결과 제안된 방법이 더 나은 오브젝트 디테일로 더 높은 품질을 제공하는 것으로 나타났습니다.
    
    ![MVDream DreamBooth 결과의 설명. 입력에서 우리는 하단의 설명 프롬프트에서 주어진 다중 뷰 이미지 (MV 이미지)를 생성하여 보여준다. 오른쪽에는 DreamBooth3D (Raj et al., 2023)와 비교하여 NeRF 렌더링 결과를 보여준다. 우리의 것은 털진 피부와 같은 객체 세부 사항을 더 잘 처리한다는 것을 알 수 있다.](MVDream%20Multi-view%20Diffusion%20for%203D%20Generation%20332f41c2a6ea43108193758c2324a1e2/Untitled%207.png)
    
    MVDream DreamBooth 결과의 설명. 입력에서 우리는 하단의 설명 프롬프트에서 주어진 다중 뷰 이미지 (MV 이미지)를 생성하여 보여준다. 오른쪽에는 DreamBooth3D (Raj et al., 2023)와 비교하여 NeRF 렌더링 결과를 보여준다. 우리의 것은 털진 피부와 같은 객체 세부 사항을 더 잘 처리한다는 것을 알 수 있다.
    
- MV 드림부스 확산 모델은 SDS 손실이 있는 NeRF 훈련 과정에서 더 높은 지오메트리 일관성을 생성했습니다.
- 전반적으로 실험을 통해 제안한 멀티뷰 확산 모델이 일관되고 고품질의 멀티뷰 이미지와 3D 모델을 생성하는 데 효과적이고 우수하다는 것을 입증했습니다.

### 6 DISCUSSION AND CONCLUSION

결론:

- 이 논문에서는 텍스트에서 객체/장면의 멀티뷰 이미지를 생성할 수 있는 최초의 멀티뷰 확산 모델을 소개했습니다.
- 이 모델은 3D 렌더링 데이터 세트와 대규모 텍스트-이미지 데이터 세트의 혼합에 대해 미세 조정되어 일반화 가능성과 멀티뷰 일관성을 보장합니다.
- 연구 결과, 카메라 매트릭스 임베딩을 사용한 3D 셀프 어텐션이 멀티뷰 일관성을 효과적으로 학습하는 것으로 나타났습니다.
- 멀티뷰 확산 모델은 SDS를 통해 3D 생성에 사용할 수 있어 기존 2D 리프팅 방법보다 안정성과 품질이 우수합니다.
- 또한 이 모델은 "멀티뷰 드림부스"라고 하는 개인화된 3D 생성을 위해 훈련할 수도 있습니다.

한계:

- 이 모델은 현재 원래의 안정적인 확산의 512×512보다 낮은 256×256 해상도로 이미지를 생성합니다.
- 이 모델의 일반화 가능성은 기본 모델에 국한된 것으로 보입니다.
- 데이터 세트를 확대하고 SDXL과 같은 더 큰 확산 모델을 사용하면 이러한 문제를 해결할 수 있습니다.
- 생성된 스타일은 렌더링된 데이터 세트와 유사한 경향이 있어 보다 다양하고 사실적인 렌더링이 필요합니다.

사회적 영향:

- 이 모델은 게임 및 미디어 분야에서 3D 생성을 지원하도록 설계되었습니다.
- 그러나 부적절한 콘텐츠를 생성하는 등 오용될 가능성이 있습니다.
- 이 방법을 사용하여 제작한 이미지/모델에는 합성임을 명확하게 표시하는 것이 좋습니다.