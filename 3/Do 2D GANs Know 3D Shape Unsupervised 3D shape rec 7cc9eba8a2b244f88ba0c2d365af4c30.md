# Do 2D GANs Know 3D Shape? Unsupervised 3D shape reconstruction from 2D Image GANs

[https://xingangpan.github.io/projects/GAN2Shape.html](https://xingangpan.github.io/projects/GAN2Shape.html)

[https://arxiv.org/abs/2011.00844](https://arxiv.org/abs/2011.00844)

### 1 INTRODUCTION

생성적 적대 신경망(GAN)은 매우 상세한 2D 이미지를 생성하는 데 능숙합니다. 흥미롭게도 이러한 2D 이미지는 3D 물체를 투영한 것이기 때문에 3D 특징을 포착하는 경우가 많습니다. 이는 "GAN을 사용하여 단일 2D 이미지에서 3D 모양을 추론할 수 있을까?"라는 질문으로 이어집니다. 이전에도 이 문제를 해결하려는 시도가 있었지만, 명시적인 3D 모델이 필요했기 때문에 메모리 소모가 많고 학습 복잡성이 증가하는 등의 단점이 있었습니다.

![프레임워크 개요. 초기 타원체 3D 형상(표면 법선에서 볼 때)으로 시작하여 다양한 시점과 조명 조건으로 다양한 '의사 샘플'을 렌더링하는 방식입니다. 이러한 샘플에 GAN 반전을 적용하여 '투영된 샘플'을 얻고, 이 샘플은 렌더링 프로세스의 기준이 되어 초기 3D 모양을 다듬는 데 사용됩니다. 이 과정은 보다 정확한 결과를 얻을 때까지 반복됩니다.](Do%202D%20GANs%20Know%203D%20Shape%20Unsupervised%203D%20shape%20rec%207cc9eba8a2b244f88ba0c2d365af4c30/Untitled.png)

프레임워크 개요. 초기 타원체 3D 형상(표면 법선에서 볼 때)으로 시작하여 다양한 시점과 조명 조건으로 다양한 '의사 샘플'을 렌더링하는 방식입니다. 이러한 샘플에 GAN 반전을 적용하여 '투영된 샘플'을 얻고, 이 샘플은 렌더링 프로세스의 기준이 되어 초기 3D 모양을 다듬는 데 사용됩니다. 이 과정은 보다 정확한 결과를 얻을 때까지 반복됩니다.

감독 없이 3D 모양을 학습하는 다른 기술도 유망했지만, 물체가 대칭이라고 가정하는 경우가 많으며, 항상 그런 것은 아닙니다. 우리의 접근 방식인 GAN2Shape는 사전 훈련된 2D GAN이 이미 2D 이미지에서 3D 모양을 재구성할 수 있는 충분한 지식을 가지고 있다고 주장합니다. 2D GAN 이미지 매니폴드 내에서 다양한 시점과 조명을 생성함으로써 3D 구조를 추론할 수 있다고 믿습니다.

그러나 매니폴드 내에서 시점과 조명에 대한 제어를 찾는 것은 노동 집약적이고 시간이 많이 소요될 수 있습니다. 이를 극복하기 위해 우리는 간단한 타원체 모양을 3D 모양의 시작점으로 사용한 다음 다양한 시점과 조명 조건에서 생성된 이미지를 기반으로 이 모양을 구체화할 것을 제안합니다. 반복적으로 모양을 다듬음으로써 3D 모양 추정을 점진적으로 개선할 수 있습니다.

우리의 GAN2Shape 기법은 사전 학습된 2D GAN이 다양한 물체 범주에 대해 단일 이미지의 3D 모양을 효과적으로 재구성할 수 있음을 보여줍니다. 이 방법은 2D 또는 3D 주석이나 물체 모양의 대칭을 가정할 필요 없이 작동합니다. 또한 이 방법은 이미지를 회전하거나 조명을 다시 비추는 등 3D를 인식하는 방식으로 이미지를 조작하는 데도 탁월합니다. 우리의 접근 방식은 기존 방법보다 성능이 뛰어나며 3D 형상 생성을 위한 새로운 관점을 제공한다는 것을 입증했습니다.

### 2 RELATED WORK

생성적 적대 신경망(GAN)은 고품질의 사실적인 2D 이미지를 생성하는 데 상당한 진전을 이루었습니다. 하지만 3D 이미지를 생성하는 데 사용할 경우, GAN은 메모리 사용량이 많고 훈련 과정이 복잡해지는 등의 문제에 직면하게 됩니다. 이 연구에서는 2D GAN의 기능을 활용하여 3D 물체 모양을 검색할 수 있는지 살펴보고, 2D와 3D 모델의 장점을 결합하여 고품질의 세밀한 3D 표현을 제공하는 방법을 제시합니다.

GAN을 사용하여 3D로 제어 가능한 방식으로 이미지의 콘텐츠를 조작하려는 기존 방법에는 여러 가지가 있습니다. 이 중 일부는 수작업으로 주석을 달거나 감독을 거쳐야 하고, 다른 일부는 외부의 3D 사람 얼굴 모델을 강력한 3D 모양으로 미리 사용합니다. 그러나 우리의 방법은 외부 3D 모델이나 감독 없이도 포즈와 조명 요소를 모두 정확하게 조작할 수 있습니다. 따라서 사람 얼굴뿐만 아니라 고양이, 자동차 등 다양한 피사체에 적용할 수 있습니다.

원시 단일 뷰 이미지에서 3D 형상을 비지도 학습하는 것은 수동 주석의 필요성을 줄여주기 때문에 성장하고 있는 분야입니다. 일반적인 문제는 단일 인스턴스에 대한 여러 시점이나 조명 조건이 부족하다는 것입니다. 이 문제를 해결하기 위해 외부 3D 형상 모델이나 2D 키포인트와 같은 약한 감독을 사용하는 방법도 있습니다. 다른 방법은 자연스러운 2D 이미지에 의존하고 자동 인코더를 사용하여 각 이미지의 시점과 모양을 분리하는 방법을 학습합니다. 하지만 이러한 방법은 특정 가정이나 제약 조건에 의존하는 경우가 많아 결과가 흐릿하거나 이미지 속 물체의 비대칭적인 측면을 포착하지 못할 수 있습니다.

![(a) 단일 이미지가 주어지면 1단계에서는 타원체(표면 법선에서 볼 때)로 깊이를 초기화하고 (로 깊이를 초기화하고 알베도 네트워크 A를 최적화합니다. (b) 2단계에서는 깊이와 알베도를 사용하여 알베도를 사용하여 다양한 임의의 시점과 조명 조건으로 '의사 샘플'을 렌더링하고 이에 대해 GAN 반전을 수행하여 '투영된 샘플'을 얻습니다. (c) 3단계에서는 투영된 샘플을 재구성하기 위해 (V, L, D, A) 네트워크를 최적화하여 심도 맵을 개선합니다. 정제된 깊이와 모델은 위의 단계를 반복하기 위한 새로운 초기화로 사용됩니다.](Do%202D%20GANs%20Know%203D%20Shape%20Unsupervised%203D%20shape%20rec%207cc9eba8a2b244f88ba0c2d365af4c30/Untitled%201.png)

(a) 단일 이미지가 주어지면 1단계에서는 타원체(표면 법선에서 볼 때)로 깊이를 초기화하고 (로 깊이를 초기화하고 알베도 네트워크 A를 최적화합니다. (b) 2단계에서는 깊이와 알베도를 사용하여 알베도를 사용하여 다양한 임의의 시점과 조명 조건으로 '의사 샘플'을 렌더링하고 이에 대해 GAN 반전을 수행하여 '투영된 샘플'을 얻습니다. (c) 3단계에서는 투영된 샘플을 재구성하기 위해 (V, L, D, A) 네트워크를 최적화하여 심도 맵을 개선합니다. 정제된 깊이와 모델은 위의 단계를 반복하기 위한 새로운 초기화로 사용됩니다.

우리의 방법은 2D GAN으로 모델링된 이미지 매니폴드를 사용하여 여러 뷰와 조명 조건을 생성함으로써 '단일 뷰'의 문제를 극복합니다. 물체의 모양에 대한 대칭 가정이 필요하지 않으므로 물체의 비대칭적인 측면을 더 정확하게 포착할 수 있습니다. 실험 결과는 최근의 최신 방법인 Unsup3d와 비교했을 때 이 방법의 우수한 성능을 입증합니다.

### 3 METHODOLOGY

2D 이미지에서 3D 모양을 복구하기 위해 생성적 적대 신경망(GAN), 특히 StyleGAN2를 활용하는 방법에 대한 연구입니다.

소개: 제너레이터와 판별자로 구성된 GAN은 잠재 벡터(z)로부터 사실적인 이미지를 생성하는 데 성공했습니다. StyleGAN2는 잠재 벡터를 중간 벡터에 매핑한 다음 출력 이미지에 매핑하는 변형입니다. 이 구조는 실제 목표 이미지를 재구성하는 과정인 GAN 반전을 가능하게 합니다.

2D GAN을 3D 모양으로: 3D 형상을 도출하기 위해 2D 이미지에서 깊이 맵, 알베도 이미지, 시점, 빛의 방향을 예측하는 자동 인코딩 설계를 사용했습니다. 그런 다음 이러한 요소를 사용하여 원본 이미지를 재구성합니다.

1단계 - 약한 모양 사전 사용: 여기서는 타원체 모양을 초기 뎁스 맵으로 사용하여 많은 오브젝트에 대한 일반적인 모양 사전을 표현합니다. 이 타원체는 이미지의 오브젝트와 정렬되도록 배치된 다음 최적화됩니다.

2단계 - 샘플링 및 GAN 이미지 매니폴드에 투영: 초기 뎁스 맵을 생성한 후 작성자는 임의의 시점과 조명 방향을 사용하여 '의사 샘플'을 생성합니다. 이러한 샘플은 왜곡이 있기는 하지만 물체가 빛에 따라 어떻게 회전하고 변화하는지에 대한 단서를 제공합니다. 인코더는 의사 샘플과 원본 샘플의 차이를 예측하도록 훈련되어 GAN을 생성하는 데 도움이 됩니다.

3단계 - 3D 모양 학습: 2단계에서 투사된 샘플은 다양한 시점과 조명 조건에서 이미지를 제공합니다. 사진 기하학적 자동 인코딩 모델은 이러한 샘플에서 기본 3D 모양을 학습하는 데 사용됩니다.

반복적 자체 개선: 위의 단계가 반복적으로 반복되어 3D 모양과 투사된 샘플을 점진적으로 개선할 수 있습니다.

저자는 잠재 오프셋에 대한 더 강력한 정규화의 필요성에 대해 논의하면서 오프셋이 매핑 네트워크에서 생성된 유효한 오프셋으로 제한하는 새로운 전략을 제안합니다. 또한 더 나은 일반화와 새로운 샘플에 대한 더 빠른 수렴을 위해 여러 인스턴스에 대한 공동 훈련의 잠재력에 대해서도 언급합니다.

### 4 EXPERIMENTS

이 연구에서는 CelebA, BFM, 고양이 데이터 세트, LSUN 자동차, LSUN 교회 등 다양한 데이터 세트를 사용하여 3D 형상 복구 및 3D 인식 이미지 조작을 위한 새로운 방법을 탐구합니다. 이 방법은 이러한 데이터 세트에 대해 사전 학습된 StyleGAN2를 사용합니다.

정성적 평가 결과 이 방법은 사람 얼굴, 고양이, 자동차, 건물 등 다양한 물체의 3D 형상을 정확하게 복구할 수 있는 것으로 나타났습니다. 비대칭 물체와 시점의 변화가 큰 물체에서 어려움을 겪는 이전 방법인 Unsup3d보다 성능이 뛰어납니다.

정량적 평가는 스케일 불변 깊이 오차(SIDE)와 평균 각도 편차(MAD) 점수를 지표로 사용하여 BFM 데이터세트에서 수행됩니다. GAN 반전으로 인해 잠재적으로 추가 오류가 발생할 수 있음에도 불구하고 이 방법은 여전히 Unsup3d 및 기타 기준선을 능가합니다. 이 방법의 효과는 대칭 가정에 의존하지 않으며, 대칭 가정을 사용하지 않고 테스트하여 입증되었습니다.

이 연구는 또한 다양한 셰이프 선행자를 사용할 때의 효과를 연구하여 변형이 성능에 약간의 영향을 미친다는 것을 발견했습니다. 평평한 모양을 사용하면 시점과 조명 변화를 나타낼 수 없기 때문에 결과가 저하됩니다.

이 방법은 오브젝트 회전 및 조명 재조명을 포함한 3D 인식 이미지 조작에도 사용됩니다. 이 방법은 또한 신원을 유지하면서 얼굴 회전을 구현할 수 있어 HoloGAN, GANSpace, SeFa와 같은 다른 비지도 방식보다 성능이 뛰어납니다.

하지만 이 방법에는 한계가 있습니다. 말과 같이 복잡한 모양의 오브젝트에는 어려움을 겪습니다. 또한 3D 메쉬는 물체의 뒷면 모양을 모델링할 수 없습니다. 그럼에도 불구하고 형상의 측면을 캡처하고 합리적인 재조명 효과를 얻을 수 있습니다.