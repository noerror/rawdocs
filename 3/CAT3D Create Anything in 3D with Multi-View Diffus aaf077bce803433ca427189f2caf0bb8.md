# CAT3D: Create Anything in 3D with Multi-View Diffusion Models

[https://arxiv.org/abs/2405.10314](https://arxiv.org/abs/2405.10314)

- May 2024

![CAT3D는 생성된 이미지나 실제 이미지의 수에 관계없이 3D 장면 생성을 가능하게 합니다.](CAT3D%20Create%20Anything%20in%203D%20with%20Multi-View%20Diffus%20aaf077bce803433ca427189f2caf0bb8/Untitled.png)

CAT3D는 생성된 이미지나 실제 이미지의 수에 관계없이 3D 장면 생성을 가능하게 합니다.

## 1 Introduction

3D 콘텐츠에 대한 수요는 게임, 시각 효과, 착용 가능한 혼합 현실 장치 등에서 실시간 상호작용을 가능하게 하기 위해 그 어느 때보다 높아졌습니다. 그러나 고품질의 3D 콘텐츠는 여전히 부족합니다. 이는 2D 이미지와 비디오는 소비자용 사진 장치로 쉽게 캡처할 수 있는 반면, 3D 콘텐츠는 복잡한 전문 도구와 많은 시간과 노력이 필요하기 때문입니다.

최근 포토그래메트리 기술의 발전으로 2D 이미지에서 3D 자산을 생성하는 접근성이 크게 향상되었습니다. 예를 들어 NeRF, Instant-NGP, Gaussian Splatting과 같은 방법을 통해 누구나 실제 장면의 사진을 찍어 3D 기하학과 외관을 최적화할 수 있습니다. 그러나 여전히 수백에서 수천 장의 사진을 캡처해야 하는 고된 과정이 필요합니다. 충분한 장면 커버리지가 없는 캡처는 최적화 문제를 잘못 설정하게 되어, 새로운 시점에서 3D 모델을 렌더링할 때 부정확한 기하학과 외관을 초래할 수 있습니다.

이러한 문제를 해결하기 위해 다중 뷰 캡처의 요구 사항을 단일 이미지나 텍스트와 같은 덜 포괄적인 입력으로 줄이면 3D 콘텐츠 생성이 더 쉬워집니다. 기존 연구들은 다양한 입력 설정에 대한 전문화된 솔루션을 개발했지만, 품질, 효율성, 일반성 면에서 제한이 있습니다.

이 논문에서는 제한된 관찰 환경에서 기존 3D 복원 방법의 사용을 제한하는 근본적인 문제, 즉 감독 뷰의 부족을 해결하는 데 중점을 둡니다. CAT3D 시스템은 입력 이미지의 수에 관계없이 일관된 새로운 관찰을 생성하여 복잡한 복원 문제를 생성 문제로 전환합니다. 이를 통해 효율적이고 빠르게 고품질의 3D 콘텐츠를 생성할 수 있습니다. CAT3D는 다양한 입력 설정에서 뛰어난 성능을 보이며, 기존 방법보다 속도가 한층 빠릅니다.

## 2 Related Work

3D 생성 모델은 제한된 관찰로부터 전체 3D 장면을 생성하는 연구에 기반을 두고 있습니다. 3D 데이터셋이 상대적으로 부족하기 때문에 많은 연구가 풍부한 2D 이미지 데이터를 활용하여 3D 생성 모델을 개발하고 있습니다. CAT3D는 이러한 연구 성과를 바탕으로 비디오 및 다중 뷰 확산 모델을 사용하여 일관된 새로운 뷰를 생성하고, 이를 3D 복원과 결합하여 효율적이고 고품질의 3D 생성이 가능하도록 합니다.

### **2D 프리어 (2D Priors)**

2D 이미지 공간 프리어는 텍스트-3D 생성에 강력한 사전 학습된 모델을 제공합니다. 텍스트-이미지 모델은 텍스트 프롬프트에서 3D 객체를 합성하기 위해 Score Distillation Sampling (SDS) 같은 방법을 도입했습니다. 이 분야의 연구는 증류 전략을 개선하거나 다른 3D 표현으로 대체하며 최적화 과정을 단축하는 데 중점을 두고 있습니다. 텍스트 기반 프리어를 단일 이미지-3D 생성에 사용하는 것도 유망하지만, 이미지 관찰과 추가 제약 조건을 복잡하게 균형 맞춰야 합니다.

### **2D 프리어와 카메라 조건부 (2D Priors with Camera Conditioning)**

텍스트-이미지 모델은 시각적으로 매력적인 이미지를 생성하지만, 이미지의 자세를 정확하게 제어하기 어렵습니다. 이를 해결하기 위해 이미지와 자세 조건을 명시적으로 훈련 또는 미세 조정하는 접근 방식이 개발되었습니다. 이러한 모델은 텍스트 및/또는 입력 이미지가 주어졌을 때 객체나 장면이 어떻게 보일지에 대한 강력한 프리어를 제공하지만, 모든 출력 뷰를 독립적으로 모델링합니다. 생성된 뷰 간의 불일치를 해결하기 위해 여전히 비용이 많이 드는 3D 증류 과정이 필요합니다.

### **다중 뷰 프리어 (Multi-view Priors)**

다중 뷰 간의 상관관계를 모델링하면 부분적인 관찰로부터 일관된 3D 콘텐츠를 생성할 수 있는 강력한 프리어를 제공합니다. 예를 들어, MVDream, ImageDream, Zero123++, ConsistNet, SyncDreamer, ViewDiff 등의 방법은 다중 뷰 생성을 동시에 수행하도록 텍스트-이미지 모델을 미세 조정합니다. CAT3D는 비디오 확산 모델과 유사한 아키텍처를 사용하여 다중 뷰 종속성을 캡처합니다. 이러한 프리어 덕분에 CAT3D는 높은 품질과 효율적인 3D 추출을 보여줍니다.

### **비디오 프리어 (Video Priors)**

비디오 확산 모델은 현실적인 비디오를 생성하는 데 뛰어난 성능을 보입니다. 그러나 이러한 모델은 정확한 카메라 제어가 어렵고, 카메라 움직임만 있는 비디오를 생성하는 데 한계가 있습니다. 이를 해결하기 위해 비디오 확산 모델을 카메라 제어 또는 다중 뷰 생성을 위해 미세 조정하는 접근 방식이 제안되었습니다. 예를 들어, AnimateDiff는 고정된 유형의 카메라 움직임으로 비디오 확산 모델을 미세 조정했고, MotionCtrl은 임의로 지정된 카메라 궤적을 조건으로 모델을 훈련했습니다. 그러나 이러한 접근 방식들은 주로 3D 객체 생성에 집중되어 있으며, 3D 장면 생성이나 객체의 문맥 내 생성에는 적합하지 않습니다.

### **피드포워드 방법 (Feed-forward Methods)**

몇 가지 뷰를 입력으로 받아 최적화 과정 없이 직접 3D 표현을 출력하는 피드포워드 모델은 효율적이지만, 이미지 공간 프리어에 기반한 접근 방식보다 품질이 떨어지는 경우가 많습니다. 이러한 모델은 몇 초 내에 3D 표현을 생성할 수 있지만, 전반적인 품질은 반복적인 최적화 접근 방식에 비해 낮습니다.

## 3 Method

![정성적 결과: CAT3D는 다양한 입력 모달리티로부터 고품질의 3D 객체나 장면을 생성할 수 있습니다: 텍스트-이미지 모델로 생성된 입력 이미지 (1-2행), 단일로 캡처된 실제 이미지 (3-4행), 그리고 다중으로 캡처된 실제 이미지 (5행).](CAT3D%20Create%20Anything%20in%203D%20with%20Multi-View%20Diffus%20aaf077bce803433ca427189f2caf0bb8/Untitled%201.png)

정성적 결과: CAT3D는 다양한 입력 모달리티로부터 고품질의 3D 객체나 장면을 생성할 수 있습니다: 텍스트-이미지 모델로 생성된 입력 이미지 (1-2행), 단일로 캡처된 실제 이미지 (3-4행), 그리고 다중으로 캡처된 실제 이미지 (5행).

### **3.1 다중 뷰 확산 모델 (Multi-View Diffusion Model)**

**이미지 인코딩 (Image Encoding)**

CAT3D의 다중 뷰 확산 모델은 입력 이미지를 잠재 표현으로 변환하기 위해 이미지 변동 자동 인코더(Variational Auto-Encoder, VAE)를 사용합니다. 각 입력 이미지는 512 × 512 × 3 해상도에서 64 × 64 × 8 크기의 잠재 표현으로 인코딩됩니다. 이 과정은 이미지의 중요한 특징을 압축된 형태로 추출하여, 후속 확산 모델이 학습하고 처리할 수 있는 형태로 변환하는 역할을 합니다.

**확산 모델 (Diffusion Model)**

잠재 표현으로 인코딩된 이미지를 기반으로, 확산 모델은 잠재 표현의 공동 분포를 학습합니다. 이 모델은 사전 훈련된 텍스트-이미지 확산 모델에서 초기화되며, 2D 확산 모델 백본을 사용하지만 다중 입력 이미지의 잠재 표현을 연결하는 추가 레이어가 포함됩니다. 이 확산 모델은 조건부 신호를 기반으로 잠재 표현의 변화를 추정하여, 입력 뷰와 일관된 새로운 뷰를 생성합니다.

**3D 자기 주의 레이어 (3D Self-Attention Layers)**

다중 뷰 간의 종속성을 캡처하기 위해, CAT3D의 모델은 3D 자기 주의(2D 공간 + 이미지 간 1D)를 사용합니다. 이 레이어는 2D 공간과 시간 차원을 결합하여 이미지 간의 일관성을 유지합니다. 기존의 2D 자기 주의 레이어를 3D 자기 주의 레이어로 변환하여, 사전 훈련된 모델의 파라미터를 계승합니다. 이러한 3D 자기 주의는 다중 뷰 사이의 정보 교환을 촉진하여, 더 일관된 3D 재구성을 가능하게 합니다.

**카메라 조건부 (Camera Conditioning)**

각 이미지의 카메라 자세를 표현하기 위해 'raymap'을 사용합니다. Raymap은 이미지의 각 픽셀 위치에서 광선의 기원과 방향을 인코딩하며, 잠재 표현과 채널-wise로 연결되어 카메라 자세에 대한 정보를 모델에 제공합니다. 이러한 카메라 조건부는 3D 세계 좌표의 강체 변환에 대해 불변이기 때문에, 모델이 입력 이미지의 다양한 카메라 각도를 효과적으로 처리할 수 있도록 합니다. 이를 통해 모델은 다양한 카메라 자세에 따라 일관된 출력을 생성할 수 있습니다.

![방법의 설명. 하나 이상의 뷰를 주어졌을 때, CAT3D는 전체 장면의 3D 표현을 단 1분 만에 생성할 수 있습니다. CAT3D는 두 단계로 구성됩니다: (1) 입력 뷰와 타겟 뷰의 카메라 자세를 조건으로 다중 뷰 잠재 확산 모델을 사용하여 많은 수의 합성 뷰를 생성합니다; (2) 관찰된 뷰와 생성된 뷰를 사용하여 NeRF 표현을 학습하기 위해 견고한 3D 복원 파이프라인을 실행합니다. 이 생성 프리어와 3D 복원 과정을 분리함으로써, 이전 작업에 비해 계산 효율성이 향상되고 방법론적 복잡성이 감소되며, 이미지 품질도 향상됩니다.](CAT3D%20Create%20Anything%20in%203D%20with%20Multi-View%20Diffus%20aaf077bce803433ca427189f2caf0bb8/Untitled%202.png)

방법의 설명. 하나 이상의 뷰를 주어졌을 때, CAT3D는 전체 장면의 3D 표현을 단 1분 만에 생성할 수 있습니다. CAT3D는 두 단계로 구성됩니다: (1) 입력 뷰와 타겟 뷰의 카메라 자세를 조건으로 다중 뷰 잠재 확산 모델을 사용하여 많은 수의 합성 뷰를 생성합니다; (2) 관찰된 뷰와 생성된 뷰를 사용하여 NeRF 표현을 학습하기 위해 견고한 3D 복원 파이프라인을 실행합니다. 이 생성 프리어와 3D 복원 과정을 분리함으로써, 이전 작업에 비해 계산 효율성이 향상되고 방법론적 복잡성이 감소되며, 이미지 품질도 향상됩니다.

### **3.2 새로운 뷰 생성 (Generating Novel Views)**

입력 뷰를 기반으로 장면을 완전히 커버하고 정확한 3D 복원을 가능하게 하기 위해 일관된 새로운 뷰를 대량으로 생성해야 합니다. 이를 위해 필요한 카메라 궤적을 설계하고, 다중 뷰 확산 모델을 사용하여 샘플링 전략을 개발합니다.

카메라 궤적 설계는 장면의 특성에 따라 달라집니다. 예를 들어, 중심 장면 주위를 도는 궤적, 정면을 향한 원형 궤적, 스플라인 궤적, 나선형 궤적 등을 사용합니다. 모델이 한 번에 처리할 수 있는 뷰의 수가 제한되어 있으므로, 타겟 뷰포인트를 더 작은 그룹으로 클러스터링하여 독립적으로 생성합니다. 단일 이미지 조건의 경우, 7개의 앵커 뷰를 생성한 후, 나머지 뷰를 병렬로 생성하는 전략을 채택합니다.

### **3.3 견고한 3D 복원 (Robust 3D Reconstruction)**

다중 뷰 확산 모델이 생성한 합성 뷰는 일반적으로 완벽하게 3D 일관성이 없기 때문에, 표준 NeRF 훈련 절차를 수정하여 일관성 없는 입력 뷰에 대한 견고성을 높입니다. 이를 위해 Zip-NeRF의 훈련 절차를 기반으로 추가적인 손실 항목을 포함합니다.

구체적으로, 생성된 뷰가 관찰된 뷰에 더 가까울수록 불확실성이 적기 때문에, 관찰된 뷰에 가까운 생성된 뷰의 재구성 손실에 더 큰 가중치를 부여합니다. 이를 통해 생성된 뷰의 일관성을 향상시키고, 최종적으로 고품질의 3D 복원을 달성합니다.

![mip-NeRF 360 [73] 및 CO3D [74] 데이터셋의 장면에서 몇몇 뷰 복원에 대한 정성적 비교. 여기 표시된 샘플은 3개의 입력 캡처 뷰를 사용하여 렌더링된 이미지입니다. ReconFusion [7]과 같은 기본 접근 방식과 비교할 때, CAT3D는 관찰된 영역에서는 실제와 잘 맞추고, 보이지 않는 영역에서는 그럴듯한 콘텐츠를 생성합니다.](CAT3D%20Create%20Anything%20in%203D%20with%20Multi-View%20Diffus%20aaf077bce803433ca427189f2caf0bb8/Untitled%203.png)

mip-NeRF 360 [73] 및 CO3D [74] 데이터셋의 장면에서 몇몇 뷰 복원에 대한 정성적 비교. 여기 표시된 샘플은 3개의 입력 캡처 뷰를 사용하여 렌더링된 이미지입니다. ReconFusion [7]과 같은 기본 접근 방식과 비교할 때, CAT3D는 관찰된 영역에서는 실제와 잘 맞추고, 보이지 않는 영역에서는 그럴듯한 콘텐츠를 생성합니다.

## 4 Experiments

### **4.1 몇몇 뷰로부터의 3D 복원 (Few-View 3D Reconstruction)**

CAT3D는 제한된 수의 뷰로부터 고품질의 3D 복원을 수행하는 능력을 평가하기 위해 다섯 가지 실제 벤치마크 데이터셋에서 실험을 수행했습니다. 사용된 데이터셋은 CO3D, RealEstate10K, DTU, LLFF, 그리고 mip-NeRF 360입니다. CO3D와 RealEstate10K는 훈련 세트에 포함되었던 데이터셋이고, DTU, LLFF, mip-NeRF 360은 훈련에 포함되지 않은 데이터셋입니다.

CAT3D는 3, 6, 9 뷰 복원 작업에서 테스트되었으며, ZeroNVS와 ReconFusion과 같은 최신 기법들과 성능을 비교했습니다. CAT3D는 거의 모든 설정에서 최신 기법들보다 뛰어난 성능을 보였으며, 특히 CO3D와 mip-NeRF 360과 같은 더 복잡한 데이터셋에서 더 큰 성능 향상을 보여주었습니다. CAT3D는 높은 품질의 텍스처와 기하학을 유지하면서도 생성 시간을 기존의 1시간에서 몇 분으로 줄였습니다.

### **4.2 단일 이미지로부터의 3D 생성 (Single Image to 3D)**

![단일 입력 이미지로부터의 3D 생성. CAT3D로 생성된 3D 모델의 렌더링(중간 행)은 장면에 대해서는 기본 접근 방식(하단 행)보다 더 높은 품질을 제공하며, 객체에 대해서는 경쟁력 있는 성능을 보여줍니다. 스케일 모호성은 방법 간 렌더링의 차이를 증폭시킵니다.](CAT3D%20Create%20Anything%20in%203D%20with%20Multi-View%20Diffus%20aaf077bce803433ca427189f2caf0bb8/Untitled%204.png)

단일 입력 이미지로부터의 3D 생성. CAT3D로 생성된 3D 모델의 렌더링(중간 행)은 장면에 대해서는 기본 접근 방식(하단 행)보다 더 높은 품질을 제공하며, 객체에 대해서는 경쟁력 있는 성능을 보여줍니다. 스케일 모호성은 방법 간 렌더링의 차이를 증폭시킵니다.

단일 이미지를 입력으로 받아 3D 콘텐츠를 생성하는 CAT3D의 효율성과 성능을 평가했습니다. 이 설정에서는 단일 뷰로부터 다양한 3D 장면을 생성해야 하는 도전적인 과제를 다룹니다. CAT3D는 ZeroNVS와 RealmDreamer와 같은 기존의 방법들과 비교하여 더 높은 해상도의 결과를 생성하며, 입력 이미지의 세부 사항을 더 잘 보존했습니다.

세그먼트된 객체를 포함하는 이미지의 경우, CAT3D의 기하학적 품질은 ImageDream과 DreamCraft3D 같은 기존 접근 방식보다 약간 떨어지지만, 전반적인 세부 사항 보존과 해상도 측면에서 우수한 성능을 보였습니다. CAT3D는 기존 방법보다 훨씬 빠른 속도로 3D 콘텐츠를 생성할 수 있습니다.

### **4.3 설계 요소 분석 (Ablations)**

CAT3D의 다양한 설계 요소와 모델 변형을 평가하기 위해 여러 실험을 수행했습니다. 이를 통해 모델의 샘플 품질과 3D 복원 성능에 대한 각 요소의 영향을 분석했습니다.

- **이미지와 자세 임베딩**: PixelNeRF 피처맵 조건부 대신 조건부 비디오 확산 아키텍처에서 카메라 자세를 포함한 per-image 임베딩을 사용한 경우, 샘플과 3D 복원 품질이 향상되었습니다.
- **뷰의 수 증가**: 다중 출력 뷰(5 또는 7)를 공동으로 모델링하면 샘플 메트릭이 향상되고, 더 일관된 뷰를 생성하여 3D 복원 성능이 개선되었습니다.
- **어텐션 레이어**: 3D 자기 주의(시공간)는 성능 향상에 중요하며, 이는 2D 자기 주의(공간 전용)와 1D 자기 주의(시간 전용)보다 우수한 성능을 보였습니다. 가장 세밀한 피처 맵에서 3D 자기 주의를 사용하면 이미지의 충실도가 가장 높아졌지만, 계산 비용이 증가하였습니다.
- **다중 뷰 확산 모델 훈련**: 사전 훈련된 텍스트-이미지 잠재 확산 모델에서 초기화하면 도메인 외 예제에 대한 성능이 향상되었습니다.
- **3D 복원**: LPIPS 손실은 고품질의 텍스처와 기하학을 달성하는 데 중요했습니다. 생성된 뷰의 수를 늘리면 중심 객체의 기하학이 개선되었지만, 배경 블러가 발생할 수 있었습니다.

## 5 Discussion

### **성과 및 기여**

CAT3D는 여러 가지 중요한 성과를 달성했습니다. 첫째, 다양한 입력 설정에서 기존의 최신 기법들을 능가하는 성능을 보였습니다. 특히, 입력 이미지의 수가 제한된 상황에서도 높은 해상도와 세부 사항을 유지하며 빠르게 3D 콘텐츠를 생성할 수 있었습니다. 예를 들어, 단일 이미지나 텍스트 프롬프트를 입력으로 받아 고품질의 3D 결과물을 생성할 수 있습니다. 또한, CAT3D는 입력 이미지가 제한된 경우에도 일관된 새로운 뷰를 생성하여 기존의 복원 방법보다 효율적이고 정확한 3D 복원이 가능하게 했습니다.

### **한계 및 제약**

CAT3D는 여러 장점을 가지고 있지만, 여전히 몇 가지 한계와 제약이 있습니다. 첫째, 훈련 데이터셋의 카메라 내재 변수가 일정하기 때문에, 서로 다른 내재 변수를 가진 여러 카메라로 캡처된 입력 뷰를 잘 처리하지 못합니다. 둘째, CAT3D의 생성 품질은 기본 텍스트-이미지 모델의 표현력에 의존하며, 기본 모델의 분포에서 벗어난 장면 콘텐츠에 대해서는 성능이 저하될 수 있습니다. 셋째, 다중 뷰 확산 모델이 지원하는 출력 뷰의 수가 여전히 상대적으로 적어, 많은 샘플을 생성할 때 모든 뷰가 3D 일관성을 유지하지 못할 수 있습니다. 마지막으로, CAT3D는 수동으로 설계된 카메라 궤적을 사용하여 장면을 충분히 커버하지만, 이는 대규모 개방형 3D 환경에서는 설계하기 어려울 수 있습니다.

### **향후 연구 방향**

CAT3D의 성능을 더욱 향상시키기 위해 여러 가지 향후 연구 방향을 제안할 수 있습니다. 첫째, CAT3D의 다중 뷰 확산 모델을 사전 훈련된 비디오 확산 모델에서 초기화함으로써 성능을 더욱 향상시킬 수 있습니다. 둘째, 샘플의 일관성을 높이기 위해 조건부 및 타겟 뷰의 수를 확장하는 것이 필요합니다. 셋째, 다양한 장면에 필요한 카메라 궤적을 자동으로 결정하는 알고리즘을 개발하면 시스템의 유연성을 높일 수 있습니다. 이러한 개선을 통해 CAT3D는 더욱 강력하고 유연한 3D 생성 시스템으로 발전할 수 있을 것입니다.