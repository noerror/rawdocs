# Text-to-3D using Gaussian Splatting

![제안된 GSGEN을 사용하여 생성된 섬세한 3D 자산. 이 이미지의 동영상은 [gsgen3d.github.io](http://gsgen3d.github.io/) 프로젝트 페이지에서 확인하실 수 있습니다.](Text-to-3D%20using%20Gaussian%20Splatting%20822e21a790f649259db5229e7b94b521/Untitled.png)

제안된 GSGEN을 사용하여 생성된 섬세한 3D 자산. 이 이미지의 동영상은 [gsgen3d.github.io](http://gsgen3d.github.io/) 프로젝트 페이지에서 확인하실 수 있습니다.

[https://arxiv.org/abs/2309.16585](https://arxiv.org/abs/2309.16585)

[https://gsgen3d.github.io/](https://gsgen3d.github.io/)

- Sep 2023

### 1 INTRODUCTION

소개 및 배경:
텍스트-이미지 생성 방법, 특히 확산 모델에 기반한 방법은 텍스트 설명에서 사실적인 이미지를 생성하는 데 성공했습니다. 사하리아, 롬바흐, 라메시, 알렉스 등의 중요한 공헌이 이러한 성공을 뒷받침합니다. 그러나 텍스트에서 3D 콘텐츠를 생성할 때는 3D 장면의 복잡성으로 인해 어려움이 발생합니다. 드림퓨전이라는 주목할 만한 모델이 품질과 속도를 향상시켰지만, 그럼에도 불구하고 현재의 많은 방법은 지오메트리 불량 및 제한된 충실도와 같은 문제에 직면해 있습니다. 이는 부분적으로 이러한 방식에 3D 프리오어를 통합하는 것이 어렵기 때문인데, 특히 NeRF 및 DMTET와 같은 기존 프레임워크에서는 더욱 그렇습니다.

Kerbl 등이 개발한 3D 가우시안 스플래팅이라는 새로운 접근 방식은 3D 콘텐츠를 다른 방식으로 재구성하는 방법을 도입했습니다. 이 방법은 이전에 사용된 암시적 방법 대신 명시적 3D 가우시안 방식을 활용합니다. 이 접근 방식은 텍스트에서 3D로 생성할 때 3D 선행 요소를 통합할 수 있는 기반을 제공하므로 유망한 방법입니다.

제안된 방법 - GSGEN:
이 연구에서는 3D 가우시안 스플래팅 방법을 기반으로 하는 GSGEN을 소개합니다. GSGEN은 이전 모델을 가우시안으로 대체하는 대신 3D 포인트 클라우드 확산을 먼저 추가하여 기하학적 일관성을 개선합니다. 즉, 생성되는 3D 콘텐츠는 가우시안 그룹으로 표현됩니다. 이는 지오메트리 최적화와 외형 개선이라는 두 가지 주요 단계로 최적화됩니다.

지오메트리 최적화 단계에서 가우시안 그룹은 3D 포인트 클라우드 확산 선행과 표준 2D 이미지 선행의 안내를 통해 미세 조정됩니다. 이를 통해 보다 일관된 3D 지오메트리를 얻을 수 있습니다. 그 후 외형 개선 단계에서 가우시안 기능을 더욱 강화하여 생성된 콘텐츠의 세부적인 뉘앙스를 포착합니다. 또한 GSGEN은 거친 포인트 클라우드로 초기화하고 특수 고밀도화 기법을 통해 외형과 충실도를 향상시키는 등 생성된 에셋의 품질을 높이기 위한 다른 기법도 도입합니다.

![이전 방법들과 비교하여, GSGEN은 직접적인 3D 지오메트리 안내와 섬세한 디테일로 콘텐츠를 표현할 수 있는 3D 가우시안 스플래팅을 사용하여 3D 장면을 표현함으로써 Janus 문제를 완화합니다. DreamFusion과 Magic3D의 결과는 공식적인 구현이 사적인 확산 모델의 사용으로 인해 공개적으로 이용 가능하지 않기 때문에 Stable DreamFusion (Tang, 2022)와 threestudio (Guo et al., 2023)을 사용하여 얻었습니다. 모든 결과는 공정한 비교를 위해 StableDiffusion (Rombach et al., 2022)의 checkpoint runwayml/stable-diffusion-v1-5에서 얻었습니다. 이 이미지의 동영상은 부록 동영상에서 제공됩니다.](Text-to-3D%20using%20Gaussian%20Splatting%20822e21a790f649259db5229e7b94b521/Untitled%201.png)

이전 방법들과 비교하여, GSGEN은 직접적인 3D 지오메트리 안내와 섬세한 디테일로 콘텐츠를 표현할 수 있는 3D 가우시안 스플래팅을 사용하여 3D 장면을 표현함으로써 Janus 문제를 완화합니다. DreamFusion과 Magic3D의 결과는 공식적인 구현이 사적인 확산 모델의 사용으로 인해 공개적으로 이용 가능하지 않기 때문에 Stable DreamFusion (Tang, 2022)와 threestudio (Guo et al., 2023)을 사용하여 얻었습니다. 모든 결과는 공정한 비교를 위해 StableDiffusion (Rombach et al., 2022)의 checkpoint runwayml/stable-diffusion-v1-5에서 얻었습니다. 이 이미지의 동영상은 부록 동영상에서 제공됩니다.

주요 기여:

- 이 연구는 3D 가우시안(Gaussians)을 활용하는 선구적인 텍스트-3D 생성 모델인 GSGEN을 소개합니다. 이 모델은 기하학적 선행을 사용하여 가우시안 스플래팅의 고유한 이점을 활용합니다.
- 이 백서에서는 2단계 최적화 접근 방식을 소개합니다. 첫 번째 단계에서는 2D 및 3D 가이던스를 모두 사용하여 일관된 기본 지오메트리를 생성하는 데 중점을 둡니다. 그 다음 단계에서는 외관을 다듬는 데 중점을 둡니다.
- 다양한 텍스트 프롬프트를 사용한 실험을 통해 GSGEN은 이전 모델에 비해 3D 에셋 생성, 특히 깃털, 복잡한 텍스처, 동물의 털 등과 같은 물체의 세부 요소를 캡처하는 데 있어 우수한 성능을 입증했습니다.

### 2 RELATED WORK

2.1 3D 씬 표현:
차별화를 허용하는 방식으로 3D 장면을 표현하는 능력은 인상적인 발전을 보였습니다. 마일든홀 등이 개발한 NeRF라는 중요한 모델은 좌표 기반 신경망을 사용하여 3D 장면을 생성하는 새로운 방법을 제공합니다. 여러 연구자들이 NeRF의 품질, 더 크고 동적인 장면을 관리할 수 있는 능력, 최적화된 훈련 및 렌더링 속도를 더욱 개선했습니다. 그러나 느린 렌더링과 훈련 중 높은 메모리 소비와 같은 문제는 여전히 남아 있습니다. 이에 대한 해결책으로 Kerbl 등은 실시간 렌더링 기능을 제공하는 3D 가우시안으로 장면을 표현하는 아이디어를 도입했습니다. 본 연구에서는 가우시안 스플래팅 방법을 명시적인 3D 프리어와 결합하여 세부적인 3D 에셋을 생성할 수 있는 잠재력을 강조합니다.

2.2 확산 모델:
확산 모델은 복잡한 데이터 분포에서 학습하는 데 주목할 만한 접근 방식이 되었습니다. 시간이 지남에 따라 노이즈가 추가되고 신경망을 사용하여 이 노이즈를 제거하는 물리학에서 영감을 받아 설계되었습니다. 확산 모델이 실제 이미지를 처리할 수 있는 능력을 보여준 DDPM이 도입된 후, 이러한 모델, 특히 샘플링 속도와 아키텍처를 개선하기 위한 연구가 활발히 진행되었습니다.

확산 모델의 주목할 만한 응용 분야는 텍스트 설명에서 사실적인 이미지를 생성하는 데 사용되는 것입니다. 고품질 이미지 생성을 위해 연구자들은 저해상도 확산 모델과 초고해상도 모델을 결합한 다단계 구조를 사용하거나 자동 인코더와 함께 모델을 학습시켰습니다. 이번 연구에 도입된 GSGEN 모델은 최고 수준의 3D 콘텐츠 생성을 위한 세부 지침을 제공하는 확산 모델인 StableDiffusion에 의존합니다.

텍스트를 3D 비주얼로 변환하려는 이전의 시도에서는 CLIP-forge, 드림 필드, 탱고와 같은 모델을 활용했는데, 이는 주로 CLIP의 지침을 활용했습니다. 드림퓨전의 도입은 3D 생성에 앞서 이미지 확산을 사용함으로써 변화를 가져왔습니다. Magic3D, 판타지아3D, 프로리컬드리머와 같은 후속 모델에서는 다단계 개선 접근 방식을 사용하여 매우 사실적인 메시 생성을 달성하는 등 다양한 혁신이 도입되었습니다. 3D 디퓨전 모델을 사용하여 3D 에셋을 직접 생성하는 것을 목표로 하는 연구도 있습니다. 이 연구는 특히 텍스트로부터 3D 포인트 클라우드를 생성하는 모델인 Point-E를 기반으로 하며, 추가 세분화를 위한 기초 구조를 제공합니다.

### 3 PRELIMINARY

3.1 점수 증류 샘플링:
최근 3D 모델링의 발전은 2023년 Poole 등이 처음 제안한 방법인 사전 학습된 2D 이미지 확산 모델을 사용하여 3D 표현을 개선하는 방향으로 전환되었습니다. 이 프레임워크 내에서 장면은 카메라 특성에 따라 렌더링 가능한 이미지로 변환할 수 있는 차별적 이미지 파라미터화(DIP)로 기호화됩니다. 이 표현은 모든 카메라 각도에서 렌더링된 이미지가 가이딩 확산 모델의 그럴듯한 이미지와 밀접하게 정렬되도록 미세 조정됩니다. 이 분야에서 중요한 성과는 이미지의 변환 프로세스를 안내하기 위한 점수를 추정하기 위해 Imagen이라는 모델을 사용하는 DreamFusion입니다. 이 연구는 다양한 확산 모델을 사용하여 2D 및 3D 차원 모두에서 점수 증류 샘플링과 또 다른 기술인 3D 가우시안 스플래팅을 결합하여 방법론을 발전시켰습니다. 목표는 복잡하고 디테일하며 기하학적으로 일관된 3D 비주얼을 제작하는 것입니다.

![제안된 GSGEN의 개요. 우리의 접근 방식은 정확한 지오메트리와 섬세한 외관을 가진 3D 자산을 생성하는 것을 목표로 합니다. GSGEN은 가우시안의 위치를 초기화하기 위해 Point-E를 사용하여 시작합니다. 최적화는 지오메트리 최적화 (Sec 4.1) 및 외관 정제 (Sec 4.2)로 그룹화되어 일관된 지오메트리 구조와 고도로 세부적인 질감 사이의 균형을 맞춥니다.](Text-to-3D%20using%20Gaussian%20Splatting%20822e21a790f649259db5229e7b94b521/Untitled%202.png)

제안된 GSGEN의 개요. 우리의 접근 방식은 정확한 지오메트리와 섬세한 외관을 가진 3D 자산을 생성하는 것을 목표로 합니다. GSGEN은 가우시안의 위치를 초기화하기 위해 Point-E를 사용하여 시작합니다. 최적화는 지오메트리 최적화 (Sec 4.1) 및 외관 정제 (Sec 4.2)로 그룹화되어 일관된 지오메트리 구조와 고도로 세부적인 질감 사이의 균형을 맞춥니다.

3.2 3D 가우시안 스플래팅:
2023년 Kerbl 등은 다양한 카메라 시점에서 3D 비주얼을 생성하고 재구성하는 획기적인 기술인 가우시안 스플래팅을 소개했습니다. 가우시안 스플래팅은 NeRF와 달리 위치, 분산, 색상 및 투명도로 설명되는 이방성 3D 가우시안 모음을 사용하여 장면을 묘사합니다. 렌더링 단계에서 이러한 3D 가우시안 모음이 카메라 뷰에 투영되고 일련의 계산을 통해 최종 이미지가 생성됩니다. 이 방법의 중요한 혁신은 개별 처리 클러스터가 이미지의 특정 부분을 렌더링하는 데 집중하는 GPU에 맞춘 메모리 효율적 설계입니다. 이 접근 방식은 더 풍부한 재구성을 제공하고 렌더링 시간을 단축하며 학습 중에 더 적은 메모리를 사용함으로써 NeRF 모델을 능가합니다. 이번 연구에서는 가우시안 스플래팅을 확장하여 텍스트를 3D 비주얼로 변환하고, 가우시안 스플래팅의 명시적 특성과 3D 확산 모델을 결합하는 혁신적인 기법을 제안합니다. 이는 제너레이티브 프로젝트의 기본 구성 요소로서 3D 가우시안 모델의 잠재력을 강조합니다.

### 4 APPROACH

GSGEN의 주요 목표는 정밀한 지오메트리와 복잡한 디테일을 모두 보여주는 3D 비주얼을 제작하는 것입니다. 다양한 표현 기능으로 잘 알려진 3D 가우시안(Gaussian)을 활용하는 이 방법론은 포인트 클라우드를 등방성 가우시안 집합으로 표현할 수 있다는 아이디어에서 발전한 것입니다. 이 접근 방식은 3D SDS 손실과 이미 훈련된 포인트 클라우드 확산 모델을 융합하여 3D 일관된 지오메트리를 생성합니다. 지오메트리 최적화와 외형 개선을 포함하는 2단계 프로세스를 통해 GSGEN은 야누스 문제와 같은 도메인의 고유한 문제를 해결한 다음 미세한 디테일을 개선하는 것을 목표로 합니다.

4.1 지오메트리 최적화:
텍스트를 3D 비주얼로 변환하는 기존 방식은 3D 에셋에 여러 면이 있거나 지오메트리가 왜곡되는 등 불일치가 나타나는 야누스 문제와 같은 문제가 종종 발생합니다. GSGEN은 포인트 클라우드를 사용하여 3D 가우시안 지오메트리를 미리 최적화함으로써 이 문제를 해결합니다. 이 방법은 텍스트-포인트 클라우드 모델인 Point-E를 사용하여 가우시안 위치를 최적화하고 3D SDS 손실을 활용합니다. 이 프로세스는 등록 및 스케일링과 같은 복잡성을 피하고, 이 모델은 때때로 지나치게 단순한 색상 패턴을 생성할 수 있으므로 주로 위치 그라데이션에 Point-E를 활용합니다.

4.2 외관 개선:
3D 사전 임베딩은 논리적 지오메트리를 생성하는 데 도움이 되지만, 때때로 모델이 세부적인 외관을 학습하는 데 방해가 될 수 있습니다. 이를 방지하기 위해 GSGEN은 2D 이미지 선행만을 사용하여 후속 단계에서 가우시안 외관을 개선합니다. 이 단계의 핵심은 지오메트리를 개선하기 위해 가우시안 '밀도화' 또는 추가를 포함합니다. 적절한 고밀도화 양을 결정할 때 어려움이 발생합니다. GSGEN의 솔루션인 콤팩트니스 기반 밀도화는 이웃과의 근접성에 따라 가우시안들을 전략적으로 배치합니다. 불투명도에 따라 불필요한 가우시안들은 제거되고, 초기 위치에서 벗어난 가우시안들은 기하학적 일관성을 유지하기 위해 페널티를 받습니다.

![제안된 밀도 기반 조밀화의 설명. 두 개의 가우시안에 대해, 만약 그들 사이의 거리 (r12)가 그들의 반경 (r1 +r2)의 합보다 크면, 보다 완전한 지오메트리를 달성하기 위해 가우시안이 증가됩니다.](Text-to-3D%20using%20Gaussian%20Splatting%20822e21a790f649259db5229e7b94b521/Untitled%203.png)

제안된 밀도 기반 조밀화의 설명. 두 개의 가우시안에 대해, 만약 그들 사이의 거리 (r12)가 그들의 반경 (r1 +r2)의 합보다 크면, 보다 완전한 지오메트리를 달성하기 위해 가우시안이 증가됩니다.

4.3 지오메트리 선행으로 초기화하기:
일관된 기하학적 토대 위에서 시작하는 것이 중요합니다. 과거에는 기본 패턴을 사용한 시도가 종종 기형적인 3D 오브젝트로 이어졌습니다. GSGEN의 솔루션은 생성된 포인트 클라우드에 따라 또는 사용자가 제공한 3D 도형을 기반으로 가우시안으로 배치하는 것으로 시작합니다. 표준 텍스트에서 3D로 생성하는 시나리오에서 Point-E는 기본 지오메트리를 생성합니다. 초기 테스트에서 나타나는 문제를 방지하기 위해 색상 초기화는 무작위로 이루어집니다. 사용자별 설계의 경우, 사용자가 선택한 모양을 포인트 클라우드로 변환하여 가우시안 배치를 결정하므로 정점이나 포인트가 과도하게 사용되지 않습니다.
ts.

![Point-E 생성 색상의 채택이 미치는 영향.](Text-to-3D%20using%20Gaussian%20Splatting%20822e21a790f649259db5229e7b94b521/Untitled%204.png)

Point-E 생성 색상의 채택이 미치는 영향.

### 5 EXPERIMENTS

이 섹션에서는 GSGEN 방법론의 효과를 검증하기 위해 수행한 실험에 대해 자세히 설명합니다. 테스트에는 텍스트에서 3D로 생성하는 분야의 기존 방법과 GSGEN을 비교하는 것뿐만 아니라 초기화, 3D 안내 및 밀도화 전략의 중요성에 대한 자세한 평가도 포함되었습니다.

![제안된 GSGEN과 이전의 최첨단 텍스트-3D 생성 방법, Magic3D (Lin et al., 2023) 및 Fantasia3D (Chen et al., 2023) 사이의 질적 비교. 우리의 접근 방식은 특히 높은 주파수 세부 사항에서 더 나은 시각적 품질을 달성합니다. 이미지 아래에 제공된 프롬프트를 참조하십시오. 보다 자세한 비교 결과는 부록 B.3을 참조하십시오. 이 이미지의 동영상은 부록 동영상에서 제공됩니다.](Text-to-3D%20using%20Gaussian%20Splatting%20822e21a790f649259db5229e7b94b521/Untitled%205.png)

제안된 GSGEN과 이전의 최첨단 텍스트-3D 생성 방법, Magic3D (Lin et al., 2023) 및 Fantasia3D (Chen et al., 2023) 사이의 질적 비교. 우리의 접근 방식은 특히 높은 주파수 세부 사항에서 더 나은 시각적 품질을 달성합니다. 이미지 아래에 제공된 프롬프트를 참조하십시오. 보다 자세한 비교 결과는 부록 B.3을 참조하십시오. 이 이미지의 동영상은 부록 동영상에서 제공됩니다.

5.1 구현 세부 사항

우리의 안내 모델은 공개 StableDiffusion 모델을 기반으로 개발되었습니다. 모든 에셋은 특정 체크포인트에서 소싱했으며, 기능을 향상시키기 위해 다른 작품의 기술을 통합했습니다. 3D 가우시안 스플래팅은 널리 사용되는 프로그래밍 프레임워크를 사용하여 구현했으며, 일정한 간격으로 콤팩트니스 기반 밀도화를 적용하고 부적합한 가우시안을 제거했습니다. 훈련 설정은 지오메트리 최적화 및 외형 개선을 위해 균일한 카메라 위치와 특정 손실 가중치 설정에 중점을 두고 이전의 몇 가지 방법론을 반영했습니다.

![초기화와 3D 이전에 대한 제거 연구 결과. 여기서의 Coarse Model은 지오메트리 최적화 후에 얻은 대략적인 자산을 나타냅니다. 우리는 임의 초기화로 생성된 자산이 심하게 퇴화되어 완전히 부적합한 지오메트리를 가지고 있다는 것을 관찰할 수 있습니다 (첫 번째 열). 포인트-E로 초기화된 자산은 약간 더 나은 지오메트리를 가지고 있지만 여전히 Janus 문제에 직면하고 있습니다 (두 번째 열). 제안된 GSGEN은 Point-E 초기화와 3D 안내를 사용하여 더 나은 3D 일관성을 가진 모양을 생성합니다.](Text-to-3D%20using%20Gaussian%20Splatting%20822e21a790f649259db5229e7b94b521/Untitled%206.png)

초기화와 3D 이전에 대한 제거 연구 결과. 여기서의 Coarse Model은 지오메트리 최적화 후에 얻은 대략적인 자산을 나타냅니다. 우리는 임의 초기화로 생성된 자산이 심하게 퇴화되어 완전히 부적합한 지오메트리를 가지고 있다는 것을 관찰할 수 있습니다 (첫 번째 열). 포인트-E로 초기화된 자산은 약간 더 나은 지오메트리를 가지고 있지만 여전히 Janus 문제에 직면하고 있습니다 (두 번째 열). 제안된 GSGEN은 Point-E 초기화와 3D 안내를 사용하여 더 나은 3D 일관성을 가진 모양을 생성합니다.

5.2 텍스트에서 3D로 생성

텍스트에서 3D로 생성하는 GSGEN의 기능을 평가할 때, 우리의 접근 방식은 정확한 지오메트리로 세밀하게 디테일한 3D 에셋을 생성했습니다. 이와 반대로 기존 방식은 동일한 지침이 주어졌을 때 결함이 있는 지오메트리로 어려움을 겪었습니다. 대표적인 두 가지 방법인 Magic3D와 판타지아3D를 나란히 비교한 결과, 오브젝트의 세부적인 특징을 유지하는 데 있어 GSGEN의 우수성이 두드러졌습니다. 이전 방법들이 지나치게 매끄러운 결과를 생성하는 경우가 많았던 반면, GSGEN은 복잡한 디테일이 돋보였습니다.

5.3 제거 연구

초기화: 시스템을 시작하거나 '초기화'하는 방법은 매우 중요한 역할을 합니다. 경쟁사 방식(드림퓨전)의 초기화 전략을 모방했을 때, 우리 시스템은 종종 지오메트리에 결함이 있는 만족스럽지 못한 3D 오브젝트를 생성했습니다. 이와는 대조적으로 초기화에 Point-E를 사용한 결과, 보다 사실적이고 일관된 3D 모델이 생성되었습니다.

![밀도 전략에 대한 제거 연구. 이 그림에서 사용된 텍스트 프롬프트는 생크림과 마쉬멜로와 함께 한 잔의 뜨거운 초콜릿입니다.](Text-to-3D%20using%20Gaussian%20Splatting%20822e21a790f649259db5229e7b94b521/Untitled%207.png)

밀도 전략에 대한 제거 연구. 이 그림에서 사용된 텍스트 프롬프트는 생크림과 마쉬멜로와 함께 한 잔의 뜨거운 초콜릿입니다.

3D 이전: 또한 3D 가이던스의 중요성도 테스트했습니다. 이 가이던스가 없었을 때 우리 모델은 특히 독특하고 비대칭적인 디자인의 오브젝트를 처리할 때 야누스 문제로 여전히 어려움을 겪었습니다. 3D 가이던스를 통합하면 이 문제를 효과적으로 해결하여 보다 안정적이고 일관된 모양을 생성할 수 있었습니다.

고밀도화 전략: 3D 모델의 밀도 또는 '고밀도화'를 높이기 위한 전략도 테스트했습니다. 뷰 공간 기울기에만 의존하는 방법과 가우시안 과잉을 방지하기 위해 보다 완화된 접근 방식을 취하는 두 가지 대안이 평가되었습니다. 우리의 새로운 컴팩트니스 기반 고밀도화 전략은 특정 지침에 따라 에셋 디테일을 향상시킴으로써 두 가지 방법 모두보다 우수한 성능을 보였습니다.

### 6 LIMITATIONS AND CONCLUSION

한계점: 우리가 제안한 방법인 GSGEN은 복잡한 텍스트 설명이나 복잡한 논리를 처리할 때 때때로 어려움을 겪습니다. 이러한 단점의 주된 이유는 Point-E 시스템과 스테이블디퓨전 모델의 CLIP 텍스트 인코더의 제한된 언어 이해력 때문입니다. 3D 사전을 도입하여 야누스 문제와 같은 일부 문제를 해결하는 데 진전을 이루었지만, 특히 까다로운 텍스트 안내를 처리할 때 결함이 있는 출력의 가능성을 완전히 제거하지는 못했습니다. 이러한 오류의 자세한 예와 분석은 부록 C에 나와 있습니다.

결론: 이번 연구를 통해 가우시안 스플래팅을 사용하여 복잡하고 3D 일관성이 있는 오브젝트를 생성하는 선구적인 방법인 GSGEN을 소개했습니다. 우리 접근 방식에는 기본 모양을 생성하는 지오메트리 최적화 단계와 생성된 모양을 더욱 세밀하고 연속적으로 만드는 외형 개선 단계의 두 단계 최적화 프로세스가 포함됩니다. 광범위한 테스트를 통해 지에스젠의 일관된 3D 모델 제작 능력과 복잡한 디테일을 보존하는 능숙함을 확인할 수 있었습니다. 저희는 이 방법이 텍스트에서 3D로 변환하는 품질을 향상시키고 가우시안 스플래팅 애플리케이션과 보다 직접적인 3D 통합을 위한 발판을 마련할 것으로 낙관하고 있습니다.

하지만 3D 제너레이티브 모델링을 발전시키면서도 윤리적 측면을 고려하기 위해 최선을 다하고 있습니다. 3D 모델은 사실적이기 때문에 2D 이미지보다 더 설득력 있는 허위 콘텐츠를 제작하는 데 악용될 수 있습니다. StableDiffusion을 기반으로 하는 우리의 방법은 원본 훈련 데이터에 존재하는 편향을 상속할 수 있다는 점을 인식하는 것이 중요합니다. 따라서 의도치 않게 오해의 소지가 있는 콘텐츠를 홍보하지 않으려면 신중한 데이터 세트 선택이 무엇보다 중요합니다. 하지만 적절한 감독만 이루어진다면 저희와 같은 제너레이티브 모델의 이점이 위험성을 능가하여 해당 분야에서 긍정적인 변화를 이끌어낼 수 있을 것으로 믿습니다.

### A IMPLEMENTATION DETAILS

3D 가우시안 스플래팅:
Kerbl 등(2023)의 공식 3D 가우시안 스플래팅 코드를 직접 채택하는 대신, 학습 가능한 MLP 배경을 지원하기 위해 자체 버전을 만들었습니다. 역순으로 그라디언트를 계산하는 공식 버전과 달리, 이 팀의 접근 방식은 플레녹셀 스타일의 역전파를 따르기 때문에 픽셀 단위 배경을 통합하기가 더 쉽습니다. 가우시안 뎁스 맵은 중앙의 뷰 공간 깊이를 사용하여 렌더링됩니다. 이 방법의 정확도는 가우시안 눈금의 미세한 스케일 때문이라고 합니다. 또한 3D 에셋에 미치는 영향은 미미하지만 z-변수 렌더러가 개발되었습니다. 렌더링 및 최적화 중 안정성을 위해 가우시안 불투명도는 특정 한계 내에서 고정되었습니다.

가이던스 세부 사항:
이 연구에서는 2D 이미지 확산 모델에 대해 허깅페이스 디퓨저의 가이던스를 활용했습니다(von Platen et al., 2022). "runwayml/stable-diffusion-v1-5" 체크포인트는 일관되게 사용되었지만, 다른 체크포인트는 개선 사항을 관찰하지 않고 테스트했습니다. Point-E 확산 모델은 변경 없이 그대로 사용했습니다.

훈련 세부 사항:
이 백서 및 보충 비디오에 소개된 모든 3D 에셋은 4개의 NVIDIA 3090 GPU에서 훈련되었습니다. 훈련에는 배치 크기 8로 각 프롬프트당 약 30분이 소요되었지만, 에셋을 단일 GPU에서 약 1시간 40분 만에 훈련할 수도 있습니다. 3D 콘텐츠의 하이퍼 파라미터 설정은 다양한 입력 프롬프트에 대해 견고함을 입증했기 때문에 전체적으로 유지되었습니다.

오픈 소스 리소스:
개발팀은 실험에 다음과 같은 여러 오픈 소스 리소스를 활용했습니다:

- Stable DreamFusion, Fantasia3D, threestudio, HuggingFace Diffusers(모두 Apache License 2.0에 의거).
- StableDiffusion (MIT 라이선스).
- DeepFloyd IF(DeepFloyd IF 라이선스 계약).
- OpenAI Point-E(MIT 라이선스).
- ULIP (BSD 3 조항 라이선스).

특정 결과를 얻기 위해 원본 버전이 비공개 확산 모델로 인해 오픈소스화되지 않았기 때문에 Stable DreamFusion과 threestudio를 사용했습니다. Fatansia3D의 경우 특히 개와 같은 모양을 위해 공식 설정을 사용했습니다.

### B ADDTIONAL RESULTS

사용자 가이드 생성:
3D 가우시안 스플래팅 기법은 초기화를 쉽게 할 수 있어 사용자 안내 생성에 도움이 됩니다. 평가에서 연구팀은 Latent-NeRF 데이터 세트의 도형에 GSGEN 방법을 사용했습니다. 초기 포인트는 메시 표면에서 포인트를 샘플링하여 결정했습니다. 사용자의 모양 선호도를 유지하기 위해 위치 지정에 느린 학습 속도를 선택했습니다. 생성된 3D 콘텐츠를 Latent-NeRF 및 Fantasia-3D와 같은 유명한 방법의 3D 콘텐츠와 비교했을 때, 사용자가 원래 지정한 지오메트리를 보존하면서 지오메트리와 텍스처 모두에서 GSGEN 방법이 다른 방법보다 뛰어난 성능을 보였습니다.

텍스트-3D 결과:
이 팀은 텍스트-3D 생성 방법의 추가 결과를 그림으로 보여주었습니다. GSGEN 접근 방식은 정밀한 지오메트리와 향상된 선명도를 갖춘 3D 에셋을 효과적으로 생성합니다. 자세한 결과와 데모 동영상을 보려면 프로젝트 페이지와 함께 제공되는 동영상으로 이동하세요.

정성적 비교:
드림퓨전, 매직3D, 판타지아3D, 라텐트네알에프 등 주목할 만한 다른 방법과 GSGEN 방법을 나란히 비교하는 정성적 비교도 제공했습니다. 공정성을 위해 비교에 사용된 이미지는 각 논문 또는 프로젝트 페이지에서 직접 가져왔습니다. 비디오 비교는 보충 자료에서도 확인할 수 있습니다.

![사용자 지침 생성에 대한 질적 비교 결과. 왼쪽에서 오른쪽까지의 프롬프트는 (1)독일 셰퍼드; (2) 현실적인 로봇 손; (3) 턱시도를 입은 테디 베어; (4) 레고 사람; (5) 레고로 만든 집입니다.](Text-to-3D%20using%20Gaussian%20Splatting%20822e21a790f649259db5229e7b94b521/Untitled%208.png)

사용자 지침 생성에 대한 질적 비교 결과. 왼쪽에서 오른쪽까지의 프롬프트는 (1)독일 셰퍼드; (2) 현실적인 로봇 손; (3) 턱시도를 입은 테디 베어; (4) 레고 사람; (5) 레고로 만든 집입니다.

절제:

3D 포인트 클라우드 안내: GSGEN의 가이던스에 Point-E를 사용하는 것 외에도 팀은 또 다른 모델인 ULIP도 테스트했습니다. ULIP는 포인트 클라우드 분류에서는 우수한 성능을 보였지만, 생성 컨텍스트에서는 부족했습니다. 특정 손실 기준에 따라 비교했을 때 Point-E는 포인트 클라우드를 더 효과적으로 안내한 반면, ULIP는 혼란스러운 결과물을 생성했습니다.

![Point-E 및 ULIP하에서 최적화된 포인트 클라우드. 프롬프트: 코기](Text-to-3D%20using%20Gaussian%20Splatting%20822e21a790f649259db5229e7b94b521/Untitled%209.png)

Point-E 및 ULIP하에서 최적화된 포인트 클라우드. 프롬프트: 코기

![Point-E 또는 ULIP로 3D 전용 텍스트-3D 생성에 대한 질적 비교. 프롬프트: 아이스크림 선데의 DSLR 사진.](Text-to-3D%20using%20Gaussian%20Splatting%20822e21a790f649259db5229e7b94b521/Untitled%2010.png)

Point-E 또는 ULIP로 3D 전용 텍스트-3D 생성에 대한 질적 비교. 프롬프트: 아이스크림 선데의 DSLR 사진.

2D 이미지 안내: 스테이블디퓨전 외에도 또 다른 선도적인 텍스트-이미지 확산 모델인 딥플로이드 IF의 안내에 따라 GSGEN의 성능도 평가했습니다. 이 모델은 더 우수한 아키텍처와 더 강력한 텍스트 인코더를 갖추고 있었습니다. 비교 결과, DeepFloyd IF로 생성된 에셋은 주로 T-5 인코더 덕분에 텍스트-3D 정렬이 더 우수했습니다. 그러나 몇 가지 제한 사항으로 인해 출력물이 약간 흐릿하게 나타났습니다.

실패 사례:
3D 이전 버전을 도입했음에도 불구하고 팀은 "야누스 문제"를 완전히 극복할 수 없었습니다. 이 문제는 2D 프리뷰를 통해 텍스트에서 3D로 전환하는 과정의 어려움과 현재 3D 프리뷰의 제한된 기능에서 비롯되었습니다.

![GSGEN의 세 가지 전형적인 실패 사례.](Text-to-3D%20using%20Gaussian%20Splatting%20822e21a790f649259db5229e7b94b521/Untitled%2011.png)

GSGEN의 세 가지 전형적인 실패 사례.

![StableDiffusion이 제대로 처리할 수 없는 프롬프트로 인해 해당 텍스트-3D 생성에 실패합니다.](Text-to-3D%20using%20Gaussian%20Splatting%20822e21a790f649259db5229e7b94b521/Untitled%2012.png)

StableDiffusion이 제대로 처리할 수 없는 프롬프트로 인해 해당 텍스트-3D 생성에 실패합니다.

![GSGEN으로 생성된 더 많은 3D 자산](Text-to-3D%20using%20Gaussian%20Splatting%20822e21a790f649259db5229e7b94b521/Untitled%2013.png)

GSGEN으로 생성된 더 많은 3D 자산