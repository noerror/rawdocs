# Magic-Me: Identity-Specific Video Customized Diffusion

[https://arxiv.org/abs/2402.09368](https://arxiv.org/abs/2402.09368)

- Feb 2024

Video Custom Diffusion (VCD) 프레임워크는 텍스트 기반의 비디오 생성에서 아이덴티티 특정과 시간적 일관성을 달성하기 위해 세 가지 핵심 기술을 도입합니다. 첫 번째로, 3D Gaussian Noise Prior를 사용하여 비디오 프레임 간의 일관성을 강화하고, 동작의 안정성을 높이면서 동작의 크기를 조절합니다. 이는 추론 단계에서만 적용되어 복잡한 재훈련 과정 없이도 효과를 발휘합니다. 두 번째로, ID 모듈은 확장된 ID 토큰을 통해 특정 아이덴티티의 시각적 특성을 정밀하게 포착하고 재현하는 데 초점을 맞춥니다. 이 모듈은 prompt-to-segmentation 기법을 활용하여 아이덴티티와 배경을 구분하고, 아이덴티티의 세부 사항을 더욱 명확히 합니다. 마지막으로, Face VCD와 Tiled VCD 기술은 각각 비디오 내 인물의 얼굴을 선명하게 하고 전반적인 해상도를 향상시키는 방식으로, 비디오의 품질과 아이덴티티 표현의 세밀함을 개선합니다. 이 세 가지 기술의 결합을 통해 VCD는 주어진 텍스트 프롬프트에 따라 아이덴티티를 정확하게 유지하면서 시간적으로 일관된 비디오를 생성할 수 있는 능력을 제공합니다.

## 1. Introduction

서론에서는 텍스트 기반 비디오 생성(T2V) 기술의 최근 발전에 대해 논의합니다. 이 기술들은 텍스트 설명에서 일관되고 현실적인 애니메이션을 생성할 수 있는 능력을 향상시켰지만, 생성된 콘텐츠에 대한 정밀한 제어, 특히 아이덴티티에 특화된 제어는 여전히 큰 도전 과제로 남아 있습니다. 실제 응용에서는 영화 제작이나 광고와 같이 특정 아이덴티티를 유지하면서 텍스트로 설명된 컨텍스트에 따라 콘텐츠를 생성할 필요가 종종 있습니다. 이러한 요구를 충족하기 위해 아이덴티티 특정 생성 기술의 중요성이 강조됩니다.

이 문제에 대응하기 위해, 이 논문은 아이덴티티를 특정하는 것에 초점을 맞춘 새로운 비디오 생성 프레임워크인 Video Custom Diffusion (VCD)을 제안합니다. VCD는 특정 캐릭터의 아이덴티티를 다양한 동작과 장면에 걸쳐 애니메이션화하면서도 그 아이덴티티를 유지하는 것을 목표로 합니다. 기존의 접근법들이 스타일과 동작에 초점을 맞추거나 비디오 편집을 통해 맞춤형 생성을 시도했지만, 아이덴티티 특정 제어에는 주목하지 않았던 점을 개선하고자 합니다.

![특정 아이덴티티의 소수 이미지만으로도, 우리의 Video Custom Diffusion (VCD)는 주어진 프롬프트와 일치하는 시간적으로 일관된 비디오를 생성할 수 있습니다.](Magic-Me%20Identity-Specific%20Video%20Customized%20Diffus%20881a0618373a4c2ab7d5613eeb3f3601/Untitled.png)

특정 아이덴티티의 소수 이미지만으로도, 우리의 Video Custom Diffusion (VCD)는 주어진 프롬프트와 일치하는 시간적으로 일관된 비디오를 생성할 수 있습니다.

서론에서는 또한 아이덴티티 특정 텍스트-이미지(T2I) 모델의 최근 발전을 언급하며, 이를 비디오 생성에 적용하는 것이 직관적이지만, 아이덴티티 일관성과 비디오 배경의 안정성 유지에 있어서 여전히 문제가 있다고 지적합니다. 이를 해결하기 위해, VCD 프레임워크는 아이덴티티 정보의 정렬 개선과 프레임 간 일관성을 강화하는 새로운 기술을 도입하여 이전 방법들에서 발견된 주요 문제점들을 해결하고자 합니다.

![제안된 Video Custom Diffusion (VCD) 방법과 이전 접근 방식과의 비교. 첫 번째 행은 T2V 방법 [9]을 사용한 결과를 보여주며, 중간 행은 비디오 생성 프레임워크 [18] 내에서 Custom Diffusion [31]을 사용한 결과를 표시하고, 맨 아래 행은 VCD의 결과를 제시합니다. T2V는 참조 이미지와 생성된 비디오 사이의 유사성을 보여주지만, ID의 보존이 누락되었습니다. 반면, Custom Diffusion의 직접 사용은 특정 ID의 비디오를 생성하는 경향이 있지만, 일관성이 부족합니다. 반대로, VCD는 ID 보존을 크게 향상시킵니다.](Magic-Me%20Identity-Specific%20Video%20Customized%20Diffus%20881a0618373a4c2ab7d5613eeb3f3601/Untitled%201.png)

제안된 Video Custom Diffusion (VCD) 방법과 이전 접근 방식과의 비교. 첫 번째 행은 T2V 방법 [9]을 사용한 결과를 보여주며, 중간 행은 비디오 생성 프레임워크 [18] 내에서 Custom Diffusion [31]을 사용한 결과를 표시하고, 맨 아래 행은 VCD의 결과를 제시합니다. T2V는 참조 이미지와 생성된 비디오 사이의 유사성을 보여주지만, ID의 보존이 누락되었습니다. 반면, Custom Diffusion의 직접 사용은 특정 ID의 비디오를 생성하는 경향이 있지만, 일관성이 부족합니다. 반대로, VCD는 ID 보존을 크게 향상시킵니다.

## **2. Related works**

관련 연구 챕터에서는 텍스트-이미지(T2I) 생성, 텍스트-비디오(T2V) 생성, 비디오 편집, 그리고 이미지 애니메이션 분야에서의 주요 발전과 기술적 진보를 소개합니다. 이러한 분야들은 비디오 생성과 관련된 다양한 측면을 다루며, 각각이 어떻게 현재 연구의 기반이 되는지를 설명합니다.

### **2.1 텍스트-이미지 생성**

이 세부 섹션에서는 텍스트 기반 이미지 생성 기술의 발전을 다룹니다. 특히, 확산 모델을 기반으로 하는 최신 T2I 기술이 실제적인 초상화와 판타지적인 존재들의 상상적 묘사를 생성하는 데 있어 중요한 진전을 이루었습니다. 이러한 발전은 모델을 미세 조정하고, 원하는 주제와 연결된 고유 식별자를 학습하여 특정 주제 이미지의 맞춤화를 목표로 합니다. 이 과정에서 텍스트 역전(Textual Inversion), DreamBooth와 같은 방법론이 등장했으며, 이는 토큰 임베딩을 조정하여 주제 이미지와 토큰 사이의 매핑을 학습합니다.

### **2.2 텍스트-비디오 생성**

이 섹션은 이미지 생성에서 한 걸음 더 나아가 비디오 생성으로의 진전을 다룹니다. 비디오 생성은 여러 프레임에 걸쳐 공간적 및 시간적 일관성을 유지하는 데 높은 계산 비용이 드는 등, 이미지 생성보다 더 복잡합니다. 초기의 연구는 단순한 동작과 낮은 해상도의 비디오에 제한되었으나, 최근에는 고화질 비디오 생성을 위한 대규모 변환 아키텍처와 확산 모델 기반 아키텍처의 발전을 통해 상당한 진보가 이루어졌습니다.

### **2.3 비디오 편집**

비디오 생성의 더욱 세밀한 제어를 가능하게 하는 기술적 진보를 소개합니다. 여기에는 비디오 내용을 변경하면서 동작을 보존하는 Tune-a-Video, 텍스트 및 포즈/에지/이미지에 의해 안내되는 비디오 합성을 가능하게 하는 Text2Video-Zero와 Runway Gen 같은 접근 방식이 포함됩니다. 이들은 비디오 생성 과정에서 사용자의 입력에 더 잘 맞추기 위한 기술적 진보를 보여줍니다.

### **2.4 이미지 애니메이션**

정적 이미지를 동적 비디오 시퀀스로 확장하거나, 캐릭터의 속성을 변경하고 배경을 변경하는 등, 이미지 애니메이션 분야의 주요 연구를 다룹니다. 이러한 연구는 이미지나 비디오에서 주제를 취하여 다른 비디오에서 발생하는 동작을 그 주제에 전달하는 방법을 탐구합니다.

이 챕터는 텍스트 기반 비디오 생성 분야에서 현재 연구가 어떻게 다양한 관련 분야의 발전 위에 구축되고 있는지를 보여주며, 이러한 기술적 진보가 어떻게 향후 비디오 생성의 새로운 가능성을 열어가고 있는지를 설명합니다.

## 3. Preliminaries

예비 지식 챕터에서는 Video Custom Diffusion (VCD) 프레임워크의 기술적 기반과 주요 구성 요소에 대한 배경 지식을 제공합니다. 이 챕터는 안정적 확산 모델(Stable Diffusion), 노이즈 프로세스, 그리고 학습 및 추론 단계에서의 주요 기술적 과제들을 다룹니다.

### **안정적 확산 모델(Stable Diffusion)**

VCD는 안정적 확산 모델(Stable Diffusion)을 기반으로 합니다. 이 모델은 이미지 x0와 조건 c를 입력으로 받아, 이미지 인코더를 사용하여 x0를 잠재 코드 z0으로 인코딩합니다. 이후, z0는 가우시안 노이즈와 함께 반복적으로 혼합되어 잠재 공간에서의 확산 프로세스를 통해 이미지를 생성합니다. 이 과정은 역확산 과정을 통해 초기의 무작위 가우시안 노이즈로부터 최종 이미지를 단계적으로 복원하는 방식으로 진행됩니다.

### **노이즈 프로세스와 역확산**

확산 모델은 노이즈를 점진적으로 추가하는 '전방 프로세스'와 이 노이즈를 제거하는 '역확산 프로세스'를 통해 작동합니다. 역확산 과정에서는 모델이 노이즈로부터 원본 데이터 분포를 복원하도록 학습됩니다. 이 과정은 특정 조건(c)에 따라 잠재 코드(z0)로부터 최종 이미지를 생성하는 데 사용됩니다.

### **노출 편향(Exposure Bias)**

노출 편향은 학습과 추론 단계에서 모델 입력이 다르게 되어, 추론 시 누적된 오류를 초래하는 문제를 지칭합니다. T2V 생성에서는 시간적 차원에서도 이러한 노출 편향 문제가 발생합니다. 학습 단계에서는 실제 비디오로부터 샘플링된 zt가 시간적 상관관계를 보이지만, 추론 단계에서는 zt가 이전 예측에 기반하여 계산되어, 프레임 간 일관성 유지가 어려워질 수 있습니다.

### **3D 가우시안 노이즈 우선 순위**

이 문제를 해결하기 위해, 3D 가우시안 노이즈 우선 순위 기법이 도입됩니다. 이는 추론 단계에서 노이즈 초기화에 공분산을 도입함으로써 프레임 간 일관성을 향상시키는 훈련-무료 접근 방식입니다. 이 방식은 프레임 간 일관된 아이덴티티를 유지하면서도 동작의 질과 크기를 균형있게 조정하는 데 도움이 됩니다.

![ID 특정 비디오 생성의 프레임워크. 이 프레임워크는 T2V VCD, Face VCD, Tiled VCD를 포함합니다. 기본 구성 요소, ID 모듈, 및 3D Gaussian Noise Prior는 이들 노이즈 제거 파이프라인에서 재사용됩니다.](Magic-Me%20Identity-Specific%20Video%20Customized%20Diffus%20881a0618373a4c2ab7d5613eeb3f3601/Untitled%202.png)

ID 특정 비디오 생성의 프레임워크. 이 프레임워크는 T2V VCD, Face VCD, Tiled VCD를 포함합니다. 기본 구성 요소, ID 모듈, 및 3D Gaussian Noise Prior는 이들 노이즈 제거 파이프라인에서 재사용됩니다.

이 챕터는 VCD를 이해하고 사용하기 위한 필수적인 기술적 배경을 제공하며, 특히 확산 모델을 비디오 생성에 적용하는 데 있어서의 주요 과제와 이를 해결하기 위한 기술적 접근 방식에 대해 설명합니다.

![3D Gaussian Noise Prior 공분산의 영향. 공분산 하이퍼파라미터 γ가 증가함에 따라, 동작은 더 안정되지만 그 크기는 감소합니다. 노이즈 우선 순위는 추론 중에만 적용되어, 재훈련의 필요성을 없앱니다. 프롬프트는 '눈 위를 달리는 V* 개'입니다.](Magic-Me%20Identity-Specific%20Video%20Customized%20Diffus%20881a0618373a4c2ab7d5613eeb3f3601/Untitled%203.png)

3D Gaussian Noise Prior 공분산의 영향. 공분산 하이퍼파라미터 γ가 증가함에 따라, 동작은 더 안정되지만 그 크기는 감소합니다. 노이즈 우선 순위는 추론 중에만 적용되어, 재훈련의 필요성을 없앱니다. 프롬프트는 '눈 위를 달리는 V* 개'입니다.

## 4. Method

### 4.1 3D Gaussian Noise Prior

- **목표:** 비디오 프레임 간의 일관성 향상 및 노출 편향 문제 해결.
- **방법론:** 3D Gaussian Noise Prior는 다차원 가우시안 분포를 사용하여 비디오 프레임 간의 상관 관계를 모델링합니다. 이를 통해 초기화된 노이즈가 프레임 간 일관된 아이덴티티를 유지하도록 하여, 비디오의 동작을 안정화시키고 일관성을 개선합니다.

### 4.2 ID 모듈

- **목적:** 특정 아이덴티티의 시각적 특징을 보존하면서 비디오 생성.
- **핵심 구성요소:**
    - **Extended ID tokens:** 아이덴티티 특정 이미지 생성을 위해 확장된 ID 토큰을 사용합니다. 이 토큰들은 조건부 인코딩과 상호 작용하여 아이덴티티의 시각적 특징을 더 잘 보존합니다.
        
        ![확장된 ID 토큰 학습. 확장된 ID 토큰은 prompt-to-segmentation에 의해 마스크된 주제 영역에 대해 최적화됩니다.](Magic-Me%20Identity-Specific%20Video%20Customized%20Diffus%20881a0618373a4c2ab7d5613eeb3f3601/Untitled%204.png)
        
        확장된 ID 토큰 학습. 확장된 ID 토큰은 prompt-to-segmentation에 의해 마스크된 주제 영역에 대해 최적화됩니다.
        
    - **Prompt-to-segmentation:** 배경 노이즈를 제거하고 텍스트 조건과의 일관성을 높이기 위해, 주요 주제를 설명하는 GPT-4V를 사용하여 분류 및 분할 마스크를 생성합니다. 이는 아이덴티티와 배경 사이의 구분을 명확히 하여, 아이덴티티 보존에 초점을 맞춘 비디오 생성을 가능하게 합니다.
        
        ![prompt-to-segmentation 없이 인코딩된 배경 노이즈가 텍스트 조건을 오염시킵니다. 여기서 사용된 프롬프트는 '거리에 앉아 있는 V* 고양이, 지나가는 자동차, 불빛, 도시의 밤을 바라보다'입니다.](Magic-Me%20Identity-Specific%20Video%20Customized%20Diffus%20881a0618373a4c2ab7d5613eeb3f3601/Untitled%205.png)
        
        prompt-to-segmentation 없이 인코딩된 배경 노이즈가 텍스트 조건을 오염시킵니다. 여기서 사용된 프롬프트는 '거리에 앉아 있는 V* 고양이, 지나가는 자동차, 불빛, 도시의 밤을 바라보다'입니다.
        

### 4.3 Face VCD와 Tiled VCD

- **Face VCD:** 멀리 있는 인물의 얼굴을 더 선명하게 만들기 위해, 얼굴 부분을 감지하고, 이를 고해상도로 업스케일한 후, 다시 원래 비디오에 합성하는 기법입니다. 이를 통해 잠재 공간에서의 소규모 세포들로 인해 발생할 수 있는 얼굴의 흐림을 개선합니다.
- **Tiled VCD:** 비디오의 해상도를 향상시키기 위해 사용되며, 비디오를 타일로 분할하여 각 타일을 부분적으로 노이즈 제거하는 방식으로 세부적인 아이덴티티 특징을 복원합니다.

이 챕터에서는 VCD 프레임워크의 핵심 방법론을 소개하며, 비디오 생성 과정에서 아이덴티티 보존과 프레임 간 일관성을 달성하기 위한 기술적인 세부 사항들을 설명합니다. 3D Gaussian Noise Prior는 프레임 간 일관성을 강화하는 핵심 기술이며, ID 모듈은 아이덴티티 특정 생성을 위한 중요한 구성 요소입니다. Face VCD와 Tiled VCD는 비디오의 해상도와 세부적인 아이덴티티 표현을 개선하는 데 기여합니다. 이러한 기술들의 조합을 통해, VCD는 텍스트 기반의 비디오 생성 분야에서 아이덴티티 보존과 일관성 있는 비디오 생성을 위한 새로운 접근 방식을 제시합니다.

## 5. Experiments

### 5.1 질적 결과

- 실험에서는 VCD가 실제적인 기반 모델뿐만 아니라 다양한 스타일의 모델에서도 캐릭터의 아이덴티티를 유지하면서 비디오를 생성할 수 있음을 보여줍니다. 사용된 모델에는 Civitai의 Realist Vision, ToonYou, RCNZ Cartoon 3D 등이 포함됩니다.

### 5.2 구현 세부 사항

- **훈련:** Stable Diffusion 1.5를 사용하여 ID 모듈을 훈련시키고, Realistic Vision으로 추론을 진행합니다. 학습률과 배치 크기, 최적화 단계 수 등의 매개변수 설정을 포함합니다.
- **데이터셋:** DreamBooth 데이터셋, CustomConcept101, 인터넷에서 수집한 다양한 주제를 포함하는 16개의 주제를 선택하여 다양한 배경에 대한 애니메이션을 생성하기 위한 25개의 프롬프트를 GPT-4V로 생성합니다.
- **평가 지표:** 생성된 비디오는 아이덴티티 일치, 텍스트 일치, 시간적 부드러움의 세 가지 관점에서 평가됩니다. 이는 CLIP-I와 DINO를 사용하여 비디오 프레임과 참조 이미지 간의 유사성 점수를 계산함으로써 수행됩니다.

### 5.3 정량적 결과

- 실험은 Stable Diffusion 및 Realistic Vision을 포함한 사전 훈련된 모델들을 평가하여, VCD가 제공하는 개선 사항을 정량적으로 보여줍니다. Realistic Vision은 SD에 비해 우수한 성능을 보이며, VCD를 기반 모델로 사용할 때의 장점을 강조합니다.
    
    ![질적 결과. 각 주제에 대해 Realist Vision [3], ToonYou [4], RCNZ Cartoon 3D [2]의 결과를 나열합니다.](Magic-Me%20Identity-Specific%20Video%20Customized%20Diffus%20881a0618373a4c2ab7d5613eeb3f3601/Untitled%206.png)
    
    질적 결과. 각 주제에 대해 Realist Vision [3], ToonYou [4], RCNZ Cartoon 3D [2]의 결과를 나열합니다.
    

### 5.4 Ablation Study

- 3D Gaussian Noise Prior의 중요성을 강조하며, 이를 제거했을 때 비디오의 부드러움, 이미지 일치, CLIP-T 점수에 미치는 영향을 분석합니다. 또한, prompt-to-segmentation 모듈을 제거한 결과를 통해, 배경 노이즈가 텍스트 조건을 오염시키고 결과적으로 모션 부족으로 인한 높은 부드러움 점수를 초래한다는 것을 보여줍니다.

이 실험 챕터는 VCD 프레임워크가 다양한 조건과 설정에서 아이덴티티를 일관되게 유지하면서 텍스트 기반의 비디오 생성을 수행할 수 있는 능력을 실험을 통해 입증합니다. 정량적 및 질적 결과 모두 VCD가 아이덴티티 특정 비디오 생성 분야에서 중요한 개선을 제공함을 보여줍니다. Ablation study는 VCD의 각 구성 요소가 전체 성능에 어떻게 기여하는지를 더 잘 이해하는 데 도움이 됩니다.

## 6. Limitations and Future Works

### 6.1 제한 사항

- **다양한 아이덴티티의 비디오 생성:** VCD 프레임워크는 여러 다른 아이덴티티를 포함하는 비디오를 생성할 때 어려움을 겪습니다. 특히, 각각의 아이덴티티가 서로 상호작용할 때 비디오의 품질이 저하될 수 있습니다.
- **동작 모듈의 한계:** 현재의 동작 모듈은 짧은 비디오만 생성할 수 있으며, 비디오의 길이를 확장하면서 동일한 일관성과 품질을 유지하는 것이 어렵습니다.

### 6.2 향후 작업

- **다중 아이덴티티 상호작용 개선:** 여러 아이덴티티가 포함된 비디오에서 각각의 아이덴티티가 서로 상호작용하면서도 품질을 유지할 수 있는 기술 개발이 필요합니다.
- **비디오 길이 확장:** 현재 동작 모듈의 한계를 극복하고, 더 긴 비디오에서도 높은 품질과 일관성을 유지할 수 있는 방법에 대한 연구가 요구됩니다.

## 7. Conclusion

VCD(Video Custom Diffusion) 프레임워크는 텍스트 기반의 아이덴티티 특정 비디오 생성 분야에서 중요한 진보를 나타냅니다. 이 프레임워크는 아이덴티티 정보와 프레임 간 상관관계를 통합하여 아이덴티티가 프레임 전반에 걸쳐 일관되게 유지되는 비디오를 생성할 수 있는 새로운 방법을 제시합니다. VCD의 주요 기여로는 정밀한 아이덴티티 분리를 위한 ID 모듈, 프레임 일관성을 향상시키는 T2V VCD 모듈, 그리고 비디오 품질을 개선하는 V2V 모듈이 있습니다. 이러한 기여를 통해, VCD는 기존 방법들을 뛰어넘는 고품질, 안정적인 비디오 생성을 가능하게 합니다. 또한, VCD의 ID 모듈은 기존의 텍스트-이미지 모델과의 호환성을 높이며, 다양한 응용 분야에서의 사용을 용이하게 합니다. 연구 결과는 VCD가 아이덴티티 보존에 있어서 우수한 성능을 보이며, 다양한 설정에서의 비디오 생성 가능성을 확장한다는 것을 확인시켜 줍니다.