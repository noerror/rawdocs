# MagiCapture: High-Resolution Multi-Concept Portrait Customization

[https://arxiv.org/abs/2309.06895](https://arxiv.org/abs/2309.06895)

- Sep 2023

### 1 Introduction

![제안된 MagiCapture의 생성된 결과, 주제 및 스타일 참조를 몇 개만 사용하여 고해상도 초상화 이미지를 생성하기 위한 다중 개념 개인화 방법입니다.](MagiCapture%20High-Resolution%20Multi-Concept%20Portrait%200fc0344786a947158e1c52fedfed8858/Untitled.png)

제안된 MagiCapture의 생성된 결과, 주제 및 스타일 참조를 몇 개만 사용하여 고해상도 초상화 이미지를 생성하기 위한 다중 개념 개인화 방법입니다.

이력서나 결혼식 등 전문적인 용도의 고품질 이미지를 캡처하려면 일반적으로 비용이 많이 드는 스튜디오 과정과 사진 편집을 거쳐야 합니다. 이 백서에서는 이를 간소화할 수 있는 새로운 기술을 소개합니다. 최근 텍스트-이미지 변환 모델의 발전으로 사실적인 사진 제작이 가능해졌습니다. 이 연구는 몇 가지 입력 및 참조 사진을 사용하여 특정 스타일의 이미지를 생성하도록 이러한 모델을 개인화하는 데 중점을 둡니다.

이러한 모델의 잠재력에도 불구하고 문제가 있습니다. 특히 몇 장의 참조 사진만으로 큰 모델을 조정하려고 할 때 생성된 이미지가 비현실적으로 보일 수 있습니다. 이 문제는 서로 다른 이미지 개념을 병합할 때 더욱 심각해져 부자연스러운 이미지로 이어집니다.

이 문제를 해결하기 위해 이 논문에서는 인물 사진에서 피사체와 스타일을 모두 융합할 수 있도록 설계된 방법인 'MagiCapture'를 소개합니다. 합성 프롬프트 학습과 고유한 손실 함수 등 새로운 기술을 사용하여 보다 사실적인 이미지를 생성하는 데 도움이 됩니다. MagiCapture는 품질 테스트와 실제 애플리케이션 모두에서 뛰어난 성능을 발휘합니다. 이 백서의 주요 성과는 다음과 같습니다:

피사체와 스타일을 모두 포착하는 사실적인 고해상도 인물 이미지를 생성하는 새로운 방법.
이미지 선명도를 개선하고 데이터 혼동을 방지하기 위한 주의력 리포커싱 손실과 같은 새로운 기술 도입.
MagiCapture는 다른 방법보다 성능이 우수하며 다른 유형의 이미지에도 적용할 수 있습니다.

### 2 Related Work

텍스트를 이미지로 변환하는 텍스트-이미지 확산 모델은 최근 상당히 발전하여 다양한 애플리케이션에서 널리 사용되고 있습니다. 이 분야의 대표적인 모델로는 '안정적 확산'과 '이미지'가 있습니다. 이 백서는 안정적 확산 모델을 기반으로 합니다.

이러한 이미지 생성 모델을 개인화하려는 움직임도 있습니다. 인공 신경망의 일종인 GAN의 등장으로 이러한 생성 모델을 미세 조정하는 몇 가지 기술이 개발되었습니다. 예를 들어 '드림부스', '텍스트 반전', '사용자 지정 확산' 등의 모델은 이미지 생성 프로세스의 특정 측면을 수정하도록 설계되었습니다. 그러나 때로는 현실적이지 않은 이미지를 생성하거나 의도한 정체성을 잃을 수 있습니다.

데이터 기반 접근 방식을 사용하는 "ELITE" 및 "InstantBooth"와 같은 다른 방법도 있지만, 이 백서에서 제안하는 방법과는 상당히 다릅니다.

### 3 Preliminaries

![MagiCapture의 전체 파이프라인, 훈련 과정은 세 가지 다른 작업: 원본, 참조, 및 구성된 프롬프트 학습의 다중 작업 학습으로 서술됩니다. 구성된 프롬프트 학습에서 참조 스타일 이미지는 가상의 레이블로 사용되며, 원본과 예측된 이미지 사이의 보조 신원 손실과 함께 사용됩니다. Attention Refocusing 손실은 모든 세 작업에 적용되지만 간결함을 위해 그림에는 표시되지 않습니다. 훈련 후 사용자는 통합된 개념으로 고화질 이미지를 생성할 수 있으며, 다양한 텍스트 조건을 사용하여 더욱 조작할 수 있습니다.](MagiCapture%20High-Resolution%20Multi-Concept%20Portrait%200fc0344786a947158e1c52fedfed8858/Untitled%201.png)

MagiCapture의 전체 파이프라인, 훈련 과정은 세 가지 다른 작업: 원본, 참조, 및 구성된 프롬프트 학습의 다중 작업 학습으로 서술됩니다. 구성된 프롬프트 학습에서 참조 스타일 이미지는 가상의 레이블로 사용되며, 원본과 예측된 이미지 사이의 보조 신원 손실과 함께 사용됩니다. Attention Refocusing 손실은 모든 세 작업에 적용되지만 간결함을 위해 그림에는 표시되지 않습니다. 훈련 후 사용자는 통합된 개념으로 고화질 이미지를 생성할 수 있으며, 다양한 텍스트 조건을 사용하여 더욱 조작할 수 있습니다.

확산 모델:

- 노이즈 제거 프로세스를 반복하여 이미지를 만드는 모델 유형입니다. 노이즈가 많은 사진에서 시작하여 점차 선명하게 만드는 것으로 생각하면 됩니다. 이 모델은 두 부분으로 구성됩니다:
    - 포워드 패스: 초기 이미지에 노이즈를 추가합니다.
    - 백워드 패스: 노이즈 제거 메커니즘을 사용하여 노이즈가 있는 이미지를 선명하게 만듭니다.
    잠복 확산 모델(LDM)이라는 특수한 종류는 잠복(숨겨진) 공간에서 노이즈 제거를 수행합니다. 즉, 이 모델은 이미지를 다른 형식(잠상 표현)으로 변환하여 노이즈를 제거한 다음 다시 이미지로 변환합니다.

안정적인 확산:

- 이는 LDM의 특정 버전으로, 텍스트를 사용하여 프로세스를 안내합니다. 대량의 페어링된 텍스트와 이미지로 학습됩니다.

텍스트-이미지 모델 사용자 지정:

- 이러한 모델을 개인화하려는 노력이 있습니다. 드림부스, 텍스트 반전, 사용자 지정 확산과 같은 기법은 사전 학습된 안정적인 확산 모델을 사용하고 몇 가지 특정 이미지를 사용하여 조정합니다. 이러한 기법은 고유 단어와 같은 특수 텍스트 토큰을 사용하여 모델에 특정 개념을 포함할 수 있습니다. 방법에 따라 모델의 여러 부분이 미세 조정됩니다.

주의 지도:

- 이는 일부 대규모 텍스트-이미지 모델에 사용되는 도구입니다. 텍스트가 이미지 생성에 어떤 영향을 미치는지 보여줍니다. 예를 들어, 스테이블 디퓨전에서는 CLIP이라는 텍스트 인코더를 사용하여 텍스트를 모델이 사용할 수 있는 기능으로 변환합니다. 관심도 맵은 특정 단어나 문구가 이미지에 미치는 영향을 시각적으로 표현할 수 있으며, 프롬프트 투 프롬프트와 같은 방법에서 볼 수 있듯이 이미지 생성에 영향을 미치도록 수정할 수도 있습니다.

### 4 Method

![Attention Refocusing (AR) 손실 적용 전후의 UNet 레이어에서 집계된 주의지도의 시각화는 정보 분리와 정보 유출 방지에 있어 그 중요성을 보여줍니다.](MagiCapture%20High-Resolution%20Multi-Concept%20Portrait%200fc0344786a947158e1c52fedfed8858/Untitled%202.png)

Attention Refocusing (AR) 손실 적용 전후의 UNet 레이어에서 집계된 주의지도의 시각화는 정보 분리와 정보 유출 방지에 있어 그 중요성을 보여줍니다.

이 논문에서는 주로 인물 생성을 중심으로 소스 이미지 세트의 콘텐츠를 참조 이미지 스타일과 통합하여 이미지를 생성하는 방법을 제시합니다. 프로세스는 다음과 같이 요약할 수 있습니다:

2단계 최적화:

- 특수 토큰에 대한 텍스트 임베딩을 최적화하는 것으로 시작합니다.
- 이어서 텍스트 임베딩과 모델 파라미터를 공동으로 최적화합니다. 전체 모델을 세분화하는 대신, 재구성과 일반화 사이의 균형을 유지하는 데 도움이 되는 LoRA라는 방법을 사용하여 특정 레이어만 미세 조정합니다.

마스크 재구성:

- 특히 인물 이미지를 생성할 때는 얽힘을 제거하는 것이 중요합니다. 배경과 같은 원치 않는 정보가 간섭하지 않도록 하기 위해 마스크 재구성 손실이 도입됩니다.
- 메인 이미지와 참조 스타일 이미지에 각각 얼굴과 비얼굴 영역에 초점을 맞추기 위해 별도의 마스크가 사용됩니다.

구성된 프롬프트 학습:

- 모델이 이전에 본 적이 없는 프롬프트를 사용할 때 발생하는 문제를 해결합니다.
- 실측 데이터가 없는 상황에서는 의사 레이블을 생성하고 보조 목적 함수를 사용하여 모델을 안내합니다.

주의 재집중:

- 특정 토큰이 의도치 않게 원치 않는 영역에 초점을 맞출 수 있다는 점을 인식한 저자는 주의 집중(AR) 손실을 도입했습니다.
- 이 AR 손실은 모델의 주의가 의도한 영역에만 집중되도록 하여 특히 추론 중에 정보가 유출되는 것을 방지하는 데 도움이 됩니다.

후처리:

- 생성된 이미지의 품질은 사전 학습된 모델과 소스 이미지의 해상도에 따라 제한될 수 있으므로 추가적인 후처리 단계가 포함됩니다.
- 여기에는 생성된 이미지의 품질을 향상시키기 위해 초고해상도 모델과 얼굴 복원 모델을 사용하는 것이 포함됩니다.

본질적으로 이 방법은 인물 생성을 중심으로 고충실도 맞춤형 이미지를 생성하기 위한 세부 프로세스를 제공하며, 원치 않는 정보 및 주의 유출과 관련된 문제를 해결할 수 있는 솔루션을 제공합니다.

### 5 Experiments

![MagiCapture의 선별된 결과](MagiCapture%20High-Resolution%20Multi-Concept%20Portrait%200fc0344786a947158e1c52fedfed8858/Untitled%203.png)

MagiCapture의 선별된 결과

![기타 기본 메소드와의 MagiCapture의 질적 비교.](MagiCapture%20High-Resolution%20Multi-Concept%20Portrait%200fc0344786a947158e1c52fedfed8858/Untitled%204.png)

기타 기본 메소드와의 MagiCapture의 질적 비교.

![사용자는 추가 설명을 포함한 프롬프트를 사용하여 구성된 결과를 더욱 조작할 수 있습니다.](MagiCapture%20High-Resolution%20Multi-Concept%20Portrait%200fc0344786a947158e1c52fedfed8858/Untitled%205.png)

사용자는 추가 설명을 포함한 프롬프트를 사용하여 구성된 결과를 더욱 조작할 수 있습니다.

![실패 사례: 제안된 방법은 때때로 비정상적인 신체 부위(예: 팔, 손가락)를 생성합니다.](MagiCapture%20High-Resolution%20Multi-Concept%20Portrait%200fc0344786a947158e1c52fedfed8858/Untitled%206.png)

실패 사례: 제안된 방법은 때때로 비정상적인 신체 부위(예: 팔, 손가락)를 생성합니다.

방법론:

- 이 연구에서는 인물 사진을 중심으로 소스 이미지의 콘텐츠와 참조 이미지의 스타일을 병합하는 기법을 제시합니다.
- 이 방법은 처음에는 텍스트 임베딩에 초점을 맞춘 다음 텍스트 임베딩과 모델 파라미터를 모두 최적화하는 2단계 최적화를 포함합니다.
- 이미지에서 얼굴 디테일과 비얼굴 요소를 분리하기 위해 '마스크 재구성'이라는 개념이 도입되었습니다.
- "구성된 프롬프트 학습"은 보이지 않는 프롬프트를 기반으로 이미지를 생성하는 전략입니다.
- 이 논문에서는 이미지 합성 중에 주의 지도를 지시하기 위해 "주의 재초점" 손실을 도입하여 보다 정확한 이미지 출력을 보장합니다.
- 초고해상도 및 얼굴 복원 모델을 포함한 후처리 단계는 최종 이미지 품질을 향상시키는 데 사용됩니다.

실험:

- 모델은 안정 확산 V1.5를 사용하여 훈련되며, 첫 번째 단계에서는 1200단계, 두 번째 단계에서는 1500단계를 거칩니다. GeForce RTX 3090 GPU에서 훈련되었습니다.
- 결과는 드림부스, 텍스트 반전, 커스텀 디퓨전과 같은 방법과 비교됩니다. 비교에는 10개의 서로 다른 아이덴티티와 10개의 스타일 컨셉이 포함되며, 각 방법에 대해 10,000개의 샘플이 생성됩니다.
- 이 연구는 소스 이미지와 생성된 이미지 간의 유사성, 스타일 보존 및 전반적인 이미지 품질을 평가합니다. 연구 결과에 따르면 제시된 방법은 모든 평가 지표에서 다른 기법을 능가하는 것으로 나타났습니다.
- 사용자 연구를 수행한 결과, 새로운 방법이 다른 방법보다 선호도가 높았습니다.
- 드림부스 방식은 참조 스타일에 과도하게 부합하는 것으로 나타났고, 텍스트 반전은 이미지 충실도가 낮은 것으로 나타났습니다. 커스텀 확산은 더 좋았지만 일관성이 없었습니다.
- 어블레이션 연구는 이미지 출력 개선을 위한 주의 집중 손실의 중요성을 확인했습니다.
- 이 방법의 유연성 덕분에 사용자는 프롬프트에 설명을 더 추가하여 결과를 더 조정할 수 있습니다.

본질적으로 이 논문은 특히 인물 사진 영역에서 한 이미지의 콘텐츠와 다른 이미지의 스타일을 매끄럽게 통합하는 고급 이미지 합성 방법을 제안합니다. 이 방법론은 비교에서 우수함을 입증하고 응용 분야에서 다재다능합니다.

### 6 Limitations and Conclusions

제한 사항:

- 이 방법은 때때로 팔다리와 손가락을 포함한 비정상적인 신체 특징을 생성합니다.
- 특히 인종과 성별과 관련하여 모델에 눈에 띄는 편향성이 있습니다. 예를 들어, 백인이 아닌 피사체에 대한 고품질 이미지를 생성하는 데 어려움이 있으며 웨딩 드레스와 같이 전통적으로 여성 복장을 한 남성의 이미지를 생성하는 데 어려움을 겪습니다.

결론:

- 이러한 편견과 문제는 주로 텍스트-이미지 합성에 사용되는 기본 모델에 기인합니다.
- 특히 소수의 샷 학습 시나리오에서 이러한 편견을 해결해야 할 필요성이 인식되고 있습니다.
- 저자들은 자신의 작업과 관련된 윤리적 측면을 충분히 인지하고 있으며 윤리적 고려에 대한 강한 의지를 표명합니다. 또한 향후 연구의 오용을 완화하기 위해 적극적으로 노력하고 있습니다.