# Coin3D: Controllable and Interactive 3D Assets Generation with Proxy-Guided Conditioning

[https://arxiv.org/abs/2405.08054](https://arxiv.org/abs/2405.08054)

- May 2024

## 1 INTRODUCTION

![Coin3D는 기본 형태로 조립된 거친 프록시를 사용하여 객체 생성을 3D 인식 제어로 추가할 수 있게 하며, 세밀한 부분 편집과 반응형 3D 미리보기를 지원하는 상호작용적 생성 워크플로우를 가능하게 합니다.](Coin3D%20Controllable%20and%20Interactive%203D%20Assets%20Gene%201add883234534854b591ee9fe3972632/Untitled.png)

Coin3D는 기본 형태로 조립된 거친 프록시를 사용하여 객체 생성을 3D 인식 제어로 추가할 수 있게 하며, 세밀한 부분 편집과 반응형 3D 미리보기를 지원하는 상호작용적 생성 워크플로우를 가능하게 합니다.

어린 시절, 우리는 상상력으로 무언가를 만들고자 하는 본능을 가지고 태어납니다. 예를 들어, 다양한 레고 블록으로 집이나 차량을 만들거나 연필로 그림을 그리는 등 창의적인 활동을 하곤 합니다. 그러나 이러한 창의적인 본능을 발전시켜 실제로 자격 있는 예술 작품을 만드는 데 필요한 그림이나 모델링 기술을 배우는 사람은 소수에 불과합니다.

다행히도, 생성 기술의 급속한 발전은 누구에게나 환상적인 콘텐츠를 창작할 기회를 제공합니다. 예를 들어, LLM(대형 언어 모델)을 사용한 자동 원고 작성이나 텍스트를 이미지나 비디오로 변환하는 2D 확산 방법이 있습니다. 생성 모델의 제어 가능성을 높이기 위해 최근 2D 확산 기술의 발전은 사용자가 깊이, 스케치 또는 인간의 자세를 통해 생성 과정을 제어할 수 있게 하며, 지정된 영역을 반복적으로 편집하고 다시 생성할 수 있는 메커니즘을 제공합니다.

그러나 3D 자산 생성 분야에서는 기존의 3D 생성 방법이 예술적 창작을 위한 제어 기능이 부족합니다. 첫째, 기존 방법들은 보통 텍스트 프롬프트나 시점 이미지를 조건으로 사용합니다. 이는 3D 객체를 정확하게 표현하기에는 충분하지 않습니다. 둘째, 생성적 편집이나 인페인팅과 같은 고차원 작업을 수행할 때, 기존 접근 방식은 편집 작업을 미리보기 전에 재구성을 위해 상당한 시간이 필요합니다.

이러한 문제를 해결하기 위해 우리는 다음과 같은 속성을 갖춘 제어 가능하고 사용자 친화적인 3D 자산 생성 프레임워크가 필요하다고 믿습니다. 첫째, 3D 인식 제어 가능성: 어린 아이가 레고 블록을 쌓고 생생한 모습을 상상하듯이, 기본 형태를 조립하여 3D 생성을 시작할 수 있습니다. 이는 일반 사용자에게 3D 모델링의 난이도를 낮추고 생성에 대한 충분한 제어를 제공합니다. 둘째, 유연성: 프레임워크는 사용자가 3D 인식 방식으로 로컬 영역을 상호작용적으로 조합하거나 조정할 수 있어야 합니다. 셋째, 반응성: 사용자가 편집을 임시로 완료하면 프레임워크는 긴 재구성 기간을 기다리지 않고 원하는 시점에서 생성된 객체의 미리보기 이미지를 즉시 제공해야 합니다.

이 논문에서는 Coin3D라는 새로운 제어 가능하고 상호작용적인 3D 자산 생성 프레임워크를 제안합니다. Coin3D는 텍스트 프롬프트나 이미지를 조건으로 사용하는 대신 기본 형태로 조립된 3D 프록시를 사용하여 객체 생성을 안내합니다. 이를 통해 사용자는 익숙한 모델링 소프트웨어를 사용하여 기본 형태를 조립하고 텍스트 프롬프트를 입력하여 원하는 객체를 묘사할 수 있습니다. 그런 다음 Coin3D는 몇 초 만에 실시간 특징 볼륨을 구성하여 임의의 시점에서 결과를 미리 보거나 객체의 지정된 로컬 부분을 점진적으로 조정하거나 재생성할 수 있습니다. 예를 들어, 기본 형태를 조립하고 튜브를 추가하거나 타이어를 교체하여 청동차를 생성할 수 있습니다.

그러나 3D 인식 조건을 추가하는 것이 기술적으로 가능하더라도 상호작용적인 3D 모델링 워크플로우에는 여전히 몇 가지 도전 과제가 있습니다. 이러한 과제들은 이 연구에서 다루어질 것입니다.

## 2 RELATED WORKS

![개요. 거친 형태 프록시와 객체의 정체성을 설명하는 사용자 프롬프트가 주어지면, 먼저 프록시의 실루엣과 3D 프록시 샘플로부터 2D 이미지 후보를 입력 조건으로 구성합니다. 그런 다음, 3D 어댑터를 사용하여 3D 제어 볼륨 𝐹 𝐶  과 함께 확산의 디노이징 과정에 3D 인식 제어를 통합하여 객체의 다중 시점 이미지를 생성합니다. 𝐹 𝐶  를 완전히 활용하여 체적 캐시를 통한 가속화된 3D 미리보기를 실현하고, 메쉬 재구성 품질을 향상시킵니다.](Coin3D%20Controllable%20and%20Interactive%203D%20Assets%20Gene%201add883234534854b591ee9fe3972632/Untitled%201.png)

개요. 거친 형태 프록시와 객체의 정체성을 설명하는 사용자 프롬프트가 주어지면, 먼저 프록시의 실루엣과 3D 프록시 샘플로부터 2D 이미지 후보를 입력 조건으로 구성합니다. 그런 다음, 3D 어댑터를 사용하여 3D 제어 볼륨 𝐹 𝐶  과 함께 확산의 디노이징 과정에 3D 인식 제어를 통합하여 객체의 다중 시점 이미지를 생성합니다. 𝐹 𝐶  를 완전히 활용하여 체적 캐시를 통한 가속화된 3D 미리보기를 실현하고, 메쉬 재구성 품질을 향상시킵니다.

### **2.1 3D Object Generation**

3D 객체 생성은 컴퓨터 비전과 그래픽스 분야에서 매우 활발하게 연구되고 있는 주제입니다. 초기 연구들은 주로 CAD 데이터베이스에서 특정 범주(예: 의자, 자동차 등)의 모델을 학습하여 3D 표현을 생성하는 데 초점을 맞췄습니다. 예를 들어, 폴리곤 메쉬, 포인트클라우드, 매개변수 모델, 보켈, 또는 암묵적 필드를 사용하는 모델들이 있습니다. 이러한 초기 모델들은 특정 카테고리에 국한되며, 네트워크 용량과 데이터 다양성의 한계로 인해 범용성이 부족했습니다.

최근 들어, 특히 2D 확산 모델의 큰 성공과 함께 대규모 생성 모델의 빠른 진화로 인해 3D 객체 생성에 새로운 접근 방식들이 등장하고 있습니다. DreamFusion과 SJC 같은 방법들은 2D 그라디언트 프라이어를 활용하여 사용자 텍스트 프롬프트를 기반으로 신경 재구성을 유도하는 방식입니다. 그러나 이러한 접근 방식들은 종종 불안정한 수렴 문제와 불완전한 결과를 초래할 수 있습니다. 예를 들어, 일관되지 않은 그라디언트 신호로 인해 "다중 얼굴 야누스 문제"와 같은 현상이 발생할 수 있습니다.

Zero123은 2D 잠재 확산 모델의 시점 편향 문제를 분석하고, Objaverse 데이터셋을 사용하여 상대적인 시점을 조건으로 하는 객체 특정 LDM을 훈련하는 방법을 제안했습니다. 이 방법은 이미지에서 3D로 변환하는 작업에서 유망한 결과를 보여주었고, 후속 연구들에서도 널리 채택되었습니다. 그러나 여전히 생성된 이미지들이 재구성 요구사항을 충족하지 못하는 교차 시점 일관성 문제를 겪고 있습니다. 이를 개선하기 위해 MVDream, SyncDreamer, Zero123++, Wonder3D와 같은 최근 연구들은 다중 시점 이미지 생성을 강화하여 보다 일관성 있는 3D 재구성을 가능하게 하고 있습니다.

### **2.2 Controllable and Interactive Generation**

정확한 제어를 생성 방법에 추가하는 것은 생산적인 콘텐츠 창작에 매우 중요합니다. 이전의 생성 연구들은 속성의 잠재 매핑을 학습하여 제어를 추가하려 했지만, 이는 특정 카테고리(예: 인간 얼굴, 자연 경관)에 한정되었습니다. 최근 2D 확산 모델의 발전으로 ControlNet과 T2I-Adapter와 같은 방법들이 다양한 2D 이미지 힌트(예: 깊이, 노멀, 소프트 에지, 인간의 자세, 색상 격자 등)를 통해 생성 과정을 상호작용적으로 제어할 수 있게 되었습니다. 그러나 3D 생성에서 비슷한 제어 능력은 아직 실용적이지 않습니다.

3D 생성 편집을 위한 최근 연구들은 텍스트 기반 3D 생성에서 원하는 영역을 제약하려고 시도했지만, 정확한 기하학적 형태를 제어할 수는 없었습니다. 가장 관련 있는 연구는 Latent-NeRF와 Fantasia3D입니다. Latent-NeRF는 스케치 형태의 안내 손실을 도입하여 3D 형태 주변의 밀도 필드를 제약하려 했으며, Fantasia3D는 DMTet을 사용하여 초기화된 3D 형태를 생성합니다. 그러나 이러한 방법들은 일반적으로 생성된 결과가 주어진 3D 형태에서 멀리 벗어나거나 "다중 얼굴 문제"를 겪을 수 있습니다. 또한, 이러한 방법들은 편집이나 제어 효과를 확인하기 위해 긴 재구성 시간이 필요하여 상호작용적인 모델링 요구를 충족하지 못합니다.

반면, 우리의 방법은 확산 과정에 3D 인식 제어를 직접 통합하여 생성된 3D 객체의 제어 가능성과 상호작용적인 미리보기를 몇 초 만에 제공할 수 있습니다. 이를 통해 사용자는 텍스트 프롬프트나 형태를 자유롭게 변경하거나 지정된 로컬 부분을 재생성할 수 있습니다.

## 3 METHOD

### **3.1 Proxy-Guided 3D Conditioning for Diffusion**

![프록시로 제한된 부분 편집. 사용자의 프록시 부분 주석에서 마스크를 사용하여 2D 이미지 조건과 3D 제어 볼륨을 업데이트합니다.](Coin3D%20Controllable%20and%20Interactive%203D%20Assets%20Gene%201add883234534854b591ee9fe3972632/Untitled%202.png)

프록시로 제한된 부분 편집. 사용자의 프록시 부분 주석에서 마스크를 사용하여 2D 이미지 조건과 3D 제어 볼륨을 업데이트합니다.

Coin3D는 기본 요소(예: 큐브, 원통, 원뿔, 구 등)로 조립된 3D 거친 형태 프록시와 사용자의 프롬프트를 사용하여 다중 시점 확산 프로세스를 조건으로 삼습니다. 구체적으로, 거친 형태 프록시 𝑃*P*와 프롬프트 𝑦*y*가 주어지면, 다중 시점 확산 기반 생성기 𝑓*f*는 카메라 포즈 𝑐𝑖*ci*에 따라 일관된 이미지를 예측합니다.

이 방법은 사용자가 복잡한 모델링 기술에 의존하지 않고 기본 형태를 조립하여 입력을 실현할 수 있게 합니다. 프록시 입력을 3D 생성 작업에 적응시키기 위해 두 가지 경로 조건 전처리 방법을 개발했습니다. 첫째, 프록시 메쉬에서 표면 점을 샘플링하여 3D 인식 제어를 위해 사용합니다. 둘째, 프록시의 렌더링된 실루엣과 사용자의 프롬프트를 조건으로 사용하여 상호작용적인 외관 선택을 위한 여러 2D 이미지 후보를 생성합니다.

3D 어댑터는 거친 프록시 샘플에서 다중 시점 확산 파이프라인으로 3D 인식 제어를 추가하여 주어진 프록시 형태를 따르는 객체의 다중 시점 이미지를 생성합니다. 이를 위해 우리는 3D 어댑터가 프록시 특징 볼륨 𝐹𝑉*FV*와 다중 시점 이미지 융합 볼륨 𝐹𝐼*FI*의 두 입력을 받도록 설계했습니다. 𝐹𝑉*FV*는 프록시 샘플을 복셀화하여 생성된 특징 그리드로, 다중 시점 이미지의 특징 볼륨 𝐹𝐼*FI*와 결합하여 최종 3D 제어 볼륨 𝐹𝐶*FC*를 생성합니다. 이 제어 볼륨은 2D 확산 모델의 다중 시점 디노이징 과정에서 각 시점에 맞춰 투영됩니다.

### **3.2 Interactive Generation Workflow**

3D 모델링 작업에서 예술가들은 목표 객체를 반복적으로 조정하고, 로컬 부분을 점진적으로 편집하여 만족스러운 결과를 얻고자 합니다. 그러나 3D 객체의 상호작용적 생성 및 미리보기는 세밀한 제어 능력과 느린 재구성 속도로 인해 여전히 어려운 문제로 남아 있습니다. 따라서 우리는 Coin3D 프레임워크를 기반으로 새로운 상호작용적이고 반응성이 뛰어난 생성 워크플로우를 개발했습니다.

프록시로 제한된 부분 편집 워크플로우를 설계하여 사용자가 기본 형태 조각을 지정하고 해당 내용을 재생성할 수 있게 했습니다. 예를 들어, 사용자가 접시에 있는 구형 물체를 빨간 사과로 재생성할 수 있습니다. 이를 위해 2D 및 3D 조건을 모두 고려한 두 경로 조건 편집 방식을 제안합니다. 2D 조건의 경우, 프록시의 마스크된 부분을 편집 시점에서 투영하고 마스크된 이미지-투-이미지 재생성을 수행하여 편집된 이미지를 디노이징 단계의 이미지 조건으로 사용합니다. 3D 조건의 경우, 마스크된 프록시를 약간 확장하여 3D 특징 마스크를 생성하고, 각 디노이징 단계에서 원본 3D 제어 볼륨을 다시 사용하여 마스크된 볼륨만 부분적으로 업데이트합니다.

### **3.3 Volume-Conditioned Reconstruction**

확산 모델의 결과는 객체의 다중 시점 이미지 세트이므로 이를 3D 표현으로 재구성해야 합니다. 그러나 단순히 다중 시점 이미지를 사용하여 재구성하는 것은 제한된 시점으로 인해 예기치 않은 기하학을 초래할 수 있습니다. 따라서 우리는 3D 제어 볼륨의 3D 인식 컨텍스트를 재구성 단계에 통합하여 재구성 품질을 향상시킵니다.

구체적으로, 우리는 체적 기반 점수 증류 샘플링(volume-SDS)이라는 새로운 방법을 제안하여, 3D 제어 볼륨에서 얻은 3D 제어 프라이어를 필드의 역전파에 통합합니다. 이를 통해 재구성된 객체가 더 나은 메쉬 품질을 갖도록 합니다.

이와 같은 방법으로 Coin3D는 텍스트 프롬프트와 형태 조정을 통해 객체를 자유롭게 생성하고 편집할 수 있는 혁신적인 3D 자산 생성 프레임워크를 제공합니다.

## 4 EXPERIMENTS

### **4.1 Comparison on Proxy-based and Image-based 3D Generation**

![생성된 다중 시점 이미지와 재구성된 텍스처 메쉬에 대해 이미지 기반 방법(Wonder3D [Long et al. 2023] 및 SyncDreamer [Liu et al. 2023a])과 우리의 프록시 기반 생성 방법을 비교합니다.](Coin3D%20Controllable%20and%20Interactive%203D%20Assets%20Gene%201add883234534854b591ee9fe3972632/Untitled%203.png)

생성된 다중 시점 이미지와 재구성된 텍스처 메쉬에 대해 이미지 기반 방법(Wonder3D [Long et al. 2023] 및 SyncDreamer [Liu et al. 2023a])과 우리의 프록시 기반 생성 방법을 비교합니다.

![Latent-NeRF [Metzer et al. 2023] 및 Fantasia3D [Chen et al. 2023a]와 제어 가능한 3D 생성을 비교합니다.](Coin3D%20Controllable%20and%20Interactive%203D%20Assets%20Gene%201add883234534854b591ee9fe3972632/Untitled%204.png)

Latent-NeRF [Metzer et al. 2023] 및 Fantasia3D [Chen et al. 2023a]와 제어 가능한 3D 생성을 비교합니다.

![여러 기본 형태 프록시에 대해 부분 편집을 통한 상호작용적 생성을 수행합니다.](Coin3D%20Controllable%20and%20Interactive%203D%20Assets%20Gene%201add883234534854b591ee9fe3972632/Untitled%205.png)

여러 기본 형태 프록시에 대해 부분 편집을 통한 상호작용적 생성을 수행합니다.

![체적 조건 재구성의 효능을 검사합니다.](Coin3D%20Controllable%20and%20Interactive%203D%20Assets%20Gene%201add883234534854b591ee9fe3972632/Untitled%206.png)

체적 조건 재구성의 효능을 검사합니다.

현재까지 가장 안정적인 3D 객체 생성 파이프라인은 주로 이미지 기반으로, 단일 이미지를 조건으로 입력받아 다중 시점 이미지를 생성한 후 재구성하거나 직접 3D 표현을 생성합니다. 우리의 방법은 거친 형태의 프록시를 조건으로 사용하는 방식으로 이러한 방법들과 비교했습니다.

- **질적 비교:** 다양한 시점의 이미지와 재구성된 텍스처 메쉬를 비교했습니다. Wonder3D와 SyncDreamer는 예측된 시점 이미지와 텍스처 메쉬에서 왜곡된 부분이나 누락된 세부 사항을 보여주었습니다. 반면, 우리의 방법은 프록시로 안내되는 조건과 체적 기반 재구성을 통해 일관된 형상을 유지하며 생생한 외관을 갖춘 3D 객체를 생성했습니다.
- **정량적 비교:** 텍스트-객체 매칭 정도를 평가하는 CLIP 점수, 예측된 다중 시점 이미지의 지각 품질을 평가하는 ImageReward 및 GPTEvals3D를 사용하여 비교했습니다. 우리의 방법은 전반적으로 가장 높은 점수를 기록했습니다.
- **사용자 연구:** 30명의 사용자가 35개의 테스트 예제를 임의의 순서로 정렬하여 지각 품질과 콘텐츠 매칭 정도를 평가하도록 했습니다. 우리의 방법이 가장 높은 점수를 기록했습니다.

### **4.2 Comparison on Controllable 3D Object Generation**

Latent-NeRF와 Fantasia3D와 같은 제어 가능한 3D 객체 생성 방법과 비교했습니다. Latent-NeRF는 스케치 형태의 안내 손실을 도입했으며, Fantasia3D는 거친 형태를 DMTet의 초기화로 사용합니다.

- **질적 비교:** Latent-NeRF는 대체로 그럴듯한 결과를 얻었지만 세부 형상과 외관을 재현하지 못했습니다. Fantasia3D는 초기화된 형태를 벗어난 과도한 결과를 생성하는 경향이 있었습니다. 반면, 우리의 방법은 3D 인식 제어를 통해 일관된 고품질 생성을 달성했습니다.
- **재구성 시간:** Latent-NeRF와 Fantasia3D는 편집 결과를 확인하는 데 긴 시간이 걸리는 반면, 우리의 방법은 몇 초 만에 3D 객체를 미리보기할 수 있습니다.

### **4.3 Interactive Generation with Part Editing**

부분 편집을 통해 상호작용적으로 3D 객체를 생성하는 예시를 제시했습니다. 사용자는 먼저 기본 인스턴스를 생성한 후, 텍스트 프롬프트를 변경하여 새로운 형태 블록을 점진적으로 추가할 수 있습니다. 이러한 모든 편집 작업은 약 5~10초 내에 완료되며, 상호작용적인 3D 미리보기를 제공합니다.

### **4.4 Ablation Studies**

Coin3D의 다양한 구성 요소의 효과를 분석하기 위해 다음과 같은 연구를 수행했습니다.

- **체적 조건 재구성:** 볼륨-SDS 손실을 사용하여 형태 재구성 시의 효율성을 평가했습니다. 볼륨-SDS 손실을 추가함으로써 형상 재구성 품질이 향상되었습니다.
- **프록시로 제한된 부분 편집:** 프록시 조건과 마스크 확장 전략을 분석했습니다. 프록시 조건 없이 편집한 경우 불완전한 형상이 생성되었으며, 마스크 확장 없이 편집한 경우 자연스럽지 않은 결과가 나타났습니다. 모든 전략을 완전하게 사용한 경우, 원래 객체의 다른 부분을 변경하지 않고도 자연스러운 편집 효과를 얻을 수 있었습니다.

이 실험들은 Coin3D의 제어 가능성, 상호작용성, 그리고 고품질 3D 생성 능력을 입증했습니다. Coin3D는 사용자가 텍스트 프롬프트와 형태 조정을 통해 자유롭게 3D 객체를 생성하고 편집할 수 있는 혁신적인 프레임워크를 제공합니다.

![프록시로 제한된 부분 편집에서 프록시 가이드와 3D 마스크 확장의 중요성을 분석합니다.](Coin3D%20Controllable%20and%20Interactive%203D%20Assets%20Gene%201add883234534854b591ee9fe3972632/Untitled%207.png)

프록시로 제한된 부분 편집에서 프록시 가이드와 3D 마스크 확장의 중요성을 분석합니다.

## 5 CONCLUSIONS

이 논문에서는 Coin3D라는 새로운 제어 가능하고 상호작용적인 3D 자산 생성 프레임워크를 제안했습니다. Coin3D는 거친 형태의 3D 프록시를 사용하여 다중 시점 확산 프로세스에 3D 인식 제어를 추가함으로써, 사용자가 텍스트 프롬프트와 형태 조정을 통해 3D 객체를 자유롭게 생성하고 편집할 수 있게 합니다.

Coin3D는 여러 기술들을 도입하여 상호작용적이고 일관된 생성 경험을 제공합니다. 여기에는 프록시로 제한된 정밀한 편집, 임의의 시점에서의 반응형 미리보기를 지원하는 점진적 체적 캐싱, 그리고 재구성 품질을 향상시키는 체적 조건 재구성 방법이 포함됩니다.

실험 결과, Coin3D는 기존의 이미지 기반 및 제어 가능한 3D 생성 방법들과 비교하여 우수한 성능을 보였으며, 다양한 3D 생성 작업에서 높은 품질의 결과를 생성하는 능력을 입증했습니다.

앞으로는 2D 확산 모델의 객체 중심 데이터로의 훈련, LLM 기반 프롬프트 향상, 더 나은 백본 모델 채택, 고해상도 최적화, PBR 재질 생성 모델 훈련 등의 방법을 통해 Coin3D의 성능을 더욱 향상시킬 수 있을 것입니다.