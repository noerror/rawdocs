# An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale

*이 연구에서는 전통적으로 자연어 처리에 사용되던 Transformer 모델을 이미지 인식 작업에 사용하는 방법을 살펴봅니다. 이미지를 패치로 분할한 다음 Transformer 인코더로 처리합니다. 이 방법을 통해 개발된 비전 트랜스포머(ViT)는 이미지 분류에서 기존 기술과 일치하거나 이를 능가하며 상대적으로 비용 효율적입니다. 연구팀은 ViT를 다른 컴퓨터 비전 작업에 적용하고 자체 감독 사전 학습 방법을 개선하는 데 어려움이 있음을 인정하며, ViT를 더 확장하면 성능을 향상시킬 수 있다고 제안합니다.*

[https://paperswithcode.com/paper/an-image-is-worth-16x16-words-transformers-1](https://paperswithcode.com/paper/an-image-is-worth-16x16-words-transformers-1)

[https://arxiv.org/abs/2010.11929](https://arxiv.org/abs/2010.11929)

- Oct 2020

원래 자연어 처리 작업을 위해 설계된 트랜스포머 아키텍처는 컴퓨터 비전 애플리케이션에서도 유망한 결과를 보여주었습니다. 전통적으로 비전 작업에서는 주의 메커니즘을 컨볼루션 네트워크와 결합하거나 부분적으로 대체하는 데 사용하는 경우가 많았습니다. 그러나 최근의 연구 결과에 따르면 트랜스포머 모델, 특히 비전 트랜스포머(ViT)에만 의존하는 것이 매우 효과적인 결과를 가져올 수 있습니다.

ViT 접근 방식은 전체 이미지를 처리하는 대신 이미지를 일련의 패치로 분할하여 트랜스포머 모델에 직접 공급하는 방식입니다. 이 방법은 대규모 데이터 세트에 대해 사전 학습한 다음 다양한 이미지 인식 벤치마크(예: ImageNet, CIFAR-100, VTAB 등)로 전송할 때 기존의 컨볼루션 네트워크에 비해 우수한 결과를 얻을 수 있습니다. ViT의 가장 큰 장점은 훈련에 훨씬 적은 컴퓨팅 리소스가 필요하기 때문에 효율성이 높다는 점입니다.

### 1 INTRODUCTION

자기 주의 기반 아키텍처의 일종인 트랜스포머는 자연어 처리(NLP)를 위한 주요 선택이 되었습니다. 이러한 모델은 일반적으로 대규모 텍스트 데이터에 대해 사전 학습된 다음 소규모의 작업별 데이터 세트에 대해 미세 조정됩니다. 트랜스포머의 확장성과 계산 효율성 덕분에 이제 1,000억 개 이상의 파라미터로 모델을 훈련할 수 있게 되었으며, 그 성능은 규모가 커짐에 따라 계속 향상되고 있습니다.

그러나 컴퓨터 비전 분야에서는 컨볼루션 아키텍처가 여전히 선도적인 접근 방식입니다. 일부 연구자들은 컨볼루션 네트워크(CNN)를 자기 주의 메커니즘과 병합하거나 심지어 완전히 대체하려고 시도했지만, 이러한 모델은 특히 규모를 확장했을 때 기대만큼 효과적이지 않았습니다.

NLP에서 트랜스포머의 성공에 영감을 받은 저자들은 표준 트랜스포머를 이미지에 직접 적용하는 실험을 했습니다. 이미지를 패치로 분할하고 이러한 패치 시퀀스(NLP에서 단어와 유사하게 취급됨)를 Transformer에 공급했습니다. 비전 트랜스포머(ViT)로 명명된 이 새로운 모델은 중간 크기의 데이터 세트에 대해 훈련할 때 적당한 성능을 발휘합니다. 이는 기존의 컨볼루션 네트워크인 ResNet의 성능에 미치지 못하는데, 그 이유는 트랜스포머에 CNN에 내재된 특정 유도 편향이 없기 때문입니다.

그러나 대규모 데이터 세트에 대해 학습하면 ViT의 성능이 크게 향상됩니다. 이 모델은 충분히 큰 데이터 세트에 대해 사전 학습한 다음 데이터 포인트가 적은 작업에 대해 미세 조정할 때 우수한 결과를 얻을 수 있습니다. 예를 들어, ImageNet-21k 또는 JFT-300M 데이터 세트에 대해 사전 학습된 ViT는 여러 이미지 인식 벤치마크에서 최첨단 모델에 근접하거나 그 성능을 능가하며 ImageNet, ImageNet-ReaL, CIFAR-100 및 VTAB 작업 제품군에서 인상적인 정확도를 달성합니다.

### 2 RELATED WORK

원래 기계 번역을 위해 제안된 트랜스포머는 많은 자연어 처리(NLP) 작업에서 선도적인 방법이 되었습니다. BERT 및 GPT와 같은 대규모 트랜스포머 모델은 일반적으로 방대한 텍스트 말뭉치에 대해 사전 학습한 다음 특정 작업에 맞게 미세 조정됩니다.

그러나 같은 방식으로 이미지에 자가 주의를 적용하는 것은 계산 비용이 높기 때문에 실현 가능하지 않습니다. 따라서 이미지 처리를 위해 트랜스포머를 구현하는 데 몇 가지 근사치가 사용되었습니다. 일부 방법은 전체 이미지가 아닌 주변 지역이나 다양한 크기의 블록에 자체 주의를 적용합니다. 다른 방법들은 컨볼루션 신경망(CNN)과 자기 주의 기능을 결합합니다. 하지만 이러한 특화된 주의 아키텍처는 하드웨어에서 효율적으로 구현하기 위해 복잡한 엔지니어링이 필요한 경우가 많습니다.

비전 트랜스포머(ViT)와 가장 밀접한 관련이 있는 모델은 Cordonnier 등이 제안한 것으로, 이미지에서 2x2 픽셀 패치를 추출하고 완전한 자기 주의를 적용했습니다. ViT 모델은 유사한 접근 방식을 따르지만 대규모 사전 학습을 통해 이를 확장하여 최첨단 CNN과 경쟁하거나 그보다 우수합니다. 또한 ViT는 Cordonnier 등이 제안한 모델과 달리 중간 해상도 이미지를 처리하도록 설계되었습니다.

또 다른 관련 모델인 이미지 GPT(iGPT)는 이미지 해상도와 색 공간을 줄인 후 이미지 픽셀에 트랜스포머를 적용합니다. 이 모델은 생성 모델로 학습되며 ImageNet에서 72%의 정확도를 달성합니다.

이 연구는 표준 ImageNet 데이터 세트보다 더 큰 규모의 이미지 인식을 탐색하는 연구들이 늘어나고 있는 추세에 더해졌습니다. 추가 데이터 소스를 활용하면 표준 벤치마크에서 최고 수준의 결과를 얻을 수 있습니다. 이 사례의 경우 연구원들은 ImageNet-21k 및 JFT-300M과 같은 대규모 데이터 세트에 초점을 맞추었지만, 기존에 사용되던 ResNet 기반 모델 대신 Transformers를 사용했습니다.

### 3 METHOD

비전 트랜스포머(ViT) 모델은 자연어 처리 작업을 위해 설계된 오리지널 트랜스포머 모델을 기반으로 합니다. 설계가 단순하기 때문에 최소한의 조정만으로 이미지 처리 작업에 효율적으로 적용할 수 있습니다.

![모델 개요. 이미지를 고정된 크기의 패치로 분할하고 각 패치를 선형적으로 임베딩합니다, 위치 임베딩을 추가하고, 결과 벡터 시퀀스를 표준 Transformer 인코더에 공급합니다. 분류를 수행하기 위해 표준 접근 방식을 사용하여 학습 가능한 "분류 토큰"을 추가하는 표준 접근 방식을 사용합니다. 트랜스포머 인코더의 그림은 다음에서 영감을 얻었습니다.](An%20Image%20is%20Worth%2016x16%20Words%20Transformers%20for%20Ima%20e4860115e5b847649d6c287830b7336f/Untitled.png)

모델 개요. 이미지를 고정된 크기의 패치로 분할하고 각 패치를 선형적으로 임베딩합니다, 위치 임베딩을 추가하고, 결과 벡터 시퀀스를 표준 Transformer 인코더에 공급합니다. 분류를 수행하기 위해 표준 접근 방식을 사용하여 학습 가능한 "분류 토큰"을 추가하는 표준 접근 방식을 사용합니다. 트랜스포머 인코더의 그림은 다음에서 영감을 얻었습니다.

ViT에서는 이미지를 일련의 2D 패치로 분할한 다음 선형 투영을 통해 일련의 패치 임베딩으로 평평하게 변환합니다. 이 시퀀스의 시작 부분에 BERT의 '[class]' 토큰과 유사한 학습 가능한 임베딩이 추가됩니다. 이렇게 추가된 임베딩의 최종 상태는 트랜스포머 인코더에 의해 처리된 후 이미지 표현으로 사용됩니다.

위치 정보를 유지하기 위해 위치 임베딩이 추가되며, 임베딩 시퀀스는 Transformer 인코더에 대한 입력으로 사용됩니다. 인코더는 멀티헤드 셀프 어텐션(MSA) 및 다층 퍼셉트론(MLP) 블록 레이어로 구성되며, 각 블록 앞에 레이어 정규화가 적용되고 각 블록 뒤에 잔류 연결이 적용됩니다.

ViT 모델은 컨볼루션 신경망(CNN)에 비해 이미지별 유도 편향이 적습니다. CNN은 본질적으로 로컬리티, 2D 이웃 구조, 번역 등가성을 이해하지만, ViT는 이러한 개념을 거의 사용하지 않습니다. ViT는 처음에 이미지를 패치로 자르고 해상도에 따라 위치 임베딩을 조정하지만 모든 공간 관계는 처음부터 학습해야 합니다.

입력 시퀀스가 CNN의 특징 맵에서 형성되는 '하이브리드 아키텍처'를 사용할 수도 있습니다. 이 설정에서는 패치 임베딩 투영이 CNN 특징 맵에서 추출한 패치에 적용됩니다.

일반적으로 ViT 모델은 대규모 데이터 세트에 대해 사전 학습된 다음 제로 초기화 피드포워드 레이어를 첨부하여 특정 작업에 맞게 미세 조정됩니다. 이 모델은 패치 크기를 일관되게 유지하면서 원본 이미지의 위치와 일치하도록 위치 임베딩을 조정하여 다양한 해상도의 이미지를 수용할 수 있습니다. 이 조정은 ViT에서 이미지의 2D 구조를 수동으로 변경하는 유일한 작업입니다.

### 4 EXPERIMENTS

이 연구에서는 이미지에서 표현을 학습할 때 ResNet, 비전 트랜스포머(ViT), 하이브리드 모델 등 세 가지 모델의 성능을 평가합니다. 다양한 크기의 데이터 세트에 대한 사전 학습 후 다양한 벤치마크에서 성능을 평가합니다.

주요 결과:

계산 비용을 고려할 때 ViT는 매우 우수한 성능을 발휘하며, 대부분의 벤치마크에서 낮은 사전 학습 비용으로 최첨단 결과를 달성합니다.

ViT와 함께 자가 지도 학습을 사용한 소규모 실험은 미래에 대한 가능성을 보여주었습니다.

ViT 구성의 경우, BERT 모델이 기본으로 사용됩니다. 입력 패치 크기가 더 큰 ViT는 계산적으로 더 저렴하다는 것이 입증되었습니다.

이 연구에서는 전송을 개선하는 것으로 밝혀진 "ResNet(BiT)"이라고 하는 수정된 버전의 ResNet을 기본으로 사용합니다.

대규모 데이터 세트에서 훈련된 ViT 모델은 ResNet 모델보다 성능이 뛰어납니다. 그러나 소규모 데이터 세트에 대해 학습된 ViT 모델은 성능이 떨어지며, 이는 ResNet의 컨볼루션 유도 편향이 소규모 데이터 세트에 더 유용하다는 개념을 강화합니다.

매우 적은 데이터 전송의 경우, 이 결과는 유망한 것으로 보이며, ViT의 소수 샷 속성에 대한 추가 탐색은 향후 흥미로운 방향으로 간주됩니다.

통제된 연구에서 비전 트랜스포머는 동일한 성능을 달성하기 위해 훨씬 적은 계산을 사용하여 성능/컴퓨팅 트레이드오프 측면에서 ResNet보다 우수한 성능을 보였습니다.

또한 ViT 모델은 테스트 범위 내에서 포화 상태가 되지 않는 것으로 나타나 향후 확장 가능성을 보여주었습니다.

ViT의 내부 작동을 분석한 결과, 이 모델은 2D 이미지 토폴로지를 표현하는 방법을 학습하고 분류를 위해 이미지의 의미적으로 관련된 영역에 주목하는 것으로 나타났습니다.

ViT를 사용한 자체 감독에 대한 예비 탐색은 유망한 결과를 보여줍니다.

![출력 토큰에서 입력 토큰으로 출력 토큰에서 입력 공간입니다.](An%20Image%20is%20Worth%2016x16%20Words%20Transformers%20for%20Ima%20e4860115e5b847649d6c287830b7336f/Untitled%201.png)

출력 토큰에서 입력 토큰으로 출력 토큰에서 입력 공간입니다.

### 5 CONCLUSION

이 연구에서는 이미지 인식 작업에 자연어 처리(NLP)에 일반적으로 사용되는 아키텍처인 트랜스포머를 사용하는 방법에 대해 설명합니다. 여기서 이미지는 일련의 패치로 분할된 후 표준 Transformer 인코더에 의해 처리됩니다.

이미지별 가정을 모델에 통합했던 이전 접근 방식과 달리, 여기서 이미지별 단계는 초기 패치 추출뿐입니다. 놀랍게도 이 간단한 접근 방식은 특히 대규모 데이터 세트에 대해 사전 학습된 경우 우수한 성능을 발휘합니다. 그 결과 기존의 최첨단 이미지 분류 방법과 경쟁하거나 그 성능을 능가하는 비전 트랜스포머(ViT)가 탄생했으며, 사전 학습에 상대적으로 비용 효율적입니다.

하지만 여전히 극복해야 할 과제가 남아 있습니다. 예를 들어, 탐지 및 분할과 같은 다른 컴퓨터 비전 작업에 ViT를 적용하려면 더 많은 연구가 필요합니다. 또한 예비 테스트에 따르면 자체 감독 사전 훈련에서 개선된 결과가 나타났지만, 대규모 감독 사전 훈련과 비교하면 여전히 상당한 성능 격차가 있습니다. 이 연구는 ViT를 더욱 확장하면 잠재적으로 성능을 개선할 수 있음을 시사합니다.

### Appendix

멀티헤드 셀프 어텐션: 이 부분에서는 '헤드'가 병렬로 작동하고 그 출력이 연결 및 투사되는 트랜스포머 아키텍처에서 멀티헤드 셀프 어텐션이 어떻게 사용되는지 설명합니다.

훈련: 저자들은 ImageNet에서 모델을 처음부터 훈련할 때 강력한 정규화가 필수적이라는 사실을 발견했습니다. 또한 쿼리 키 값 투영을 제외한 모든 고밀도 레이어 뒤에 드롭아웃이 적용된다고 언급했습니다. 이들은 해상도 224가 훈련에 최적이라는 사실을 발견했습니다.

미세 조정: ViT 모델은 0.9의 모멘텀을 가진 SGD를 사용하여 미세 조정되었습니다. 또한 저자들은 학습 속도에 대해 작은 그리드 검색을 실행하고 원본 데이터 세트의 더 작은 하위 집합에 대해 학습했습니다.

자체 감독: 저자는 예비 자체 감독 실험을 위해 마스크 패치 예측을 사용했습니다. 패치 임베딩의 50%를 손상시키고 각각의 패치 표현을 사용하여 손상된 모든 패치의 평균 색상을 예측했습니다.

추가 결과: 저자들은 다양한 크기의 데이터 세트에 대해 사전 학습된 다양한 ViT 모델의 전송 성능을 보고하고 ViT, ResNet, 하이브리드 모델의 성능을 비교했습니다.

추가 분석: SGD와 Adam 옵티마이저 간의 비교, 트랜스포머 스케일링에 대한 조사, 다양한 위치 임베딩 방법의 탐색, 경험적 계산 비용 평가 등 여러 가지 분석이 있습니다.

축 주의는 다차원 텐서에서 큰 입력을 처리하는 데 사용되는 기법입니다. 입력의 평면화된 버전에 1차원 주의력을 적용하는 대신 텐서의 단일 축에서 각각 여러 주의력 연산이 수행됩니다.

ResNet50 모델의 기존 컨볼루션이 상대 위치 인코딩으로 강화된 축 자체 주의, 즉 행 및 열 주의로 대체된 AxialResNet 모델이 제안되었습니다.

또한 비전 트랜스포머(ViT)는 2차원 형태의 입력을 처리하도록 조정되었습니다. 이 경우, 자기 주의와 다층 퍼셉트론(MLP)이 있는 기존의 트랜스포머 블록은 두 개의 축 방향 트랜스포머 블록, 즉 행-자기 주의와 MLP, 그리고 열-자기 주의와 MLP로 대체되었습니다.

Axial-ViT 모델은 ViT 모델보다 성능이 더 좋았지만 더 많은 계산 리소스가 필요했습니다. AxialResNet은 정확도와 계산의 적절한 균형에도 불구하고 TPU에서 구현 속도가 상당히 느렸습니다.

"ViT가 이미지에서 자기 주의를 어떻게 사용하는지 이해하기 위해 '주의 거리'를 분석했습니다. 이 개념은 CNN의 수용 필드 크기와 유사하며, 네트워크 깊이가 증가함에 따라 주의 거리가 증가하는 경향이 있음을 시사합니다.

출력 토큰에서 입력 공간으로의 주의도 맵을 계산하기 위해 "주의도 롤아웃"이 사용되었습니다. 여기에는 모든 레이어에 걸쳐 관심도 가중치를 평균화하여 토큰 간의 관심도 혼합을 고려하는 것이 포함됩니다.

또한, 이 논문에서는 상위 5위 정확도 82.1%, 상위 1위 정확도 61.7%를 달성한 주력 모델인 ViT-H/14의 ObjectNet 벤치마크 결과를 공유했습니다. 각 VTAB-1k 작업에 대한 자세한 점수도 제공되었습니다.

- 요약
    
    이미지 인식을 위한 트랜스포머: 이 논문은 전통적으로 자연어 처리(NLP)에 사용되던 트랜스포머 아키텍처를 이미지 인식 작업에 적용하자는 제안으로 시작합니다. 트랜스포머는 주의 메커니즘을 통해 모델이 입력 데이터의 다른 부분에 집중할 수 있게 해주며, 이는 텍스트와 같은 순차적 데이터에 특히 유용합니다.
    
    패치 시퀀스로서의 이미지: 이미지 인식에 트랜스포머를 사용하기 위해 저자는 이미지를 패치 시퀀스로 해석하여 이러한 패치를 문장의 단어처럼 취급합니다. 이렇게 하면 Transformer는 NLP 작업에서 단어의 문맥을 이해하는 방식과 유사하게 패치의 '컨텍스트'(주변 패치와의 관계)를 이해할 수 있습니다.
    
    이미지별 귀납적 편향 최소화: 저자는 아키텍처에 이미지별 귀납적 편향(가정)을 도입하는 대신 이미지별 단계로 패치 추출만 사용합니다. 다른 이미지별 가정이 없다는 것은 이 모델이 잠재적으로 다양한 이미지 유형과 작업에 적용될 수 있다는 것을 의미합니다.
    
    대규모 데이터 세트에 대한 사전 학습: 저자들은 대규모 데이터 세트에 대해 비전 트랜스포머(ViT)를 사전 훈련하면 성능이 크게 향상된다는 사실을 발견했습니다. 이는 다른 트랜스포머 모델과 자연어 처리 분야에서 사전 학습의 성공과 일치합니다.
    
    경쟁력 있는 성능: 제안된 ViT 모델은 이미지 분류 작업에서 기존의 최첨단 모델과 비슷하거나 심지어 능가합니다. 또한 사전 학습 비용이 상대적으로 저렴하여 이미지 인식 작업에 유망한 솔루션이 될 수 있습니다.
    
    향후 과제: 이 논문은 향후 작업의 잠재적 영역을 개괄적으로 설명하며 마무리합니다. 여기에는 탐지 및 분할과 같은 다른 컴퓨터 비전 작업에 ViT를 적용하고, 자체 감독 사전 학습 방법을 추가로 탐색하고, ViT 모델을 확장함으로써 얻을 수 있는 잠재적인 성능 향상을 조사하는 것이 포함됩니다.