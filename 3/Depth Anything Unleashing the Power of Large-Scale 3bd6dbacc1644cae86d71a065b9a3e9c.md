# Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data

[https://arxiv.org/abs/2401.10891](https://arxiv.org/abs/2401.10891)

- Jan 2024

![이 모델은 보이지 않는 광범위한 장면에서 인상적인 일반화 능력을 보여줍니다. 왼쪽 두 열: COCO [35]. 가운데 두 개: SA-1B [27](보이지 않는 세트). 오른쪽 두 개: 직접 촬영한 사진. 이 모델은 저조도 환경(1열과 3열), 복잡한 장면(2열과 5열), 안개가 낀 날씨(5열), 초원거리(5열과 6열) 등에서도 안정적으로 작동합니다.](Depth%20Anything%20Unleashing%20the%20Power%20of%20Large-Scale%203bd6dbacc1644cae86d71a065b9a3e9c/Untitled.png)

이 모델은 보이지 않는 광범위한 장면에서 인상적인 일반화 능력을 보여줍니다. 왼쪽 두 열: COCO [35]. 가운데 두 개: SA-1B [27](보이지 않는 세트). 오른쪽 두 개: 직접 촬영한 사진. 이 모델은 저조도 환경(1열과 3열), 복잡한 장면(2열과 5열), 안개가 낀 날씨(5열), 초원거리(5열과 6열) 등에서도 안정적으로 작동합니다.

### 1 Introduction

최근 컴퓨터 비전과 자연어 처리 분야는 "기반 모델"의 등장으로 큰 변화를 겪고 있습니다. 이러한 모델들은 다양한 하류 시나리오에서 강력한 제로샷 또는 소수샷 성능을 보여주며, 이는 대규모 훈련 데이터에 기반한 것입니다. 특히, 단일 카메라 심도 추정(Monocular Depth Estimation, MDE)은 로보틱스, 자율 주행, 가상 현실 등 다양한 분야에서 중요한 역할을 하고 있으며, 이를 위해서는 단일 이미지로부터 심도 정보를 추정할 수 있는 기반 모델이 필요합니다. 그러나 수천만 개의 심도 레이블을 갖춘 데이터 세트를 구축하는 것은 매우 어려운 일이기 때문에, MDE를 위한 기반 모델 구축은 상대적으로 소홀히 다뤄져 왔습니다. 이 연구에서는 데이터 세트 확장을 통해 MDE를 위한 강력한 기반 모델을 구축하는 것을 목표로 하고 있습니다. 이를 위해, 우리는 대규모의 레이블이 없는 데이터를 수집하고 자동으로 주석을 달아 데이터 세트를 확장하는 새로운 접근 방식을 제안합니다. 이러한 방식은 MDE 분야에서 새로운 가능성을 열어줄 것으로 기대됩니다.

### 2. Related Work

초기 MDE 연구:

초기 단일 카메라 심도 추정 연구는 수작업으로 만들어진 특징과 전통적인 컴퓨터 비전 기술에 의존했습니다. 이러한 방법들은 명시적인 심도 단서에 기반하고 있었으며, 가려짐이나 질감이 없는 영역과 같은 복잡한 장면을 처리하는 데 한계가 있었습니다.

딥러닝 기반 MDE:

딥러닝 기반 방법은 정교하게 주석이 달린 데이터 세트에서 심도 표현을 효과적으로 학습함으로써 MDE를 혁신적으로 발전시켰습니다. Eigen 등은 다중 스케일 융합 네트워크를 제안하여 심도를 회귀하는 최초의 방법 중 하나였습니다. 이후 많은 연구들이 심도 추정 정확도를 향상시키기 위해 회귀 작업을 분류 작업으로 재설계하고, 더 많은 사전 지식을 도입하며, 더 나은 목적 함수를 사용하는 등의 방법을 지속적으로 개선해 왔습니다. 그러나 이러한 방법들은 보이지 않는 영역으로 일반화하는 데 어려움이 있습니다.

제로샷 심도 추정:

제로샷 심도 추정 연구는 다양한 훈련 세트를 사용하여 주어진 이미지의 심도를 예측하는 것을 목표로 합니다. 초기 연구들은 더 많은 훈련 이미지를 수집하여 이 방향으로 탐구했지만, 이들의 감독은 매우 희소하며 제한된 점 쌍에만 적용되었습니다. MiDaS는 다양한 데이터 세트를 효과적으로 결합하기 위해 아핀 불변 손실을 사용하여 상대적 심도 정보를 제공하는 중요한 연구였습니다. 최근에는 메트릭 심도를 추정하는 방법들이 등장했으나, MiDaS의 최신 버전에 비해 일반화 능력이 떨어지는 경향이 있습니다.

레이블이 없는 데이터 활용:

레이블이 없는 데이터를 활용하는 연구는 반지도 학습 분야에 속합니다. 이 분야는 제한된 이미지만 사용할 수 있다고 가정하는 기존 연구와는 달리, 충분한 레이블이 있는 이미지와 더 큰 규모의 레이블이 없는 이미지가 모두 존재하는 현실적이지만 도전적인 시나리오를 고려합니다. 이 연구는 레이블이 없는 이미지가 데이터 커버리지를 크게 향상시키고 모델의 일반화 및 견고성을 개선할 수 있음을 보여줍니다.

### 3. Depth Anything

3.1. 레이블이 있는 이미지 학습:

이 과정은 MiDaS의 훈련 방식과 유사합니다. 우리는 1.5백만 개의 레이블이 있는 이미지를 6개의 공개 데이터 세트에서 수집했습니다. 이 데이터 세트들은 다양한 장면을 포함하고 있으며, 모델의 일반화 능력과 견고성을 크게 향상시키는 데 도움이 됩니다. 또한, DINOv2에서 사전 훈련된 가중치를 사용하여 인코더를 초기화하고, 하늘 영역을 감지하여 그 부분의 심도 값을 0으로 설정합니다.

3.2. 레이블이 없는 이미지의 힘 발휘:

레이블이 없는 이미지의 가치를 강조하며, 이를 통해 데이터 커버리지를 확장합니다. 62백만 개 이상의 다양한 장면을 포함하는 여러 대규모 공개 데이터 세트에서 이미지를 수집했습니다. 이러한 이미지들은 사전 훈련된 MDE 모델을 사용하여 자동으로 심도 레이블을 할당받습니다. 이후, 이 레이블이 없는 이미지들을 강력한 변형을 적용하여 학습하는 과정을 통해 모델이 추가적인 시각적 지식을 탐색하고 더 견고한 표현을 학습하도록 합니다.

3.3. 의미론적 보조 지각:

우리는 심도 추정 모델에 고급 의미론적 정보를 제공하기 위해 DINOv2 모델에서 강력한 의미론적 능력을 상속받습니다. 이를 통해 모델은 더 풍부한 의미론적 정보를 포함하는 연속적인 특징 공간에서 학습하며, 이는 심도 추정 작업에 대한 보조 감독으로 작용합니다. 결과적으로, 우리의 인코더는 MDE 데이터 세트에서 뿐만 아니라 의미론적 분할 작업에서도 강력한 성능을 보여주며, 중간 수준과 고급 수준의 시각적 인식 시스템에 대한 범용 다중 작업 인코더로서의 잠재력을 가지고 있습니다.

![파이프라인. 실선: 레이블이 지정된 이미지의 흐름, 점선: 레이블이 지정되지 않은 이미지. 특히 라벨이 지정되지 않은 대규모 이미지의 가치를 강조합니다. S는 강한 섭동을 추가하는 것을 나타냅니다(섹션 3.2). 깊이 추정 모델에 풍부한 시맨틱 선구자를 장착하기 위해 온라인 학생 모델과 고정 인코더 사이에 보조 제약 조건을 적용하여 시맨틱 기능을 보존합니다(섹션 3.3).](Depth%20Anything%20Unleashing%20the%20Power%20of%20Large-Scale%203bd6dbacc1644cae86d71a065b9a3e9c/Untitled%201.png)

파이프라인. 실선: 레이블이 지정된 이미지의 흐름, 점선: 레이블이 지정되지 않은 이미지. 특히 라벨이 지정되지 않은 대규모 이미지의 가치를 강조합니다. S는 강한 섭동을 추가하는 것을 나타냅니다(섹션 3.2). 깊이 추정 모델에 풍부한 시맨틱 선구자를 장착하기 위해 온라인 학생 모델과 고정 인코더 사이에 보조 제약 조건을 적용하여 시맨틱 기능을 보존합니다(섹션 3.3).

### 4. Experiment

4.1. 구현 세부 사항:

DINOv2 인코더를 사용하여 특징 추출을 수행하고, MiDaS에서 사용된 DPT 디코더를 심도 회귀에 사용합니다.

모든 레이블이 있는 데이터 세트를 단순히 결합하여 사용하며, 첫 번째 단계에서는 레이블이 있는 이미지로 교사 모델을 20 에포크 동안 훈련합니다.

두 번째 단계에서는 레이블이 없는 이미지로 학생 모델을 훈련시키며, 레이블이 있는 이미지와 레이블이 없는 이미지의 비율을 배치당 1:2로 설정합니다.

레이블이 있는 이미지에 대해서는 수평 뒤집기만을 데이터 증강으로 사용하며, 특징 정렬 손실을 위한 허용 오차 마진은 0.15로 설정합니다.

4.2. 제로샷 상대 심도 추정:

이 연구는 모든 이미지에 대해 정확한 심도 추정을 제공하는 것을 목표로 합니다.

KITTI, NYUv2, Sintel, DDAD, ETH3D, DIODE 등 여섯 개의 대표적인 보이지 않는 데이터 세트에서 제로샷 심도 추정 능력을 광범위하게 검증합니다.

MiDaS v3.1과 비교했을 때, 우리의 "Depth Anything" 모델은 다양한 장면에서 AbsRel(절대 상대 오류)과 δ1(정확도 지표) 메트릭 모두에서 뛰어난 성능을 보여줍니다.

![6개의 보이지 않는 데이터 세트에 대한 정성적 결과.](Depth%20Anything%20Unleashing%20the%20Power%20of%20Large-Scale%203bd6dbacc1644cae86d71a065b9a3e9c/Untitled%202.png)

6개의 보이지 않는 데이터 세트에 대한 정성적 결과.

4.3. 메트릭 심도 추정으로 미세 조정:

제로샷 상대 심도 추정에서 인상적인 성능을 보인 후, "Depth Anything" 모델을 메트릭 심도 추정을 위한 유망한 가중치 초기화로 검토합니다.

인도메인 메트릭 심도 추정과 제로샷 메트릭 심도 추정 두 가지 시나리오에서 모델을 평가합니다.

![깊이 예측을 MiDaS와 비교합니다. 한편, 컨트롤넷을 사용하여 깊이 맵(마지막 행)에서 새로운 이미지를 합성합니다. 첫 번째 행: 입력 이미지, 두 번째 행: 깊이 예측.](Depth%20Anything%20Unleashing%20the%20Power%20of%20Large-Scale%203bd6dbacc1644cae86d71a065b9a3e9c/Untitled%203.png)

깊이 예측을 MiDaS와 비교합니다. 한편, 컨트롤넷을 사용하여 깊이 맵(마지막 행)에서 새로운 이미지를 합성합니다. 첫 번째 행: 입력 이미지, 두 번째 행: 깊이 예측.

NYUv2와 KITTI 데이터 세트에서 이전 최고 방법보다 더 나은 성능을 보여줍니다.

![KITTI의 정성적 결과. 시각화하기 어려운 극히 희박한 실측 자료로 인해 여기서는 가장 진보된 MiDAS v3.1 [5] 예측과 비교합니다. 색상이 밝을수록 거리가 가까움을 나타냅니다.](Depth%20Anything%20Unleashing%20the%20Power%20of%20Large-Scale%203bd6dbacc1644cae86d71a065b9a3e9c/Untitled%204.png)

KITTI의 정성적 결과. 시각화하기 어려운 극히 희박한 실측 자료로 인해 여기서는 가장 진보된 MiDAS v3.1 [5] 예측과 비교합니다. 색상이 밝을수록 거리가 가까움을 나타냅니다.

![NYUv2에 대한 정성적 결과. 한 가지 주목할 점은 MiDAS [5]는 제로 샷이 아닌 NYUv2 훈련 데이터를 사용하지만, 우리는 그렇지 않다는 점입니다.](Depth%20Anything%20Unleashing%20the%20Power%20of%20Large-Scale%203bd6dbacc1644cae86d71a065b9a3e9c/Untitled%205.png)

NYUv2에 대한 정성적 결과. 한 가지 주목할 점은 MiDAS [5]는 제로 샷이 아닌 NYUv2 훈련 데이터를 사용하지만, 우리는 그렇지 않다는 점입니다.

4.4. 의미론적 분할로 미세 조정:

우리의 MDE 모델은 사전 훈련된 인코더로부터 풍부한 의미론적 선행 지식을 상속받도록 설계되었습니다.

Cityscapes와 ADE20K 데이터 세트에서 의미론적 분할 작업에 대한 MDE 인코더를 미세 조정하여 우수한 성능을 보여줍니다.

4.5. 소거 연구:

각 훈련 데이터 세트의 제로샷 전송 성능, 학생 모델 학습 시 레이블이 없는 이미지에 대한 도전, 의미론적 제약의 효과 등을 평가합니다.

MiDaS 훈련 인코더와 DINOv2와 비교하여 하류 작업에서의 미세 조정 성능을 비교합니다.

4.6. 질적 결과:

여섯 개의 보이지 않는 데이터 세트에서 모델 예측을 시각화하고, MiDaS와 비교합니다.

예측된 심도 맵을 기반으로 새로운 이미지를 합성하는 실험을 수행합니다.

![Sintel의 정성적 결과.](Depth%20Anything%20Unleashing%20the%20Power%20of%20Large-Scale%203bd6dbacc1644cae86d71a065b9a3e9c/Untitled%206.png)

Sintel의 정성적 결과.

![DDAD에 대한 정성적 결과.](Depth%20Anything%20Unleashing%20the%20Power%20of%20Large-Scale%203bd6dbacc1644cae86d71a065b9a3e9c/Untitled%207.png)

DDAD에 대한 정성적 결과.

### 5. Conclusion

이 연구에서는 "Depth Anything"라는 단일 카메라 심도 추정을 위한 매우 실용적인 솔루션을 제시했습니다. 이 모델은 특히 저렴하고 다양한 레이블이 없는 이미지의 가치를 강조하며, 이를 최대한 활용하기 위한 두 가지 간단하지만 매우 효과적인 전략을 설계했습니다. 첫 번째 전략은 레이블이 없는 이미지를 학습할 때 더 도전적인 최적화 목표를 제시하는 것이며, 두 번째는 사전 훈련된 모델로부터 풍부한 의미론적 선행 지식을 보존하는 것입니다.

"Depth Anything" 모델은 제로샷 심도 추정 능력이 뛰어나며, 메트릭 심도 추정 및 의미론적 분할 작업에 대한 유망한 초기화로 작용합니다. 이는 모델이 다양한 시나리오와 환경에서 강력한 성능을 발휘할 수 있음을 보여줍니다. 또한, 이 연구는 MDE 분야뿐만 아니라 다른 컴퓨터 비전 작업에도 적용 가능한 새로운 방향을 제시합니다.

결론적으로, 이 연구는 단일 카메라 심도 추정을 위한 새로운 접근 방식을 제시하며, 이를 통해 더 나은 일반화 능력과 견고성을 갖춘 모델을 개발할 수 있음을 보여줍니다. "Depth Anything"는 단일 카메라 심도 추정 분야에서 중요한 발전을 나타내며, 향후 연구에 대한 기초를 마련합니다.