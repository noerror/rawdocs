# HyperDreamer: Hyper-Realistic 3D Content Generation and Editing from a Single Image

[https://arxiv.org/abs/2312.04543](https://arxiv.org/abs/2312.04543)

- 7 Dec 2023

![단일 RGB 이미지가 주어지면 전체 범위에서 보고, 렌더링하고, 편집할 수 있는 풍부한 디테일의 사실적인 3D 모델을 생성합니다.](HyperDreamer%20Hyper-Realistic%203D%20Content%20Generation%201dd98ac158c943c7817a9e967b74219c/Untitled.png)

단일 RGB 이미지가 주어지면 전체 범위에서 보고, 렌더링하고, 편집할 수 있는 풍부한 디테일의 사실적인 3D 모델을 생성합니다.

### 1 INTRODUCTION

이 논문은 게임, 가상 회의 등 다양한 분야에서 3D 콘텐츠 생성의 중요성이 커지고 있다는 점을 강조하는 것으로 시작합니다. 전통적으로 이 분야는 카테고리별 모델에 의존했으며 대규모 3D 또는 2D 데이터 세트에 의존하기 때문에 한계에 직면해 있었습니다. 하지만 최근에는 특히 2D 생성 모델의 확산 전제를 통합하는 등 많은 발전이 이루어지면서 보다 정확한 3D 콘텐츠 생성이 가능해졌습니다.

현재 당면한 과제와 혁신

이러한 발전에도 불구하고 기존의 3D 콘텐츠 생성 방법에는 생성 후 사용성 제한과 2D 확산 모델의 편향성이라는 두 가지 주요 문제가 있습니다. 이러한 한계는 실제 적용 및 편집 유연성을 제한하는 암시적 3D 표현의 사용과 2D 데이터세트에 대한 확산 모델 훈련으로 인해 3D 모델의 텍스처에 의도치 않게 영향을 미치는 데서 비롯됩니다.

하이퍼드리머 프레임워크

이 백서에서는 이러한 문제를 극복하기 위해 3D 콘텐츠 생성 및 편집을 위한 포괄적인 프레임워크인 HyperDreamer를 소개합니다. 이 프레임워크는 세 가지 핵심 기능으로 구분됩니다:

- 풀레인지 뷰어블: HyperDreamer는 의사 멀티뷰 이미지를 사용하는 초고해상도 모듈을 사용하여 모든 각도에서 볼 수 있는 고해상도 텍스처를 생성할 수 있습니다.
- 풀레인지 렌더링 가능: 온라인 3D 시맨틱 세분화를 위한 세그먼트-애니싱 모델을 통합합니다. 이 통합은 새로운 손실 기능과 함께 확산 편향을 완화하는 데 도움이 됩니다. 또한 이 프레임워크는 알베도, 거칠기, 스페큘러 특성과 같은 머티리얼 속성을 사실적으로 렌더링하기 위해 공간적으로 변화하는 BRDF 모델을 사용합니다.
- 풀레인지 편집 가능: 3D 메시에서 텍스처 편집을 위한 텍스트 기반 안내를 제공하는 대화형 편집 방법이 제공됩니다. 이 기능은 생성된 콘텐츠의 유연성과 편집성을 향상시킵니다.

광범위한 실험을 통해 하이퍼드리머는 고해상도, 영역 인식 머티리얼을 생성하는 데 탁월하며 사용자 친화적인 편집 기능을 제공한다는 것을 확인할 수 있었습니다. 3D 생성 및 편집 품질 모두에서 기존 방식보다 훨씬 뛰어난 성능을 발휘합니다. 이 논문은 HyperDreamer의 뛰어난 품질과 유연성으로 인해 다양한 애플리케이션에서 AI로 생성된 3D 콘텐츠에 대한 접근성과 실용성을 높일 수 있다고 결론지었습니다.

### 2 RELATED WORKS

텍스트 가이드 3D 생성

텍스트-투-이미지 방식의 성공에 힘입어 텍스트 가이드 3D 생성 분야가 크게 발전했습니다. 드림 필드와 드림퓨전과 같은 주목할 만한 방법은 텍스트-이미지 모델(각각 CLIP 및 확산 모델)을 활용하여 3D 생성 품질을 향상시킵니다. Magic3D 및 Fantasia3D와 같은 후속 혁신 기술은 텍스처와 사실감을 개선하기 위해 더욱 진보된 기술을 도입했습니다. 이러한 방법은 일반적으로 텍스트를 안내 조건으로 사용하여 일반적인 방향을 제시하지만 구체적인 디테일이 부족합니다.

단일 이미지 재구성

단일 이미지 3D 재구성은 또 다른 관심 분야입니다. 추론 기반 방법은 훈련 데이터 세트에 의존하며 다양하고 일반적인 물체에는 어려움을 겪는 경우가 많습니다. 반면에 최적화 기반 방법은 2D 텍스트-이미지 변환 모델의 선행 모델을 지침으로 사용합니다. RealFusion, Make-it-3D, Zero-1-to-3과 같은 기술은 재구성된 모델에서 더 나은 품질과 질감을 제공하는 이 영역의 발전된 기술입니다.

머티리얼 및 조명 추정

멀티뷰 재구성에서 머티리얼과 조명 조건을 추정하는 작업은 복잡합니다. 이전 연구에서는 다양한 거칠기와 금속 분포를 모델링하려고 시도했지만, 이 논문에서는 동일한 시맨틱 클래스 내의 머티리얼이 유사한 속성을 공유하는 보다 현실적인 접근 방식을 제안합니다. 이 접근 방식은 보다 정확하고 공간적으로 다양한 머티리얼 모델을 제공하는 것을 목표로 합니다.

텍스트 가이드 3D 편집

텍스트 가이드 3D 편집은 품질과 다양성 측면에서 상당한 진전을 이루었습니다. Text2Mesh 및 TANGO와 같은 기술은 텍스트 입력을 기반으로 3D 모델의 모양을 최적화하기 위해 신경 스타일 필드와 BRDF를 사용해 왔습니다. 그러나 이러한 방법은 실제 사용에 필요한 정확도가 부족한 경우가 많습니다. 최근에 개발된 텍스처는 여러 관점에서 반복적인 방식을 적용하여 프로세스를 개선했습니다. 이러한 발전에도 불구하고 이러한 방법 중 어느 것도 3D 객체에서 국소화된 영역을 텍스트로 정밀하게 편집할 수 있는 방법은 없습니다. 이 논문에서는 텍스트 안내와 간단한 클릭을 기반으로 사용자가 선택한 3D 영역 또는 전체 텍스처를 편집할 수 있는 새로운 인터랙티브 편집 방법을 제안합니다.

![3D 생성 및 편집 파이프라인 개요. 우리는 제약이 많은 이 문제에 디퓨전 전구, 시맨틱 전구, 디렌더링 전구를 도입하여 생성 후 머티리얼 모델링과 인터랙티브 편집을 통해 고해상도 텍스처를 구현할 수 있습니다.](HyperDreamer%20Hyper-Realistic%203D%20Content%20Generation%201dd98ac158c943c7817a9e967b74219c/Untitled%201.png)

3D 생성 및 편집 파이프라인 개요. 우리는 제약이 많은 이 문제에 디퓨전 전구, 시맨틱 전구, 디렌더링 전구를 도입하여 생성 후 머티리얼 모델링과 인터랙티브 편집을 통해 고해상도 텍스처를 구현할 수 있습니다.

### 3 PRELIMINARIES

3.1 3D 표현

이 논문은 3D 콘텐츠 생성을 위한 2단계 훈련 접근 방식에 대해 설명합니다. 첫 번째 단계에서는 3D 위치와 시청 방향을 볼륨 밀도 및 색상에 매핑하는 암시적 함수로 장면을 표현하는 신경 방사 필드(NeRF)가 사용됩니다. 이 과정에는 카메라에서 픽셀로 투사되는 광선을 따라 밀도와 색상을 알파 합성하는 작업이 포함됩니다. 훈련 효율을 높이기 위해 이 논문에서는 순수 다층 퍼셉트론(MLP)보다 더 효과적인 인스턴트 NGP의 효율적인 해시 그리드 인코딩을 채택했습니다.

두 번째 단계에서는 고해상도 출력을 효율적으로 생성하기 위해 변형 가능한 메시 사면체화(DMTet)를 사용합니다. DMTet은 암시적 및 명시적 표면 표현을 통합하고 3D 형상 모델링을 위해 변형 가능한 사면체 그리드를 활용합니다. 이 방법은 차별적인 래스터화를 통해 고해상도 텍스처 메시를 렌더링할 수 있습니다.

3.2 스코어 증류 샘플링(SDS)

이 논문에서는 텍스트에서 3D로 생성하기 위한 사전 지식으로 2D 확산 모델을 활용하는 이전 연구에서 차용한 기술인 점수 증류 샘플링(SDS)에 대해 설명합니다. 확산 모델은 노이즈가 있는 이미지, 텍스트 임베딩 및 노이즈 단계를 기반으로 노이즈를 추정하는 노이즈 제거 함수를 학습합니다. SDS는 렌더링된 이미지가 확산 전제 하에서 주어진 텍스트 임베딩과 일치하도록 안내합니다. 여기에는 노이즈가 점진적으로 감소하고 이미지 구조가 도입되는 과정이 포함됩니다. 이 논문에서는 입력 뷰를 조건으로 하는 변형된 3D 인식 SDS에 대해서도 언급하고 있습니다.

3.3 무엇이든 세그먼트 모델(SAM:Segment Anything Model)

마지막으로 세그먼트 무엇이든 모델(SAM)을 소개합니다. SAM은 일반적인 이미지 분할을 위한 기본 모델로 다양한 분할 모드를 지원합니다. 사용자별 프롬프트를 통해 이미지를 처리하고 그에 맞는 세그먼트 마스크를 출력할 수 있습니다. 이 모델은 이미지와 점 좌표 및 해당 레이블을 포함한 일련의 점 프롬프트를 받아 세분화 마스크를 생성합니다. 이 모델은 이미지 처리 및 3D 콘텐츠 생성에서 유연하고 정밀한 분할을 가능하게 하는 데 매우 중요합니다.

![생성 단계에서의 SAM. 원시 SAM 결과와 비교하여 간결한 시맨틱 그룹을 효과적으로 클러스터링합니다.](HyperDreamer%20Hyper-Realistic%203D%20Content%20Generation%201dd98ac158c943c7817a9e967b74219c/Untitled%202.png)

생성 단계에서의 SAM. 원시 SAM 결과와 비교하여 간결한 시맨틱 그룹을 효과적으로 클러스터링합니다.

### 4 METHODOLOGY

하이퍼드리머는 3D 콘텐츠 생성의 문제를 해결하기 위해 설계된 프레임워크입니다. 2D 확산 모델, 시맨틱 세분화 모델, 머티리얼 추정 모델의 딥 프리어를 활용하여 3D 콘텐츠의 고품질 시청, 렌더링, 인터랙티브 편집을 가능하게 합니다. 이 방법론은 고해상도 텍스처 생성, 시맨틱 인식 머티리얼 추정, 인터랙티브 편집의 세 가지 주요 섹션으로 나뉩니다.

4.1 360° 고해상도 텍스처 생성

두 번째 훈련 단계에서는 고해상도 텍스처 맵을 생성하는 데 중점을 둡니다. 원래의 안내 모델인 0-1-3은 저해상도 이미지로 훈련되었기 때문에 고해상도 이미지에 적용하면 텍스처가 흐릿해집니다. 이 문제를 해결하기 위해 이 논문에서는 새로운 뷰를 선택하고, 0-1-3을 사용하여 이미지를 생성한 다음, 초고해상도 네트워크를 사용하여 이러한 이미지를 업스케일링하는 모듈을 제안합니다. 이 접근 방식은 지각 손실을 사용하여 콘텐츠와 스타일 차이를 최소화하고, 학습과 추론에 사용되는 해상도 간의 불일치를 극복합니다.

![확산 편향. d의 2D 확산 편향은 b의 3D 생성 실패로 이어지며, 이는 c의 알베도 정규화를 통해 완화될 수 있습니다.](HyperDreamer%20Hyper-Realistic%203D%20Content%20Generation%201dd98ac158c943c7817a9e967b74219c/Untitled%203.png)

확산 편향. d의 2D 확산 편향은 b의 3D 생성 실패로 이어지며, 이는 c의 알베도 정규화를 통해 완화될 수 있습니다.

4.2 시맨틱 인식 소재 추정

이 백서에서는 전 세계적으로 일관된 메시 세분화를 위한 다층 퍼셉트론(MLP)을 기반으로 하는 새로운 분야를 소개합니다. 이 프로세스에는 과도하게 세분화된 레퍼런스 이미지의 시맨틱 부분을 클러스터링하고 시맨틱 레이블을 할당하는 작업이 포함됩니다. 생성된 3D 모델의 음영 및 반사율 효과와 관련된 문제를 해결하기 위해 이 백서에서는 몇 가지 알베도 손실을 제안합니다. 이러한 손실은 동일한 시맨틱 레이블 아래의 알베도 색상이 유사하다고 가정하고, 이러한 일관성을 유지하기 위해 시맨틱 인식 알베도 정규화를 도입합니다. 또한 보다 사실적인 렌더링을 위해 물리 기반 렌더링(PBR) 머티리얼 모델을 통합했습니다.

![인터랙티브 편집 프로세스. 사용자가 관심 영역을 선택하면 유니티의 방법은 텍스트 안내 편집을 위해 대상 영역의 텍스처 마스크를 텍스처 합성 파이프라인으로 출력합니다.](HyperDreamer%20Hyper-Realistic%203D%20Content%20Generation%201dd98ac158c943c7817a9e967b74219c/Untitled%204.png)

인터랙티브 편집 프로세스. 사용자가 관심 영역을 선택하면 유니티의 방법은 텍스트 안내 편집을 위해 대상 영역의 텍스처 마스크를 텍스처 합성 파이프라인으로 출력합니다.

4.3 인터랙티브 편집

하이퍼드리머는 사용자가 텍스트 안내를 통해 3D 메시의 텍스처를 선택하고 편집할 수 있는 혁신적인 인터랙티브 편집 툴을 제공합니다. 이 프로세스에는 3D 메시의 인터랙티브 세그먼테이션이 포함되며, UV 맵을 활용하여 선택된 영역과 나머지 영역을 표현합니다. 이 접근 방식을 사용하면 메시 영역을 타겟팅하여 수정할 수 있으며 텍스트 안내에 따라 로컬 편집을 수행할 수 있습니다.

4.4 구현 세부 사항

구현 측면에서 HyperDreamer는 2단계 훈련 파이프라인을 따르며, 첫 번째 단계에서는 거친 NeRF 모델을, 두 번째 단계에서는 DMTet 모델을 사용합니다. 이 프레임워크는 두 번째 단계에서 초해상도, 시맨틱 및 머티리얼 모듈을 통합합니다. 또한 이 백서에서는 단일 이미지 기반 3D 생성에 대한 최근의 네 가지 접근 방식과 하이퍼드리머를 비교하여 고품질 3D 콘텐츠를 생성하는 데 있어 하이퍼드리머의 발전과 기능을 강조합니다.

### 5 EXPERIMENTS

5.1 질적 비교

여러 최신 3D 콘텐츠 생성 방법과 HyperDreamer의 질적 비교를 제시합니다. 비교에서는 생성된 오브젝트의 레퍼런스 뷰와 백뷰를 모두 보여줍니다. 그 결과 사실감과 품질 측면에서 HyperDreamer가 다른 방법보다 우수한 것으로 나타났습니다. Shap-E 및 NeuralLift-360과 같은 방법은 품질과 크기에서 한계를 보였습니다. RealFusion과 Zero-1-to-3은 레퍼런스 이미지의 충실도를 유지하면서도 다중 얼굴 문제와 흐릿함 같은 문제를 겪었습니다. 반면에 하이퍼드리머는 레퍼런스 이미지와 백뷰 모두에서 높은 품질을 달성했습니다.

![정성적 비교. 하이퍼드리머는 충실도가 높은 레퍼런스 뷰를 생성하고 신규 뷰에서는 더욱 사실적이고 합리적인 결과를 생성합니다.](HyperDreamer%20Hyper-Realistic%203D%20Content%20Generation%201dd98ac158c943c7817a9e967b74219c/Untitled%205.png)

정성적 비교. 하이퍼드리머는 충실도가 높은 레퍼런스 뷰를 생성하고 신규 뷰에서는 더욱 사실적이고 합리적인 결과를 생성합니다.

5.2 정량적 비교

정량적 분석을 위해 세 가지 지표가 사용되었습니다:

- 레퍼런스 뷰 이미지의 재구성 품질을 평가하기 위한 LPIPS.
- 렌더링된 새로운 뷰 이미지와 레퍼런스 이미지 사이의 픽셀 수준 거리를 측정하기 위한 컨텍스트 거리.
- 새로운 뷰 이미지와 기준 이미지 간의 의미 수준 거리를 평가하기 위한 CLIP-Score.

이 논문에서는 이 비교를 위해 온라인에서 20개의 다양한 이미지와 DTU에서 10개의 인스턴스를 선택했습니다. 요약본에 자세히 설명되어 있지는 않지만, 결과는 이러한 지표에서 HyperDreamer가 더 우수한 성능을 보인 것으로 추정됩니다.

5.3 분석 및 요약

이 백서에서는 HyperDreamer의 특정 구성 요소에 대한 인사이트를 제공합니다:

초고해상도(SR): 그림 7에서 볼 수 있듯이 SR 모듈은 텍스처 디테일과 사실감을 크게 향상시켜 다른 방식에 비해 고해상도 줌인 뷰를 제공합니다.

![초고해상도(SR) 모듈의 에블레이션. 텍스처의 고주파 디테일이 SR 감독하에 생성됩니다.](HyperDreamer%20Hyper-Realistic%203D%20Content%20Generation%201dd98ac158c943c7817a9e967b74219c/Untitled%206.png)

초고해상도(SR) 모듈의 에블레이션. 텍스처의 고주파 디테일이 SR 감독하에 생성됩니다.

재질: 시맨틱 레이블과 연관된 러프니스 및 스페큘러 맵의 생성은 그림 8-a에 나와 있습니다. 이 백서는 또한 알베도 손실이 기준 뷰에서 알베도 텍스처를 분리하는 데 어떻게 도움이 되는지 보여줍니다.

![머티리얼 모델링 분석. 블렌더의 렌더링 결과와 함께 출력 러프니스 및 스페큘러 맵의 예시를 보여줍니다. 참조 뷰에서의 알베도 손실이 알베도 텍스처의 셰이딩 및 반사율 학습을 완화하는 데 어떻게 도움이 되는지 b에서 보여 줍니다.](HyperDreamer%20Hyper-Realistic%203D%20Content%20Generation%201dd98ac158c943c7817a9e967b74219c/Untitled%207.png)

머티리얼 모델링 분석. 블렌더의 렌더링 결과와 함께 출력 러프니스 및 스페큘러 맵의 예시를 보여줍니다. 참조 뷰에서의 알베도 손실이 알베도 텍스처의 셰이딩 및 반사율 학습을 완화하는 데 어떻게 도움이 되는지 b에서 보여 줍니다.

편집: 그림 9는 메시에서 세분화를 위한 순진한 방법이 특히 복잡한 영역에서 높은 실패율을 보인다는 것을 보여줍니다. SAM에 공급되는 포지티브 및 네거티브 프롬프트와 함께 패치 샘플링을 사용하는 하이퍼드리머의 접근 방식이 더 강력하고 효과적인 것으로 입증되었습니다.

![메시에서 세분화하는 방식에 대한 분석. 우리의 방법은 복잡한 상황을 처리하는 능력이 더 뛰어납니다. 기본적으로 완성된 데이터 세트 [Aanæs 외. 2016]. 두 데이터 세트에 대한 결과는 각각 표 1과 표 2에 나와 있습니다. 우리 모델은 세 가지 메트릭 모두에서 비교 방법보다 큰 차이로 우수한 성능을 보여 파이프라인의 효율성을 정량적으로 보여줍니다.](HyperDreamer%20Hyper-Realistic%203D%20Content%20Generation%201dd98ac158c943c7817a9e967b74219c/Untitled%208.png)

메시에서 세분화하는 방식에 대한 분석. 우리의 방법은 복잡한 상황을 처리하는 능력이 더 뛰어납니다. 기본적으로 완성된 데이터 세트 [Aanæs 외. 2016]. 두 데이터 세트에 대한 결과는 각각 표 1과 표 2에 나와 있습니다. 우리 모델은 세 가지 메트릭 모두에서 비교 방법보다 큰 차이로 우수한 성능을 보여 파이프라인의 효율성을 정량적으로 보여줍니다.

### 6 CONCLUSION

하이퍼드리머는 단일 이미지에서 초현실적인 3D 콘텐츠를 생성하고 편집할 수 있는 획기적인 프레임워크로 소개되었습니다. 3D 콘텐츠의 전체 범위 보기 기능, 렌더링 기능, 편집 기능을 제공함으로써 기존 방식을 뛰어넘습니다. 광범위한 실험을 통해 고해상도 텍스처로 영역을 인식하는 머티리얼을 모델링하고 사용자 친화적인 편집을 용이하게 하는 데 있어 하이퍼드리머가 효과적임을 입증했습니다. 이 논문은 하이퍼드리머가 학술 및 산업 분야의 3D 콘텐츠 제작과 편집을 크게 발전시킬 수 있는 가능성을 제시하며 결론을 맺습니다.

![더 많은 보기가 있는 HyperDreamer의 추가 결과. 마지막 열의 이미지는 각각 스페큘러 및 러프니스 맵입니다(위에서 아래로)](HyperDreamer%20Hyper-Realistic%203D%20Content%20Generation%201dd98ac158c943c7817a9e967b74219c/Untitled%209.png)

더 많은 보기가 있는 HyperDreamer의 추가 결과. 마지막 열의 이미지는 각각 스페큘러 및 러프니스 맵입니다(위에서 아래로)