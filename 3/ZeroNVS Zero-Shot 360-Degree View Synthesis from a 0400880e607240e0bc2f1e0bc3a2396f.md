# ZeroNVS: Zero-Shot 360-Degree View Synthesis from a Single Real Image

[https://arxiv.org/abs/2310.17994](https://arxiv.org/abs/2310.17994)

[https://kylesargent.github.io/zeronvs/](https://kylesargent.github.io/zeronvs/)

- Oct 2023

### 1 INTRODUCTION

하나의 정적인 사진으로 360도 전경을 시뮬레이션할 수 있는 사실적인 이미지를 생성하는 기술의 발전에 대해 설명합니다. 새로운 뷰 합성(NVS)으로 알려진 이 프로세스는 생성된 이미지가 자연스럽고 입체적으로 보일 뿐만 아니라 원본 사진에서 직접 볼 수 없는 다양한 잠재적 배경을 표현해야 하기 때문에 복잡합니다. 이전 연구에서는 종종 설명이 없는 배경의 물체에 초점을 맞추었기 때문에 사실감과 다양성을 더 쉽게 얻을 수 있었습니다. 이러한 노력은 Objaverse-XL과 같은 상세한 오브젝트 모델의 광범위한 데이터 세트와 3D 정확도를 높이기 위한 스코어 증류 샘플링(SDS)과 같은 기술을 통해 뒷받침되었습니다.

![단일 이미지에서 뷰 합성 결과. 모든 NeRF는 동일한 모델에 의해 예측됩니다.](ZeroNVS%20Zero-Shot%20360-Degree%20View%20Synthesis%20from%20a%200400880e607240e0bc2f1e0bc3a2396f/Untitled.png)

단일 이미지에서 뷰 합성 결과. 모든 NeRF는 동일한 모델에 의해 예측됩니다.

그러나 이번 연구는 오브젝트에 대한 Objaverse-XL과 같은 광범위한 데이터 세트가 존재하지 않고 배경이 다양성에 중요한 역할을 하는 전체 실제 장면에 대해 360도 NVS를 생성하는 더 어려운 과제를 해결하는 것을 목표로 합니다. 이 백서에서는 기존 오브젝트 중심 방법의 강점을 기반으로 하되 복잡한 장면을 위해 특별히 설계된 두 가지 주요 혁신 기술을 도입한 새로운 모델인 제로NVS를 소개합니다. 첫 번째는 다양한 장면 데이터 세트에 대한 효과적인 학습을 가능하게 하는 새로운 카메라 매개변수화 및 정규화 방법입니다. 두 번째는 생성된 장면의 배경 다양성 부족 문제를 해결하는 'SDS 앵커링'이라는 메커니즘입니다.

훈련 데이터의 부족에 대처하기 위해 저자는 다양한 소스의 방대한 혼합 데이터 세트를 사용하여 모델이 실제 세계에서 발견되는 복잡한 장면을 처리할 수 있도록 할 것을 제안합니다. 혼합 데이터 세트에는 다양한 카메라 설정과 3D 지상 실측 데이터 유형이 포함됩니다. 저자들이 제안한 새로운 카메라 매개변수화 및 정규화 체계를 사용하면 이러한 다양한 데이터를 보다 효과적으로 사용할 수 있으므로 실제 장면에서 우수한 NVS를 얻을 수 있습니다.

또한 이 논문은 특히 180도와 같이 넓은 시야각에 대한 다양한 배경을 생성하는 데 있어 SDS의 한계를 다룹니다. 다른 샘플링 방법을 사용하여 여러 개의 "앵커" 뷰를 생성함으로써 다양성을 향상시키는 "SDS 앵커링"을 도입하여 SDS가 작동할 수 있는 더 넓은 범위의 배경 조건을 제공합니다.

제로엔브이는 보이지 않는 장면에 대한 인상적인 일반화 기능을 보여주었으며, 까다로운 DTU 벤치마크에서 이미지 합성 리얼리즘의 새로운 기준을 세웠습니다. 또한 저자들은 단일 이미지 NVS 성능을 평가하기 위한 새로운 표준으로 Mip-NeRF 360 데이터세트를 사용할 것을 제안합니다. 마지막으로, 사용자 연구를 통해 SDS 앵커링이 NVS에서 배경 생성의 다양성을 크게 향상시킨다는 사실을 입증합니다.

결론적으로 이 백서에서는 풀 씬 NVS를 위한 ZeroNVS 개발, 다양한 실제 장면을 위한 새로운 카메라 컨디셔닝 접근 방식, 배경 다양성 문제를 극복하는 새로운 방법, 표준 벤치마크에서 최첨단 결과를 달성하여 다양하고 사실적인 이미지를 생성하는 SDS 앵커링의 실용성을 보여주는 등 여러 가지 공헌을 강조하고 있습니다.

### 2 RELATED WORK

관련 연구 섹션에서는 세 가지 주요 영역에 대한 이전 연구를 검토합니다: 3D 생성, 단일 이미지 신규 뷰 합성, 깊이 추정이며, 모두 본 연구와 관련이 있습니다.

3D 생성 영역에서는 텍스트 프롬프트에서 신경 방사 필드(NeRF)를 생성하기 위해 점수 증류 샘플링(SDS)을 사용한 선구적인 작업인 DreamFusion이라는 모델을 중점적으로 다룹니다. 드림퓨전 이후 3D 모델의 품질, 다양성, 해상도, 런타임을 향상시킨 Magic3D, ATT3D, ProlificDreamer, 판타지아3D와 같은 다른 모델에서 다양한 개선이 이루어졌습니다. 이 외에도 GAN 기반 3D 제너레이터와 같은 다른 모델들은 대부분 특정 오브젝트 카테고리나 합성 데이터로 제한되어 있었습니다. 최근에는 3DGP, VQ3D, IVID를 사용하는 ImageNet과 같이 보다 다양한 데이터 세트에 GAN 기반 접근 방식을 적용하려는 시도가 이루어지고 있습니다. 후자의 IVID는 고품질 합성을 위해 증류 대신 메시 기반 워핑 및 확산 인페인팅을 사용한다는 점에서 차이가 있습니다.

단일 이미지 신규 뷰 합성의 경우, 초기 연구는 주로 3D 감독으로 훈련할 수 있는 특징 추출기를 개발하는 데 중점을 두었습니다. PixelNeRF 및 DietNeRF와 같은 모델이 이러한 접근 방식의 예로, 단일 또는 소수의 이미지에서 3D 장면을 추론합니다. 오브젝트의 새로운 뷰 합성을 위해 새로운 확산 기반 방법이 개발되었는데, 일반적으로 확산 모델을 훈련한 다음 이를 3D 장면 표현 증류에 사용하는 두 단계로 이루어집니다. ZeroNVS는 대규모 실제 장면 데이터 세트를 학습하고 카메라 시점 변경(최대 360도)을 포함하여 장면에 대한 새로운 뷰를 합성할 수 있다는 점에서 차별화됩니다.

이 백서의 주요 초점은 아니지만 제로엔브이에스에서 사용하는 3D SDS 증류 프로세스의 구성 요소인 깊이 추정의 맥락에서 이 백서는 획기적인 연구인 MIDAS에서 영감을 얻었습니다. MIDAS는 광범위한 데이터 소스와 호환되는 훈련 목표를 선택함으로써 모델 훈련을 위한 데이터의 양을 크게 확장할 수 있음을 보여주었습니다. 깊이 추정에 대한 MIDAS의 접근 방식은 특히 다양한 데이터 세트를 효과적으로 활용할 수 있는 새로운 카메라 컨디셔닝 표현과 장면 정규화 전략을 개발하는 데 영향을 미쳤습니다.

요약하자면, 이 논문은 이전의 모델과 기법을 인정하면서 제로엔브이에스가 도입한 차별화된 접근 방식과 개선 사항을 강조하는 등 기존 연구 환경 내에서 제로엔브이의 공헌을 자리매김하고 있습니다. 여기에는 실제 씬 렌더링을 위한 대규모의 다양한 데이터 세트 활용과 특히 풀 360도 NVS의 맥락에서 합성 품질과 다양성을 향상시키기 위한 새로운 방법론이 포함됩니다.

### 3 APPROACH

이 논문에서 저자는 하나의 실제 이미지에서 씬의 새로운 뷰를 생성하는 문제, 즉 새로운 뷰 합성이라는 과제를 해결합니다. 이들은 개별 오브젝트가 아닌 전체 장면에 초점을 맞춰 이전 접근 방식을 개선하는 것을 목표로 합니다. 이전 방법에서는 카메라 및 스케일 표현에 문제가 있어 새로운 뷰의 배경이 다양하지 못했습니다. 저자는 이러한 문제를 해결하기 위한 새로운 접근 방식을 소개합니다.

![3DoF 카메라 포즈는 원점을 향하는 카메라의 카메라 고도, 방위각, 반경을 캡처하지만 카메라 롤(사진)이나 공간에서 임의로 방향이 지정된 카메라는 표현할 수 없습니다. 이러한 매개변수화가 적용된 모델은 많은 카메라 포즈가 3DoF 포즈로 부적절하게 표현되는 실제 데이터에 대해 학습할 수 없습니다.](ZeroNVS%20Zero-Shot%20360-Degree%20View%20Synthesis%20from%20a%200400880e607240e0bc2f1e0bc3a2396f/Untitled%201.png)

3DoF 카메라 포즈는 원점을 향하는 카메라의 카메라 고도, 방위각, 반경을 캡처하지만 카메라 롤(사진)이나 공간에서 임의로 방향이 지정된 카메라는 표현할 수 없습니다. 이러한 매개변수화가 적용된 모델은 많은 카메라 포즈가 3DoF 포즈로 부적절하게 표현되는 실제 데이터에 대해 학습할 수 없습니다.

![단안 카메라에서는 카메라에 가까이 있는 작은 물체(왼쪽)와 멀리 있는 큰 물체(오른쪽)가 서로 다른 장면을 표현함에도 불구하고 동일하게 보입니다. 입력 뷰의 스케일 모호성은 새로운 뷰 합성에서 모호성을 유발합니다. 구체적으로, 입력 뷰에서 촬영한 이미지를 컨디셔닝한 후에도 새로운 카메라에서 촬영한 이미지에는 왼쪽에 작은 오토바이가 있거나(Scale A) 오른쪽에 큰 오토바이가 있을 수 있습니다(Scale B)](ZeroNVS%20Zero-Shot%20360-Degree%20View%20Synthesis%20from%20a%200400880e607240e0bc2f1e0bc3a2396f/Untitled%202.png)

단안 카메라에서는 카메라에 가까이 있는 작은 물체(왼쪽)와 멀리 있는 큰 물체(오른쪽)가 서로 다른 장면을 표현함에도 불구하고 동일하게 보입니다. 입력 뷰의 스케일 모호성은 새로운 뷰 합성에서 모호성을 유발합니다. 구체적으로, 입력 뷰에서 촬영한 이미지를 컨디셔닝한 후에도 새로운 카메라에서 촬영한 이미지에는 왼쪽에 작은 오토바이가 있거나(Scale A) 오른쪽에 큰 오토바이가 있을 수 있습니다(Scale B)

저자는 이미지, 뎁스 맵, 카메라 외연, 시야각을 사용하여 장면을 설명합니다. 뷰 합성 모델을 조절하기 위해 이 정보를 포함하는 함수 M을 사용합니다. 이 모델은 입력 이미지와 필요한 모든 조건부 정보가 포함된 M 함수를 기반으로 다음 뷰를 예측하여 새로운 뷰를 생성합니다.

이 모델은 3자유도로 제한되어 있고 객체 중심 이미지에는 잘 작동하지만 실제 장면에서는 어려움을 겪는 "0-1-3" 접근 방식과 비교합니다. 이 모델은 6개의 자유도에 시야각을 더한 '6DoF+1' 표현을 사용하여 카메라의 움직임과 방향을 더 정확하게 표현할 수 있습니다.

![각 정규화 방식에 대해 ZeroNVS에서 여러 샘플의 소벨 에지 맵 분산에 대한 히트맵을 보여줍니다. M6DoF+1은 스케일 모호성으로 인한 임의성을 줄여줍니다.](ZeroNVS%20Zero-Shot%20360-Degree%20View%20Synthesis%20from%20a%200400880e607240e0bc2f1e0bc3a2396f/Untitled%203.png)

각 정규화 방식에 대해 ZeroNVS에서 여러 샘플의 소벨 에지 맵 분산에 대한 히트맵을 보여줍니다. M6DoF+1은 스케일 모호성으로 인한 임의성을 줄여줍니다.

![위: 두 대의 카메라가 물체를 향하고 있는 장면. 아래쪽: 새 카메라가 추가되어 지면을 향하는 동일한 장면. 스케일을 계산하기 전에 카메라를 통합하면 각 설정마다 다른 스케일이 계산됩니다. 뷰어 중심 정규화는 이러한 문제를 방지하고 스케일 모호성을 줄입니다.](ZeroNVS%20Zero-Shot%20360-Degree%20View%20Synthesis%20from%20a%200400880e607240e0bc2f1e0bc3a2396f/Untitled%204.png)

위: 두 대의 카메라가 물체를 향하고 있는 장면. 아래쪽: 새 카메라가 추가되어 지면을 향하는 동일한 장면. 스케일을 계산하기 전에 카메라를 통합하면 각 설정마다 다른 스케일이 계산됩니다. 뷰어 중심 정규화는 이러한 문제를 방지하고 스케일 모호성을 줄입니다.

또한 저자들은 씬의 스케일 모호성 문제도 해결했습니다. 축척을 고려하지 않은 기존 방식은 정확도가 떨어지는 뷰를 생성할 수 있었습니다. 저자는 뎁스 맵을 사용하여 여러 장면에서 일관된 배율을 정의하는 정규화 방법을 소개합니다.

깊이 정보를 사용하여 표시되는 콘텐츠의 배율을 안내함으로써 배율 모호성을 더 잘 처리하는 새로운 정규화 방식이 추가적으로 개선되었습니다. 이 방식은 사분위수 함수를 사용하여 뎁스 맵에서 배율을 결정하고, 집계가 아닌 입력 뷰에만 의존하도록 개선하여 여러 장면에서 프로세스를 보다 일관성 있게 만듭니다.

마지막으로 이 논문에서는 합성된 뷰, 특히 배경의 다양성 문제에 대해 논의합니다. 다양성을 향상시키기 위해 새로운 뷰를 만들 때 다양하고 그럴듯한 콘텐츠 생성을 유지하는 'SDS 앵커링'을 제안합니다.

![SDS 기반 NeRF 증류(왼쪽)는 모든 360도 신규 뷰에 동일한 안내 이미지를 사용합니다. "SDS 앵커링"(오른쪽)은 먼저 DDIM을 통해 새로운 뷰를 샘플링한 다음 가장 가까운 이미지(입력 또는 샘플링된 새로운 뷰)를 가이던스로 사용합니다(송 외., 2020).](ZeroNVS%20Zero-Shot%20360-Degree%20View%20Synthesis%20from%20a%200400880e607240e0bc2f1e0bc3a2396f/Untitled%205.png)

SDS 기반 NeRF 증류(왼쪽)는 모든 360도 신규 뷰에 동일한 안내 이미지를 사용합니다. "SDS 앵커링"(오른쪽)은 먼저 DDIM을 통해 새로운 뷰를 샘플링한 다음 가장 가까운 이미지(입력 또는 샘플링된 새로운 뷰)를 가이던스로 사용합니다(송 외., 2020).

저자들은 카메라 위치, 스케일의 변화, 합성 이미지의 다양성 필요성 등을 고려하여 실제 장면의 복잡성을 처리하는 새로운 뷰 합성을 위한 고급 방법을 제안합니다. 이들의 접근 방식은 단일 이미지에서 보다 사실적이고 다양한 뷰를 생성하여 이전 방법의 한계를 개선하는 것을 목표로 합니다.

### 4 EXPERIMENTS

이 논문에서 저자들은 이전에 본 적이 없는 장면의 새로운 3D 뷰를 생성하는 제로샷 3D 일관된 새로운 뷰 합성 프로세스에 대한 연구를 발표합니다. 실험 설정, 주요 결과, 실험의 세부 사항, 접근 방식의 효과를 이해하기 위해 수행한 분석에 대해 설명합니다.

![뷰 합성 평가를 위한 PSNR 및 SSIM의 한계. 정렬이 잘못되면 의미적으로 더 합리적인 예측을 위한 PSNR 및 SSIM 값이 더 나빠질 수 있습니다.](ZeroNVS%20Zero-Shot%20360-Degree%20View%20Synthesis%20from%20a%200400880e607240e0bc2f1e0bc3a2396f/Untitled%206.png)

뷰 합성 평가를 위한 PSNR 및 SSIM의 한계. 정렬이 잘못되면 의미적으로 더 합리적인 예측을 위한 PSNR 및 SSIM 값이 더 나빠질 수 있습니다.

![기준 방법과 당사 방법 간의 정성적 비교.](ZeroNVS%20Zero-Shot%20360-Degree%20View%20Synthesis%20from%20a%200400880e607240e0bc2f1e0bc3a2396f/Untitled%207.png)

기준 방법과 당사 방법 간의 정성적 비교.

설정 및 데이터:
실험에는 CO3D, ACID 및 RealEstate10K의 결합된 데이터 세트에서 학습된 모델이 포함됩니다. 훈련에는 이러한 데이터 세트에서 무작위 샘플링이 포함되며 256x256픽셀의 해상도로 실행됩니다. 평가를 위해 모델은 동일한 데이터 세트의 개별 하위 집합에서 테스트되고 표준 벤치마크를 사용하여 다른 기법과 비교됩니다. 또한 보다 포괄적인 테스트를 위해 DTU 벤치마크 및 Mip-NeRF 360 데이터 세트와 같은 특수 데이터 세트를 사용합니다. 모델은 기존에 확립된 다양한 코딩 프레임워크와 도구를 사용하여 구현되었으며, 구체적인 내용과 추가 세부 사항은 백서의 부록에 나와 있습니다.

![SDS 앵커링의 효과에 대한 정성적 묘사. 표준 SDS(왼쪽)는 단조로운 배경을 예측하는 경향이 있는 반면, SDS 앵커링(오른쪽)은 보다 다양한 배경 콘텐츠를 생성합니다. 또한 표준 SDS는 모드 붕괴가 발생하기 쉬운 반면, SDS 앵커링은 무작위 시드에 따라 다른 결과를 생성합니다.](ZeroNVS%20Zero-Shot%20360-Degree%20View%20Synthesis%20from%20a%200400880e607240e0bc2f1e0bc3a2396f/Untitled%208.png)

SDS 앵커링의 효과에 대한 정성적 묘사. 표준 SDS(왼쪽)는 단조로운 배경을 예측하는 경향이 있는 반면, SDS 앵커링(오른쪽)은 보다 다양한 배경 콘텐츠를 생성합니다. 또한 표준 SDS는 모드 붕괴가 발생하기 쉬운 반면, SDS 앵커링은 무작위 시드에 따라 다른 결과를 생성합니다.

주요 결과:
결과 측면에서 모델의 성능은 PSNR, SSIM, LPIPS와 같은 표준 메트릭을 사용하여 측정되었으며, 관련성이 높은 LPIPS에 더 중점을 두었습니다. 새로운 모델은 DTU 벤치마크의 제로샷 시나리오에서 기존 방법보다 성능이 뛰어났으며, 특히 Mip-NeRF 360 데이터 세트의 단일 이미지에서 360도 뷰를 생성하는 데 있어 상당한 개선이 있었습니다. 또한 사용자 연구를 통해 효과가 확인된 SDS 앵커링을 도입하여 합성 장면의 다양성 제한 문제를 해결했습니다.

어블레이션 연구:
이 논문에서는 훈련 과정에서 다양한 데이터 세트를 제거하는 실험을 통해 데이터의 다양성이 모델 성능에 매우 중요하다는 것을 보여주는 제거 연구에 대해서도 설명합니다. 또한 계산상의 제약으로 인해 이러한 실험의 범위가 제한되었지만 모델 매개변수를 세분화하면 성능이 더욱 향상되는 효과에 대해서도 살펴봅니다.

요약하면, 이 논문은 보이지 않는 데이터에서 3D 뷰를 합성하는 새로운 접근 방식을 제시하고 이 방법이 기존 모델보다 우수하다는 것을 보여줍니다. 저자는 보다 사실적이고 창의적인 장면 렌더링을 생성하는 데 있어 다양한 학습 데이터와 파라미터 개선의 중요성을 강조합니다. 정량적 지표와 정성적 사용자 연구를 통해 그 효과를 뒷받침하고 있습니다.

## 5 CONCLUSION

연구진은 하나의 2D 사진에서 새로운 3D 이미지를 생성하도록 설계된 제로엔브이에스(ZeroNVS)라는 새로운 시스템을 개발했습니다. 이 시스템은 다양한 종류의 장면을 처리할 수 있으며 표준 벤치마크에서 테스트했을 때 이전 방법보다 더 나은 것으로 입증되었습니다. 한계를 뛰어넘기 위해 연구팀은 Mip-NeRF 360 데이터세트라는 더 까다로운 테스트도 도입했습니다. 이 새로운 시스템인 ZeroNVS는 다목적이며 이미 다양한 작업에 3D 인식 확산 모델을 사용하고 있는 기존 워크플로에 추가할 수 있습니다. 즉, 제로엔브이는 다양한 애플리케이션에서 2D 이미지를 3D 모델로 변환하는 방식을 개선할 수 있습니다.

### Appendix

이 기술 문서에서는 2D 이미지에서 3D 이미지를 생성하는 데 사용되는 확산 모델(신규 뷰 합성)이라는 인공 지능의 개발 및 훈련에 대해 설명합니다. 이 모델은 3D 공간에서 카메라가 설정되는 방식을 처리하기 위해 다양한 설정으로 학습됩니다. 이러한 설정에는 MZero 1~3 및 M6DoF+1과 같은 이름이 지정되며, 일부 설정에는 성능 향상을 위한 추가 기능이 있습니다. 이러한 모델을 훈련하는 데 컴퓨터 처리 시간이 많이 걸리지 않으며, 최대 60,000단계까지 훈련해도 성능 손실 없이 20,000단계 훈련 후에 최고의 성능을 발휘합니다.

연구진은 시야각과 같은 카메라 정보를 모델에 포함하기 위해 독특한 방법을 사용했으며, 3D 이미지를 생성할 때 깊이 정보를 처리하는 특별한 방법을 사용했습니다. 또한 대량의 3D 장면 데이터를 처리하기 위한 효율적인 시스템(데이터 로더)을 설계하여 모델이 장면을 샘플링하는 밀도를 유연하게 조정할 수 있도록 했습니다.

3D 장면을 합성하기 위해 연구원들은 생성된 장면에 다양성을 더하는 것을 목표로 하는 SDS 앵커링이라는 기술을 도입했습니다. 그러나 결과 이미지가 3D 공간의 불일치로 인해 이상하게 보이지 않고 사실적으로 보이도록 주의를 기울입니다. 또한 노이즈 레벨과 샘플링 방법 등 최상의 결과를 얻기 위해 조정하는 다양한 기술 설정(하이퍼파라미터)에 대해서도 설명합니다.

이 문서에는 연구진이 다양한 데이터 세트에서 모델을 테스트하고 기존 방법과 비교한 방법도 자세히 설명되어 있습니다. 또한 사용자 연구를 수행하여 사람들이 SDS 앵커링으로 생성된 장면이 더 사실적이거나 창의적이라고 생각하는지 확인했습니다.

마지막으로, 새로운 3D 뷰를 생성하는 데 가장 적합한 데이터 세트와 카메라 설정을 파악하기 위해 추가 테스트(제거 연구)를 수행했습니다. 기술적인 이유로 일부 모델을 더 적은 단계(60,000단계가 아닌 25,000단계)로 훈련해야 했다는 사실을 공유합니다.

전반적으로 이 백서에서는 2D 이미지에서 3D 이미지를 생성하기 위해 AI 모델을 학습시켜 이러한 이미지가 사실적이고 다양하며 실제 세계에서 볼 수 있는 것과 잘 일치하도록 하는 기술적 세부 사항에 중점을 둡니다.