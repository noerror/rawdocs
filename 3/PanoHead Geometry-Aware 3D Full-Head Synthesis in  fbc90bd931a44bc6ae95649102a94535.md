# PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360∘

[https://arxiv.org/abs/2303.13071](https://arxiv.org/abs/2303.13071)

[https://github.com/sizhean/panohead](https://github.com/sizhean/panohead)

[https://www.youtube.com/watch?v=Y8NXiBOEWoE](https://www.youtube.com/watch?v=Y8NXiBOEWoE)

[https://psh01087.github.io/K-Hairstyle/](https://psh01087.github.io/K-Hairstyle/) K-Hairstyle: A Large-scale Korean hairstyle dataset for virtual hair editing and hairstyle classificatio

[https://github.com/NVlabs/ffhq-dataset](https://github.com/NVlabs/ffhq-dataset) Flickr-Faces-HQ Dataset (FFHQ)

- Mar 2023

### 1. Introduction

컴퓨터 그래픽으로 실제와 같은 인물 사진을 만드는 것은 디지털 아바타, 텔레프레즌스, 게임 등의 잠재적인 응용 분야로 인해 컴퓨터 비전 및 그래픽 분야에서 중요한 초점이 되어 왔습니다. 최근 생성적 적대 신경망(GAN)의 발전으로 고품질 이미지 합성이 가능해졌지만, 이러한 모델 중 상당수는 기본 3D 장면을 고려하지 않고 2D로 작동합니다. 즉, 다양한 각도에서 3D 헤드 이미지를 생성할 때 일관성을 유지하는 데 어려움을 겪습니다.

다양한 외관을 가진 3D 헤드를 생성하는 기존 방법에는 광범위한 3D 스캔 컬렉션에서 학습한 텍스처 메시 모델이 필요합니다. 하지만 이러한 방식은 종종 미세한 디테일을 포착하지 못해 이미지의 품질과 표현력이 제한됩니다. 최근의 모델들은 이미지 합성을 위해 3D 장면 모델링과 GAN을 통합하기 시작하여 보다 사실적인 3D 인식 얼굴 이미지를 구현하고 있습니다. 하지만 이러한 모델은 종종 멀티뷰 이미지 또는 3D 스캔을 통해 감독을 받아야 하는데, 이는 획득하기 어렵고 출현 범위가 제한적입니다.

이 논문에서는 이러한 문제를 해결하기 위해 실제 세계의 비정형 이미지만을 사용하여 모든 각도에서 볼 수 있는 고품질의 풀 3D 헤드 합성을 생성할 수 있는 새로운 3D 인식 GAN인 PanoHead를 소개합니다. 이는 이러한 작업을 수행할 수 있는 최초의 3D GAN입니다.

하지만 파노헤드를 개발하는 과정에서 몇 가지 과제가 있었습니다. 많은 3D GAN은 전경(머리)과 배경을 분리할 수 없어 '2.5D' 헤드 지오메트리로 이어집니다. PanoHead는 2D 배경에서 3D 헤드를 분리하는 전경 인식 트라이 디스커네이터로 이를 극복합니다.

기존의 3D 씬 표현은 360° 카메라 포즈에 대한 투영 문제를 일으켜 머리 뒤쪽에 '거울 얼굴'이 나타나기도 합니다. PanoHead는 새로운 3D 트라이그리드 볼륨 표현으로 이 문제를 해결하여 머리의 앞면과 뒷면을 분리하는 동시에 효율성을 유지합니다.

마지막으로, 머리 뒤쪽의 카메라 뷰를 제대로 추정하는 것은 매우 까다롭고 매력적이지 않은 지오메트리와 이미지 노이즈를 유발합니다. PanoHead는 이러한 정렬 문제를 처리하기 위해 카메라의 렌더링 위치를 조정하는 2단계 이미지 정렬 프로세스를 제안합니다.

요약하자면, PanoHead는 모든 각도에서 볼 수 있는 고품질의 일관된 3D 헤드 이미지를 생성할 수 있는 최초의 3D GAN입니다. 새로운 3D 장면 표현, 헤드와 배경을 분리하는 시스템, 까다로운 카메라 뷰를 처리하는 2단계 이미지 정렬 프로세스를 통해 이전 방식을 개선했습니다.

### 2. Related Work

다양한 모양과 외관을 가진 다양한 3D 머리 표현을 생성하는 것은 이전 연구에서 일반적인 접근 방식이었습니다. 이러한 모델에는 3D 스캔에서 학습한 3DMM(3D 모퍼블 모델) 또는 FLAME 헤드 모델과 같은 파라메트릭 텍스처 메시 표현을 사용하는 경우가 많습니다. 그러나 이러한 방법은 앞면이나 두개골을 넘어서는 사실적인 외형과 지오메트리를 정확하게 표현하는 데 어려움을 겪습니다.

![우리의 프레임워크는 전경(foreground)-인식 생성기 G, 판별자 D, 그리고 신경 렌더러 R 세 가지 주요 구성 요소로 이루어져 있습니다. 매핑 네트워크는 먼저 잠재 코드 z와 조건화된 카메라 포즈 ccon을 중간 잠재 코드 w로 매핑합니다. 그런 다음 생성기 G는 w를 사용하여 3D 트리 그리드 표현 특징 f를 얻습니다. 신경 렌더러 R는 f와 렌더링 카메라 포즈 ccam을 사용하여 초해상도 이미지 I+, 양선형 업샘플링 이미지 I, 그리고 초해상도 마스크 Im+를 합성합니다. 마지막으로, 전경 인식 트리 판별자 D는 실제 이미지와 함께 (I+, I, Im+)를 비판합니다. 데이터 처리 파이프라인은 오른쪽에 나와 있습니다. 실제 이미지는 수정된 YOLO 경계 상자로 잘라내지만, 정확한 얼굴 랜드마크가 부족하기 때문에 종종 규모와 위치가 다릅니다. 카메라 자기 적응 스키마를 사용하면, 렌더링 카메라 포즈 ccam은 일관된 규모와 위치로 이미지를 생성하기 위해 스스로를 수정할 수 있습니다.](PanoHead%20Geometry-Aware%203D%20Full-Head%20Synthesis%20in%20%20fbc90bd931a44bc6ae95649102a94535/Untitled.png)

우리의 프레임워크는 전경(foreground)-인식 생성기 G, 판별자 D, 그리고 신경 렌더러 R 세 가지 주요 구성 요소로 이루어져 있습니다. 매핑 네트워크는 먼저 잠재 코드 z와 조건화된 카메라 포즈 ccon을 중간 잠재 코드 w로 매핑합니다. 그런 다음 생성기 G는 w를 사용하여 3D 트리 그리드 표현 특징 f를 얻습니다. 신경 렌더러 R는 f와 렌더링 카메라 포즈 ccam을 사용하여 초해상도 이미지 I+, 양선형 업샘플링 이미지 I, 그리고 초해상도 마스크 Im+를 합성합니다. 마지막으로, 전경 인식 트리 판별자 D는 실제 이미지와 함께 (I+, I, Im+)를 비판합니다. 데이터 처리 파이프라인은 오른쪽에 나와 있습니다. 실제 이미지는 수정된 YOLO 경계 상자로 잘라내지만, 정확한 얼굴 랜드마크가 부족하기 때문에 종종 규모와 위치가 다릅니다. 카메라 자기 적응 스키마를 사용하면, 렌더링 카메라 포즈 ccam은 일관된 규모와 위치로 이미지를 생성하기 위해 스스로를 수정할 수 있습니다.

최근에는 신경 암시적 함수가 3D 장면 표현을 위한 강력한 도구로 부상하고 있습니다. 신경 방사 필드(NeRF)는 복잡한 장면 디테일을 캡처하고 고유한 3D 일관성을 유지하면서 멀티뷰 이미지를 합성하는 기능으로 인해 디지털 헤드 모델링에 특히 많이 사용되고 있습니다. 이 논문에서는 멀티뷰 이미지 또는 비디오에서 사람별 NeRF를 최적화하는 이러한 방법과 달리, 구조화되지 않은 2D 단안 이미지에서 생성 NeRF를 구축할 것을 제안합니다.

EG3D의 3면 공식과 같은 하이브리드 3D 표현도 3D 장면 표현의 효율성과 품질로 인해 사용되어 왔습니다. 저자들은 3면 표현을 3그리드 표현으로 변환하여 3D 헤드 합성을 위한 더 나은 피처 임베딩을 제공함으로써 이를 더욱 발전시켰습니다.

2D 이미지 생성에서 GAN의 놀라운 발전을 3D로 확장하는 것을 목표로 하는 연구도 많이 진행되었습니다. 이러한 3D GAN은 2D 이미지에서 3D 표현을 학습하는 것을 목표로 합니다. Szabo 등의 초기 연구에서는 3D 표현으로 정점 위치 맵을 사용할 것을 제안했으며, Shi 등은 2D StyleGAN을 3D 생성 모델로 변환하기 위한 자체 감독 프레임워크를 제안했습니다. 다른 연구에서는 NeRF를 3D GAN에 통합했지만, 엄청난 계산 비용으로 인해 성능이 제한되었습니다.

이 연구의 기반이 된 EG3D는 효율적인 3D 표현을 생성하기 위해 2D GAN 백본을 활용하는 3면 표현을 도입했으며, 다른 3D 표현보다 뛰어난 성능을 보였습니다. 다른 연구에서도 생성된 3D 얼굴이나 신체를 조작할 수 있는 제어 가능한 3D GAN을 탐색하고 있습니다.

### 3. Methodology

PanoHead는 효율성과 합성 품질이 뛰어난 최첨단 3D 인식 생성적 적대 신경망(GAN)인 EG3D를 기반으로 구축된 모델입니다. PanoHead는 EG3D를 확장하여 360도 뷰 일관성 있는 헤드 이미지를 생성합니다. 그러나 이 작업에는 전경-배경 얽힘, 얼굴 아티팩트 미러링 문제, 일관되지 않은 뒷머리 이미지 크롭 등 몇 가지 과제가 있습니다.

![이중 식별(a) 및 전경 인식 삼중 식별(b, c)의 지오메트리 및 RGB 이미지. EG3D(a)는 배경을 분리하지 못합니다. 배경이 없는 지오메트리(b)와 배경 전환이 가능한 풀 헤드 이미지 합성(c)을 모두 제공하는 PanoHead의 삼분화(3분화)](PanoHead%20Geometry-Aware%203D%20Full-Head%20Synthesis%20in%20%20fbc90bd931a44bc6ae95649102a94535/Untitled%201.png)

이중 식별(a) 및 전경 인식 삼중 식별(b, c)의 지오메트리 및 RGB 이미지. EG3D(a)는 배경을 분리하지 못합니다. 배경이 없는 지오메트리(b)와 배경 전환이 가능한 풀 헤드 이미지 합성(c)을 모두 제공하는 PanoHead의 삼분화(3분화)

전경-배경 디커플링: 전경(머리)과 배경을 분리하기 위해 PanoHead는 배경 제너레이터와 트라이 디스커네이터를 도입했습니다. 배경 제너레이터는 다른 StyleGAN2 네트워크를 사용하여 2D 배경을 생성합니다. 볼륨 렌더링 중에 얻은 전경 마스크는 새로운 저해상도 이미지를 구성하는 데 사용됩니다. 트라이 디스크리네이터는 이 마스크를 RGB 이미지와 함께 사용하여 모델을 훈련함으로써 3D 풀 헤드 지오메트리를 형성할 때 학습 난이도를 줄입니다.

![Z축에서의 트라이플레인 (a)과 트라이그리드 (b) 아키텍처 비교. 트라이플레인에서는 두 점의 투영이 P XY 평면의 특징을 공유함으로써 표현의 모호성을 도입합니다. 트라이그리드에서는 위의 두 점의 특징이 두 개의 다른 평면에서 삼선형 보간되어 서로 다른 특징을 생성합니다.](PanoHead%20Geometry-Aware%203D%20Full-Head%20Synthesis%20in%20%20fbc90bd931a44bc6ae95649102a94535/Untitled%202.png)

Z축에서의 트라이플레인 (a)과 트라이그리드 (b) 아키텍처 비교. 트라이플레인에서는 두 점의 투영이 P XY 평면의 특징을 공유함으로써 표현의 모호성을 도입합니다. 트라이그리드에서는 위의 두 점의 특징이 두 개의 다른 평면에서 삼선형 보간되어 서로 다른 특징을 생성합니다.

트라이 그리드에서 피처 엉킴 제거: EG3D에서 사용되는 원래의 트라이 플레인 표현은 표현력이 제한적이며 미러링 얼굴 아티팩트가 발생할 수 있습니다. PanoHead는 이 문제를 완화하기 위해 고차원 트라이그리드 표현을 도입했습니다. 트라이 그리드에는 추가 깊이 차원이 포함되어 있어 앞면과 뒷면 헤드의 피처 표현을 분리합니다. 이를 통해 3D 씬 표현의 효율성을 유지하면서 표현력을 높일 수 있습니다.

![트라이플레인과 트라이그리드를 사용한 이미지 합성 (D = 3). 투영의 모호성으로 인해, 트라이플레인 표현 (a)은 좋은 품질의 앞면 이미지를 생성하지만 뒷면에 '거울처럼 반영된 얼굴'이 보이고, 반면에 우리의 트라이그리드 표현은 뒷머리의 고품질 외형과 기하학적 형상을 합성합니다 (b).](PanoHead%20Geometry-Aware%203D%20Full-Head%20Synthesis%20in%20%20fbc90bd931a44bc6ae95649102a94535/Untitled%203.png)

트라이플레인과 트라이그리드를 사용한 이미지 합성 (D = 3). 투영의 모호성으로 인해, 트라이플레인 표현 (a)은 좋은 품질의 앞면 이미지를 생성하지만 뒷면에 '거울처럼 반영된 얼굴'이 보이고, 반면에 우리의 트라이그리드 표현은 뒷머리의 고품질 외형과 기하학적 형상을 합성합니다 (b).

![카메라 자기 적응 스키마 없이 (a) 그리고 있음으로써 합성된 이미지 (b). 그것이 없으면, 모델은 정렬되지 않은 뒷머리 이미지를 생성하여 뒷머리에 결함이 있는 움푹 들어간 모양을 만듭니다.](PanoHead%20Geometry-Aware%203D%20Full-Head%20Synthesis%20in%20%20fbc90bd931a44bc6ae95649102a94535/Untitled%204.png)

카메라 자기 적응 스키마 없이 (a) 그리고 있음으로써 합성된 이미지 (b). 그것이 없으면, 모델은 정렬되지 않은 뒷머리 이미지를 생성하여 뒷머리에 결함이 있는 움푹 들어간 모양을 만듭니다.

자체 적응형 카메라 정렬: PanoHead는 이미지 정렬을 위해 2단계 프로세스를 사용합니다. 첫 번째 단계에서는 감지 가능한 얼굴 랜드마크가 있는 이미지에 표준 프로세싱을 사용하고 카메라 포즈가 큰 이미지에는 헤드 포즈 추정기를 사용합니다. 두 번째 단계에서는 모델이 각 훈련 이미지에 대한 볼륨 렌더링의 변환을 미세 조정하여 다양한 시각적 관찰에 걸쳐 정렬을 개선합니다. 이러한 자가 적응 방식을 통해 360도 뷰에서 실제와 같은 모양과 외관을 가진 일관된 헤드 합성을 구현할 수 있습니다.

![GRAF [37], GIRAFFEHD [48], StyleSDF [31], EG3D [5], 멀티뷰 지도 학습된 NeRF [43] (왼쪽에서 아래로 이어지는 다른 방법들), 그리고 우리의 PanoHead (오른쪽) 사이의 질적인 비교. [43]을 제외하면, 모든 모델들은 FFHQ-F에서 훈련되었습니다. 우리는 yaw 각도가 0, 45, 90, 135, 그리고 180◦ 인 결과를 렌더링합니다. GRAF, GIRAFFEHD, 그리고 StyleSDF는 지도되지 않은 카메라 포즈 메커니즘 때문에 잠재 공간에서 올바른 카메라 분포를 모델링하지 못하므로 뒤로 돌지 않습니다. EG3D는 '거울처럼 반영된 얼굴' 유물과 엉킨 배경과 함께 뒤로 돌 수 있습니다. 멀티뷰 지도 학습된 NeRF는 우리와 비교할 만하나, 하나의 사람에 대한 멀티뷰 데이터가 필요하며, 생성 모델이 아닙니다.](PanoHead%20Geometry-Aware%203D%20Full-Head%20Synthesis%20in%20%20fbc90bd931a44bc6ae95649102a94535/Untitled%205.png)

GRAF [37], GIRAFFEHD [48], StyleSDF [31], EG3D [5], 멀티뷰 지도 학습된 NeRF [43] (왼쪽에서 아래로 이어지는 다른 방법들), 그리고 우리의 PanoHead (오른쪽) 사이의 질적인 비교. [43]을 제외하면, 모든 모델들은 FFHQ-F에서 훈련되었습니다. 우리는 yaw 각도가 0, 45, 90, 135, 그리고 180◦ 인 결과를 렌더링합니다. GRAF, GIRAFFEHD, 그리고 StyleSDF는 지도되지 않은 카메라 포즈 메커니즘 때문에 잠재 공간에서 올바른 카메라 분포를 모델링하지 못하므로 뒤로 돌지 않습니다. EG3D는 '거울처럼 반영된 얼굴' 유물과 엉킨 배경과 함께 뒤로 돌 수 있습니다. 멀티뷰 지도 학습된 NeRF는 우리와 비교할 만하나, 하나의 사람에 대한 멀티뷰 데이터가 필요하며, 생성 모델이 아닙니다.

전반적으로 PanoHead는 3D 헤드 합성의 상당한 발전을 보여줌으로써 사실적이고 보기 일관적인 전체 헤드 이미지를 생성하는 데 따르는 문제를 해결합니다.

### 4. Experiments

이 섹션에서는 "PanoHead"라고 하는 새로운 생성적 적대 신경망(GAN) 모델에 대한 실험 설정과 결과에 대해 자세히 설명합니다. 이 모델은 FFHQ, K-헤어스타일, 자체 대형 포즈 헤드 이미지 컬렉션으로 구성된 결합된 데이터 세트인 FFHQ-F로 학습되었습니다. 이 모델은 GRAF, EG3D, StyleSDF, GIRAFFEHD를 포함한 다른 최신 3D 인식 GAN과 비교됩니다.

![PanoHead는 높은 품질의 완전한 머리 기하학을 달성하는 반면, StyleSDF [31]와 EG3D [5]는 3D 노이즈 또는 홀로된 머리를 생성합니다.](PanoHead%20Geometry-Aware%203D%20Full-Head%20Synthesis%20in%20%20fbc90bd931a44bc6ae95649102a94535/Untitled%206.png)

PanoHead는 높은 품질의 완전한 머리 기하학을 달성하는 반면, StyleSDF [31]와 EG3D [5]는 3D 노이즈 또는 홀로된 머리를 생성합니다.

![다른 카메라 포즈에서의 단일 뷰 재구성. 첫 번째 열은 타겟 이미지를 보여주고, 두 번째 열은 GAN 역변환을 사용하여 투영된 RGB 이미지와 재구성된 3D 형상을 보여줍니다. 마지막 두 열은 주어진 카메라 포즈에서 렌더링된 이미지를 보여줍니다.](PanoHead%20Geometry-Aware%203D%20Full-Head%20Synthesis%20in%20%20fbc90bd931a44bc6ae95649102a94535/Untitled%207.png)

다른 카메라 포즈에서의 단일 뷰 재구성. 첫 번째 열은 타겟 이미지를 보여주고, 두 번째 열은 GAN 역변환을 사용하여 투영된 RGB 이미지와 재구성된 3D 형상을 보여줍니다. 마지막 두 열은 주어진 카메라 포즈에서 렌더링된 이미지를 보여줍니다.

정성적 비교:

PanoHead 모델은 멀티뷰 일관성을 유지하면서 모든 카메라 포즈에 대해 사진처럼 사실적인 헤드 이미지를 생성하는 것으로 관찰되었습니다. 다양한 모습에서 세밀한 디테일이 살아있는 사실적인 이미지를 생성하여 기준 모델보다 월등히 뛰어난 성능을 보였습니다.
정량적 결과:

생성된 이미지의 시각적 품질, 충실도, 다양성은 프리쳇 시작 거리(FID), ID 유사성 점수(ID), 평균 제곱 오차(MSE) 등의 메트릭을 사용하여 평가됩니다.
PanoHead 모델은 이러한 메트릭에서 다른 기준선보다 일관되게 우수한 성능을 보이는 것으로 관찰되었습니다.
저자들은 360° 풀 헤드의 전반적인 생성 품질을 철저히 반영하지 못하는 기존 FID 지표의 한계를 해결하기 위해 새로운 지표인 FID-back을 제안합니다.

전경 인식 식별 기능을 추가하고 트라이 플레인에서 트라이 그리드 표현으로 변경했을 때 상당한 개선이 이루어졌음을 보여주기 위해 PanoHead 모델에 대한 제거 연구를 수행했습니다.

마지막으로, 단일 뷰 인물 사진에서 전체 머리 재구성을 위해 PanoHead 모델의 생성 잠재 공간을 사용합니다. 이 모델은 사실적인 이미지와 고충실도 지오메트리를 재구성하고 큰 포즈와 뒷모습을 포함한 360°의 새로운 뷰를 합성할 수 있습니다.

### 5. Discussion, Conclusion

저자들은 이러한 한계에 대해 언급하고 PanoHead 모델에 대한 향후 작업을 제안합니다:

한계점:

이 모델에는 여전히 사소한 아티팩트가 있으며, 특히 치아 영역에서 두드러집니다.
원본 EG3D와 유사하게 텍스처가 깜빡이는 문제가 있습니다.
이 모델에는 머리카락 끝과 같은 미세한 고주파 기하학적 디테일이 부족합니다.
성별, 인종, 외모 측면에서 다양한 이미지를 생성할 수 있지만, 제한된 데이터 세트 조합에 의존하기 때문에 데이터 편향이 발생합니다.
향후 작업:

StyleGAN3을 백본으로 사용하면 고빈도 디테일을 보존하는 데 도움이 될 수 있습니다.
뎁스 맵을 사용한 기하학적 품질의 정량적 평가.
대규모 풀헤드 주석이 달린 훈련 이미지 데이터 세트를 생성하여 풀헤드 합성 연구를 용이하게 하고 일부 제한 사항을 해결합니다.
또한 저자들은 특히 단일 뷰 인물 재구성의 경우 악의적인 목적으로 PanoHead가 오용될 수 있음을 인정하며 윤리적 고려 사항을 명시하고 있습니다. 이들은 타인의 권리를 침해하기 위해 이 방법을 사용하는 것을 권장하지 않습니다.

이러한 한계에도 불구하고 PanoHead는 단일 뷰 이미지를 사용하여 뷰 일관성 있는 전체 머리 이미지를 합성하는 새로운 3D GAN 프레임워크입니다. 저자들은 전경 인식 3분할, 3D 3분할 장면 표현, 자체 적응형 이미지 정렬이라는 혁신적인 설계를 통해 360°에서 진정한 멀티뷰 일관성 있는 풀헤드 이미지를 합성할 수 있다고 강조합니다. 그들은 PanoHead가 3D 인물 사진 제작의 새로운 방향을 제시하여 수많은 잠재적 다운스트림 작업에 대한 가능성을 열어준다고 믿습니다.

- 요약
    
    이 백서에서는 단일 뷰 이미지를 사용하여 뷰 일관성 있는 풀 헤드 이미지를 생성하도록 설계된 3D 생성적 적대 신경망(GAN) 프레임워크인 PanoHead라는 새로운 모델을 소개합니다. 다음은 논문을 단계별로 요약한 내용입니다:
    
    논문 소개 및 동기: 저자는 기존 모델이 모든 각도에서 사실적이고 일관된 머리 이미지를 합성하는 데 어려움을 겪고 있는 현재 3D GAN 환경의 격차를 파악하는 것으로 서두를 시작합니다. 저자는 이 문제에 대한 해결책으로 새로운 모델인 PanoHead를 제안합니다.
    
    데이터 세트와 기준선: 저자들은 훈련과 평가에 사용된 데이터세트(FFHQ, K-헤어스타일 데이터세트, 독점적인 대형 포즈 헤드 이미지 컬렉션)를 자세히 설명합니다. 또한 모델을 비교할 최신 3D 인식 GAN을 식별합니다.
    
    정성적 비교: 저자들은 다양한 각도에서 합성된 이미지의 시각적 품질에 대해 논의하며 PanoHead와 기준선을 비교합니다. 그 결과 PanoHead가 멀티뷰 일관성을 유지하면서 모든 카메라 포즈에 대해 뛰어난 사실적인 이미지를 생성한다는 사실을 발견했습니다.
    
    지오메트리 생성: 저자들은 여러 모델에서 추출한 기본 3D 지오메트리의 시각적 품질을 비교합니다. 그 결과 PanoHead가 배경이 없는 고충실도의 3D 헤드 지오메트리를 일관되게 생성한다는 사실을 발견했습니다.
    
    정량적 결과: 저자는 여러 지표를 사용하여 생성된 이미지의 시각적 품질, 충실도, 다양성, 멀티뷰 일관성을 정량적으로 평가했습니다. PanoHead는 이러한 지표에서 다른 모델보다 우수한 성능을 보였습니다.
    
    단일 뷰 GAN 반전: 저자는 PanoHead가 전체 머리 이미지를 재구성하고 단일 뷰 초상화에서 360° 뷰를 생성할 수 있음을 보여줍니다.
    
    절제 연구: 고품질 결과를 얻는 데 있어 각 요소의 중요성을 보여주는 PanoHead의 각 구성 요소의 영향을 정량화하기 위해 절제 연구를 수행합니다.
    
    한계점 및 향후 작업: 저자는 이미지의 사소한 아티팩트, 깜박이는 텍스처 문제, 미세한 기하학적 디테일 부족 등 PanoHead의 몇 가지 한계를 인정합니다. 저자들은 향후 작업을 위한 몇 가지 방법을 제안하는데, 여기에는 StyleGAN3를 백본으로 사용하고 뎁스 맵을 사용하여 기하학적 품질을 정량적으로 평가하는 방법이 포함됩니다.
    
    윤리적 고려 사항: 저자들은 PanoHead의 단일 뷰 인물 재구성 기능의 오용과 관련된 잠재적인 윤리적 문제를 강조합니다.
    
    결론: 이 백서에서는 특히 3D 초상화 제작 및 기타 관련 작업에서 PanoHead의 기여와 잠재적 영향에 대한 요약으로 마무리합니다.
    
- 영상요약
    
    PanoHead란 무엇인가요? PanoHead는 다양한 관점에서 이마를 세밀하고 사실적인 이미지로 생성하도록 훈련된 새로운 3D 모델(또는 생성적 적대 신경망 - GAN)입니다. 이전 모델에서는 불가능했던 360도 전체 이마 합성을 생성할 수 있다는 점이 독특합니다.
    
    PanoHead는 어떻게 작동하나요? PanoHead는 제너레이터, 판별기, 렌더러의 세 가지 주요 부분으로 구성되어 있습니다. 제너레이터는 머리의 3D 표현을 생성하고, 판별기는 합성의 품질을 개선하며, 렌더러는 최종 초고해상도 이미지를 생성합니다.
    
    PanoHead는 어떤 문제를 해결하나요? 기존의 많은 3D 모델은 다양한 각도에서 사실적이고 일관된 이미지를 생성하는 데 한계가 있습니다. 측면과 후면에서 어려움을 겪고 전경(머리)과 배경을 적절히 구분하지 못하는 경우가 많습니다. PanoHead는 이러한 문제를 해결합니다.
    
    트라이 그리드 포뮬레이션: 이 프레젠테이션에서는 기존의 트라이 플레인 방식을 확장한 '트라이 그리드 포뮬레이션'이라는 새로운 접근 방식을 소개하며, 이를 통해 모델이 머리의 3D 구조, 특히 이마를 더 잘 표현할 수 있도록 합니다. 이 방식은 모델에 깊이 차원을 추가하여 머리의 앞면과 뒷면 표현 사이의 혼동을 줄입니다.
    
    전경 인식 디스커네이터: 이 컴포넌트는 머리(전경)와 다른 모든 것(배경)을 구분하는 데 도움이 됩니다. 이 컴포넌트는 머리의 윤곽을 그리는 세그먼테이션 마스크를 사용하여 생성 프로세스를 안내합니다.
    
    카메라 포즈 자체 적응 모듈: 이 새로운 기능은 이미지가 완벽하게 정렬되지 않았을 때 불완전한 카메라 각도나 포즈를 조정하는 데 도움이 됩니다. 이 기능은 모델 내에서 가상 카메라 포즈를 조정하여 실제 이미지를 더 잘 표현합니다.
    
    PanoHead 활용: PanoHead는 다양한 용도로 사용할 수 있습니다. 예를 들어, 두 사람의 머리 구조의 서로 다른 부분을 결합하여 두 사람의 머리를 '매시업'하는 데 사용할 수 있습니다. 또 다른 용도로는 한 장의 정면 사진에서 누군가의 뒷모습을 재구성하는 데 사용할 수 있습니다.
    
    이 연구는 머신 러닝과 신경망을 사용하여 2D 이미지에서 3D 표현을 생성하는 연구 분야의 일부입니다. 이러한 모델은 영화, 게임, 가상 현실 등 다양한 산업 분야에서 점점 더 많이 사용되고 있습니다.
    
- 트라이 플레인과 트라이 그리드
    
    트라이 플레인: 트라이 플레인 표현은 세 개의 직교 평면을 사용하여 3D 정보를 캡처하고 설명합니다. 이 경우 일반적으로 XYZ 좌표계가 사용됩니다. 각 평면은 두 가지 차원에 해당합니다(예: XY, YZ, ZX 평면). 백서에 설명된 대로 이 접근 방식의 주요 한계는 표현 모호성의 가능성입니다. 즉, 서로 다른 두 점이 같은 평면에 투영될 때 해당 평면에서 동일한 특징을 공유하게 됩니다. 결과적으로 트라이 플레인 표현은 두 점 사이의 미묘한 차이를 포착할 수 없습니다.
    
    트라이 그리드: 트라이-그리드 표현은 트라이-플레인 방법을 확장하고 개선한 것입니다. 트라이 그리드 방식은 세 개의 평면 대신 전체 3D 공간에 걸쳐 있는 복셀 또는 볼륨 픽셀 그리드를 사용합니다. 이 3D 공간에 두 점을 투영하면 두 개의 다른 평면에서 특징이 삼선 보간되어 뚜렷한 특징을 생성합니다. 이렇게 하면 3D 공간의 모든 점이 고유한 표현을 가질 수 있으므로 3면 표현의 모호성 문제가 해결됩니다.
    
    이 논문에서는 이러한 차이가 이미지 합성에 어떤 영향을 미치는지 보여줍니다. 삼면 표현을 사용하면 모델은 고품질의 전면 얼굴 이미지를 생성하지만 표현 모호성으로 인해 머리 뒤쪽에 "거울 얼굴" 아티팩트가 생깁니다. 반면, 트라이 그리드 표현은 머리 뒤쪽의 고품질 이미지를 합성하여 머리의 모양과 형상을 효과적으로 캡처할 수 있습니다.