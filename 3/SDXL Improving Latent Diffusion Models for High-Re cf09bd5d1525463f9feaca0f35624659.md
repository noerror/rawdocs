# SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis

[https://arxiv.org/abs/2307.01952](https://arxiv.org/abs/2307.01952)

- Jul 2023

![Untitled](SDXL%20Improving%20Latent%20Diffusion%20Models%20for%20High-Re%20cf09bd5d1525463f9feaca0f35624659/Untitled.png)

저자들은 텍스트-이미지 합성을 위한 안정적 확산 모델의 새롭고 개선된 버전인 SDXL을 소개합니다. 이 버전은 더 큰 UNet 백본을 활용하며, 주로 더 많은 주의 블록과 더 큰 교차 주의 컨텍스트를 통해 모델 파라미터를 증가시킵니다. 이는 SDXL이 두 번째 텍스트 인코더를 사용하기 때문에 가능합니다. 이 외에도 몇 가지 혁신적인 컨디셔닝 체계가 도입되어 SDXL은 여러 종횡비에 걸쳐 학습됩니다. SDXL로 생성된 샘플의 시각적 품질을 더욱 향상시키기 위해 사후 이미지 대 이미지 기법을 활용하는 정제 모델도 사용됩니다. 그 결과 SDXL은 이전 버전의 Stable Diffusion에 비해 현저한 개선이 이루어졌으며, 블랙박스의 최첨단 이미지 생성기와 비교하여 경쟁력 있는 결과를 제공한다는 점이 강조되었습니다. 대규모 모델의 훈련과 평가에서 개방적인 연구와 투명성을 촉진하기 위해 저자는 코드와 모델 가중치에 액세스할 수 있도록 했습니다.

### 1 Introduction

지난 한 해 동안 심층 생성 모델링 영역, 특히 자연어, 오디오, 시각 미디어와 같은 영역에서 상당한 발전이 있었습니다. 이 보고서에서는 텍스트-이미지 확산 모델인 SDXL이라는 안정적 확산 모델의 향상된 버전을 소개합니다. 이 모델은 3D 분류, 이미지 편집, 데이터 증강, 음악 생성 등 다양한 분야의 최근 개발에 핵심적인 역할을 해왔습니다.

사용자 연구에 따르면 SDXL은 이전의 안정 확산 모델보다 성능이 훨씬 뛰어난 것으로 나타났습니다. SDXL의 향상된 성능은 다음과 같은 이유로 설명할 수 있습니다:

3배 더 커진 UNet 백본 구조,
추가 감독이 필요 없는 간단하면서도 효과적인 두 가지 새로운 컨디셔닝 기법, 그리고
출력의 시각적 품질을 향상시키는 별도의 확산 기반 개선 모델.
그러나 이 보고서는 또한 많은 최첨단 '블랙박스' 모델의 투명성 부족에 대한 업계 전반의 우려를 지적합니다. 이러한 모델은 폐쇄적인 아키텍처로 인해 재현성과 적절한 성능 검증을 허용하지 않는 경우가 많습니다. 이러한 개방성의 부족은 혁신을 저해하고 커뮤니티가 이러한 모델을 기반으로 구축하는 것을 방해할 수 있습니다. 또한 모델의 편견과 한계를 평가하기 어렵게 만들며, 이는 책임감 있는 모델 사용에 매우 중요합니다. 이에 따라 저자들은 이미지 생성 성능에서 이러한 블랙박스 모델과 경쟁할 수 있는 개방형 모델인 SDXL을 출시하게 되었습니다.

### 2 Improving Stable Diffusion

이 보고서에서는 SDXL을 만들면서 안정적 확산 아키텍처에 적용된 다양한 개선 사항을 자세히 설명합니다. 이러한 개선 사항은 모듈식이며 개별적으로 또는 여러 모델에서 함께 구현할 수 있습니다.

2.1 아키텍처 및 규모: 확산 기반 이미지 합성에 널리 사용되어 온 UNet 아키텍처는 셀프 어텐션, 향상된 업스케일링 레이어, 교차 어텐션, 트랜스포머 기반 아키텍처 등 다양한 기능을 통합하여 지속적으로 발전해 왔습니다. SDXL의 경우, 저자들은 가장 높은 기능 레벨의 블록을 건너뛰고 낮은 레벨에 더 많은 블록을 추가하는 등 UNet 내에 트랜스포머 블록을 고르지 않게 분산시켰습니다. 또한 텍스트 컨디셔닝을 위해 더 강력한 사전 학습된 텍스트 인코더를 사용했습니다. 그 결과 UNet의 모델 크기는 26억 개의 파라미터가 되었고, 텍스트 인코더의 총 파라미터 크기는 8억 1,700만 개에 달했습니다.

![왼쪽: SDXL과 Stable Diffusion 1.5 & 2.1 사이의 사용자 선호도 비교. SDXL은 이미 Stable Diffusion 1.5 & 2.1을 확실히 앞섰으며, 추가적인 정제 단계를 추가함으로써 성능이 향상되었습니다. 오른쪽: 두 단계 파이프라인 시각화: 우리는 SDXL을 사용하여 초기 잠재 변수들을 128 × 128 크기로 생성합니다. 이후에, 우리는 특수화된 고해상도 정제 모델을 사용하고 SDEdit [28]를 첫 번째 단계에서 생성된 잠재 변수에 동일한 프롬프트를 사용하여 적용합니다. SDXL과 정제 모델은 동일한 자동 인코더를 사용합니다.](SDXL%20Improving%20Latent%20Diffusion%20Models%20for%20High-Re%20cf09bd5d1525463f9feaca0f35624659/Untitled%201.png)

왼쪽: SDXL과 Stable Diffusion 1.5 & 2.1 사이의 사용자 선호도 비교. SDXL은 이미 Stable Diffusion 1.5 & 2.1을 확실히 앞섰으며, 추가적인 정제 단계를 추가함으로써 성능이 향상되었습니다. 오른쪽: 두 단계 파이프라인 시각화: 우리는 SDXL을 사용하여 초기 잠재 변수들을 128 × 128 크기로 생성합니다. 이후에, 우리는 특수화된 고해상도 정제 모델을 사용하고 SDEdit [28]를 첫 번째 단계에서 생성된 잠재 변수에 동일한 프롬프트를 사용하여 적용합니다. SDXL과 정제 모델은 동일한 자동 인코더를 사용합니다.

2.2 마이크로 컨디셔닝: 이 섹션에서는 두 가지 컨디셔닝 기법을 소개합니다:

이미지 크기에 따른 컨디셔닝: 저자는 작은 이미지를 폐기하거나 업스케일링하는 대신(업스케일링 아티팩트가 발생할 수 있음) 원본 이미지 해상도에 따라 모델을 컨디셔닝할 것을 제안합니다. 이 정보는 훈련 중에 사용할 수 있으므로 사용자가 추론 중에 원하는 이미지 해상도를 설정할 수 있습니다. 이 접근 방식은 ImageNet FID 및 IS 메트릭 모두에서 기준 모델을 개선합니다.

![사전 학습 데이터셋의 높이 대 너비 분포. 제안된 크기 조절 없이는, 가장자리 길이가 256 픽셀보다 작아서 데이터의 39%가 버려질 것입니다. 이는 점선으로 표시된 검은 선으로 시각화되었습니다. 각 시각화된 셀의 색상 강도는 샘플 수에 비례합니다.](SDXL%20Improving%20Latent%20Diffusion%20Models%20for%20High-Re%20cf09bd5d1525463f9feaca0f35624659/Untitled%202.png)

사전 학습 데이터셋의 높이 대 너비 분포. 제안된 크기 조절 없이는, 가장자리 길이가 256 픽셀보다 작아서 데이터의 39%가 버려질 것입니다. 이는 점선으로 표시된 검은 선으로 시각화되었습니다. 각 시각화된 셀의 색상 강도는 샘플 수에 비례합니다.

자르기 매개변수에 대한 조건: 이미지 훈련 중 자르기 효과에 대응하기 위해 저자는 자르기 좌표에 대한 컨디셔닝을 제안합니다. 이 방법은 추론 중에 자르기 효과를 제어하는 데 도움이 되며, 크기 조절과 결합하여 성능을 향상시킬 수 있습니다.

![크기 조절을 변화시키는 효과: 우리는 같은 무작위 시드에서 4개의 샘플을 SDXL에서 그린 후 각 열 위에 표시된 것처럼 크기 조절을 변화시킵니다. 크기를 더 크게 조절할수록 이미지 품질이 확실히 향상됩니다. 5122 모델에서 샘플을 뽑아보세요. 참고: 이 시각화를 위해 512 × 512 픽셀 기본 모델을 사용합니다 (Sec. 2.5 참조), 크기 조절의 효과가 1024 × 1024 피니튜닝 전에 더 명확하게 보이기 때문입니다. 확대해서 보는 것이 좋습니다.](SDXL%20Improving%20Latent%20Diffusion%20Models%20for%20High-Re%20cf09bd5d1525463f9feaca0f35624659/Untitled%203.png)

크기 조절을 변화시키는 효과: 우리는 같은 무작위 시드에서 4개의 샘플을 SDXL에서 그린 후 각 열 위에 표시된 것처럼 크기 조절을 변화시킵니다. 크기를 더 크게 조절할수록 이미지 품질이 확실히 향상됩니다. 5122 모델에서 샘플을 뽑아보세요. 참고: 이 시각화를 위해 512 × 512 픽셀 기본 모델을 사용합니다 (Sec. 2.5 참조), 크기 조절의 효과가 1024 × 1024 피니튜닝 전에 더 명확하게 보이기 때문입니다. 확대해서 보는 것이 좋습니다.

두 가지 컨디셔닝 방법 모두 추가 데이터 전처리 없이 훈련 중에 온라인 방식으로 활용할 수 있어 이미지 합성 제어 및 개선을 위한 실용적이고 효과적인 솔루션을 제공합니다.

![SDXL의 출력과 이전 버전의 Stable Diffusion의 출력을 비교합니다. 각 프롬프트에 대해, 우리는 각 모델의 50단계 DDIM 샘플러 [46]와 cfg-scale 8.0 [13]에 대한 3개의 무작위 샘플을 보여줍니다. 추가 샘플은 Fig. 14에서 확인할 수 있습니다.](SDXL%20Improving%20Latent%20Diffusion%20Models%20for%20High-Re%20cf09bd5d1525463f9feaca0f35624659/Untitled%204.png)

SDXL의 출력과 이전 버전의 Stable Diffusion의 출력을 비교합니다. 각 프롬프트에 대해, 우리는 각 모델의 50단계 DDIM 샘플러 [46]와 cfg-scale 8.0 [13]에 대한 3개의 무작위 샘플을 보여줍니다. 추가 샘플은 Fig. 14에서 확인할 수 있습니다.

2.3 다중 관점 훈련: 저자들은 정사각형인 텍스트-이미지 모델의 일반적인 출력 해상도는 가로 또는 세로 형식 화면의 광범위한 사용과 같은 실제 데이터 세트에서 이미지 모양의 자연스러운 분포를 반영하지 못한다고 지적합니다. 따라서 다각도 훈련 접근 방식을 제안합니다.

![Sec. 2.2에서 논의된 것처럼 크롭 조절을 변화시킵니다. SD 1.5와 SD 2.1의 샘플은 이 매개변수에 대한 명시적인 제어를 제공하지 않으므로 크롭 아티팩트를 도입합니다. 5122 모델에서 샘플을 뽑아보세요. Sec. 2.5 참조.](SDXL%20Improving%20Latent%20Diffusion%20Models%20for%20High-Re%20cf09bd5d1525463f9feaca0f35624659/Untitled%205.png)

Sec. 2.2에서 논의된 것처럼 크롭 조절을 변화시킵니다. SD 1.5와 SD 2.1의 샘플은 이 매개변수에 대한 명시적인 제어를 제공하지 않으므로 크롭 아티팩트를 도입합니다. 5122 모델에서 샘플을 뽑아보세요. Sec. 2.5 참조.

이를 구현하기 위해 데이터는 각각 다른 종횡비를 가진 버킷으로 나뉩니다. 각 버킷의 픽셀 수는 가능한 한 1024^2 픽셀에 가깝게 유지되며, 높이와 너비는 64의 배수로 변화합니다. 최적화 중에 훈련 배치는 동일한 버킷의 이미지로 구성되며, 각 훈련 단계마다 버킷 크기가 번갈아 가며 변경됩니다. 모델은 버킷 크기를 컨디셔닝 변수로 받아 앞서 설명한 크기 및 자르기 컨디셔닝 방법과 유사한 방식으로 푸리에 공간에 임베드합니다.

이 다중 종횡비 훈련은 고정 종횡비 및 해상도로 모델을 사전 훈련한 후 미세 조정 단계로 적용됩니다. 앞서 설명한 컨디셔닝 기법을 채널 축을 따라 연결하여 결합합니다. 크롭 컨디셔닝과 다각도 훈련은 상호 보완적인 작업이며, 크롭 컨디셔닝은 일반적으로 64픽셀인 버킷 경계 내에서만 작동합니다.

2.4 개선된 자동 인코더: 저자들은 LDM(잠복 확산 모델)인 안정적 확산이 자동 인코더의 사전 학습된 고정 잠복 공간에서 어떻게 작동하는지에 대해 설명합니다. 자동 인코더를 개선하여 생성된 이미지의 국부적인 고주파 디테일을 개선할 수 있다고 제안합니다. 이를 위해 원래의 Stable Diffusion에 사용된 것과 동일한 자동 인코더 아키텍처를 더 큰 배치 크기로 훈련하고 지수 이동 평균을 통한 가중치 추적 기능을 추가했습니다. 이렇게 개선된 자동 인코더는 모든 평가된 재구성 지표에서 원래 모델보다 더 나은 성능을 보였으며 저자의 모든 실험에 사용되었습니다.

2.5 모든 것을 종합하기: 최종 모델인 SDXL은 다단계 절차를 통해 훈련됩니다. 개선된 자동 인코더와 1000단계의 이산 시간 확산 스케줄을 사용합니다. 처음에는 내부 데이터 세트에서 크기 및 자르기 조절을 사용하여 256×256픽셀의 해상도와 2048배치 크기로 600,000개의 최적화 단계에 대해 기본 모델을 사전 학습합니다. 추가로 20만 개의 최적화 단계를 위해 512 × 512픽셀 이미지로 훈련을 계속합니다. 마지막으로 다중 종횡비 훈련과 0.05의 오프셋 노이즈 레벨을 적용하여 약 1024×1024픽셀의 다양한 종횡비로 모델을 훈련합니다.

샘플의 품질을 향상시키기 위해 저자는 동일한 잠재 공간에서 고품질, 고해상도 데이터에 특화된 별도의 LDM을 훈련합니다. 여기에는 기본 모델의 샘플에 노이즈 제거 프로세스가 사용됩니다. 이 개선 모델은 처음 200개의 이산 노이즈 스케일에 특화되어 있습니다. 추론하는 동안 기본 SDXL 모델의 잠상이 렌더링되고 정제 모델을 통해 잠상 공간에서 직접 확산 및 노이즈 제거됩니다.

모델의 성능을 평가하기 위해 사용자 연구를 실시했으며, 참가자들은 네 가지 모델 중에서 가장 마음에 드는 세대를 선택했습니다: SDXL, SDXL(리파이너 포함), 안정적 확산 1.5, 안정적 확산 2.1. 정제 단계가 포함된 SDXL 모델이 가장 높은 평가를 받았으며, Stable Diffusion 1.5 및 2.1을 크게 앞질렀습니다. 그러나 FID 및 CLIP 점수와 같은 기존의 성능 지표는 이전 방법에 비해 SDXL의 개선 사항을 반영하지 못했으며, 이는 Kirstain 등의 연구 결과와 일치하고 이를 뒷받침합니다.

![10242 샘플들 (확대 이미지 포함)을 SDXL에서 정제 모델 없이 (왼쪽) 및 정제 모델과 함께 (오른쪽) 생성합니다. 프롬프트: "오션에 침몰한 뉴욕 시티의 웅장한 장거리 도시 풍경 사진과 과도하게 성장한 빌딩들과 정글 폐허들이 비가 오는 숲에 가려져 있으며, 해질 무렵에 찍은 영화 같은 촬영, 세부적으로 잘 묘사된, 8k, 황금빛 빛". 추가 샘플은 Fig. 13에서 확인할 수 있습니다.](SDXL%20Improving%20Latent%20Diffusion%20Models%20for%20High-Re%20cf09bd5d1525463f9feaca0f35624659/Untitled%206.png)

10242 샘플들 (확대 이미지 포함)을 SDXL에서 정제 모델 없이 (왼쪽) 및 정제 모델과 함께 (오른쪽) 생성합니다. 프롬프트: "오션에 침몰한 뉴욕 시티의 웅장한 장거리 도시 풍경 사진과 과도하게 성장한 빌딩들과 정글 폐허들이 비가 오는 숲에 가려져 있으며, 해질 무렵에 찍은 영화 같은 촬영, 세부적으로 잘 묘사된, 8k, 황금빛 빛". 추가 샘플은 Fig. 13에서 확인할 수 있습니다.

### 3 Future Work

단일 단계 생성:현재 SDXL의 최고 품질 샘플은 추가 정제 모델을 사용하는 2단계 접근 방식을 사용하여 생성됩니다.이 프로세스는 두 개의 큰 모델을 메모리에 로드해야 하므로 접근성 및 샘플링 속도에 영향을 미칩니다. 향후 연구에서는 단일 단계 모델을 사용하여 동등하거나 더 나은 품질의 결과를 생성하는 방법을 찾는 데 중점을 두어야 합니다.

텍스트 합성:모델의 텍스트 렌더링 기능은 더 커진 규모와 OpenCLIP ViT-bigG 텍스트 인코더의 도입으로 크게 향상되었습니다. 향후 개선 사항에는 바이트 수준 토큰화기 통합 또는 단순히 모델을 더 큰 크기로 확장하여 텍스트 합성을 더욱 개선하는 것이 포함될 수 있습니다.

아키텍처:이 작업에서는 UViT 및 DiT와 같은 트랜스포머 기반 아키텍처를 간략하게 살펴봤지만 즉각적인 이점을 제공하지는 못했습니다. 그러나 저자는 하이퍼파라미터를 신중하게 조정하면 이러한 아키텍처를 더 효과적으로 만들 수 있을 것으로 낙관하고 있습니다.

증류:기존 안정 확산 모델에 비해 개선된 점은 상당하지만, VRAM 사용량과 샘플링 속도 측면에서 추론 비용이 증가합니다.향후 연구는 추론에 필요한 컴퓨팅 리소스를 줄이고 샘플링 속도를 높이는 데 초점을 맞춰야 합니다. 이는 지도 기반, 지식 기반, 점진적 증류와 같은 기법을 통해 달성할 수 있을 것입니다.

모델 훈련:현재 모델은 이산 시간 공식을 사용하여 훈련되며, 미학적으로 만족스러운 결과를 얻기 위해 오프셋 노이즈가 필요합니다.Karras 등의 EDM 프레임워크는 향후 모델 학습을 위한 유망한 후보로 제안되었습니다. 이 프레임워크는 연속 시간 공식으로 샘플링 유연성을 높이고 노이즈 스케줄 보정이 필요하지 않습니다.

### Appendix

A 감사의 말

B 한계점

주목할 만한 성과에도 불구하고 이 모델은 책임감 있는 사용과 추가 개선을 위해 인식해야 할 내재적 한계를 가지고 있습니다:사진 속 구조의 복잡성과 높은 편차로 인해 사람의 손과 같은 복잡한 구조를 렌더링하는 데 어려움이 있습니다.이는 추가적인 모델 스케일링과 전문화된 훈련 기술의 필요성을 강조합니다.

![SDXL의 실패 사례. Stable Diffusion의 이전 버전에 비해 크게 개선되었지만, 모델은 때때로 세부적인 공간 배치와 세부적인 설명이 포함된 매우 복잡한 프롬프트에 어려움을 겪습니다 (예: 왼쪽 위 예제). 또한, 손은 아직 항상 정확하게 생성되지 않습니다 (예: 왼쪽 위) 그리고 모델은 때때로 두 개념이 서로에게 흘러 들어가는 것으로 고통받습니다 (예: 오른쪽 아래 예제). 모든 예제들은 50단계의 DDIM 샘플러 [46]와 cfg-scale 8.0 [13]를 사용하여 무작위로 생성된 샘플입니다.](SDXL%20Improving%20Latent%20Diffusion%20Models%20for%20High-Re%20cf09bd5d1525463f9feaca0f35624659/Untitled%207.png)

SDXL의 실패 사례. Stable Diffusion의 이전 버전에 비해 크게 개선되었지만, 모델은 때때로 세부적인 공간 배치와 세부적인 설명이 포함된 매우 복잡한 프롬프트에 어려움을 겪습니다 (예: 왼쪽 위 예제). 또한, 손은 아직 항상 정확하게 생성되지 않습니다 (예: 왼쪽 위) 그리고 모델은 때때로 두 개념이 서로에게 흘러 들어가는 것으로 고통받습니다 (예: 오른쪽 아래 예제). 모든 예제들은 50단계의 DDIM 샘플러 [46]와 cfg-scale 8.0 [13]를 사용하여 무작위로 생성된 샘플입니다.

이 모델은 완벽한 포토리얼리즘을 구현하지 못하여 미묘한 조명 효과나 미세한 텍스처 변화를 포착하지 못하는 경우도 있습니다.

모델 학습에 사용되는 대규모 데이터 세트는 의도치 않게 사회적, 인종적 편견을 도입할 수 있으며, 이러한 편견은 이미지를 생성할 때 증폭될 수 있습니다.

서로 다른 시각적 요소가 의도치 않게 합쳐지거나 겹치는 '컨셉 블리딩' 사례는 사전 학습된 텍스트 인코더에 잠재적인 결함이 있음을 나타냅니다.

길고 읽기 쉬운 텍스트를 렌더링하는 데 어려움이 있어 모델의 텍스트 생성 기능을 개선해야 할 필요성을 시사합니다.
C 확산 모델

이 섹션에서는 확산 모델(DM)에 대한 간결한 요약을 제공합니다.연속 시간 DM 프레임워크에 대해 설명하고, 모델이 가우시안 노이즈를 활용하고 반복적인 노이즈 제거 프로세스를 따르는 방법을 자세히 설명합니다.확률 흐름 일반 미분 방정식(ODE)과 확률 미분 방정식(SDE)의 수치 시뮬레이션에 대해 설명합니다.점수 함수에 대한 모델 학습의 역할을 강조하면서 DM의 훈련에 대해 설명합니다.노이즈 제거 점수 매칭을 통해 모델을 훈련할 수 있습니다.

마지막으로, DM의 반복 샘플링 프로세스를 컨디셔닝 신호로 안내하는 데 사용되는 기술인 분류기 없는 안내의 개념이 소개됩니다.이는 조건부 모델과 비조건부 모델의 예측을 혼합하여 수행됩니다.

E Midjourney v5.1과 비교 저자들은 PartiPrompts(P2) 벤치마크를 사용한 사용자 연구에서 SDXL 모델을 최첨단 텍스트-이미지 생성 플랫폼인 Midjourney v5.1과 비교했습니다. 이 벤치마크는 다양하고 까다로운 프롬프트에 대한 대규모 텍스트-이미지 모델을 비교하기 위해 설계되었습니다.연구 결과, 프롬프트 준수 측면에서 Midjourney보다 SDXL이 약간 더 선호되는 것으로 나타났습니다. 6개 카테고리 중 4개 카테고리에서 SDXL이 Midjourney를 능가했으며, 10개 과제 중 7개 과제에서는 두 모델 간에 큰 차이가 없거나 SDXL이 Midjourney를 능가하는 것으로 나타났습니다.F 제너레이티브 텍스트-이미지 기반 모델의 FID 평가에 관하여저자들은 제너레이티브 텍스트-이미지 모델을 평가할 때 프리셰트 시작 거리(FID)와 CLIP 점수를 사용할 때의 한계에 대해 논의합니다.시각적 구성뿐만 아니라 심층적인 텍스트 이해, 고유한 예술적 스타일 간의 세밀한 구분, 시각적 미학을 목표로 하는 기초 텍스트-이미지 모델이 개발됨에 따라 이러한 평가 방법이 의문을 갖게 되었다고 주장합니다. 인간 평가자가 평가한 SDXL의 성능은 크게 개선되었지만, FID 점수는 이전 SD 버전보다 높지 않아 추가적인 정량적 성능 점수가 필요하다는 것을 나타냅니다.

G 단일 단계와 2단계 SDXL 파이프라인 간의 추가 비교

이 섹션에서는 단일 단계와 2단계 SDXL 파이프라인 간의 비교에 대해 자세히 설명합니다.

H SD 1.5와 SD 2.1, SDXL의 비교

이 섹션에서는 서로 다른 버전의 모델인 SD 1.5, SD 2.1 및 SDXL을 자세히 비교합니다.I 멀티-스펙트 트레이닝 하이퍼파라미터

이 부분에서는 본문의 2.3절에 설명된 기술인 혼합 종횡비 미세 조정에 사용되는 이미지 해상도에 대해 자세히 설명합니다.