# TexDreamer: Towards Zero-Shot High-Fidelity 3D Human Texture Generation

[https://ggxxii.github.io/texdreamer/](https://ggxxii.github.io/texdreamer/)

[https://arxiv.org/abs/2403.12906](https://arxiv.org/abs/2403.12906)

## 1. Introduction

![왼쪽: ATLAS 데이터셋 개요. ATLAS는 현재까지 가장 큰 고해상도(1,024 × 1,024) 3D 인간 텍스처 데이터셋으로, 실제와 가상 아이덴티티를 포함한 텍스트 설명과 함께 제공됩니다. 오른쪽: TexDreamer의 기본 구조. 텍스트와 이미지 입력을 모두 지원하는 최초의 제로샷 고충실도 인간 텍스처 생성 방법입니다](TexDreamer%20Towards%20Zero-Shot%20High-Fidelity%203D%20Huma%20d4a9d86108184715a93b0f15d5480dbb/Untitled.png)

왼쪽: ATLAS 데이터셋 개요. ATLAS는 현재까지 가장 큰 고해상도(1,024 × 1,024) 3D 인간 텍스처 데이터셋으로, 실제와 가상 아이덴티티를 포함한 텍스트 설명과 함께 제공됩니다. 오른쪽: TexDreamer의 기본 구조. 텍스트와 이미지 입력을 모두 지원하는 최초의 제로샷 고충실도 인간 텍스처 생성 방법입니다

겹침, 스트레칭을 최소화하여 3D 모델에 정확한 텍스처를 적용할 수 있게 해줍니다. UV 맵은 영화 제작, 게임, 가상 현실 등 다양한 산업 분야에서 널리 사용되지만, 고품질 텍스처를 얻기 위해서는 많은 시간과 노력이 필요합니다. 현재의 그래픽 제작에서는 고가의 3D 스캐너와 숙련된 텍스처 페인팅 아티스트가 필요하며, 이는 복잡한 캡처 시스템과 전문 소프트웨어를 요구합니다.

최근의 텍스트-이미지 변환 기술 발전으로 텍스트 설명만으로 3D 인간 모델을 직접 생성할 수 있게 되었지만, 이 방법들은 텍스처 품질이 제한되고 처리 시간이 많이 걸리는 단점이 있습니다. 또 다른 접근법으로는 2D 이미지를 사용하여 3D 인간을 텍스처링하는 것이 있습니다. 단일 이미지로부터 텍스처를 예측하는 것은 가시적인 부분과 보이지 않는 부분의 정확한 맵핑과 보완을 필요로 하여 어려움이 있습니다.

이 문제를 해결하기 위해, 우리는 텍스트와 이미지를 사용하여 고품질 3D 인간 텍스처를 생성하는 최초의 제로샷 멀티모달 방법인 TexDreamer를 소개합니다. TexDreamer는 효율적인 텍스처 적응 미세 조정과 특징 번역기를 통해 텍스트와 이미지에서 UV 텍스처를 생성합니다. 또한, 우리는 50,000개의 고해상도 3D 인간 텍스처를 포함하는 ATLAS 데이터셋을 제안하며, 이는 풍부한 텍스트 설명과 함께 다양한 캐릭터 아이덴티티를 제공합니다. TexDreamer는 텍스트 일관성과 UV 품질 측면에서 기존 방법들을 능가하는 성능을 보여줍니다.

## 2. Related Work

![합성 데이터 생성 파이프라인. 왼쪽: 샘플 텍스처 획득. 먼저, 다중 뷰 이미지를 사용하여 UV를 최적화하는 분화 렌더를 사용한 후, 프로젝션 페인팅으로 이를 더욱 정제합니다. 획득한 샘플 텍스처와 프롬프트는 TexDreamer의 T2UV 훈련에 사용됩니다. 오른쪽: 다양한 텍스처의 인간 합성. ChatGPT의 도움을 받아 T2UV를 사용해 5만 개의 인간 텍스처를 생성합니다. 인간 이미지는 애니메이션 시퀀스, 배경 이미지, HDR 조명 및 원근 카메라로 렌더링됩니다. 주황색 별은 ATLAS 데이터셋에 포함된 데이터를 나타냅니다.](TexDreamer%20Towards%20Zero-Shot%20High-Fidelity%203D%20Huma%20d4a9d86108184715a93b0f15d5480dbb/Untitled%201.png)

합성 데이터 생성 파이프라인. 왼쪽: 샘플 텍스처 획득. 먼저, 다중 뷰 이미지를 사용하여 UV를 최적화하는 분화 렌더를 사용한 후, 프로젝션 페인팅으로 이를 더욱 정제합니다. 획득한 샘플 텍스처와 프롬프트는 TexDreamer의 T2UV 훈련에 사용됩니다. 오른쪽: 다양한 텍스처의 인간 합성. ChatGPT의 도움을 받아 T2UV를 사용해 5만 개의 인간 텍스처를 생성합니다. 인간 이미지는 애니메이션 시퀀스, 배경 이미지, HDR 조명 및 원근 카메라로 렌더링됩니다. 주황색 별은 ATLAS 데이터셋에 포함된 데이터를 나타냅니다.

3D 인간 모델과 텍스처 생성에 관련된 기존 연구들을 검토하면, 다양한 접근 방식과 데이터셋이 사용되어 왔습니다. 고정밀 3D 스캔 데이터셋은 가장 정확하지만 획득하는 데 많은 시간과 비용이 듭니다. 예를 들어, 다중 카메라와 능동 스테레오 시스템을 사용하여 고해상도의 전신 인간 스캔을 얻는 연구들이 있습니다. 의류를 별도로 예측하는 연구들도 있으며, 이는 복잡한 하드웨어와 높은 비용을 피하기 위해 신경망을 사용하여 단안 RGB 비디오로부터 직접 3D 인간을 재구성하는 시도들을 포함합니다. 그러나 이러한 데이터셋들은 종종 많은 정점과 비구조적 그리드를 포함하고 있어 텍스처 맵을 얻기 어렵습니다.

비디오 데이터셋은 다중 뷰 정보를 제공하지만, 대부분 3D 정보를 포함하지 않으며, 일부 연구는 2D 이미지 애니메이션을 직접 사용하여 3D 인간을 재구성하려고 시도합니다. 몇몇 연구는 단일 이미지로부터 3D 인간을 재구성하는데 집중하며, 이들 데이터셋은 제한된 수의 UV 텍스처만 포함합니다. 예를 들어, SURREAL 데이터셋은 921개의 UV 텍스처를 제공하지만, 개인정보 보호 정책으로 인해 동일한 평균 얼굴을 사용합니다. 다른 연구들은 스캔 데이터를 구매하여 텍스처 데이터셋을 구축하는 데 많은 시간과 비용이 듭니다.

텍스트를 이용한 텍스처 생성 연구는 최근 큰 주목을 받았습니다. 사람 중심의 최적화 방법은 3D 아바타 생성을 위해 SMPL 선행 지식을 사용하여 텍스처를 생성하지만, 텍스처 품질이 제한적입니다. 제로샷 추론 방법은 3D 객체의 텍스처링에서 큰 진전을 보였으며, 특히 PBR 재질을 사용하여 사실적인 외관 모델링을 달성합니다. 텍스처 생성에서 텍스트와 이미지를 모두 사용하는 방법은 제한된 수의 훈련 데이터를 사용하여 텍스처를 생성하는데, 이는 일반화 능력이 부족하여 텍스처 품질이 떨어질 수 있습니다.

이미지를 이용한 텍스처 생성 연구들은 주로 GAN 기반 네트워크를 사용하여 UV 텍스처를 생성합니다. Texformer는 트랜스포머 기반 네트워크를 사용하여 2D 인간 신체 분할을 SMPL UV 텍스처와 정렬하며, 다른 연구들은 부분 기반 분할과 크로스뷰 일관성을 강조합니다. Stylepeople은 GAN의 비결합 잠재 공간을 도입하여 숨겨진 부분을 재구성하지만, 불완전한 생성 모델로 인해 비합리적인 결과를 초래할 수 있습니다. 일부 연구는 이 작업을 인페인팅 문제로 간주하고, DensePose 부분 분할을 사용하여 텍스처 맵을 완성합니다. TexDreamer는 이러한 기존 방법들과 달리, 텍스트와 이미지를 더 효과적으로 연결하기 위해 특징 번역기를 사용하여 인간 이미지와 UV 텍스처 특징을 정렬합니다.

## 3. ATLAS Dataset

ATLAS 데이터셋은 TexDreamer 훈련을 위해 설계된 대규모 고해상도 인간 텍스처 데이터셋입니다. 이 데이터셋은 3D 인간 텍스처 생성을 위한 중요한 리소스를 제공하며, 특히 1,024×1,024 해상도의 50,000개 고품질 텍스처를 포함하고 있습니다. 각 텍스처는 SMPL UV 공간에 맞춰져 있으며, 상세한 텍스트 설명과 짝을 이루고 있어 다양한 캐릭터 아이덴티티를 제공합니다.

### **3.1 샘플 텍스처 획득**

전통적으로 잘 구조화된 인간 UV 텍스처를 얻기 위해서는 스캔 데이터를 등록하거나 예술가들이 직접 텍스처를 그려야 합니다. 이를 넘어서기 위해, 우리는 다중 뷰 이미지를 활용하여 대략적인 인간 UV를 최적화하고 프로젝트 페인팅 기법을 통해 이를 정제하는 UV 투사 방법을 제안합니다. 이 과정에서 CLIFF를 사용하여 글로벌 회전, 관절 자세, 3D 형태, 카메라 매개변수를 추정합니다. UV 맵은 분화 렌더링을 통해 최적화되며, 텍스처 페인팅 기술을 활용하여 다양한 시점에서 SMPL UV 맵을 교대로 수정합니다.

다양한 텍스처 샘플을 얻기 위해 실제 및 생성된 다중 뷰 이미지를 사용합니다. 실제 인간 텍스처는 People-Snapshot과 iPER 비디오를 사용하고, 가상의 캐릭터는 ControlNet과 DWpose를 이용하여 다중 뷰 이미지를 생성합니다. 텍스처 다양성을 높이고 LDM의 ID 일관성 문제를 해결하기 위해 각 캐릭터에 대해 8개의 SMPL A-포즈를 사용하며, 텍스트 강화 기법을 적용합니다.

### **3.2 다양한 텍스처의 인간 합성**

I2UV 훈련을 위한 다양한 텍스처의 인간 이미지를 합성하기 위해, T2UV에서 생성된 텍스처를 애니메이션, 배경, HDR 조명과 결합합니다. 이를 통해 더욱 현실감 있는 인간 이미지를 생성합니다.

텍스처 생성을 위해, T2UV를 사용하여 UV 데이터셋을 생성하며, 각 텍스처에 대응하는 텍스트 설명을 작성합니다. 텍스트 설명은 상세한 묘사, 가상의 캐릭터, 유명인, 일반적인 묘사 등 네 가지 범주로 구성되며, ChatGPT를 활용하여 총 50,000개의 프롬프트를 생성합니다. 생성된 텍스처는 Blender를 사용하여 합성되며, HDR 이미지 조명을 통해 현실적인 조명을 구현합니다. 다양한 포즈를 위해 AMASS 데이터셋을 사용하여 8.3백만 개의 렌더링 프레임을 생성합니다. 배경 이미지는 Pexels에서 가져와 합성하여 현실성을 높입니다.

ATLAS 데이터셋은 TexDreamer의 훈련에 필요한 다양하고 고품질의 텍스처 데이터를 제공하여, TexDreamer가 고해상도의 3D 인간 텍스처를 효과적으로 생성할 수 있도록 지원합니다.

## 4. Zero-Shot Human Texture Generation

TexDreamer는 효율적인 텍스처 적응 미세 조정과 새로운 특징 번역기를 통해 텍스트와 이미지를 사용하여 고품질의 3D 인간 텍스처를 생성하는 최초의 제로샷 멀티모달 방법입니다. 이 섹션에서는 TexDreamer의 훈련 방법과 두 가지 주요 모듈인 Text-to-UV (T2UV)와 Image-to-UV (I2UV)에 대해 설명합니다.

![TexDreamer의 구조. 두 가지 훈련 단계를 수행합니다. T2UV(초록색) 훈련에서는 LDM 디노이즈 손실 L1을 사용하여 텍스트 인코더와 U-Net을 최적화합니다. I2UV(파란색) 훈련에서는 특징 번역기 ϕi2t가 ϕi−enc로 인코딩된 입력 이미지 특징을 조건부 특징 fi2t로 맵핑합니다. I2UV는 L2를 사용하여 ϕt−enc와 ϕi−enc를 최적화하여 훈련합니다.](TexDreamer%20Towards%20Zero-Shot%20High-Fidelity%203D%20Huma%20d4a9d86108184715a93b0f15d5480dbb/Untitled%202.png)

TexDreamer의 구조. 두 가지 훈련 단계를 수행합니다. T2UV(초록색) 훈련에서는 LDM 디노이즈 손실 L1을 사용하여 텍스트 인코더와 U-Net을 최적화합니다. I2UV(파란색) 훈련에서는 특징 번역기 ϕi2t가 ϕi−enc로 인코딩된 입력 이미지 특징을 조건부 특징 fi2t로 맵핑합니다. I2UV는 L2를 사용하여 ϕt−enc와 ϕi−enc를 최적화하여 훈련합니다.

### **4.1 사전 지식**

TexDreamer는 사전 훈련된 대규모 텍스트-이미지 모델의 생성 능력을 활용하여 텍스처를 생성합니다. Dreambooth와 Textual Inversion, 그리고 LoRA와 같은 다양한 미세 조정 방법을 검토한 결과, LoRA가 훈련 효율성과 특정 개념을 생성하는 능력 사이에서 좋은 균형을 제공하는 것으로 나타났습니다. LoRA는 모델의 가중치 행렬을 저차원으로 업데이트하여 훈련 속도를 높입니다.

### **4.2 Text-to-UV (T2UV)**

T2UV 훈련은 효율적인 텍스처 적응 미세 조정을 통해 이루어집니다. 모델의 각 어텐션 레이어에 몇 가지 훈련 가능한 매개변수를 추가하고, LoRA 미세 조정을 통해 소규모 데이터셋에서 특정 개념을 학습하도록 훈련합니다. 이 과정에서 원래의 LDM 모델이 갖는 일반화 능력을 유지하면서도 UV 구조에 맞게 텍스처 생성을 최적화합니다.

훈련 과정에서는 고품질 샘플 텍스처와 그에 대응하는 텍스트 설명을 사용하여, CLIP 점수를 통해 텍스트-이미지 일관성을 측정하고 최적의 매개변수를 찾습니다. T2UV는 원래의 LDM 모델이 갖는 일반화 능력을 유지하면서도 UV 레이아웃에 맞게 텍스트를 일관되게 맵핑하는 능력을 보여줍니다.

### **4.3 Image-to-UV (I2UV)**

I2UV는 2D 인간 이미지를 입력받아 보이지 않는 텍스처를 예측합니다. 이를 위해 우리는 텍스트 특징을 중간 매개로 사용하여 인간 이미지와 UV 텍스처의 구조적 차이를 연결합니다. CLIP 이미지 인코더를 사용하여 2D 이미지에서 시각적 특징을 추출하고, 이를 텍스트 특징 공간으로 변환하는 새로운 특징 번역기를 구축합니다.

훈련 과정에서는 ATLAS에서 생성된 합성 텍스처 인간 이미지를 사용하여 T2UV와 결합된 I2UV를 훈련합니다. 생성된 UV 텍스처를 LDM 이미지 인코더를 통해 잠재 특징으로 인코딩하고, 노이즈를 추가한 후 이를 최적화합니다. 이를 통해 I2UV는 입력 이미지와 일치하는 텍스처를 생성할 수 있습니다.

TexDreamer는 이러한 두 가지 모듈을 통해 다양한 인간 텍스처를 생성할 수 있으며, 기존 방법보다 더 높은 텍스트 일관성과 텍스처 품질을 제공합니다. Extensive 실험 결과, TexDreamer는 텍스트와 이미지에서 고품질의 3D 인간 텍스처를 생성하는 데 있어 탁월한 성능을 보여줍니다.

![원래의 SD와 TexDreamer T2UV의 어텐션 맵 비교. 원래의 SD의 응답 영역은 무작위인 반면, T2UV는 프롬프트를 학습된 UV 구조에 일관되게 맵핑합니다.](TexDreamer%20Towards%20Zero-Shot%20High-Fidelity%203D%20Huma%20d4a9d86108184715a93b0f15d5480dbb/Untitled%203.png)

원래의 SD와 TexDreamer T2UV의 어텐션 맵 비교. 원래의 SD의 응답 영역은 무작위인 반면, T2UV는 프롬프트를 학습된 UV 구조에 일관되게 맵핑합니다.

## 5. Experiments

### **5.1 실험 설정**

T2UV 훈련에는 stable-diffusion-2-1과 clip-vit-large-patch14-336 모델을 사용했습니다. 모델의 최적화는 AdamW 옵티마이저를 사용했으며, 각 훈련 단계에 대한 구체적인 설정과 하이퍼파라미터를 조정했습니다. I2UV 훈련에서는 T2UV를 기반으로 추가 훈련 단계와 학습률 조정을 통해 더 높은 성능을 달성했습니다.

평가 메트릭으로는 T2UV의 텍스트-이미지 일관성을 측정하는 CLIP 점수를 사용하고, I2UV의 경우 기존 방법들과 비교하기 위해 MSE와 CLIP 점수를 사용했습니다.

### **5.2 정성적 비교**

TexDreamer의 T2UV와 I2UV 모듈을 최신 텍스처 생성 방법들과 비교했습니다. T2UV는 Text2Tex, TEXTure, Latent-Paint, Fantasia3D, SMPLitex와 비교했을 때 전반적인 품질과 세부 묘사에서 가장 뛰어난 성능을 보였습니다. I2UV는 Texformer와 SMPLitex와 비교하여 더 충실한 아이덴티티와 탁월한 텍스처 현실성을 보여주었습니다.

![텍스트에서 텍스처 생성의 정성적 비교. TexDreamer를 Text2Tex [9], TEXTure [46], Latent-Paint [38], Fantasia3D [10]와 같은 최신 텍스처 생성 방법들과 비교했습니다. 우리의 결과는 가장 세밀한 얼굴 디테일과 최고 품질을 달성했습니다. 더 나은 뷰를 위해 확대해서 보세요.](TexDreamer%20Towards%20Zero-Shot%20High-Fidelity%203D%20Huma%20d4a9d86108184715a93b0f15d5480dbb/Untitled%204.png)

텍스트에서 텍스처 생성의 정성적 비교. TexDreamer를 Text2Tex [9], TEXTure [46], Latent-Paint [38], Fantasia3D [10]와 같은 최신 텍스처 생성 방법들과 비교했습니다. 우리의 결과는 가장 세밀한 얼굴 디테일과 최고 품질을 달성했습니다. 더 나은 뷰를 위해 확대해서 보세요.

### **5.3 정량적 비교**

T2UV의 텍스트 일관성과 생성 품질을 평가하기 위해 다양한 뷰에서의 CLIP 점수를 계산했습니다. TexDreamer는 효율성과 텍스트 일관성 면에서 최고의 성능을 보였습니다. I2UV는 MSE와 CLIP 점수를 사용하여 Texformer와 SMPLitex보다 더 높은 텍스처 품질과 텍스트 일관성을 달성했습니다.

![왼쪽: AvatarCLIP [18] 및 AvatarCraft [24]와의 정성적 비교. 우리의 방법은 더 현실적인 머리 아바타를 생성합니다. 오른쪽: 텍스처 편집. TexDreamer는 생성된 텍스처의 세부 사항, 예를 들어 의상 스타일, 색상 및 액세서리를 텍스트로 편집할 수 있습니다.](TexDreamer%20Towards%20Zero-Shot%20High-Fidelity%203D%20Huma%20d4a9d86108184715a93b0f15d5480dbb/Untitled%205.png)

왼쪽: AvatarCLIP [18] 및 AvatarCraft [24]와의 정성적 비교. 우리의 방법은 더 현실적인 머리 아바타를 생성합니다. 오른쪽: 텍스처 편집. TexDreamer는 생성된 텍스처의 세부 사항, 예를 들어 의상 스타일, 색상 및 액세서리를 텍스트로 편집할 수 있습니다.

### **5.4 사용자 연구**

추가로 3D 인간 텍스처링의 텍스트 일관성을 평가하기 위해 사용자 연구를 실시했습니다. 참가자들은 TexDreamer가 텍스트 설명과 가장 일치하는 텍스처를 생성한다고 평가했습니다.

### **5.5 성능 검증 실험**

T2UV 훈련에서 LoRA의 랭크와 α 값의 영향을 평가하기 위한 성능 검증 실험을 수행했습니다. 실험 결과, 최적의 설정이 텍스트 일관성을 크게 향상시킨다는 것을 확인했습니다. I2UV의 경우, 고정된 텍스트 인코더와 전체 I2UV 모듈을 비교하여 전체 모델이 가장 높은 이미지 유사성과 텍스트 일관성을 보임을 확인했습니다.

이 실험들은 TexDreamer가 텍스트와 이미지로부터 고품질의 3D 인간 텍스처를 생성하는 데 있어 탁월한 성능을 보여준다는 것을 입증합니다. TexDreamer는 기존의 방법들을 능가하며, 다양한 응용 가능성을 제시합니다.

## 6. Applications

### **6.1 텍스처 편집**

TexDreamer는 텍스트를 사용하여 3D 인간의 외형을 편집할 수 있습니다. 이는 의상 스타일, 액세서리 등의 세부 사항을 빠르고 정밀하게 변경할 수 있게 해줍니다. 이러한 기능은 영화나 게임 산업에서 개념 캐릭터 디자인을 더 유연하고 적응 가능하게 만듭니다. 또한, 동일한 아이덴티티를 유지하면서 다른 의상을 생성할 수 있어 가상 시착(virtual try-on) 분야에도 활용될 수 있습니다.

![이미지에서 UV 생성의 정성적 비교. 우리는 고급 Texformer [63] 및 SMPLitex [6]와 ATLAS 데이터셋(왼쪽)과 Market-1501 76에서 비교했습니다.](TexDreamer%20Towards%20Zero-Shot%20High-Fidelity%203D%20Huma%20d4a9d86108184715a93b0f15d5480dbb/Untitled%206.png)

이미지에서 UV 생성의 정성적 비교. 우리는 고급 Texformer [63] 및 SMPLitex [6]와 ATLAS 데이터셋(왼쪽)과 Market-1501 76에서 비교했습니다.

### **6.2 의상 입은 아바타 텍스처링**

TexDreamer는 복잡한 기하학적 구조를 가진 인간 메쉬와 결합하여 더욱 사실적인 인간 같은 캐릭터를 생성할 수 있습니다. 이를 위해 최신 텍스트-3D 아바타 생성 방법인 TADA를 활용하여, 복잡한 인간 메쉬에 TexDreamer가 생성한 텍스처를 적용할 수 있습니다. 이 방법은 전통적인 3D 모델링 기술보다 더 쉽고 빠르게 개인화된 캐릭터를 만들 수 있게 해줍니다.

![의상 입은 아바타의 텍스처링. 우리의 인간 텍스처는 텍스트-3D 방법으로 생성된 복잡한 의상 메쉬에 적용될 수 있습니다. TexDreamer가 생성한 합성 UV 텍스처를 사용하여 TADA [29]로 생성된 몇 가지 예를 보여줍니다.](TexDreamer%20Towards%20Zero-Shot%20High-Fidelity%203D%20Huma%20d4a9d86108184715a93b0f15d5480dbb/Untitled%207.png)

의상 입은 아바타의 텍스처링. 우리의 인간 텍스처는 텍스트-3D 방법으로 생성된 복잡한 의상 메쉬에 적용될 수 있습니다. TexDreamer가 생성한 합성 UV 텍스처를 사용하여 TADA [29]로 생성된 몇 가지 예를 보여줍니다.

## 7. Conclusions

TexDreamer는 텍스트와 이미지를 사용하여 고품질 3D 인간 텍스처를 생성하는 최초의 제로샷 멀티모달 모델입니다. 이 모델은 대규모 텍스트-이미지 모델의 생성 능력을 UV 구조에 맞춰 효율적으로 적응시키고, 새로운 특징 번역기를 통해 다양한 인간 텍스처를 생성할 수 있습니다.

ATLAS 데이터셋은 1,024×1,024 해상도의 50,000개 고품질 3D 인간 텍스처를 포함하고 있으며, 텍스처 생성 훈련을 위한 풍부한 리소스를 제공합니다. TexDreamer는 텍스트 일관성과 UV 품질 면에서 기존 접근 방식보다 뛰어난 성능을 입증했습니다.