# PixArt-α: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis

[https://arxiv.org/abs/2310.00426](https://arxiv.org/abs/2310.00426)

[https://pixart-alpha.github.io/](https://pixart-alpha.github.io/)

- Sep 2023

### 1 INTRODUCTION

최근 우리는 텍스트-이미지(T2I) 생성 모델에서 획기적인 혁신을 목격했으며, DALL-E 2, Imagen, Stable Diffusion과 같은 사례가 그 선두를 달리고 있습니다. 이러한 모델은 이미지 편집, 비디오 제작, 3D 콘텐츠 제작 등 다양한 분야에 적용되어 초현실적인 이미지 제작의 새로운 시대를 열었습니다. 하지만 천문학적인 컴퓨팅 비용과 환경에 미치는 영향이라는 중대한 단점이 있습니다. SDv1.5 및 RAPHAEL과 같은 모델을 훈련하려면 막대한 양의 GPU 성능이 필요하며, 최대 3,080,000달러의 비용이 발생하고 7년간 한 사람이 배출하는 이산화탄소의 양만큼의 CO2가 배출됩니다! 이러한 가파른 비용은 AI 및 그래픽 컴퓨팅(AIGC) 커뮤니티의 발전을 가로막는 장벽이 되고 있습니다. 이러한 긴급한 상황은 본질적인 질문을 불러일으켰습니다: 어떻게 하면 큰 비용을 들이지 않고도 최고 수준의 이미지 생성기를 생산할 수 있을까요?

![PIXART-α로 생성된 샘플은 제공된 텍스트 설명을 준수하는 놀라운 수준의 충실도와 정밀도를 특징으로 하는 뛰어난 품질을 보여줍니다.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled.png)

PIXART-α로 생성된 샘플은 제공된 텍스트 설명을 준수하는 놀라운 수준의 충실도와 정밀도를 특징으로 하는 뛰어난 품질을 보여줍니다.

**PIXART-α 소개**

이러한 과제를 해결하기 위해 우리는 생성된 이미지의 품질을 저하시키지 않으면서도 계산 요구 사항을 줄이는 최첨단 이미지 생성기인 PIXART-α를 선보였습니다. 소니의 접근 방식은 세 가지 주요 혁신으로 구성됩니다:

- 정교한 트레이닝 전략: 복잡한 T2I 작업을 전체적으로 처리하는 대신 자연 이미지의 픽셀 구성 이해하기, 텍스트와 이미지 정렬하기, 이미지의 미적 매력 높이기 등 세 가지 간단한 작업으로 세분화했습니다. 학습 곡선을 완화하기 위해 비용 효율적인 클래스 조건 모델을 도입하고, 정보가 풍부한 사전 교육과 품질에 초점을 맞춘 미세 조정을 결합한 2단계 교육 프로세스를 도입했습니다.
- 효율적인 T2I 트랜스포머: 확산 트랜스포머의 플레이북을 차용하여 교차 주의 메커니즘을 통합하여 연산량이 많은 일부 분기를 간소화했습니다. 혁신적인 재매개변수화 접근 방식을 통해 기존 모델을 T2I 트랜스포머의 기초로 사용하여 훈련 단계를 효과적으로 빠르게 추적할 수 있습니다.
- 고품질 훈련 데이터: 조사 결과, LAION과 같은 기존 텍스트-이미지 데이터 세트에는 캡션이 충분히 설명적이지 않고 특정 용어의 빈도에 차이가 있는 경우가 많다는 사실을 발견했습니다. 이러한 문제를 해결하기 위해 최고 수준의 비전 언어 모델로 뒷받침되는 자동 라벨링 프로세스를 도입했습니다. 그런 다음 포괄적이고 다양한 객체 수집으로 유명한 SAM 데이터 세트를 사용하여 정렬 학습에 이상적인 풍부한 텍스트-이미지 페어링을 생성했습니다.

**PIXART-α의 성과**

우리의 맞춤형 전략 덕분에 PIXART-α의 효율성은 놀라울 정도로 높아졌습니다. 이 모델에는 675개의 A100 GPU와 단 26,000달러의 비용만 필요하며, 이는 Imagen이 사용하는 훈련 데이터 볼륨의 0.2% 미만과 RAPHAEL의 훈련 시간의 2% 미만을 사용한다는 것을 의미합니다. 비용 측면에서는 RAPHAEL에 비해 무려 3,000,000달러를 절약할 수 있습니다. 이미지 품질에 관해서는 사용자 연구에 따르면 PIXART-α는 이미지 품질과 텍스트-이미지 정렬 모두에서 현재의 주요 T2I 모델을 능가하는 것으로 확인되었습니다. T2I-CompBench의 테스트는 의미 제어에 대한 모델의 숙련도를 더욱 검증합니다.

PIXART-α를 통한 우리의 노력은 주머니에 구멍을 내지 않고도 효율적인 T2I 모델을 개발하는 것이 가능하다는 것을 보여주었습니다. 저희의 인사이트가 AIGC 커뮤니티의 등대 역할을 하여 신진 연구자와 스타트업이 현재보다 훨씬 적은 비용으로 높은 수준의 T2I 모델을 제작할 수 있게 되기를 바랍니다.

![T2I 발전기 간의 CO2 배출량1 및 교육 비용2 비교. PIXART-α는 26,000달러라는 매우 낮은 훈련 비용을 달성했습니다. 라파엘에 비해 CO2 배출량과 훈련 비용은 각각 1.1%와 0.85%에 불과합니다.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled%201.png)

T2I 발전기 간의 CO2 배출량1 및 교육 비용2 비교. PIXART-α는 26,000달러라는 매우 낮은 훈련 비용을 달성했습니다. 라파엘에 비해 CO2 배출량과 훈련 비용은 각각 1.1%와 0.85%에 불과합니다.

### 2 METHOD

**동기 부여:**

텍스트-이미지 변환(T2I) 생성을 위한 훈련 프로세스는 현재 복잡한 작업과 최적이 아닌 데이터 세트가 얽혀 있어 훈련 속도가 느려지는 등의 문제에 직면해 있습니다. T2I 생성은 이미지 내의 픽셀 수준 종속성 이해, 텍스트와 이미지 간의 정확한 정렬 보장, 정확할 뿐만 아니라 미적으로도 만족스러운 이미지 생성이라는 세 가지 작업으로 나눌 수 있습니다. 현재의 접근 방식은 이러한 모든 작업을 동시에 처리하려고 하기 때문에 비효율적입니다. 또한 기존 데이터 세트 캡션의 품질과 정확성에 대한 우려도 있습니다. 이러한 문제를 극복하기 위해 학습 프로세스를 여러 단계로 세분화하고 자동 라벨링 접근 방식을 도입하여 캡션 품질을 개선합니다.

![LAION 원시 캡션과 LLaVA 정제 캡션 비교. LLaVA는 고정보 밀도 캡션을 제공하여 모델이 반복당 더 많은 개념을 파악하고 텍스트-이미지 정렬 효율을 높일 수 있도록 지원합니다.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled%202.png)

LAION 원시 캡션과 LLaVA 정제 캡션 비교. LLaVA는 고정보 밀도 캡션을 제공하여 모델이 반복당 더 많은 개념을 파악하고 텍스트-이미지 정렬 효율을 높일 수 있도록 지원합니다.

**학습 전략 세분화:**

학습은 세 가지 점진적 단계로 나뉩니다:

- 픽셀 종속성 학습: 이 단계의 목표는 의미 있고 정확한 픽셀 디테일이 있는 이미지를 생성하는 것입니다. 사전 학습된 모델(이미지넷)에서 시작하면 학습이 더욱 효율적으로 이루어집니다.
- 텍스트-이미지 정렬 학습: 이 단계에서는 텍스트 설명을 생성된 이미지와 일치시키는 데 중점을 둡니다. 이 과정을 용이하게 하기 위해 정확한 텍스트-이미지 쌍이 포함된 특수 데이터 세트가 생성됩니다.
- 고해상도 및 심미적 이미지 생성: 마지막 단계에서는 고품질 데이터를 사용하여 모델을 개선하여 고해상도의 미학적으로 만족스러운 이미지를 생성합니다. 이전 단계의 이전 지식은 더 빠른 융합을 돕습니다.

![PIXART-α의 모델 아키텍처. 각 블록에 교차 주의 모듈이 통합되어 텍스트 조건을 주입합니다. 효율성을 최적화하기 위해 모든 블록은 시간 조건에 대해 동일한 adaLN 단일 파라미터를 공유합니다.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled%203.png)

PIXART-α의 모델 아키텍처. 각 블록에 교차 주의 모듈이 통합되어 텍스트 조건을 주입합니다. 효율성을 최적화하기 위해 모든 블록은 시간 조건에 대해 동일한 adaLN 단일 파라미터를 공유합니다.

이러한 단계로 학습을 분리하면 프로세스가 더욱 효율적이고 과제를 체계적으로 해결할 수 있습니다.

**효율적인 T2I 트랜스포머(PIXART-α):**

PIXART-α는 확산 트랜스포머(DiT) 아키텍처를 기반으로 구축되었으며 T2I 작업에 맞게 특별히 맞춤화되었습니다. 주요 기능은 다음과 같습니다:

- 교차 주의 레이어: 이를 통해 모델이 텍스트 임베딩과 더 잘 상호 작용할 수 있습니다.
- AdaLN-싱글: 시간 임베딩에 집중하여 모델의 파라미터를 줄이는 적응형 정규화 기법입니다.
- 매개변수 재매개화: 모델이 사전 학습된 가중치와 호환성을 유지하면서 더 효율적으로 개선되도록 합니다.

제안된 변경 사항은 모델의 생성 용량을 유지하면서 모델 크기를 줄입니다.

**데이터 세트 구축:**

기존 데이터 세트의 결함을 해결하기 위해 자동 라벨링 접근 방식이 사용됩니다. 비전 언어 모델인 LLaVA를 사용하여 이미지 캡션의 품질과 디테일이 크게 향상되었습니다. 초기 데이터 세트인 LAION은 정렬 오류와 제한된 어휘와 같은 문제를 안고 있었습니다. 이에 대한 대안으로 SAM 데이터 세트가 더 풍부한 이미지를 제공하므로 선택되었습니다. SAM에 LLaVA를 적용하면 고품질의 텍스트-이미지 쌍을 얻을 수 있습니다. 또한, 생성된 이미지의 미적 품질을 개선하기 위해 JourneyDB와 같은 추가 데이터 세트가 사용됩니다. 비교 결과, LLaVA로 라벨링된 캡션은 이미지당 유효 명사 비율과 평균 명사 수가 더 높은 것으로 나타나 개념 밀도가 개선된 것으로 나타났습니다.

![LAION(왼쪽)과 SAM(오른쪽)에 대한 사용자 지정 프롬프트와 함께 자동 라벨링이 표시됩니다. 녹색으로 강조 표시된 단어는 LAION의 원본 캡션을 나타내고, 빨간색으로 표시된 단어는 LLaVA로 레이블이 지정된 세부 캡션을 나타냅니다.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled%204.png)

LAION(왼쪽)과 SAM(오른쪽)에 대한 사용자 지정 프롬프트와 함께 자동 라벨링이 표시됩니다. 녹색으로 강조 표시된 단어는 LAION의 원본 캡션을 나타내고, 빨간색으로 표시된 단어는 LLaVA로 레이블이 지정된 세부 캡션을 나타냅니다.

![LLaVA로 생성된 레이블을 사용한 SAM 데이터 세트의 예시. LLaVA 캡션의 상세한 이미지 설명은 모델이 반복 작업당 더 많은 개념을 파악하고 텍스트-이미지 정렬 효율성을 높이는 데 도움이 됩니다.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled%205.png)

LLaVA로 생성된 레이블을 사용한 SAM 데이터 세트의 예시. LLaVA 캡션의 상세한 이미지 설명은 모델이 반복 작업당 더 많은 개념을 파악하고 텍스트-이미지 정렬 효율성을 높이는 데 도움이 됩니다.

### 3 EXPERIMENT

이 섹션에서는 훈련, 평가 및 PIXART-α 모델의 고유한 측면에 대해 설명합니다. 또한 다양한 도메인에서의 적용 가능성도 살펴봅니다.

**3.1 구현 세부 사항**

학습을 위해 T5 대규모 언어 모델을 텍스트 인코더로 사용하여 조건부 특징 추출에 활용합니다. 이전 연구와 달리, PIXART-α 캡션이 더 밀도가 높고 더 자세한 정보를 제공한다는 점을 고려하여 추출되는 텍스트 토큰의 길이를 120으로 수정했습니다. 입력 이미지를 처리하기 위해 LDM의 변형 자동 인코더(VAE)를 사용하여 입력 전에 이미지 크기를 조정하고 중앙을 자릅니다. 또한 다양한 이미지 생성을 위해 다각도 증강을 사용합니다. AdamW 옵티마이저는 특정 구성으로 모델의 학습을 구동합니다. 약 22일 동안 64개의 V100 GPU에서 모델을 훈련합니다.

평가 측면에서는 세 가지 주요 지표를 사용하여 PIXART-α의 성능을 측정합니다: 프리쳇 시작 거리(FID), 구성성, 사람 선호도 비율입니다.

**3.2 성능 비교 및 분석**

충실도 평가를 위해 생성된 이미지의 품질을 측정하는 FID 메트릭을 사용합니다. COCO 데이터 세트에서 PIXART-α는 10.65점이라는 인상적인 FID 점수를 기록했는데, 이는 다른 방법에 비해 훈련 시간과 리소스가 줄어든 것을 감안할 때 상당한 수치입니다. 특히 최고 성능의 모델인 RAPHEAL은 FID 점수가 약간 더 높지만 훨씬 더 많은 리소스를 사용합니다.

정렬 평가의 경우, 생성된 이미지와 해당 텍스트 조건 간의 일치도를 평가합니다. PIXART-α는 훈련 과정의 두 번째 단계 덕분에 다양한 지표에서 탁월한 성능을 발휘합니다.

또한 사용자 연구를 수행하여 PIXART-α의 성능을 전체적으로 파악합니다. 참가자들은 생성된 이미지의 품질과 텍스트-이미지 정렬의 정확성을 기준으로 모델과 다른 모델의 순위를 매겼습니다. 그 결과 PIXART-α가 다른 모델, 심지어 SDv2와 같은 선도적인 모델을 능가하는 것으로 나타났습니다.

**3.3 제거 연구**

PIXART-α에 도입된 중요한 수정 사항을 추가로 조사합니다. 특히 구조적 변경과 재파라미터화에 중점을 둡니다. 다양한 시각화와 FID 분석을 통해 재매개변수화가 없는 모델과 다른 매개변수화 기법을 사용한 모델을 포함한 다양한 버전의 모델을 살펴봅니다.

![Feng 등(2023)의 300개의 고정 프롬프트에 대한 사용자 연구. 비율 값은 해당 모델을 선호하는 참가자의 백분율을 나타냅니다. PIXART-α는 품질과 정렬 모두에서 우수한 성능을 달성합니다.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled%206.png)

Feng 등(2023)의 300개의 고정 프롬프트에 대한 사용자 연구. 비율 값은 해당 모델을 선호하는 참가자의 백분율을 나타냅니다. PIXART-α는 품질과 정렬 모두에서 우수한 성능을 달성합니다.

![왼쪽: 절제술 연구를 시각적으로 비교한 결과입니다. 오른쪽: SAM에서의 제로샷 FID-2K 및 GPU 메모리 사용량. 우리의 방법은 "adaLN"과 동등한 수준이며 GPU 메모리를 21% 절약합니다. 200% 더 나은 줌인.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled%207.png)

왼쪽: 절제술 연구를 시각적으로 비교한 결과입니다. 오른쪽: SAM에서의 제로샷 FID-2K 및 GPU 메모리 사용량. 우리의 방법은 "adaLN"과 동등한 수준이며 GPU 메모리를 21% 절약합니다. 200% 더 나은 줌인.

그 결과, "adaLN-단일" 설계가 "adaLN" 버전과 FID 점수는 비슷하지만 GPU 메모리와 모델 매개변수 측면에서 더 효율적이라는 것을 알 수 있었습니다. 또한 모델에 매개변수를 다시 설정하지 않으면 왜곡된 이미지가 생성되는 경향이 있어 설계 선택의 중요성을 다시 한 번 확인할 수 있었습니다.

### 4 RELATED WORK

이미지 생성 영역은 최근 몇 년 동안 특히 노이즈 제거 확산 확률 모델(DDPM)의 영역에서 상당한 발전을 이루었습니다. Ho 등 연구자들이 도입한 이 모델은 기본 가우시안 노이즈를 일관된 이미지로 변환할 수 있는 노이즈 제거 프로세스를 활용합니다. 롬바흐(Rombach) 등이 개발한 잠복 확산 모델은 이미지 잠복 공간에 점수 매칭 기법을 사용하고 교차 주의 메커니즘을 통합하여 기존 DDPM을 더욱 개선했습니다. 또 다른 주요 발전은 피블스 앤 시에(Peebles & Xie)의 확산 트랜스포머(DiT)입니다. 이 기술은 후속 변형과 함께 일반적으로 사용되는 아키텍처인 컨볼루션 기반 U-Net 백본을 트랜스포머로 대체하여 확장성과 효율성을 향상시켰습니다.

### 5 결론

이 연구 논문에서는 트랜스포머 아키텍처를 사용하는 최첨단 텍스트-이미지(T2I) 확산 모델인 PIXART-α를 소개했습니다. PIXART-α는 훈련 비용을 절감하고 환경에 미치는 영향을 줄이면서 뛰어난 이미지 생성 품질로 주목받고 있습니다. PIXART-α의 성공은 세 가지 핵심 설계, 즉 세분화된 트레이닝 접근 방식, 최적화된 T2I 트랜스포머, 풍부한 정보 데이터의 사용에서 기인할 수 있습니다. 엄격한 실험을 거쳐 PIXART-α는 이미지 생성에서 거의 상용 애플리케이션 표준을 충족하는 것으로 입증되었습니다. 그 결과, PIXART-α는 AI 및 그래픽 컴퓨팅(AIGC) 커뮤니티와 신생 스타트업에 귀중한 인사이트를 제공하여 최고 수준의 비용 효율적인 T2I 모델을 개발할 수 있도록 지원합니다. 우리의 연구가 이미지 생성 분야에서 더 많은 혁신과 창의성을 촉진할 것으로 기대합니다.

### 부록:

A.1 관련 연구

이미지 생성 분야는 노이즈 제거 확산 확률 모델(DDPM)과 점수 기반 생성 모델이 GAN, VAE, Flow를 추월하고 지배적인 모델이 되면서 발전해 왔습니다. 기존 모델과 달리 확산 모델은 단계적인 노이즈 감소 프로세스를 사용하여 가우시안 노이즈를 이미지로 변환합니다. 잠재 확산 모델과 같은 최근의 개발은 점수 매칭을 사용하고 교차 주의 메커니즘을 도입하여 이를 더욱 최적화합니다. 확산 트랜스포머(DiT)는 트랜스포머 아키텍처를 확산 모델에 통합하여 기존 U-Net을 대체하고 확장성을 높이며 이미지 생성 가능성을 향상시킵니다.

A.2 ~ A.3 PIXART-α 비교

PIXART-α와 미드저니 및 권위 있는 확산 모델과 같은 다른 최신 모델 간의 비교 영상은 PIXART-α가 생성하는 이미지의 놀라운 성능과 품질을 보여줍니다.

![미드저니와의 비교. 여기에 사용된 프롬프트는 온라인에서 무작위로 샘플링한 것입니다. 공정한 비교를 위해 두 모델에서 생성된 첫 번째 결과를 선택했습니다. 독자는 어떤 이미지가 Midjourney에 해당하고 어떤 이미지가 PIXART-α에 해당하는지 추측해 보시기 바랍니다. 정답은 논문 마지막에 공개됩니다.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled%208.png)

미드저니와의 비교. 여기에 사용된 프롬프트는 온라인에서 무작위로 샘플링한 것입니다. 공정한 비교를 위해 두 모델에서 생성된 첫 번째 결과를 선택했습니다. 독자는 어떤 이미지가 Midjourney에 해당하고 어떤 이미지가 PIXART-α에 해당하는지 추측해 보시기 바랍니다. 정답은 논문 마지막에 공개됩니다.

A.4~A.5 구현 및 세부 사항

PIXART-α는 LLaVA 모델과 같은 고급 자동 라벨링 기술을 사용하여 캡션 품질을 개선합니다. 구현 세부 사항을 보면 텍스트와 이미지 간 정렬 및 다중 샘플링 알고리즘에 중점을 두고 있으며, DPM-Solver가 선택된 방법을 확인할 수 있습니다.

![PIXART-α와 최근의 대표적인 생성기인 Stable Diffusion XL, DeepFloyd, DALL-E 2, ERNIE-ViLG 2.0, RAPHAEL을 비교한 결과입니다. 생성된 이미지 내에서 인간 아티스트가 보존하고자 하는 단어가 빨간색으로 강조 표시된 RAPHAEL(Xue et al., 2023b)과 동일한 프롬프트가 주어집니다. 각 행에 대한 구체적인 프롬프트는 그림 하단에 나와 있습니다. 200%로 확대하면 더 좋습니다.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled%209.png)

PIXART-α와 최근의 대표적인 생성기인 Stable Diffusion XL, DeepFloyd, DALL-E 2, ERNIE-ViLG 2.0, RAPHAEL을 비교한 결과입니다. 생성된 이미지 내에서 인간 아티스트가 보존하고자 하는 단어가 빨간색으로 강조 표시된 RAPHAEL(Xue et al., 2023b)과 동일한 프롬프트가 주어집니다. 각 행에 대한 구체적인 프롬프트는 그림 하단에 나와 있습니다. 200%로 확대하면 더 좋습니다.

![각 열에 대한 프롬프트(Xue et al., 2023b)가 그림에 나와 있습니다. DALL-E 2 Midjourney v5.1, Stable Diffusion XL, ERNIE ViLG 2.0, DeepFloyd 및 RAPHAEL을 비교한 것입니다. 동일한 프롬프트가 표시되며, 생성된 이미지 내에서 인간 아티스트가 보존하고자 하는 단어는 빨간색으로 강조 표시됩니다. 200% 더 잘 확대합니다.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled%2010.png)

각 열에 대한 프롬프트(Xue et al., 2023b)가 그림에 나와 있습니다. DALL-E 2 Midjourney v5.1, Stable Diffusion XL, ERNIE ViLG 2.0, DeepFloyd 및 RAPHAEL을 비교한 것입니다. 동일한 프롬프트가 표시되며, 생성된 이미지 내에서 인간 아티스트가 보존하고자 하는 단어는 빨간색으로 강조 표시됩니다. 200% 더 잘 확대합니다.

A.6~A.7 성능 분석 및 결과

다양한 구성과 데이터 세트에서 PIXART-α는 일관되고 우수한 성능을 보여줍니다. 텍스트 프롬프트에서 고품질의 세밀하고 다양한 이미지를 생성할 수 있는 PIXART-α의 능력을 보여주는 시각적 결과물이 더 많이 생성됩니다.

![(a) [1.5, 2.0, 3.0, 4.0, 5.0, 6.0]에서 샘플링한 다양한 cfg 척도에 대한 FID 대 CLIP 점수 그래프. PIXART-α는 MSCOCO에서 SDv1.5보다 약간 더 나은 성능을 보여줍니다. (b) 및 (c)는 T2ICompBench의 다양한 cfg 스케일에서 견고성을 유지하는 PIXART-α의 능력을 보여줍니다.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled%2011.png)

(a) [1.5, 2.0, 3.0, 4.0, 5.0, 6.0]에서 샘플링한 다양한 cfg 척도에 대한 FID 대 CLIP 점수 그래프. PIXART-α는 MSCOCO에서 SDv1.5보다 약간 더 나은 성능을 보여줍니다. (b) 및 (c)는 T2ICompBench의 다양한 cfg 스케일에서 견고성을 유지하는 PIXART-α의 능력을 보여줍니다.

![PIXART-α는 풍부하고 복잡한 디테일을 보존하면서 최대 1024 × 1024 해상도의 이미지를 생성할 수 있습니다. 또한 임의의 종횡비로 이미지를 생성할 수 있어 이미지 생성에 유연성을 제공합니다.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled%2012.png)

PIXART-α는 풍부하고 복잡한 디테일을 보존하면서 최대 1024 × 1024 해상도의 이미지를 생성할 수 있습니다. 또한 임의의 종횡비로 이미지를 생성할 수 있어 이미지 생성에 유연성을 제공합니다.

![프롬프트 믹싱: PIXART-α는 텍스트 프롬프트를 통해 이미지 스타일을 직접 조작할 수 있습니다. 이 그림에서는 스타일을 사용하여 개체를 제어하는 5개의 출력을 생성합니다. 예를 들어 그림의 왼쪽 모서리에 있는 첫 번째 샘플은 " 우주에 있는 블랙홀의 픽셀 아트 "라는 프롬프트를 사용합니다. 200%로 확대하는 것이 좋습니다.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled%2013.png)

프롬프트 믹싱: PIXART-α는 텍스트 프롬프트를 통해 이미지 스타일을 직접 조작할 수 있습니다. 이 그림에서는 스타일을 사용하여 개체를 제어하는 5개의 출력을 생성합니다. 예를 들어 그림의 왼쪽 모서리에 있는 첫 번째 샘플은 " 우주에 있는 블랙홀의 픽셀 아트 "라는 프롬프트를 사용합니다. 200%로 확대하는 것이 좋습니다.

A.8~A.9 논의 및 확장 사항

FID 지표는 이미지 품질을 가장 잘 평가하는 지표가 아닐 수 있으며, 사람이 평가하는 것이 더 적절할 수 있습니다. PIXART-α의 적응성은 추가 사용자 지정 및 이미지 생성을 위한 방법을 제공하는 DreamBooth 및 ControlNet을 사용한 확장을 통해 입증되었습니다.

![PIXART-α는 드림부스와 결합할 수 있습니다. 몇 가지 이미지와 텍스트 프롬프트가 주어지면 PIXART-α는 환경과의 자연스러운 상호 작용을 보여주는 고품질 이미지를 생성할 수 있으며(그림 17a), 물체 색상을 정밀하게 수정할 수 있습니다(그림 17b). 이는 PIXART-α가 뛰어난 품질의 이미지를 생성할 수 있으며 사용자 지정 확장에 강력한 기능을 가지고 있음을 보여줍니다.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled%2014.png)

PIXART-α는 드림부스와 결합할 수 있습니다. 몇 가지 이미지와 텍스트 프롬프트가 주어지면 PIXART-α는 환경과의 자연스러운 상호 작용을 보여주는 고품질 이미지를 생성할 수 있으며(그림 17a), 물체 색상을 정밀하게 수정할 수 있습니다(그림 17b). 이는 PIXART-α가 뛰어난 품질의 이미지를 생성할 수 있으며 사용자 지정 확장에 강력한 기능을 가지고 있음을 보여줍니다.

![PIXART-α의 컨트롤넷 커스터마이제이션 샘플. 레퍼런스 이미지를 사용하여 해당 HED 에지 이미지를 생성하고 이를 PIXART-α ControlNet의 제어 신호로 사용합니다. 200% 더 잘 확대합니다.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled%2015.png)

PIXART-α의 컨트롤넷 커스터마이제이션 샘플. 레퍼런스 이미지를 사용하여 해당 HED 에지 이미지를 생성하고 이를 PIXART-α ControlNet의 제어 신호로 사용합니다. 200% 더 잘 확대합니다.

A.10 트랜스포머와 U-NET 비교

컨볼루션 네트워크에 비해 트랜스포머 기반 네트워크의 장점은 분명합니다. 텍스트-이미지 합성 같은 작업에서 PIXART-α와 같은 트랜스포머 아키텍처는 다중 모드 정보를 효과적으로 융합할 수 있기 때문에 뛰어난 구성성을 제공합니다.

A.11 제한 사항

PIXART-α에는 대상의 수와 사람의 손과 같은 특정 디테일을 정확하게 제어하는 것과 같은 특정 한계가 있습니다. 텍스트 생성 능력도 다소 제한적입니다. 향후 작업은 이러한 부분을 개선하는 데 중점을 둘 것입니다.

![PIXART-α가 어려움을 겪는 상황에는 사람의 팔다리를 정밀하게 계산하거나 정확하게 표현해야 하는 상황이 포함됩니다. 이러한 경우 모델이 정확한 결과를 제공하는 데 어려움을 겪을 수 있습니다.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled%2016.png)

PIXART-α가 어려움을 겪는 상황에는 사람의 팔다리를 정밀하게 계산하거나 정확하게 표현해야 하는 상황이 포함됩니다. 이러한 경우 모델이 정확한 결과를 제공하는 데 어려움을 겪을 수 있습니다.

A.12 계시

PIXART-α와 미드저니를 비교해보면, PIXART-α의 성능이 워낙 뛰어나기 때문에 둘을 구분하기는 어렵습니다.

![이 그림은 부록 A.2에 표시된 이미지 생성 품질 평가에 대한 답을 제시합니다. 에 나와 있습니다. 각 이미지 쌍에 사용된 방법은 왼쪽 상단에 주석으로 표시되어 있습니다.](PixArt-%CE%B1%20Fast%20Training%20of%20Diffusion%20Transformer%20fo%20245586a9b1ec42a38e7a684f0f00c14a/Untitled%2017.png)

이 그림은 부록 A.2에 표시된 이미지 생성 품질 평가에 대한 답을 제시합니다. 에 나와 있습니다. 각 이미지 쌍에 사용된 방법은 왼쪽 상단에 주석으로 표시되어 있습니다.