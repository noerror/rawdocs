# Urban Architect: Steerable 3D Urban Scene Generation with Layout Prior

[https://arxiv.org/abs/2404.06780](https://arxiv.org/abs/2404.06780)

[https://urbanarchitect.github.io/](https://urbanarchitect.github.io/)

- Apr 2024

![우리는 텍스트 설명을 보완하기 위해 3D 레이아웃을 추가 사전 정보로 도입함으로써 조종 가능한 3D 도시 장면을 생성하는 방법을 제시합니다. 이 프레임워크는 세 가지 주요 특성을 갖습니다: (1) 대규모 도시 장면 생성. 우리의 실험에서는 운전 거리가 1000m를 넘습니다. (2) 높은 품질. 생성된 장면은 사실적 렌더링(상단 행)을 가능하게 하며 기하학적 일관성(첫 번째 카메라의 왼쪽 사진)을 준수합니다. (3) 조종 가능한 생성 프로세스. 다양한 장면 편집 효과를 손쉽게 지원합니다(예: 스타일 편집(하단 행))](Urban%20Architect%20Steerable%203D%20Urban%20Scene%20Generatio%20abe11a4da0b347d1ace260fd0e8d6ca4/Untitled.png)

우리는 텍스트 설명을 보완하기 위해 3D 레이아웃을 추가 사전 정보로 도입함으로써 조종 가능한 3D 도시 장면을 생성하는 방법을 제시합니다. 이 프레임워크는 세 가지 주요 특성을 갖습니다: (1) 대규모 도시 장면 생성. 우리의 실험에서는 운전 거리가 1000m를 넘습니다. (2) 높은 품질. 생성된 장면은 사실적 렌더링(상단 행)을 가능하게 하며 기하학적 일관성(첫 번째 카메라의 왼쪽 사진)을 준수합니다. (3) 조종 가능한 생성 프로세스. 다양한 장면 편집 효과를 손쉽게 지원합니다(예: 스타일 편집(하단 행))

## 1. Introduction

이 논문에서는 3D 도시 장면을 생성하는 새로운 방법론을 제시하며, 이는 다양한 응용 프로그램(예: 자율 주행 시뮬레이션, 가상 현실, 게임 등)에 중요한 의미를 가집니다. 이전 연구들은 3D 이미지 합성 및 장면 재구성에 다양한 접근 방법을 시도했지만, 장면의 규모, 품질, 유연성, 기하학적 일관성 사이에서 절충해야 하는 문제에 직면했습니다. 이에 본 논문은 텍스트를 기반으로 하는 3D 생성이라는 새로운 방향을 제안합니다. 이 방식은 텍스트에서 이미지로의 확산 모델의 품질과 3D 표현의 기하학적 일관성의 장점을 결합합니다. 특히, 스코어 증류 샘플링(SDS)이라는 기법을 중심으로, 3D 모델을 최적화하는 새로운 접근법을 소개하여, 도시 규모의 장면을 생성하는 문제에 대한 해결책을 모색합니다.

## 2. Related Work

이 장에서는 도시 장면을 모델링하기 위해 제안된 다양한 3D 표현 방식들을 소개합니다. 이러한 방식들은 주로 큰 규모의 장면에서 최적화를 어렵게 하는 점과 같은 도전과제를 가지고 있습니다.

1. **3D 표현을 위한 방법론**:
    - **명시적 표현**: 점 구름과 메쉬 같은 전통적인 3D 표현 방식이 사용되어 왔으나, 이러한 방식은 이산적인 성격 때문에 순수하게 2D 감독 하에서 최적화하기 어렵습니다.
    - **NeRF**: NeRF는 장면의 밀도와 색상을 인코딩하기 위해 명시적인 신경 표현을 채택하고, 보기 합성을 위해 체적 렌더링을 활용합니다. 다양한 3D 장면을 모델링하는 데 사용되며, 렌더링 품질과 효율성을 개선하기 위한 여러 연구가 진행되었습니다.
2. **텍스트-이미지에서 텍스트-3D로의 확장**:
    - 초기의 텍스트-이미지 방법들은 CLIP을 사용하여 최적화를 지원했으나, 고품질의 3D 콘텐츠 생성에 어려움을 겪었습니다. 최근 대규모 확산 모델이 텍스트-이미지 생성에서 성공을 거두면서, 이를 텍스트-3D 생성에 적용하는 연구가 활발해졌습니다. 특히 SDS는 텍스트 조건부 확산 모델로부터 파생된 분포와 일치하도록 임의의 시점에서 렌더링된 2D 이미지를 조정함으로써 3D 모델을 최적화합니다.
3. **3D 생성 모델**:
    - 3D 생성을 위한 주요 모델로 GAN, VAE, 확산 모델이 사용되며, 이러한 모델은 주로 단일 객체 생성에 한정됩니다. 최근에는 이러한 접근 방식을 더 큰 장면에 적용하기 위한 연구가 진행되고 있습니다.

이 장에서 다루는 관련 작업은 본 논문의 접근 방식인 ‘Urban Architect’가 텍스트-이미지 확산 모델을 기반으로 한 새로운 텍스트-3D 최적화 프레임워크를 개발하는 기초를 제공합니다.

## 3. Method

![우리는 도시 규모의 3D 장면을 3D 레이아웃 지침과 텍스처 설명을 사용하여 생성하는 방법을 소개합니다. 장면은 신경 필드로 표현되며, 조건부 방식으로 사전 훈련된 확산 모델을 증류하여 최적화됩니다. (a) 텍스트 기반 지침에만 의존하는 대신, 우리는 원하는 장면의 3D 레이아웃을 통해 Variational Score Distillation (VSD)의 증류 과정을 제어하도록 제안합니다. (b) 레이아웃 인식 정제 전략을 통해 로컬 세부 사항을 정제합니다. (c) 무한한 도시 장면을 모델링하기 위해 3D 표현을 스케일러블 해시 그리드로 이산화합니다. (d) 생성된 장면을 미세 조정함으로써 다양한 장면 편집 효과를 지원합니다.](Urban%20Architect%20Steerable%203D%20Urban%20Scene%20Generatio%20abe11a4da0b347d1ace260fd0e8d6ca4/Untitled%201.png)

우리는 도시 규모의 3D 장면을 3D 레이아웃 지침과 텍스처 설명을 사용하여 생성하는 방법을 소개합니다. 장면은 신경 필드로 표현되며, 조건부 방식으로 사전 훈련된 확산 모델을 증류하여 최적화됩니다. (a) 텍스트 기반 지침에만 의존하는 대신, 우리는 원하는 장면의 3D 레이아웃을 통해 Variational Score Distillation (VSD)의 증류 과정을 제어하도록 제안합니다. (b) 레이아웃 인식 정제 전략을 통해 로컬 세부 사항을 정제합니다. (c) 무한한 도시 장면을 모델링하기 위해 3D 표현을 스케일러블 해시 그리드로 이산화합니다. (d) 생성된 장면을 미세 조정함으로써 다양한 장면 편집 효과를 지원합니다.

### **3.1. Preliminaries**

- **Score Distillation Sampling (SDS)**: 텍스트-이미지 확산 모델을 기반으로 한 3D 생성 방법으로, 임의의 카메라 시점에서 렌더링된 이미지가 텍스트 조건부 확산 모델에서 파생된 분포와 일치하도록 최적화합니다. SDS는 합리적인 3D 콘텐츠를 생성할 수 있지만 과포화, 과부드러움, 다양성 저하 등의 문제가 있습니다.
- **Variational Score Distillation (VSD)**: SDS의 한계를 극복하기 위해 개발된 방법으로, 단일 샘플 포인트를 최적화하는 대신 가능한 3D 표현의 분포를 최적화합니다. VSD는 더 높은 충실도와 다양성을 가진 3D 콘텐츠를 생성할 수 있습니다.

### **3.2. Layout-Guided Variational Score Distillation**

- 이 절은 VSD를 텍스트 프롬프트의 모호성을 보완하기 위해 3D 레이아웃을 추가적인 제약 조건으로 통합하는 방법을 설명합니다. 3D 레이아웃에서 파생된 2D 의미론적 및 깊이 맵은 장면의 기하학적 및 의미론적 제약을 제공합니다. 이러한 맵들은 VSD 프로세스를 조건부로 적용하여, 3D 레이아웃에 일관된 2D 이미지를 생성하도록 합니다.
- **ControlNet 사용**: ControlNet은 렌더링된 의미론적 및 깊이 맵을 기반으로 훈련되어, 이러한 조건들을 확산 모델과 LoRA 모델에 통합합니다. 이를 통해 VSD는 3D 레이아웃과 일관된 장면 특정 목표 분포를 생성할 수 있습니다.

### **3.3. Layout-Aware Refinement**

![장면을 일련의 스터프 및 객체 해시 그리드(예: {Hsₖ, Hoₖ})로 분해합니다. 이 그리드들은 카메라 궤적에 따라 동적으로 성장합니다.](Urban%20Architect%20Steerable%203D%20Urban%20Scene%20Generatio%20abe11a4da0b347d1ace260fd0e8d6ca4/Untitled%202.png)

장면을 일련의 스터프 및 객체 해시 그리드(예: {Hsₖ, Hoₖ})로 분해합니다. 이 그리드들은 카메라 궤적에 따라 동적으로 성장합니다.

- **SDEdit 영감**: 렌더링된 이미지를 재샘플링하여 더욱 정제된 이미지로 개선하는 과정에서 SDEdit의 전략을 활용합니다. 레이아웃 인식 정제는 렌더링된 의미론적 및 깊이 맵을 사용하여 확산 모델의 제거 단계를 조건부로 수행함으로써 지리적 및 의미론적 일관성을 개선합니다.
- **MSE 손실**: 원래 렌더링된 이미지와 정제된 이미지 간의 MSE 손실을 통해 장면의 세부적인 정제를 진행합니다.

### **3.4. Scalable Hash Grid**

- **Zip-NeRF 기반 설계**: 이 구조는 Zip-NeRF와 Instant-NGP의 기술을 결합하여 고품질 및 효율적인 신경 렌더링을 달성합니다. 장면은 유연하게 확장 가능한 구조인 스케일러블 해시 그리드로 표현됩니다.
- **Stuff 및 Object Grids**: 장면은 고정된 객체 및 동적 객체를 분리하여 관리하는 여러 해시 그리드로 분해됩니다. 이러한 그리드는 장면의 다양한 구성 요소를 독립적으로 최적화할 수 있게 해 줍니다.
- **Layout-Constrained Rendering**: 3D 레이아웃을 기반으로 샘플링 공간을 제한함으로써, 해시 그리드에서의 밀도와 색상 예측이 용이해지며, 이는 보다 빠른 수렴과 높은 렌더링 품질을 가능하게 합니다.

### **3.5. Scene Editing**

![도시 장면에서 흔히 볼 수 있는 여러 기본 기하학적 형태(예: 도로와 인도, 자동차, 건물 등)를 제공합니다.](Urban%20Architect%20Steerable%203D%20Urban%20Scene%20Generatio%20abe11a4da0b347d1ace260fd0e8d6ca4/Untitled%203.png)

도시 장면에서 흔히 볼 수 있는 여러 기본 기하학적 형태(예: 도로와 인도, 자동차, 건물 등)를 제공합니다.

- **Instance-Level Editing**: 3D 레이아웃 표현은 인스턴스 수준에서의 장면 편집을 자연스럽게 지원합니다. 예를 들어, 건물이나 나무와 같은 고정된 요소를 추가하거나 삭제할 수 있으며, 자동차와 같은 객체의 위치를 조정할 수 있습니다.
- **Style Editing**: 대규모 확산 모델의 본질적인 능력을 활용하여 생성된 장면의 스타일을 다양하게 전환할 수 있습니다. 예를 들어, "카툰 스타일", "밤 시간" 등의 스타일로 미세 조정이 가능합니다.

### **3.6. Layout Construction**

- **3D 레이아웃 생성**: 이 연구에서는 KITTI-360 데이터셋을 기반으로 ControlNet을 훈련하는 데 사용된 기존의 3D 레이아웃 데이터를 활용합니다. 또한, 사용자는 Blender와 같은 3D 모델링 소프트웨어를 사용하여 기본 기하학적 구조를 활용해 원하는 레이아웃을 쉽게 생성할 수 있습니다.
- **SinDDM 기반 자동 레이아웃 생성**: SinDDM은 훈련 이미지의 내재적 분포를 학습하여 새로운 이미지를 다양한 규모로 생성할 수 있습니다. 이를 통해 3D 레이아웃을 2D 지면 평면으로 압축하고, 이를 기반으로 새로운 샘플을 생성할 수 있습니다.

## 4. Experiment

### **4.1. Experimental Setup**

![단일 레이아웃 예를 바탕으로 자동 3D 레이아웃 생성을 위한 대안적 방법을 제시합니다. 상위 두 행에서는 다양한 규모의 생성된 레이아웃을 보여주며, 세 번째 행에서 생성된 2D 샘플에 해당하는 3D 레이아웃을 제공합니다. 생성된 장면의 렌더링 결과는 하단 행에 표시됩니다.](Urban%20Architect%20Steerable%203D%20Urban%20Scene%20Generatio%20abe11a4da0b347d1ace260fd0e8d6ca4/Untitled%204.png)

단일 레이아웃 예를 바탕으로 자동 3D 레이아웃 생성을 위한 대안적 방법을 제시합니다. 상위 두 행에서는 다양한 규모의 생성된 레이아웃을 보여주며, 세 번째 행에서 생성된 2D 샘플에 해당하는 3D 레이아웃을 제공합니다. 생성된 장면의 렌더링 결과는 하단 행에 표시됩니다.

- **데이터셋**: 주요 실험은 KITTI-360 데이터셋을 사용하여 수행되었습니다. 이 데이터셋은 도시 환경에서 약 73.7km의 운전 거리를 커버하며, 다양한 클래스(예: 건물, 자동차, 도로, 식물 등)에 대한 3D 바운딩 박스 주석이 포함되어 있습니다.
- **구현 세부 사항**: 실험은 PyTorch를 사용하여 구현되었으며, Stable Diffusion 2.1을 텍스트-이미지 확산 모델로 사용했습니다. 학습은 단일 NVIDIA V100 GPU에서 진행되었으며, 최적화는 AdamW 옵티마이저를 사용했습니다.
- **기준 모델과 설정**: 다양한 3D 생성 방법(예: EG3D, CC3D, UrbanGIRAFFE, Text2Room, SceneDreamer, InfiniCity)과 비교를 위해 실험이 설계되었습니다. 각 모델은 공식적으로 제공된 코드와 사전 훈련된 가중치를 사용하여 평가되었습니다.

![다른 방법으로 생성된 두 장면을 비교하기 위해 표시합니다. 대부분의 결과는 원본 논문에서 직접 차용되었으며, Text2Room과 SceneDreamer는 우리 설정에서 적응되고 재훈련되었습니다. 제안된 파이프라인은 이전 기준 방법들을 크게 능가하며 고품질의 렌더링을 달성합니다. 자세한 내용은 확대해서 보세요.](Urban%20Architect%20Steerable%203D%20Urban%20Scene%20Generatio%20abe11a4da0b347d1ace260fd0e8d6ca4/Untitled%205.png)

다른 방법으로 생성된 두 장면을 비교하기 위해 표시합니다. 대부분의 결과는 원본 논문에서 직접 차용되었으며, Text2Room과 SceneDreamer는 우리 설정에서 적응되고 재훈련되었습니다. 제안된 파이프라인은 이전 기준 방법들을 크게 능가하며 고품질의 렌더링을 달성합니다. 자세한 내용은 확대해서 보세요.

![우리의 방법은 CC3D의 향상된 버전인 CC3D+H를 크게 능가합니다.](Urban%20Architect%20Steerable%203D%20Urban%20Scene%20Generatio%20abe11a4da0b347d1ace260fd0e8d6ca4/Untitled%206.png)

우리의 방법은 CC3D의 향상된 버전인 CC3D+H를 크게 능가합니다.

![점수 범위는 1에서 5까지이며, 5는 최고의 품질을 나타냅니다.](Urban%20Architect%20Steerable%203D%20Urban%20Scene%20Generatio%20abe11a4da0b347d1ace260fd0e8d6ca4/Untitled%207.png)

점수 범위는 1에서 5까지이며, 5는 최고의 품질을 나타냅니다.

### **4.2. Results**

![우리는 두 개의 대규모 3D 도시 장면을 고품질로 생성하며, 각각 약 600 × 400m²의 면적을 커버하고 1000m 이상의 운전 거리를 포함합니다.](Urban%20Architect%20Steerable%203D%20Urban%20Scene%20Generatio%20abe11a4da0b347d1ace260fd0e8d6ca4/Untitled%208.png)

우리는 두 개의 대규모 3D 도시 장면을 고품질로 생성하며, 각각 약 600 × 400m²의 면적을 커버하고 1000m 이상의 운전 거리를 포함합니다.

- **인스턴스 수준 편집**: 이 접근 방식은 개별 객체(예: 자동차의 위치 조정, 건물 제거 또는 추가)를 조작하는 것을 포함하여 장면의 인스턴스 수준에서 다양한 편집을 지원합니다.
    
    ![제안된 파이프라인은 인스턴스 수준 편집(객체 편집 및 스터프 편집 포함) 및 전역 스타일 편집을 달성합니다.](Urban%20Architect%20Steerable%203D%20Urban%20Scene%20Generatio%20abe11a4da0b347d1ace260fd0e8d6ca4/Untitled%209.png)
    
    제안된 파이프라인은 인스턴스 수준 편집(객체 편집 및 스터프 편집 포함) 및 전역 스타일 편집을 달성합니다.
    
- **스타일 편집**: 생성된 장면의 스타일을 다양하게 전환할 수 있는 기능을 제공합니다. 예를 들어, "안개 낀", "반 고흐 스타일" 등의 텍스트 프롬프트를 사용하여 스타일을 변경할 수 있습니다.
- **다른 도시 스타일로의 전환**: 장면의 도시 스타일을 "교토에서", "하와이에서" 등의 조건을 추가하여 변경할 수 있습니다.
    
    ![생성된 도시 장면은 생성된 해시 그리드를 미세 조정함으로써 주어진 텍스트 프롬프트에 따라 다른 도시 스타일로 전환될 수 있습니다.](Urban%20Architect%20Steerable%203D%20Urban%20Scene%20Generatio%20abe11a4da0b347d1ace260fd0e8d6ca4/Untitled%2010.png)
    
    생성된 도시 장면은 생성된 해시 그리드를 미세 조정함으로써 주어진 텍스트 프롬프트에 따라 다른 도시 스타일로 전환될 수 있습니다.
    
    ![NuScenes 스타일의 장면을 생성하고 다른 날씨로 전환합니다.](Urban%20Architect%20Steerable%203D%20Urban%20Scene%20Generatio%20abe11a4da0b347d1ace260fd0e8d6ca4/Untitled%2011.png)
    
    NuScenes 스타일의 장면을 생성하고 다른 날씨로 전환합니다.
    

### **4.3. Large-Scale Generation Capability**

### **4.3. Ablation Studies**

- **LG-VSD의 효과성**: Layout-Guided Variational Score Distillation (LG-VSD)의 효과성을 검증하기 위해, 기본 VSD와 직접 비교 실험을 수행했습니다. LG-VSD를 적용하지 않았을 때보다 훨씬 더 현실적이고 세밀한 결과를 얻을 수 있었습니다.
    
    ![우리의 3D 레이아웃 사전 없이는 VSD가 효과적인 지도 없이 고품질의 도시 장면을 생성하는 데 실패합니다. 심지어 미세 조정된 확산 모델이 있어도 마찬가지입니다.](Urban%20Architect%20Steerable%203D%20Urban%20Scene%20Generatio%20abe11a4da0b347d1ace260fd0e8d6ca4/Untitled%2012.png)
    
    우리의 3D 레이아웃 사전 없이는 VSD가 효과적인 지도 없이 고품질의 도시 장면을 생성하는 데 실패합니다. 심지어 미세 조정된 확산 모델이 있어도 마찬가지입니다.
    
- **레이아웃 제약 샘플링의 영향**: 레이아웃 제약 샘플링 전략을 적용하지 않았을 때의 결과와 비교하여, 샘플링 공간을 3D 레이아웃으로 제한함으로써 더 명확하고 선명한 렌더링 결과를 얻을 수 있었습니다.
- **레이아웃 인식 정제 전략**: 레이아웃 인식 정제 전략을 적용하지 않은 경우와 비교하여, 이 전략을 적용함으로써 더욱 부드럽고 현실적인 이미지를 생성할 수 있었습니다. 이는 장면의 지리적 및 의미론적 일관성을 높이는 데 기여했습니다.
    
    ![레이아웃 제약 샘플링 전략 없이는 렌더링 결과가 흐릿합니다. 레이아웃 인식 정제 전략은 생성 품질을 더욱 향상시켜 보다 현실적인 결과를 이끌어냅니다.](Urban%20Architect%20Steerable%203D%20Urban%20Scene%20Generatio%20abe11a4da0b347d1ace260fd0e8d6ca4/Untitled%2013.png)
    
    레이아웃 제약 샘플링 전략 없이는 렌더링 결과가 흐릿합니다. 레이아웃 인식 정제 전략은 생성 품질을 더욱 향상시켜 보다 현실적인 결과를 이끌어냅니다.
    

### **4.4. Further Analysis**

- **큰 카메라 뷰 변화에 대한 강인성**: 훈련 궤적에서 카메라를 -45도에서 45도로 회전시키면서 렌더링 결과를 보여주었습니다. 이를 통해 생성된 장면이 큰 카메라 뷰 변화에도 불구하고 높은 3D 일관성을 유지하는 강력한 로버스트성을 입증했습니다.
    
    ![카메라가 왼쪽에서 오른쪽으로 -45도에서 45도로 회전합니다](Urban%20Architect%20Steerable%203D%20Urban%20Scene%20Generatio%20abe11a4da0b347d1ace260fd0e8d6ca4/Untitled%2014.png)
    
    카메라가 왼쪽에서 오른쪽으로 -45도에서 45도로 회전합니다
    
- **다양성 탐색**: 동일한 레이아웃에 대해 다른 랜덤 시드를 사용하여 실험을 진행하였습니다. 이를 통해 제안된 파이프라인이 다양한 외관과 조명을 가진 요소(예: 자동차, 건물)를 포함하는 다양한 장면을 생성할 수 있음을 보여주었습니다.
    
    ![동일한 장면 레이아웃을 가진 두 가지 다른 랜덤 시드로 생성된 장면을 표시합니다.](Urban%20Architect%20Steerable%203D%20Urban%20Scene%20Generatio%20abe11a4da0b347d1ace260fd0e8d6ca4/Untitled%2015.png)
    
    동일한 장면 레이아웃을 가진 두 가지 다른 랜덤 시드로 생성된 장면을 표시합니다.
    
- **3D 시각화**: 생성된 해시 그리드 표현에서 삼각형 메쉬를 추출하여 결과를 보여주었습니다. 이 3D 삼각형 메쉬는 생성된 장면의 일관된 3D 구조를 드러냅니다.
    
    ![생성된 장면에서 3D 삼각형 메쉬를 추출하고 해당 카메라 위치에서 렌더링된 2D 이미지를 제공합니다.](Urban%20Architect%20Steerable%203D%20Urban%20Scene%20Generatio%20abe11a4da0b347d1ace260fd0e8d6ca4/Untitled%2016.png)
    
    생성된 장면에서 3D 삼각형 메쉬를 추출하고 해당 카메라 위치에서 렌더링된 2D 이미지를 제공합니다.
    

## 5. Conclusion and Limitations

이 논문은 'Urban Architect'라는 새로운 방법론을 통해 대규모 도시 장면의 3D 생성을 위한 접근 방법을 제시합니다. 핵심은 3D 레이아웃을 튼튼한 사전 지식으로 활용하고, 이를 텍스트-이미지 확산 모델과 결합하여 텍스트-3D 패러다임을 발전시키는 것입니다.

### **주요 성과**

- **3D 레이아웃 정보의 통합**: 텍스트 기반의 설명과 함께 3D 레이아웃 정보를 사용하여 품질, 다양성 및 기하학적 일관성이 향상된 3D 도시 장면을 생성할 수 있었습니다.
- **스케일러블 해시 그리드**: 도시 장면의 무한한 본성을 처리할 수 있는 새로운 3D 표현인 스케일러블 해시 그리드를 도입하여, 장면을 임의의 규모로 확장할 수 있게 하였습니다.
- **장면 편집 기능**: 이 방법론은 다양한 장면 편집 기능을 지원하여, 사용자가 인스턴스 수준에서 객체를 조작하거나, 스타일을 변경하는 등의 상세한 편집을 할 수 있게 합니다.

### **한계점 및 미래 연구 방향**

- **픽셀 수준 제어의 한계**: 현재의 최적화 과정은 픽셀 수준에서의 장면 제어를 만족시키지 못하는 한계가 있습니다. 이는 더 세밀한 조정이 필요한 애플리케이션에는 적합하지 않을 수 있습니다.
- **자동화된 레이아웃 생성의 개선 필요**: 자동화된 3D 레이아웃 생성 방법은 아직 초기 단계로, 더 정교한 장면 구성과 레이아웃을 자동으로 생성할 수 있는 기술 개발이 필요합니다.
- **확장성 및 범용성**: 다양한 도시 환경과 다른 스케일의 장면에서도 효과적으로 작동할 수 있도록 범용성과 확장성을 더욱 강화할 필요가 있습니다.