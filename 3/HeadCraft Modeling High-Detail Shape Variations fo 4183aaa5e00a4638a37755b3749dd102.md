# HeadCraft: Modeling High-Detail Shape Variations for Animated 3DMMs

[https://seva100.github.io/headcraft](https://seva100.github.io/headcraft)

[https://arxiv.org/abs/2312.14140](https://arxiv.org/abs/2312.14140)

- Dec 2023

### 1. Introduction

이 논문에서는 3D 모델링의 발전, 특히 사실적인 3D 헤드 모델 제작에 초점을 맞춰 살펴봅니다. 이러한 발전은 신경 방사장(NeRF) 및 부호화된 거리 함수(SDF)와 같은 신경 표현의 개발에 의해 주도되었습니다. 이러한 모델은 컴퓨터 그래픽, 가상 현실, 디지털 엔터테인먼트 등 다양한 분야에서 점점 더 많이 사용되고 있습니다. 비디오 게임 디자인부터 의료 시뮬레이션에 이르기까지 다양한 분야에서 실제와 같은 3D 머리 모델을 만드는 것은 필수적입니다. 최근의 발전에도 불구하고, 특히 높은 디테일을 유지하면서 애니메이션과 트래킹에 적합한 모델을 만드는 데는 여전히 어려움이 있습니다.

![우리는 애니메이션에 사용할 수 있는 고도로 세밀한 사람 머리의 생성 모델인 HeadCraft1을 소개합니다. 이 방법은 자유 표면 변위가 있는 파라메트릭 템플릿 머리를 대규모 3D 헤드 스캔 세트에 등록하여 수집한 2D 변위 맵으로 학습합니다. 결과 모델은 매우 다재다능하며, 이는 모델의 잠재 코드를 임의의 깊이 관찰에 맞춤으로써 입증할 수 있습니다.](HeadCraft%20Modeling%20High-Detail%20Shape%20Variations%20fo%204183aaa5e00a4638a37755b3749dd102/Untitled.png)

우리는 애니메이션에 사용할 수 있는 고도로 세밀한 사람 머리의 생성 모델인 HeadCraft1을 소개합니다. 이 방법은 자유 표면 변위가 있는 파라메트릭 템플릿 머리를 대규모 3D 헤드 스캔 세트에 등록하여 수집한 2D 변위 맵으로 학습합니다. 결과 모델은 매우 다재다능하며, 이는 모델의 잠재 코드를 임의의 깊이 관찰에 맞춤으로써 입증할 수 있습니다.

최근의 3D용 암시적 생성 모델인 pi-GAN, EG3D 또는 StyleSDF는 사람의 얼굴과 머리를 모델링할 때 놀라운 디테일을 보여줍니다. 하지만 이러한 모델은 애니메이션을 구현하기 위해 특정 수정이 필요합니다. 지오메트리를 모델링하고 제어하는 데 중점을 두는 방법은 일반적으로 SDF에 의존하며, 종종 변형이 있는 표현을 위해 별도의 잠재 공간을 학습해야 합니다. 일부 접근 방식은 신경 표현을 '말하는 머리' 동영상에 적용하여 파라메트릭 모델 지침을 통해 명시적인 표현을 도입합니다.

이러한 방법의 강점을 결합한 새로운 생성 모델을 도입하여 세밀한 애니메이션과 추적을 가능하게 합니다. 이는 명시적 파라메트릭 헤드 모델(FLAME)과 표면 변위를 블렌딩하여 헤드 모델의 낮은 지오메트리 디테일을 향상시킴으로써 달성할 수 있습니다. FLAME은 헤드의 모양과 표정을 위한 기반을 제공하는 선형 통계 모델입니다.

세부 변위 맵을 생성하는 프로세스에는 FLAME 모델과 NPHM 데이터 세트를 사용하는 2단계 등록 절차가 포함됩니다. 먼저 강력한 정규화를 통해 벡터 변위에 대한 최적화 문제를 해결하여 메시 자체 교차점을 방지합니다. 그런 다음 별도의 최적화를 통해 정점의 법선을 따라 변위를 세분화합니다. 이러한 변위는 사전 정의된 UV 레이아웃을 사용하여 2D 맵으로 변환됩니다. 이러한 변위 맵을 일반화하여 매우 디테일하고 애니메이션이 가능한 3D 헤드 모델을 생성할 수 있도록 StyleGAN2 모델을 학습시킵니다.

이 접근 방식의 효과와 실용성은 다양한 평가를 통해 검증되었습니다. 생성된 3D 헤드 메시는 다양성 및 충실도 측면에서 FaceVerse 데이터 세트를 사용하는 다른 방법과 비교됩니다. 포인트 클라우드 데이터에 잠상 표현을 맞추고 애니메이션 및 조작 기능을 보여줌으로써 이 접근법의 적용 가능성을 추가로 입증했습니다.

이 연구의 주요 기여 사항은 다음과 같습니다:

- 3D 스캐닝 데이터에서 세밀한 변위 지도를 생성하기 위한 2단계 등록 프로세스.
- 디테일한 피처로 FLAME의 지오메트리를 향상시키고 다양한 헤어스타일을 포함하도록 형상 공간을 확장하는 변위 지도 위의 생성 모델.
- 무조건 샘플링, 보간, 시맨틱 헤어 전송, 깊이 맵 또는 전체 스캔에 대한 적응을 통해 이 방법의 다용도성을 시연합니다.

### 2. Related Work

컴퓨터 비전과 인체 모델링의 관련 작업 개요

컴퓨터 비전과 인체 모델링 분야에서 중요한 두 가지 접근 방식을 검토합니다: 메시 기반 모델과 암시적 모델입니다. 이러한 방법은 개인화된 아바타, 모션 추적, 스캔 등록, 이미지 합성 등 다양한 애플리케이션의 기초를 형성합니다.

- 메시 기반 모델: 3D 모퍼블 모델(3DMM)에서 시작된 이 접근 방식은 사람의 얼굴과 몸의 정체성, 표정, 외형을 표현하는 데 중점을 둡니다. 이 모델은 스캔 데이터의 주성분 분석(PCA)에서 파생된 선형 파라메트릭 블렌드 셰이프가 포함된 3D 템플릿 메시를 중심으로 작동합니다. 시간이 지남에 따라 이 모델은 머리, 손, 전신 또는 이들의 조합을 포함하도록 확장되었습니다. 이 방법의 주요 특징은 고정 토폴로지로, 의미 영역이나 랜드마크와 같은 일관된 UV 언래핑과 표면 대응을 보장한다는 점입니다. 하지만 이 고정 토폴로지는 셰이프의 전체적인 표현과 디테일 수준을 제한할 수 있습니다. 이러한 한계를 해결하기 위해 후속 방법에서는 변위를 최적화하거나 메시 위에 암시적 지오메트리를 추가했습니다. 이 백서의 접근 방식은 이 개념을 기반으로 변위 맵 위에 생성 모델을 학습하여 기본 3DMM의 애니메이션 모델과 표면 대응을 활용하여 세부적인 모델링과 상당한 모양 변경을 가능하게 합니다.
    
    ![방법의 개요. 등록 단계에서는 (a) 얼굴 랜드마크에 의한 FLAME 템플릿을 NPHM 데이터 세트의 스캔에 맞추고 이를 매우 세분화하며, (b) R 3의 정점 변위를 최적화하여 강력한 정규화를 통해 거친 지오메트리에 맞추고, (c) 정상 방향을 따라 변위의 스칼라 세분화를 최적화하며, (d) 변위를 UV 오프셋 맵에 굽습니다.UV 오프셋 맵에 일반화하기 위해 StyleGAN2 [31] 모델을 훈련합니다. 훈련 후, 오프셋을 세분화하여 임의의 FLAME 템플릿에 적용하고 (e) 생성된 UV 오프셋 맵을 FLAME 정점의 (u, v) 위치로 쿼리하여 적용할 수 있습니다.](HeadCraft%20Modeling%20High-Detail%20Shape%20Variations%20fo%204183aaa5e00a4638a37755b3749dd102/Untitled%201.png)
    
    방법의 개요. 등록 단계에서는 (a) 얼굴 랜드마크에 의한 FLAME 템플릿을 NPHM 데이터 세트의 스캔에 맞추고 이를 매우 세분화하며, (b) R 3의 정점 변위를 최적화하여 강력한 정규화를 통해 거친 지오메트리에 맞추고, (c) 정상 방향을 따라 변위의 스칼라 세분화를 최적화하며, (d) 변위를 UV 오프셋 맵에 굽습니다.UV 오프셋 맵에 일반화하기 위해 StyleGAN2 [31] 모델을 훈련합니다. 훈련 후, 오프셋을 세분화하여 임의의 FLAME 템플릿에 적용하고 (e) 생성된 UV 오프셋 맵을 FLAME 정점의 (u, v) 위치로 쿼리하여 적용할 수 있습니다.
    
- 암시적 모델: 3D 모델링에서 암시적 부호화된 거리 함수(SDF)와 신경 방사 필드의 성공은 통계적 신체 모델에 이를 사용하는 데 영감을 주었습니다. 이러한 모델은 일반적으로 표준 공간에서 또는 기존 모델의 변위로 모양과 외관을 학습합니다. 이러한 모델의 관절과 애니메이션은 암시적 변형 필드 또는 블렌드 셰이프 변형을 비롯한 다양한 방법을 통해 이루어집니다. 암시적 모델은 토폴로지나 모양 템플릿의 제약을 받지 않으므로 머리카락이나 안경과 같은 더 복잡한 디테일과 모양을 캡처할 수 있습니다. 하지만 서로 다른 샘플 간에 일관된 표면 대응이 부족하여 메시 기반 모델에는 존재하지 않는 한계가 있습니다.

이 논문에서는 메시 기반 템플릿을 사용하는 접근 방식이 암시적 방법의 한계를 극복하는 방법을 강조합니다. 이 방법은 고도로 세분화된 템플릿 토폴로지에서 고해상도 변위 맵을 학습함으로써 명시적 애니메이션 기능을 유지하면서 암시적 모델과 비슷한 수준의 디테일을 얻을 수 있습니다. 따라서 이 접근 방식은 메시 기반 모델링 기법과 암시적 모델링 기법의 강점을 결합하여 3D 인체 모델링 분야에서 상당한 발전을 이루었습니다.

### 3. Method

이 논문에서 설명하는 방법은 표면 변위가 있는 FLAME의 등록 절차와 생성 모델 개발이라는 두 가지 주요 단계로 구성됩니다.

3.1. 변위 등록 절차: 이 단계에서는 3D 인체 머리 데이터 세트의 각 스캔에 대한 변위와 FLAME 머리 템플릿을 정렬합니다. 이 프로세스는 스캔한 메시로 시작하여 리지드 정렬 최적화 절차를 사용하여 스캔에 대한 FLAME 파라미터를 최적화하는 과정을 포함합니다. 그런 다음 버터플라이 알고리즘을 사용하여 FLAME 템플릿을 세분화하여 보다 세밀한 메시 구조를 만듭니다. 이렇게 세분화된 템플릿은 다음 단계에서 매우 중요합니다.

등록 프로세스에는 두 단계의 최적화가 포함됩니다. 첫 번째 단계에서는 메시 정점의 덧셈 벡터 변위를 최적화하여 자기 교차점을 방지하고 처음에는 헤어 영역에 집중합니다. 두 번째 단계에서는 이전에 변위된 버텍스의 노멀을 따라 이동할 수 있는 변위를 최적화하여 고빈도 디테일을 맞추고 헤어와 얼굴 영역 모두 변형할 수 있도록 합니다. 마지막 단계는 이러한 변위를 데이터 세트의 각 스캔에 대한 UV 맵으로 베이크하는 것입니다.

3.2. 생성 모델: 이 단계에서는 3D 헤드 지오메트리 생성의 어려움을 2D UV 변위 맵 생성으로 전환합니다. 고품질 이미지 생성을 유지하면서 작은 데이터 세트에 대한 일반화에 능숙하기 때문에 StyleGAN2가 선택되었습니다. 이 모델은 매핑 및 제너레이터 네트워크로 구성되어 잠상 코드에서 UV 오프셋 맵을 생성합니다. 이 맵은 조밀하게 세분화된 모든 FLAME 템플릿에 적용하여 각각의 버텍스 변위를 제공할 수 있습니다.

![다양한 방법으로 생성된 메시의 충실도와 다양성을 시각적으로 비교한 결과. 유니티의 경우, 가우스 분포에서 무작위 FLAME을 샘플링하여 NPHM 데이터세트에 대한 통계를 계산하고, UV 등록에 미리 맞춰진 PCA 기준선도 마찬가지입니다. NPHM의 메시는 잠재 코드를 샘플링하고 생성된 SDF 표현에 대해 행진 큐브를 실행하여 얻습니다. 다른 방법보다 생성된 헤드 지오메트리의 가변성이 높고 디테일이 더 우수합니다. 전자식 줌인을 권장합니다.](HeadCraft%20Modeling%20High-Detail%20Shape%20Variations%20fo%204183aaa5e00a4638a37755b3749dd102/Untitled%202.png)

다양한 방법으로 생성된 메시의 충실도와 다양성을 시각적으로 비교한 결과. 유니티의 경우, 가우스 분포에서 무작위 FLAME을 샘플링하여 NPHM 데이터세트에 대한 통계를 계산하고, UV 등록에 미리 맞춰진 PCA 기준선도 마찬가지입니다. NPHM의 메시는 잠재 코드를 샘플링하고 생성된 SDF 표현에 대해 행진 큐브를 실행하여 얻습니다. 다른 방법보다 생성된 헤드 지오메트리의 가변성이 높고 디테일이 더 우수합니다. 전자식 줌인을 권장합니다.

포스트 프로세싱: 생성된 UV 맵에 심이 포함되어 있으므로 모델은 심 버텍스 근처에서 유사한 변위를 생성하여 이 문제를 해결할 것으로 예상됩니다. 그러나 부드러움을 보장하기 위해 포스트 프로세싱은 심 테두리의 변위를 균등화하고 근처에서 블렌딩합니다. 심 근처의 샘플링 오류는 맵의 빈 공간을 인접 픽셀의 변위로 채워서 보정합니다.

![FLAME 레이아웃 비교. FLAME에 일반적으로 사용되는 표준 언래핑(왼쪽)은 머리 뒤쪽의 수직선에 해당하는 이음새가 있으며, 두피보다 얼굴 부위에 더 많은 주의를 기울이고 있습니다. 유니티에서 사용하는 수작업 커스텀 레이아웃(오른쪽)에서는 얼굴 테두리 주변에 다른 심을 선택하여 얼굴과 두피 영역을 분리하고 비슷한 크기로 만들므로 긴 머리와 같은 복잡한 지오메트리를 끊김 없이 모델링할 수 있습니다.](HeadCraft%20Modeling%20High-Detail%20Shape%20Variations%20fo%204183aaa5e00a4638a37755b3749dd102/Untitled%203.png)

FLAME 레이아웃 비교. FLAME에 일반적으로 사용되는 표준 언래핑(왼쪽)은 머리 뒤쪽의 수직선에 해당하는 이음새가 있으며, 두피보다 얼굴 부위에 더 많은 주의를 기울이고 있습니다. 유니티에서 사용하는 수작업 커스텀 레이아웃(오른쪽)에서는 얼굴 테두리 주변에 다른 심을 선택하여 얼굴과 두피 영역을 분리하고 비슷한 크기로 만들므로 긴 머리와 같은 복잡한 지오메트리를 끊김 없이 모델링할 수 있습니다.

요약하면, 이 방법은 매우 사실적이고 세밀한 3D 헤드 모델을 생성하기 위한 세부적이고 체계적인 접근 방식입니다. 이 방법은 세심한 메시 최적화와 고급 제너레이티브 모델링을 결합하여 사람의 머리를 미묘하고 정확하게 표현할 수 있습니다.

### 4. Experiments

이 논문에서는 3D 헤드 모델 생성 방법의 실험 절차와 적용 사례를 간략하게 설명합니다. 자세한 내용은 다음과 같습니다:

4.1. 훈련 절차:

이 방법은 327개의 다양한 신원으로부터 얻은 6975개의 고해상도 스캔 데이터 세트로 훈련되었습니다. 등록 절차는 두 단계에 걸쳐 학습 속도와 하이퍼파라미터가 지정된 아담 옵티마이저를 사용했습니다. 생성 모델은 상세한 UV 맵을 생성하기 위해 72K 단계에 대한 특정 구성으로 StyleGAN2를 사용하여 훈련되었습니다.

4.2. 결과:
이 방법의 결과를 NPHM 및 ROME과 같은 다른 접근 방식과 벤치마킹했습니다. 무조건 샘플링은 머리카락과 얼굴 영역에서 기준선에 비해 뛰어난 디테일과 다양성을 보여주었습니다. 생성된 메시의 사실성과 다양성은 FID, KID, 초기화 점수 등의 지표를 사용하여 FaceVerse 데이터세트에 대해 정량적으로 평가되었습니다. 또한 젠슨-섀넌 발산, 최소 매칭 거리, 커버리지와 같은 3D 유사성 메트릭을 사용하여 모델을 비교했습니다. 이 실험을 통해 이 방법이 모양이 크게 변화하는 사실적인 머리 모델을 생성할 수 있음을 입증했습니다.

![헤드크래프트에서 무작위로 생성된 샘플과 훈련에 사용된 스캔 중 NPHM 데이터 세트의 해당 가장 가까운 이웃 샘플.](HeadCraft%20Modeling%20High-Detail%20Shape%20Variations%20fo%204183aaa5e00a4638a37755b3749dd102/Untitled%204.png)

헤드크래프트에서 무작위로 생성된 샘플과 훈련에 사용된 스캔 중 NPHM 데이터 세트의 해당 가장 가까운 이웃 샘플.

어블레이션 연구:
UV 레이아웃과 제너레이티브 모델 아키텍처의 선택(StyleGAN과 VAE 및 VQ-VAE 비교)의 효과도 평가했습니다. 이 연구를 통해 복잡한 지오메트리를 모델링할 때 UV 레이아웃의 중요성과 세부적인 헤드 모델을 생성하는 데 있어 StyleGAN의 효과를 확인할 수 있었습니다.

![UV 레이아웃 선택에 따른 제거. 우리의 방법은 뒷모습에서 볼 수 있듯이 이음새 아티팩트를 완화하여 보다 일관된 지오메트리를 모델링할 수 있는 커스텀 UV 레이아웃을 활용합니다. 레이아웃은 그림 4에 나와 있습니다.](HeadCraft%20Modeling%20High-Detail%20Shape%20Variations%20fo%204183aaa5e00a4638a37755b3749dd102/Untitled%205.png)

UV 레이아웃 선택에 따른 제거. 우리의 방법은 뒷모습에서 볼 수 있듯이 이음새 아티팩트를 완화하여 보다 일관된 지오메트리를 모델링할 수 있는 커스텀 UV 레이아웃을 활용합니다. 레이아웃은 그림 4에 나와 있습니다.

![제너레이티브 모델 디자인에 대한 제거. VAE와 VQ-VAE는 모두 ResNet-18 인코더 및 디코더 아키텍처를 따르는 반면, 우리의 방법은 StyleGAN2를 기반으로 합니다. VAE와 VQ-VAE의 결과는 훈련 데이터의 다양성과 일치하지만 디테일 수준은 일치하지 않으며 UV 심을 더 잘 처리합니다.](HeadCraft%20Modeling%20High-Detail%20Shape%20Variations%20fo%204183aaa5e00a4638a37755b3749dd102/Untitled%206.png)

제너레이티브 모델 디자인에 대한 제거. VAE와 VQ-VAE는 모두 ResNet-18 인코더 및 디코더 아키텍처를 따르는 반면, 우리의 방법은 StyleGAN2를 기반으로 합니다. VAE와 VQ-VAE의 결과는 훈련 데이터의 다양성과 일치하지만 디테일 수준은 일치하지 않으며 UV 심을 더 잘 처리합니다.

등록 절차의 동작:

2단계 등록 절차와 다른 접근 방식을 비교한 결과, 제안된 방식이 자기 교차점과 같은 아티팩트를 피하면서 세부적인 형상을 효과적으로 캡처하는 것으로 나타났습니다.

4.3. 응용 분야:

이 모델은 다양한 시나리오에서 그 유용성을 입증했습니다:

- 심도 맵에 맞추기: 이 모델은 부분 포인트 클라우드에 피팅하여 깊이 센서와 같은 부분 관측을 완료할 수 있습니다.
    
    ![HeadCraft 모델을 사용한 지오메트리 완성 데모. 여기서는 훈련 중에 보이지 않던 NPHM 데이터 세트의 스캔에서 뎁스 맵을 추출하고 적절한 StyleGAN의 잠재적 표현을 찾아서 완성하려고 합니다. 필요한 중간 단계로 먼저 부분 포인트 클라우드에 등록 절차를 적용하여 템플릿의 UV 공간에서 포인트를 찾습니다. 관측된 영역에서 전체 UV 맵과 등록된 부분 UV 맵의 불일치를 최소화하여 최적의 잠상을 찾습니다. 헤드크래프트는 또한 매우 희박한 포인트 클라우드(포인트 수의 1%)에 대해 그럴듯한 세부 정보를 추정할 수 있습니다(마지막 행 참조).](HeadCraft%20Modeling%20High-Detail%20Shape%20Variations%20fo%204183aaa5e00a4638a37755b3749dd102/Untitled%207.png)
    
    HeadCraft 모델을 사용한 지오메트리 완성 데모. 여기서는 훈련 중에 보이지 않던 NPHM 데이터 세트의 스캔에서 뎁스 맵을 추출하고 적절한 StyleGAN의 잠재적 표현을 찾아서 완성하려고 합니다. 필요한 중간 단계로 먼저 부분 포인트 클라우드에 등록 절차를 적용하여 템플릿의 UV 공간에서 포인트를 찾습니다. 관측된 영역에서 전체 UV 맵과 등록된 부분 UV 맵의 불일치를 최소화하여 최적의 잠상을 찾습니다. 헤드크래프트는 또한 매우 희박한 포인트 클라우드(포인트 수의 1%)에 대해 그럴듯한 세부 정보를 추정할 수 있습니다(마지막 행 참조).
    
- 전체 스캔 피팅 및 애니메이션: 전체 스캔을 피팅하고 전체 머리 모델을 애니메이션화하는 모델의 기능을 멀티뷰 비디오 시퀀스에 적용하여 선보였습니다.
    
    ![모델의 애니메이션 기능 데모. 각 시퀀스는 NeRSemble 데이터세트[34]의 시퀀스에서 불꽃 모양 파라미터, 표정, 턱, 머리 포즈 파라미터를 가져와 템플릿을 세분화하고 HeadCraft에서 임의로 생성된 변위를 적용하여 생성됩니다.](HeadCraft%20Modeling%20High-Detail%20Shape%20Variations%20fo%204183aaa5e00a4638a37755b3749dd102/Untitled%208.png)
    
    모델의 애니메이션 기능 데모. 각 시퀀스는 NeRSemble 데이터세트[34]의 시퀀스에서 불꽃 모양 파라미터, 표정, 턱, 머리 포즈 파라미터를 가져와 템플릿을 세분화하고 HeadCraft에서 임의로 생성된 변위를 적용하여 생성됩니다.
    

4.4. 분석:

이 논문은 또한 잠재 공간의 변위와 스캔 간의 모발 이동 사이의 보간을 탐구하여 머리 형상을 의미적으로 수정하는 데 있어 이 방법의 다용도성을 보여주었습니다.

요약하면, 실험과 적용을 통해 제안된 3D 헤드 모델 생성 방법이 세밀하고 사실적일 뿐만 아니라 애니메이션, 뎁스 맵 피팅, 지오메트리 수정 등 다양한 실제 시나리오에서 다용도로 활용될 수 있음을 보여주었습니다.

![1단계 등록과 2단계 등록을 통한 제거. 벡터 변위 단계(a)만 남겨두면 너무 매끄러운 지오메트리가 생성되고, 법선을 따라만 학습하면(b) 첫 번째 단계를 약한 정규화로 실행하는 것과 마찬가지로 불필요한 스파이크가 발생합니다(c).](HeadCraft%20Modeling%20High-Detail%20Shape%20Variations%20fo%204183aaa5e00a4638a37755b3749dd102/Untitled%209.png)

1단계 등록과 2단계 등록을 통한 제거. 벡터 변위 단계(a)만 남겨두면 너무 매끄러운 지오메트리가 생성되고, 법선을 따라만 학습하면(b) 첫 번째 단계를 약한 정규화로 실행하는 것과 마찬가지로 불필요한 스파이크가 발생합니다(c).

### 5 Discussion

이 논문에서는 애니메이션이 가능한 파라메트릭 모델과 신경 정점 변위 모델러를 능숙하게 병합하여 3D 인간 머리를 생성하는 새로운 생성 모델을 소개합니다. 이 하이브리드 접근 방식은 사실적인 애니메이션을 구현하는 능력과 고품질의 모양 변형 생성 간의 균형을 성공적으로 유지하므로 이 분야에서 중요한 진전을 이루었습니다.

![시맨틱 편집. 헤드크래프트의 잠재적 표현을 보간하면 인물의 외모를 부드럽게 변경할 수 있습니다. 이를 위해 훈련 중에 보이지 않는 NPHM 데이터 세트의 실제 스캔 두 개(갈색, 맨 윗줄)에 대한 잠재 코드를 맞추고 λ 가중치로 혼합합니다. 마찬가지로 한 사람에서 다른 사람으로 헤어 지오메트리를 전송할 수 있습니다.](HeadCraft%20Modeling%20High-Detail%20Shape%20Variations%20fo%204183aaa5e00a4638a37755b3749dd102/Untitled%2010.png)

시맨틱 편집. 헤드크래프트의 잠재적 표현을 보간하면 인물의 외모를 부드럽게 변경할 수 있습니다. 이를 위해 훈련 중에 보이지 않는 NPHM 데이터 세트의 실제 스캔 두 개(갈색, 맨 윗줄)에 대한 잠재 코드를 맞추고 λ 가중치로 혼합합니다. 마찬가지로 한 사람에서 다른 사람으로 헤어 지오메트리를 전송할 수 있습니다.

이 방법의 주요 특징

- 고품질 셰이프 베리에이션: 이 방법을 사용하면 세밀하고 다양한 머리 모양을 생성할 수 있어 모델의 사실감을 크게 향상시킬 수 있습니다.
- 사실적인 애니메이션 기능: 이 방법은 애니메이션이 가능한 파라메트릭 모델을 통합하여 생성된 3D 헤드에 실제와 같은 방식으로 애니메이션을 적용할 수 있습니다.
- 잠복 표현 반전: 모델의 반전 프레임워크는 전체 헤드 스캔 또는 깊이 센서에서 얻은 스캔과 같은 부분 스캔을 정확하게 표현하는 데 능숙합니다. 이 기능은 부분적인 데이터만 사용할 수 있는 실제 애플리케이션에 매우 중요합니다.

향후 작업 방향:

- 외모 모델 통합: 향후 개발이 유망한 분야는 색상 및 재질 기반 재조명을 위한 모델을 포함하는 것입니다. 이렇게 하면 다양한 조명 조건에서 3D 헤드를 더욱 미묘하고 사실적으로 렌더링할 수 있습니다.
- 머리카락 움직임의 물리적 모델: 또 다른 잠재적 개선 사항은 개별 머리카락 가닥에 기반한 머리카락 움직임의 물리적 모델을 통합하는 것입니다. 이는 특히 헤어 다이내믹이 중요한 역할을 하는 시뮬레이션에서 애니메이션에 새로운 사실감을 더할 수 있습니다.

결론적으로, 이 작업은 고품질의 형상 모델링과 사실적인 애니메이션을 모두 제공함으로써 3D 인체 머리 모델링 영역에서 중요한 진전을 이루었습니다. 특히 가상 현실, 디지털 엔터테인먼트, 사실적인 시뮬레이션과 같은 분야에서 이러한 모델의 사실성과 적용 가능성을 더욱 향상시키는 것이 향후 개발의 목표입니다.

### Appendix

3D 인체 머리 모델 생성 방법에 대한 자세한 설명
이 섹션에서는 사람 머리의 상세한 3D 모델을 생성하는 방법에 대한 기술적 세부 사항을 자세히 설명합니다.

A.1. 변위 등록 절차

- 버텍스 및 변위 모델링: 30배 스케일링된 NPHM 좌표계로 구현됩니다.
- 세분화: 메시랩의 버터플라이 세분화를 사용하여 약 10만 개의 버텍스와 20만 개의 트라이앵글을 생성하여 표면을 상당히 매끄럽게 만듭니다.
- 손실 용어: 포인트 클라우드 사이의 거리를 측정하는 모따기 텀, 가장자리 길이 정규화, 라플라시안 텀이 포함되어 부드러움을 보장하고 스파이크를 방지합니다.
- 최적화 단계: 벡터 변위 최적화(두피 영역에 집중)와 일반 변위 최적화(얼굴 영역을 포함하지만 목과 입 안쪽과 같은 특정 영역은 고정된 상태로 유지)의 두 단계가 포함됩니다.
- 계산 세부 사항: 각 단계는 NVIDIA RTX 2080 Ti GPU에서 1,000단계에 약 3분이 소요됩니다.
마무리: 변위 벡터는 [-20, +20] 범위로 클리핑되고 UV 공간에서 렌더링되며, 정밀도 유지를 위해 uint16 이미지 파일로 저장됩니다.

A.2. 생성 모델

StyleGAN 훈련: 특정 하이퍼파라미터와 함께 StyleGAN2를 활용하며, NVIDIA RTX 2080 Ti GPU에서 훈련합니다.

- 얼굴 부분 교체: 더 나은 표정 지원을 위해 UV 맵의 얼굴 부분이 중립 표정 스캔의 얼굴 부분으로 대체됩니다.
- 포스트 프로세싱: 이음새의 변위를 블렌딩하고 샘플링 오류를 수정하여 부드러움과 연속성을 보장하는 작업이 포함됩니다.

B. 결과: 기술적 세부 사항

![커스텀 UV 심 주석 데모입니다. 표준 UV는 FLAME 모델과 함께 제공됩니다. 커스텀 UV는 유니티 파이프라인에 사용되는 수작업 레이아웃을 의미합니다. 이 레이아웃은 긴 머리와 같은 정교한 모양 변형을 일관된 방식으로 학습하는 것을 간소화합니다.](HeadCraft%20Modeling%20High-Detail%20Shape%20Variations%20fo%204183aaa5e00a4638a37755b3749dd102/Untitled%2011.png)

커스텀 UV 심 주석 데모입니다. 표준 UV는 FLAME 모델과 함께 제공됩니다. 커스텀 UV는 유니티 파이프라인에 사용되는 수작업 레이아웃을 의미합니다. 이 레이아웃은 긴 머리와 같은 정교한 모양 변형을 일관된 방식으로 학습하는 것을 간소화합니다.

- 무조건 샘플링: 샘플링을 위해 잘라내기 트릭을 사용하여 다양한 시점의 다양한 샘플을 제공합니다.
- 평가 지표: 정량적 평가를 위해 포인트플로우의 MMD, JSD, COV 지표를 사용합니다.
- 제너레이티브 모델 아키텍처 제거: 비교를 위해 VAE 및 VQ-VAE 아키텍처를 탐색합니다.

B.1. 애플리케이션

- 전체 스캔 및 뎁스 맵에 피팅: 머리 스캔과 뎁스 맵의 부분 관찰을 완료하기 위해 모델을 피팅하는 프로세스에 대해 설명합니다.
- 애니메이션: 일관된 세분화 및 표면 법선 회전에 대한 고려 사항을 포함하여 시간에 따라 변형되는 템플릿에 변위를 적용하는 방법에 대해 자세히 설명합니다.

요약하면, 이 방법은 3D 인체 머리 모델을 생성하기 위한 포괄적이고 기술적으로 정교한 접근 방식을 제공합니다. 버텍스 변위, 생성 모델 훈련 및 후처리를 위한 세부 절차를 통합하여 고품질의 사실적인 결과물을 보장합니다. 이 방법은 전체 스캔, 부분 뎁스 맵, 애니메이션 모델에 효과적으로 적용할 수 있다는 점에서 그 다재다능함이 돋보입니다.