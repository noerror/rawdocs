# ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation

[https://github.com/ViTAE-Transformer/ViTPose](https://github.com/ViTAE-Transformer/ViTPose)

[https://arxiv.org/abs/2204.12484](https://arxiv.org/abs/2204.12484)

### 1 Introduction

이미지에서 인체 해부학적 키포인트를 식별하는 것을 목표로 하는 인체 포즈 추정은 컴퓨터 비전의 기본 작업입니다. 최근 딥러닝 방법은 이 문제를 해결하는 데 상당한 진전을 이루었으며, 특히 컨볼루션 신경망(CNN)과 비전 트랜스포머를 사용하는 데 중점을 두고 있습니다.

![모델의 크기, 처리량, 정밀도에 대한 ViTPose와 최첨단(SOTA) 방법들의 MS COCO 검증 세트에 대한 비교입니다. 각 버블의 크기는 모델 매개변수의 수를 나타냅니다.](ViTPose%20Simple%20Vision%20Transformer%20Baselines%20for%20Hu%2062e93bb6eb8048b2a3b56556a1f569d3/Untitled.png)

모델의 크기, 처리량, 정밀도에 대한 ViTPose와 최첨단(SOTA) 방법들의 MS COCO 검증 세트에 대한 비교입니다. 각 버블의 크기는 모델 매개변수의 수를 나타냅니다.

이 논문에서 저자들은 포즈 추정을 위한 새로운 기준 모델인 ViTPose를 소개합니다. 이 모델은 비계층적 비전 트랜스포머를 활용하여 특징 맵을 추출한 다음 경량 디코더를 사용하여 이러한 특징을 처리하고 특징 맵을 업샘플링하여 키포인트의 히트맵을 결정합니다. 복잡한 트랜스포머 구조나 특징 추출을 위한 추가 CNN이 필요하지 않다는 점에서 ViTPose는 단순성이 돋보입니다.

단순함에도 불구하고 ViTPose는 이 분야의 벤치마킹에 자주 사용되는 데이터 세트인 MS COCO 키포인트 테스트 개발 세트에서 최첨단 성능을 달성합니다. 또한 단순성, 확장성, 유연성 및 전송성 측면에서 인상적인 기능을 보여줍니다. 모델의 단순성은 추가 트랜스포머 레이어 또는 피처 치수에 따라 잘 확장할 수 있어 다양한 요구 사항에 맞게 조정할 수 있다는 것을 의미합니다.

또한 ViTPose는 훈련 패러다임이 유연하여 다양한 입력 및 피처 해상도에서 우수한 성능을 발휘하고 약간의 수정만으로 여러 포즈 데이터 세트에 적응할 수 있습니다. 이러한 훈련의 다양성은 경량 디코더 덕분에 약간의 추가 계산 비용만으로 제공됩니다. 또한, 작은 ViTPose 모델은 더 큰 ViTPose 모델로부터 학습하여 성능을 향상시킬 수 있으며, 우수한 전이성을 보여줍니다.

결론적으로 이 백서에서는 간단하고 효율적인 사람 포즈 추정 모델인 ViTPose를 소개합니다. 이 모델은 복잡한 구조나 프레임워크에 의존하지 않고도 MS COCO 키포인트 데이터세트에서 인상적인 결과를 달성하여 확장성, 유연성, 전이성을 입증했습니다. 저자는 이러한 기능 덕분에 ViTPose가 비전 트랜스포머 기반 포즈 추정 작업의 향후 개발을 위한 강력한 기준이 될 것이라고 믿습니다.

### 2 Related Work

2.1 포즈 추정을 위한 비전 트랜스포머

포즈 추정 분야는 컨볼루션 신경망(CNN)을 사용하는 것에서 비전 트랜스포머 네트워크를 사용하는 것으로 전환하면서 빠르게 발전해 왔습니다. 초창기에는 CNN에서 추출한 특징을 직접 처리하는 TransPose, 가려진 키포인트의 위치를 추정하고 관계를 모델링하기 위해 추가 토큰을 도입한 TokenPose와 같이 고급 디코더로 트랜스포머를 활용하기도 했습니다.

그러나 특징 추출을 위해 CNN이 필요 없게 하기 위해 HRFormer가 도입되었습니다. 이 기술은 트랜스포머를 사용해 고해상도 특징을 직접 추출하는 한편, 다중 해상도 특징을 점진적으로 융합하기 위해 신중하게 설계된 병렬 트랜스포머 모듈을 구현합니다.

이러한 트랜스포머 기반 방법은 키포인트 추정 벤치마크에서 우수한 성능을 보였지만, 여전히 특징 추출을 위해 CNN에 의존하거나 트랜스포머 구조의 복잡한 설계가 필요합니다. 포즈 추정 작업을 위한 일반 비전 트랜스포머의 잠재력을 탐구하는 데는 최소한의 노력만 기울여 왔습니다. 이 백서에서는 일반 비전 트랜스포머를 기반으로 간단하면서도 효과적인 기준 모델인 ViTPose를 제안하여 이러한 격차를 해결하고자 합니다.

2.2 비전 트랜스포머 사전 훈련

ViT의 성공을 바탕으로 다양한 비전 트랜스포머 백본이 제안되었습니다. 이러한 비전 트랜스포머는 일반적으로 완전 감독 환경에서 ImageNet-1K 데이터세트에 대해 훈련됩니다. 최근에는 일반 비전 트랜스포머를 훈련하기 위한 자가 지도 학습 방법이 도입되었습니다. 이러한 방법은 마스크된 이미지 모델링(MIM)을 사전 작업으로 사용하여 일반 비전 변환기에 대한 견고한 초기화를 제공합니다.

이 논문에서 저자는 포즈 추정 작업에 초점을 맞추고 MIM 사전 훈련이 포함된 일반 비전 트랜스포머를 백본으로 채택합니다. 또한 포즈 추정 작업에 ImageNet-1K를 사용한 사전 훈련이 필요한지 여부를 조사합니다. 놀랍게도 레이블이 지정되지 않은 작은 포즈 데이터 세트를 사용한 사전 훈련으로도 이러한 작업에 적합한 초기화를 제공할 수 있다는 사실을 발견했습니다.

### 3 ViTPose

3.1 ViTPose의 단순성

우리의 목표는 일반적이고 계층적이지 않은 비전 트랜스포머를 활용하는 포즈 추정 작업을 위한 간단하면서도 효과적인 비전 트랜스포머 기준을 소개하는 것입니다. 따라서 우리는 성능을 향상시킬 수 있는 잠재력과 관계없이 복잡한 모듈을 피하고 단순한 구조를 선택했습니다. 따라서 그림 2 (a)와 같이 키포인트에 대한 히트맵을 추정하기 위해 트랜스포머 백본 뒤에 몇 개의 디코더 레이어를 추가했습니다. 단순성을 위해 디코더 레이어에서 스킵 연결이나 교차 주의를 피하고 간단한 디컨볼루션 레이어와 예측 레이어를 선택했습니다.

![(a) ViTPose의 프레임워크. (b) 트랜스포머 블록. (c) 클래식 디코더. (d) 간단한 디코더. (e) 다중 데이터셋에 대한 디코더들.](ViTPose%20Simple%20Vision%20Transformer%20Baselines%20for%20Hu%2062e93bb6eb8048b2a3b56556a1f569d3/Untitled%201.png)

(a) ViTPose의 프레임워크. (b) 트랜스포머 블록. (c) 클래식 디코더. (d) 간단한 디코더. (e) 다중 데이터셋에 대한 디코더들.

ViTPose는 처음에 패치 임베딩 레이어를 통해 이미지를 토큰에 임베딩합니다. 이렇게 임베드된 토큰은 멀티 헤드 셀프 어텐션(MHSA) 레이어와 피드 포워드 네트워크(FFN)로 구성된 여러 트랜스포머 레이어에 의해 처리됩니다. 백본 네트워크의 출력 기능은 Fout으로 표시됩니다.

두 가지 유형의 경량 디코더를 사용하여 백본 네트워크에서 추출한 특징을 처리하고 키포인트를 로컬라이즈합니다. 첫 번째는 특징 맵을 두 배로 업샘플링하는 두 개의 디컨볼루션 블록으로 구성된 클래식 디코더입니다. 그런 다음 컨볼루션 레이어가 키포인트에 대한 로컬라이제이션 히트맵을 생성합니다.

고전적인 디코더의 단순성에도 불구하고, 우리는 더 간단한 또 다른 디코더를 실험했습니다. 여기서는 이중 선형 보간을 사용하여 특징 맵을 직접 4배 업샘플링한 다음 ReLU와 컨볼루션 레이어를 사용하여 히트맵을 생성합니다. 이 간단한 디코더는 비선형 용량이 감소했음에도 불구하고 기존 디코더에 비해 경쟁력 있는 성능을 달성하여 ViTPose의 구조적 단순성을 강조합니다.

3.2 ViTPose의 확장성

ViTPose의 구조적 단순성 덕분에 다양한 수의 트랜스포머 레이어를 쌓고 피처 치수를 늘리거나 줄여 모델 크기를 조정하여 확장할 수 있습니다. ViTPose는 다른 부품의 수정을 최소화하면서 확장 가능한 사전 학습된 비전 트랜스포머를 빠르게 개발할 수 있다는 이점을 제공합니다. 이러한 확장성을 입증하기 위해 다양한 모델 용량의 사전 훈련된 백본을 사용하고 MS COCO 데이터 세트에서 이를 미세 조정합니다. 모델 크기가 증가함에 따라 일관된 성능 향상이 관찰됩니다. 사전 학습 중에 14 x 14 크기의 패치 임베딩을 사용하는 모델의 경우, 다른 모델에 사용된 설정과 일치하도록 제로 패딩을 적용하여 16 x 16 크기의 패치 임베딩을 공식화합니다.

3.3 ViTPose의 유연성

사전 훈련 데이터 유연성: 이미지넷으로 백본 네트워크를 사전 훈련하는 것은 일반적인 방법이지만, 포즈 데이터 외에 추가 데이터가 필요하기 때문에 데이터 요구사항이 높아집니다. 이러한 요구 사항을 완화하기 위해 전체 훈련 단계에서 포즈 데이터만 활용할 수 있는지 살펴봤습니다. 놀랍게도 포즈 데이터로만 학습한 ViTPose는 경쟁력 있는 성능을 달성할 수 있었으며, 다양한 규모의 데이터에서 학습할 수 있는 유연성을 보여주었습니다.

해상도 유연성: 입력 이미지 크기와 다운샘플링 비율을 조정하여 입력 및 특징 해상도에 대한 유연성을 측정했습니다. 입력 해상도나 특징 해상도를 높이면 ViTPose의 성능이 일관되게 향상되는 것을 확인했습니다.

주의 유형 유연성: 고해상도 피처 맵에 전체 주의력을 사용하면 계산 비용이 많이 들고 많은 양의 메모리가 필요할 수 있습니다. 이에 대응하기 위해 우리는 시프트 윈도우 메커니즘과 풀링 기법을 통합하여 추가 매개변수나 모듈 없이도 성능을 개선하고 메모리 공간을 줄였습니다.

미세 조정 유연성: MS COCO 데이터세트에서 ViTPose에 대한 다양한 미세 조정 설정을 실험한 결과, MHSA 모듈이 고정된 상태에서도 ViTPose가 완전히 미세 조정된 모델과 비슷한 성능을 달성하는 것으로 나타났습니다.

![MS COCO 데이터셋의 일부 테스트 이미지에 대한 ViTPose의 시각적 포즈 추정 결과](ViTPose%20Simple%20Vision%20Transformer%20Baselines%20for%20Hu%2062e93bb6eb8048b2a3b56556a1f569d3/Untitled%202.png)

MS COCO 데이터셋의 일부 테스트 이미지에 대한 ViTPose의 시각적 포즈 추정 결과

작업 유연성: ViTPose 디코더의 단순하고 가벼운 특성 덕분에 백본 인코더를 공유하여 여러 포즈 추정 데이터 세트를 처리할 수 있습니다. 각 반복마다 다양한 훈련 데이터세트에서 무작위로 인스턴스를 샘플링하고 해당 히트맵을 추정하여 이를 달성했습니다.

3.4 ViTPose의 이전 가능성

지식 증류는 대규모 모델에서 지식을 이전하여 소규모 모델을 개선하는 일반적인 방법입니다. 저희는 출력 증류 손실을 사용하여 학생 네트워크의 출력이 교사 네트워크의 출력을 모방하도록 하는 이 접근 방식을 채택했습니다.

표준 증류 방식 외에도 토큰 기반 증류 방식도 제안했습니다. 먼저 학습 가능한 추가 지식 토큰을 무작위로 초기화하여 교사 모델의 패치 임베딩 레이어 이후에 시각적 토큰에 추가했습니다. 그런 다음 이 지식 토큰을 몇 차례에 걸쳐 미세 조정한 후, 학습 중에 학생 네트워크의 시각적 토큰과 연결하여 동결했습니다. 이 설정에서 학생 네트워크의 손실은 토큰 증류 손실과 출력 증류 손실 및 토큰 증류 손실의 조합으로 나타났습니다.

### 4 Experiments

이 섹션에서는 ViTPose 모델에 대한 실험 설정과 결과를 설명합니다.

구현 세부 사항(섹션 4.1)에서는 사람 인스턴스에 대한 감지기와 이러한 인스턴스의 키포인트를 추정하기 위한 ViTPose를 사용하여 사람 포즈 추정을 위한 일반적인 하향식 설정에서 ViTPose를 사용하는 방법을 간략하게 설명합니다. 다양한 버전의 ViTPose(ViTPose-B, ViTPose-L, ViTPose-H)가 MS COCO 키포인트 검증 세트에서 훈련 및 평가됩니다. 배치 크기, 학습 속도, 가중치 감쇠, 레이어별 감쇠, 낙하 경로 속도와 같은 이러한 실험에 대한 하이퍼파라미터는 표 1에 나와 있습니다.

제거 연구 및 분석(섹션 4.2)에서는 ViTPose의 몇 가지 주요 측면을 조사합니다:

구조의 단순성 및 확장성: 여기서는 다양한 디코더와 다양한 백본을 사용하는 ViTPose를 비교합니다. 그 결과, ViTPose는 약간의 성능 저하만으로 간단한 디코더를 효과적으로 사용할 수 있으며, 모델 크기에 따라 성능이 일관되게 향상되어 확장성이 우수하다는 것을 발견했습니다.

사전 훈련 데이터의 영향: 저자들은 다양한 데이터 세트에 대해 사전 학습했을 때와 그렇지 않은 경우의 성능을 비교했습니다. 그 결과, 다운스트림 작업(MS COCO 및 AI Challenger)의 데이터로 사전 학습하면 데이터 효율성이 향상되고 ImageNet-1K 사전 학습과 유사한 성능을 얻을 수 있다는 사실을 발견했습니다.

입력 해상도의 영향: 이 연구의 이 부분에서는 입력 해상도가 증가함에 따라 ViTPose의 성능이 향상됨을 보여줍니다. 그러나 제곱 입력은 데이터 세트에 있는 사람 인스턴스의 평균 종횡비로 인해 큰 개선 효과를 제공하지 못했습니다.

주의 유형에 따른 영향: 저자들은 고해상도 특징 맵이 포즈 추정 작업에 유용하며, ViTPose는 다운샘플링 비율을 변경하여 이러한 맵을 생성할 수 있음을 보여줍니다. 그러나 이는 트랜스포머 레이어의 이차적 계산 복잡성으로 인해 메모리 부족 문제를 일으킬 수 있습니다. 이 문제를 해결하기 위해 저자는 윈도우 어텐션으로 실험하여 메모리 문제를 완화하면서도 비슷한 성능을 얻을 수 있음을 입증했습니다.

전반적으로 이러한 실험과 분석은 포즈 추정 작업을 위한 ViTPose의 유연성, 확장성, 효율성을 강조합니다.

이 섹션에서는 포즈 추정을 위한 비전 트랜스포머(ViT)인 ViTPose의 성능에 대한 실험 결과와 논의에 대해 설명합니다.

먼저 ViTPose 모델을 부분적으로 미세 조정했을 때의 효과를 분석합니다. 그 결과 피드 포워드 네트워크(FFN) 모듈을 미세 조정하면 모델 성능에 크게 기여하는 것으로 나타났습니다. 멀티 헤드 셀프 어텐션(MHSA) 모듈을 동결하면 성능에 미치는 영향이 적었습니다.

연구진은 다중 데이터 세트 훈련의 영향도 조사했습니다. 연구진은 다중 데이터 세트 학습을 위해 MS COCO, AI Challenger, MPII의 세 가지 데이터 세트를 사용했습니다. 이 접근 방식은 75.8 AP에서 77.1 AP로 성능이 향상되었으며, 이는 ViTPose가 여러 데이터 세트에서 다양한 데이터를 효과적으로 활용할 수 있음을 시사합니다.

전이성을 평가하기 위해 출력 증류와 제안된 지식 토큰 증류를 사용하여 더 큰 ViTPose-L 모델에서 더 작은 ViTPose-B로 지식을 전이했습니다. 그 결과 두 증류 방법 모두 더 작은 모델의 성능을 향상시켜 ViTPose의 전이 가능성을 입증했습니다.

최신(SOTA) 방법과 비교했을 때, ViTPose는 더 큰 모델 크기에도 불구하고 처리량과 정확도 사이에서 더 나은 절충점을 보여줍니다. ViTPose-L과 ViTPose-H 모델은 특히 성능이 뛰어나 UPD와 TokenPose를 포함한 다른 SOTA 모델보다 성능이 뛰어납니다.

마지막으로, 연구원들은 더 강력한 백본과 탐지기를 사용하는 ViTPose-G 모델을 통해 ViTPose의 성능 한계를 더욱 확장했습니다. ViTPose-G 모델은 MS COCO 테스트 개발 세트에서 이전의 모든 SOTA 방법을 능가합니다.

주관적인 결과에서도 오클루전이 심하고 자세가 다르며 스케일이 다른 까다로운 경우에도 포즈를 정확하게 추정할 수 있는 ViTPose의 능력을 확인할 수 있습니다.

### 5 Limitation and Discussion

이 결론 및 토론 섹션에서는 저자들이 자신들의 연구와 그 한계를 되돌아봅니다. 이들은 포즈 추정을 위한 간단하지만 효과적인 비전 변환기 기준선인 ViTPose를 개발했지만, 그 잠재력이 완전히 탐구되지는 않았다고 생각합니다. 복잡한 디코더나 피처 피라미드 네트워크(FPN) 구조와 같은 고급 기술을 사용하면 성능을 더욱 향상시킬 수 있습니다.

ViTPose는 단순성, 확장성, 유연성, 전송성과 같은 매력적인 특성을 보여줍니다. 그러나 저자는 ViTPose의 유연성을 더욱 입증하기 위해 프롬프트 기반 튜닝을 탐색하는 등 더 많은 연구 노력이 필요하다고 생각합니다. 또한 동물 포즈 추정 및 얼굴 키포인트 감지와 같은 다른 포즈 추정 데이터 세트에 ViTPose를 적용할 수 있는 가능성을 제시하고 이를 향후 연구 과제로 남겨두었습니다.

결론적으로, 연구진은 비전 트랜스포머 기반 사람 포즈 추정을 위한 간단한 기준선으로 ViTPose를 제시하고, MS COCO 데이터 세트에 대한 실험을 통해 그 다용도성을 보여줍니다. 저자는 대규모 백본인 ViTAE-G가 포함된 단일 ViTPose 모델이 MS COCO 테스트 개발 세트에서 최고의 80.9 AP를 얻었다고 언급합니다. 저자들은 이 연구가 커뮤니티에 귀중한 인사이트를 제공하고 더 많은 컴퓨터 비전 작업에서 일반 비전 트랜스포머의 잠재력에 대한 추가 연구를 촉진할 수 있기를 바랍니다.

저자들은 ARC FL-170100117 및 IH-180100002를 통해 지원을 제공한 유페이 쉬, 징 장 박사, 치밍 장에게 감사를 표하며 감사의 말을 전합니다.

### Appendix

이 추가 정보에서 논문 작성자는 ViTPose의 성능을 철저히 평가하기 위해 추가 테스트 결과를 제시합니다. 이들은 여러 다른 데이터 세트에 대해 ViTPose-B, ViTPose-L, ViTPose-H, ViTPose-G 등 다양한 ViTPose 변형을 테스트했습니다: OCHuman, MPII, AI Challenger.

OCHuman 세트의 경우, 그 결과 ViTPose는 오클루전을 처리하기 위한 특별한 디자인이 없어도 피처를 표현하는 능력이 뛰어난 것으로 나타났습니다. 특히, 이전의 최첨단(SOTA) 방법보다 훨씬 뛰어난 성능을 보였으며, OCHuman 검증 세트에서 10배 이상의 AP 증가를 달성하기도 했습니다.

![OCHuman 데이터셋의 일부 테스트 이미지에 대한 ViTPose의 시각적 포즈 추정 결과](ViTPose%20Simple%20Vision%20Transformer%20Baselines%20for%20Hu%2062e93bb6eb8048b2a3b56556a1f569d3/Untitled%203.png)

OCHuman 데이터셋의 일부 테스트 이미지에 대한 ViTPose의 시각적 포즈 추정 결과

MPII 검증 세트에 대한 ViTPose의 성능도 평가되었습니다. 모든 ViTPose 변형이 단일 공동 평가와 평균 평가 모두에서 더 나은 성능을 보였으며, 특히 ViTAE-G 백본과 더 큰 입력 해상도를 갖춘 ViTPose-G는 94.3 PCKh에 도달하여 MPII 검증 세트에서 새로운 SOTA를 기록했습니다.

![MPII 데이터셋의 일부 테스트 이미지에 대한 ViTPose의 시각적 포즈 추정 결과](ViTPose%20Simple%20Vision%20Transformer%20Baselines%20for%20Hu%2062e93bb6eb8048b2a3b56556a1f569d3/Untitled%204.png)

MPII 데이터셋의 일부 테스트 이미지에 대한 ViTPose의 시각적 포즈 추정 결과

AI 챌린저 검증 세트에서 ViTPose는 대표적인 CNN 기반 및 트랜스포머 기반 모델보다 우수한 성능을 보였습니다. 최고 AP(43.2)는 ViTPose-G가 달성했으며, 이 역시 ViTAE-G 백본과 더 큰 입력 해상도를 통해 달성되었습니다. 하지만 정밀도가 충분히 높지 않아 개선이 더 필요한 것으로 나타났습니다.

![AI Challenger 데이터셋의 일부 테스트 이미지에 대한 ViTPose의 시각적 포즈 추정 결과](ViTPose%20Simple%20Vision%20Transformer%20Baselines%20for%20Hu%2062e93bb6eb8048b2a3b56556a1f569d3/Untitled%205.png)

AI Challenger 데이터셋의 일부 테스트 이미지에 대한 ViTPose의 시각적 포즈 추정 결과

저자들은 훈련과 평가에 사용된 데이터 세트에 대한 자세한 정보도 제공했습니다. 여기에는 MS COCO, AI Challenger, MPII, CrowdPose가 포함되었으며, OCHuman은 평가 단계에만 사용되었습니다. 각 데이터세트에는 이미지 수, 사람 인스턴스, 키포인트 주석 등 고유한 특징이 있었습니다.

마지막으로 주관적인 평가를 위해 AI 챌린저, OCHuman, MPII 데이터 세트의 시각적 포즈 추정 결과를 일부 포함했습니다. 이를 통해 오클루전, 블러, 외모 변화, 불규칙한 신체 자세와 같은 까다로운 사례를 처리하는 ViTPose의 강점을 확인할 수 있었습니다.