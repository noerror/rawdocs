# Emerging Properties in Self-Supervised Vision Transformers

컨볼루션 신경망(CNN)과 같은 딥러닝 모델을 훈련하는 기존의 방법은 일반적으로 지도 학습에 의존합니다. 여기에는 각 입력 데이터 포인트에 대해 실제 결과 또는 레이블이 알려진 주석이 달린 대규모 데이터 세트가 포함됩니다. 모델은 일반적으로 역전파를 사용하여 예측과 이러한 실제 레이블 간의 차이를 최소화하도록 학습됩니다.

이와는 대조적으로 이 논문에서는 비전 트랜스포머(ViT)를 사용한 자기 지도 학습 접근 방식, 특히 DINO(DIstillation of knowledge by the NOvel teacher)라는 방법을 사용합니다. 자기 지도 학습은 주석이 달린 데이터에 의존하지 않습니다. 대신 데이터 자체에서 표현을 학습합니다. 예를 들어, 다른 부분을 기반으로 데이터의 일부를 예측하는 방법을 학습하거나, 구실 과제(학습 과정만을 위해 설계된 과제)를 푸는 방법을 학습할 수 있습니다.

이 연구는 DINO와 ViT를 사용하는 이 접근 방식이 감독 방식으로 훈련된 기존 CNN과 비슷한 성능을 달성한다는 것을 보여줍니다. 이는 다른 모델과 달리 ViT는 자기 지도 학습을 위해 특별히 설계되지 않았기 때문에 주목할 만합니다.

또한, 자가 지도 학습 접근 방식은 기존 지도 학습에서 비용과 시간을 크게 차지하는 수동으로 레이블이 지정된 데이터가 덜 필요하다는 잠재적 이점이 있습니다.

마지막으로, 저자들은 이 접근 방식이 비전 작업을 위한 BERT와 유사한 모델을 개발할 수 있는 잠재력을 가지고 있다고 제안합니다. BERT(Bidirectional Encoder Representations from Transformers)는 비지도 학습에 크게 의존하는 자연어 처리에서 널리 사용되는 모델입니다. 저자들은 비전 작업을 위한 유사한 모델을 개발할 수 있는 가능성을 암시함으로써 비전 작업에서 자율 학습의 잠재적인 힘과 향후 방향을 강조하고 있습니다.

[https://arxiv.org/abs/2104.14294](https://arxiv.org/abs/2104.14294)

[https://www.youtube.com/watch?v=h3ij3F3cPIk](https://www.youtube.com/watch?v=h3ij3F3cPIk)

[https://towardsdatascience.com/dino-vit-beyond-self-supervised-classifications-3f5d43178216](https://towardsdatascience.com/dino-vit-beyond-self-supervised-classifications-3f5d43178216)

- Apr 2021

![감독 없이 훈련된 8×8 패치가 있는 비전 트랜스포머의 자기 주의력. 마지막 레이어의 머리에 있는 마지막 레이어의 헤드에 있는 [CLS] 토큰을 살펴봅니다. 이 토큰은 어떤 레이블이나 감독에도 첨부되어 있지 않습니다. 이 맵은 모델이 모델이 클래스별 특징을 자동으로 학습하여 비지도 객체 세분화로 이어진다는 것을 보여줍니다.](Emerging%20Properties%20in%20Self-Supervised%20Vision%20Tran%20180a59fae21f49b8ba8b766b87254774/Untitled.png)

감독 없이 훈련된 8×8 패치가 있는 비전 트랜스포머의 자기 주의력. 마지막 레이어의 머리에 있는 마지막 레이어의 헤드에 있는 [CLS] 토큰을 살펴봅니다. 이 토큰은 어떤 레이블이나 감독에도 첨부되어 있지 않습니다. 이 맵은 모델이 모델이 클래스별 특징을 자동으로 학습하여 비지도 객체 세분화로 이어진다는 것을 보여줍니다.

이 논문에서 저자들은 자기 지도 학습을 사용하여 학습했을 때 비전 트랜스포머(ViT)의 기능을 살펴보고 기존의 컨볼루션 네트워크(컨넷)에 비해 뚜렷한 이점을 관찰합니다. 연구진은 자기 지도형 ViT가 지도형 ViT나 컨볼루션 네트워크에서는 명확하지 않은 이미지에 대한 명확한 의미적 세분화 정보를 제공한다는 사실을 발견했습니다. 또한, 이러한 자가 지도된 ViT는 k-NN(k-가장 가까운 이웃) 분류기로서 탁월한 성능을 발휘하며, 작은 ViT를 사용해 ImageNet 데이터 세트에서 78.3%의 상위 1퍼센트 정확도를 달성했습니다.

이 연구는 ViT의 훈련 과정에서 모멘텀 인코더, 멀티 크롭 훈련, 작은 패치를 사용하는 것의 중요성을 강조합니다. 저자는 이러한 인사이트를 DINO(Distillation of knowledge by the Novel teacher)라는 새로운 자기 지도 학습 방법으로 요약합니다. DINO를 ViT와 함께 사용하면 ViT-Base 모델을 사용하는 선형 평가 환경에서 이미지넷 데이터세트에 대해 80.1%라는 인상적인 상위 1% 정확도를 달성할 수 있습니다. 이는 DINO 접근 방식과 ViT 간의 강력한 시너지 효과를 시사하며 시각적 작업에서 자기 지도 학습 기법의 잠재력을 강조합니다.

1. Introduction

이 논문에서는 자연어 처리(NLP)에 사용되는 트랜스포머를 기반으로 시각 인식 작업에 적합한 모델인 비전 트랜스포머(ViT)의 성능과 효율성을 향상시킬 수 있는 자가 지도 학습의 잠재력을 살펴봅니다. ViT는 컨볼루션 신경망(컨브넷)과 경쟁 관계에 있지만, 높은 연산 요구 사항과 광범위한 학습 데이터 필요성, 고유한 기능 부족으로 인해 명확한 이점을 제공하는 데 다소 부족했습니다.

이 연구는 비전 작업에서 트랜스포머의 성공이 다소 제한적인 이유가 감독된 사전 훈련 때문인지에 대해 의문을 제기합니다. 이 논문은 NLP에서 트랜스포머의 성공이 감독 대상에 비해 더 풍부한 학습 신호를 제공하는 BERT의 "클로즈" 방법이나 GPT의 언어 모델링을 사용하는 자가 감독 사전 훈련에 기인할 수 있다고 생각합니다.

이 논문에서는 학생 네트워크가 교차 엔트로피 손실을 사용하여 교사 네트워크의 출력을 예측하는 새로운 자기 감독 접근 방식인 DINO를 소개합니다. DINO는 자기 지도 학습을 단순화하고 붕괴를 피하기 위해 교사 출력의 중심을 잡고 선명하게 하는 것만 필요하며 예측자, 고급 정규화 또는 대비 손실과 같은 다른 구성 요소는 안정성이나 성능 측면에서 거의 이점을 제공하지 않습니다.

이 연구에 따르면 자체 감독 ViT 기능은 미세 조정이나 데이터 증강 없이도 기본 k-NN(k-가장 가까운 이웃) 분류기를 사용하여 특히 우수한 성능을 발휘했습니다. 실제로 ImageNet에서 78.3%의 상위 1% 정확도를 달성했습니다. 또한 저자는 ViT와 함께 더 작은 패치를 사용하면 결과 기능의 품질이 향상된다는 사실도 발견했습니다.

작은 패치가 포함된 ViT-Base를 사용하여 ImageNet 선형 분류 벤치마크에서 80.1%의 최고 정확도를 달성함으로써 DINO의 효과를 더욱 검증했습니다. 또한 DINO는 컨브넷과도 잘 작동하여 ResNet-50 아키텍처의 최신 기술에 부합했습니다.

또한, DINO 방식은 아키텍처를 수정하거나 내부 정규화를 조정할 필요 없이 컨넷과 ViT 모두에서 효과적인 성능을 보여줌으로써 높은 유연성을 입증했습니다. 또한 이 접근 방식은 컴퓨팅 요구 사항을 크게 줄이면서 비슷한 규모의 컨넷에 기반한 자체 감독 시스템보다 성능이 뛰어나 효율적이었습니다.

2. Related work

이 논문에서는 자기 지도 학습과 이를 비전 작업에 어떻게 적용할 수 있는지에 대해 자세히 설명합니다. 기존의 자기 지도 학습 방법은 인스턴스 분류에 중점을 두어 각 이미지를 별개의 클래스로 취급하고 데이터 증강 대상 이미지를 구별하도록 모델을 훈련시킵니다. 그러나 이러한 방법은 이미지 수가 많을 때 확장성 문제에 직면합니다.

![라벨이 없는 셀프 증류. DINO를 간단하게 설명하기 위해 하나의 단일 뷰 쌍(x1, x2)의 경우로 설명합니다. 모델은 모델은 입력 이미지의 두 가지 다른 무작위 변환을 이미지를 학생 및 교사 네트워크에 전달합니다. 두 네트워크 모두 아키텍처는 동일하지만 매개변수가 다릅니다. 교사 네트워크의 출력은 교사 네트워크의 출력은 배치에 대해 계산된 평균으로 중앙에 배치됩니다. 각 네트워크는 특징 차원에 대해 온도 소프트 맥스로 정규화된 온도 소프트 맥스를 사용하여 정규화된 K 차원의 특징을 출력합니다. 그런 다음 유사성을 교차 엔트로피 손실로 측정합니다. 여기에는 스톱-그라디언트(SG) 연산자를 적용하여 그라디언트를 전파합니다. 를 전파합니다. 교사 매개변수는 다음과 같이 업데이트됩니다. 학생 파라미터의 지수 이동 평균(ema)으로 업데이트됩니다.](Emerging%20Properties%20in%20Self-Supervised%20Vision%20Tran%20180a59fae21f49b8ba8b766b87254774/Untitled%201.png)

라벨이 없는 셀프 증류. DINO를 간단하게 설명하기 위해 하나의 단일 뷰 쌍(x1, x2)의 경우로 설명합니다. 모델은 모델은 입력 이미지의 두 가지 다른 무작위 변환을 이미지를 학생 및 교사 네트워크에 전달합니다. 두 네트워크 모두 아키텍처는 동일하지만 매개변수가 다릅니다. 교사 네트워크의 출력은 교사 네트워크의 출력은 배치에 대해 계산된 평균으로 중앙에 배치됩니다. 각 네트워크는 특징 차원에 대해 온도 소프트 맥스로 정규화된 온도 소프트 맥스를 사용하여 정규화된 K 차원의 특징을 출력합니다. 그런 다음 유사성을 교차 엔트로피 손실로 측정합니다. 여기에는 스톱-그라디언트(SG) 연산자를 적용하여 그라디언트를 전파합니다. 를 전파합니다. 교사 매개변수는 다음과 같이 업데이트됩니다. 학생 파라미터의 지수 이동 평균(ema)으로 업데이트됩니다.

다른 접근 방식은 노이즈 대비 추정기(NCE)를 사용하여 인스턴스를 분류하지 않고 비교하지만, 이 경우 대량의 이미지 배치 또는 메모리 뱅크가 필요합니다. 클러스터링의 형태로 인스턴스를 자동으로 그룹화하는 다른 기법도 있습니다.

최근 연구에 따르면 이미지를 구분하지 않고 비지도 특징을 학습하는 것이 가능하다는 사실이 밝혀졌습니다. 모멘텀 인코더의 표현과 일치시켜 특징을 학습하는 BYOL이 그러한 방법 중 하나입니다. 이 방법은 모멘텀 인코더 없이도 작동할 수 있지만 성능이 약간 떨어집니다.

저자의 접근 방식은 BYOL에서 영감을 얻었지만 다른 유사도 매칭 손실을 도입하고 학생과 교사 모두에게 동일한 아키텍처를 사용합니다. 저자들은 자기 주도 학습을 레이블이 없는 평균 교사 자기 증류의 한 형태로 보고 있습니다.

또 다른 관련 방법으로는 레이블이 없는 대규모 인스턴스 세트에 작은 초기 주석 세트를 전파하여 기능 품질을 향상시키는 자가 학습이 있습니다. 이 전파는 하드 레이블 할당 또는 소프트 레이블 할당을 통해 수행할 수 있으며, 소프트 할당은 종종 지식 증류라고도 합니다. 이 방법은 원래 모델 압축을 위해 더 큰 네트워크의 출력을 모방하도록 작은 네트워크를 훈련하기 위해 고안되었습니다.

저자들의 접근 방식은 레이블 없이 자가 학습과 지식 증류를 결합하여 이를 자가 감독 목표로 간주합니다. 이 방법은 훈련 중에 동적 교사를 구축하여 사전 훈련된 고정 교사를 사용하는 이전 작업과 차별화됩니다. 이 논문의 방법은 학생과 교사가 동일한 아키텍처를 공유하는 공동 증류와 관련이 있지만, 이 작업에서 교사는 학생의 산출물의 평균을 기반으로 업데이트합니다.

3. Approach

제안된 방법인 DINO는 지식 증류와 유사한 자기 지도 학습 접근 방식입니다. 여기서 학생 네트워크는 주어진 입력 이미지에 대해 특정 차원에 대한 확률 분포를 출력하는 교사 네트워크의 출력과 일치하도록 훈련됩니다. 이미지의 다양한 보기(전역 및 로컬)가 생성되어 학생 네트워크와 교사 네트워크를 통과합니다. 학생 네트워크는 이러한 보기 간의 손실을 최소화하여 학습합니다. 이 시나리오에서는 미리 주어지지 않은 교사 네트워크는 학생 네트워크의 이전 반복을 사용하여 구축됩니다.

DINO에서는 두 네트워크(학생과 교사)가 동일한 아키텍처를 공유하며, 교사는 학생 가중치의 지수 이동 평균(EMA)을 사용하여 업데이트되므로 기능의 품질이 향상되고 학생의 학습을 안내합니다.

DINO는 교사의 출력을 중앙에 배치하고 선명하게 하여 모델 붕괴를 방지합니다. 센터링은 한 차원이 우세해지는 것을 방지하고 선명하게 만들면 모델이 데이터의 차이에 더 민감해집니다.

DINO는 레이블 없이 이미지넷의 비전 트랜스포머(ViT) 모델을 사용하여 학습됩니다. 이 아키텍처는 겹치지 않는 연속 이미지 패치를 입력으로 사용하고 자체 주의 및 피드 포워드 레이어를 구현합니다. 다운스트림 작업에서 가장 가까운 이웃 분류기를 사용하여 학생의 특징을 평가하므로 평가가 간단하고 하이퍼파라미터에 덜 민감합니다.

4. Main Results

이 연구에서는 이미지 인식 작업의 표준 벤치마크인 ImageNet에서 자기 지도 학습(SSL) 기법인 DINO 프레임워크를 테스트했습니다. DINO의 결과는 동일한 아키텍처를 가진 다른 자기 지도 학습 방법, 즉 ResNet-50 및 ViT-small과 비교되었습니다. DINO는 ResNet-50에서 최고의 자기 지도 방식과 비슷한 성능을 보였으며, 선형 분류에서는 다른 방식보다 3.5%, k-NN 평가에서는 7.9% 더 뛰어난 성능을 보여 ViT 아키텍처의 성능을 뛰어넘는 것으로 나타났습니다.

더 큰 아키텍처로 연구를 확장했을 때, 패치 크기를 줄이는 것이 아키텍처 크기를 늘리는 것보다 성능에 더 큰 영향을 미치는 것으로 나타났습니다. DINO로 훈련된 8x8 패치가 있는 기본 ViT는 더 적은 파라미터와 더 빠른 런타임으로 더 나은 성능을 달성했습니다.

다음으로, 가장 가까운 이웃 검색, 객체 위치 정보 유지, 다른 작업으로의 이전 가능성 측면에서 DINO 기능의 속성을 평가했습니다. 그 결과, DINO 기능은 랜드마크 검색 및 복사 감지와 같은 작업에 매우 효과적이며 다른 방법보다 성능이 뛰어나다는 것이 입증되었습니다.

DINO의 셀프 어텐션 맵은 비디오 인스턴스 세분화 작업에 유용한 세분화 정보를 포함하고 있는 것으로 밝혀졌습니다. 고밀도 작업을 위해 특별히 설계된 것은 아니지만 이러한 작업에서 DINO의 성능은 경쟁력이 있었습니다.

마지막으로, DINO로 사전 학습된 기능을 다른 다운스트림 작업에 적용했을 때, 감독을 통해 학습된 기능보다 더 나은 전이성을 보여주었습니다. 이 결과는 컨볼루션 네트워크에서 관찰된 결과와 일치했습니다. 전반적으로 DINO 프레임워크는 이미지 인식 작업에 매우 효과적이었으며, 다른 자체 감독 방법보다 성능이 뛰어나고 다른 작업으로의 전이성이 우수한 것으로 나타났습니다.

5. Ablation Study of DINO

이 경험적 연구에서 저자들은 비전 트랜스포머(ViT) 모델, 특히 ViT-S에 DINO(NOvel 교사에 의한 지식 주입) 방법을 적용하는 것을 조사했습니다. 주요 결과는 다음과 같습니다:

- 다양한 구성 요소의 중요성: 자기 지도 학습 프레임워크의 다양한 구성 요소는 DINO로 훈련된 ViT 모델의 성능에 다양한 영향을 미쳤습니다. 모멘텀이 없으면 프레임워크가 작동하지 않았고, 모델 붕괴를 방지하려면 SK와 같은 고급 연산을 사용해야 했습니다. 비교를 통해 효과적인 특징 학습을 위해 멀티 크롭 훈련과 DINO의 교차 엔트로피 손실이 중요하다는 것이 입증되었습니다.
- 패치 크기: 저자들은 패치 크기가 작을수록 추가 매개변수 없이도 ViT-S 모델의 k-NN 분류 성능이 향상된다는 사실을 발견했습니다. 그러나 패치가 작을수록 처리량이 감소했습니다.
- 교사 네트워크의 선택: 저자들은 교사 네트워크를 구성하기 위한 다양한 전략을 탐색하고 그 결과를 MoCo-v2 및 BYOL과 같은 기존 프레임워크와 비교했습니다. 그 결과, 이전 시기의 교사를 사용해도 붕괴가 일어나지 않았고 비슷한 성과를 보였다는 사실을 발견했습니다. 또한 DINO의 모멘텀 교사는 훈련 중에 학생 모델을 지속적으로 능가하는 앙상블 방법인 폴리악-루퍼트 평균의 한 형태로 해석했습니다.
- 붕괴 방지: 저자들은 모델 붕괴를 방지하는 데 있어 센터링과 타깃 선명화의 역할을 연구했습니다. 이 두 가지 작업이 모델 출력의 균형을 맞추고 다양한 형태의 붕괴를 방지하는 데 필요하다는 사실을 발견했습니다.
- 계산 요구 사항: 멀티 크롭을 사용하면 DINO 모델의 정확도/런타임 트레이드오프가 개선되었습니다. 이 방법을 사용하면 시간과 메모리를 덜 사용하면서 더 높은 성능을 얻을 수 있었습니다. 전반적으로 ViT로 DINO를 훈련한 결과, 3일 만에 두 대의 8-GPU 서버에서 76.1%의 최고 정확도를 달성했습니다.
- 소규모 배치 훈련: 저자들은 더 작은 배치 크기로도 DINO를 효과적으로 훈련할 수 있다는 사실을 발견했습니다. 배치 크기가 128인 경우 기본 크기인 1024에 비해 성능이 약간 떨어졌지만, 이 결과는 제한된 GPU 용량으로 대규모 모델을 훈련하는 데 DINO를 사용할 수 있음을 시사합니다.

이 연구는 비전 트랜스포머와 함께 DINO 자율 학습 방법을 사용할 때의 이점과 고려 사항에 대한 귀중한 통찰력을 제공합니다.

6. Conclusion

이 연구에서 저자들은 표준 비전 트랜스포머(ViT) 모델을 사용하여 자기 감독 사전 훈련의 잠재력을 입증했습니다. 달성한 성능은 이 설정을 위해 특별히 설계된 최고의 컨볼루션 신경망(컨브넷)과 비슷한 수준이었습니다.

이 연구에서 두 가지 중요한 특성이 나타났습니다:

특징의 품질: k-NN 분류에서 특징의 품질은 이미지 검색 애플리케이션에 대한 잠재력을 보여주었으며, ViT 모델이 이미 유망한 결과를 보여준 영역입니다.

장면 레이아웃 정보: 피처에 장면 레이아웃에 대한 정보가 있으면 감독 기능이 약한 이미지 분할 작업에 잠재적으로 도움이 될 수 있습니다.

이 백서의 주요 요점은 자기 지도 학습, 특히 DINO(DIstillation of knowledge by the NOvel teacher) 방법을 사용하는 것이 ViT를 기반으로 하는 BERT와 유사한 모델을 개발하는 데 유용할 수 있다는 것입니다.

향후 연구에서는 큐레이션되지 않은 무작위 이미지에 대해 DINO를 사용하여 대규모 ViT 모델을 사전 훈련하면 시각적 특징의 한계를 뛰어넘을 수 있는지 살펴볼 계획입니다.

![DINO를 사용하여 표현된 ImageNet 클래스의 t-SNE 시각화입니다. 각 클래스에 대해 유효성 검사 집합에서 해당 클래스의 모든 이미지에 대한 평균 특징을 가져와 임베딩을 얻습니다.](Emerging%20Properties%20in%20Self-Supervised%20Vision%20Tran%20180a59fae21f49b8ba8b766b87254774/Untitled%202.png)

DINO를 사용하여 표현된 ImageNet 클래스의 t-SNE 시각화입니다. 각 클래스에 대해 유효성 검사 집합에서 해당 클래스의 모든 이미지에 대한 평균 특징을 가져와 임베딩을 얻습니다.

- ViT
    
    기존의 합성곱 신경망(CNN)에서는 이미지가 2차원 픽셀 그리드로 처리됩니다. 이미지는 이미지의 작고 겹치는 직사각형 영역(즉, 수용 필드)을 한 번에 처리하는 컨볼루션 레이어를 통과합니다. 이러한 로컬 수신 필드는 겹치고 타일링되어 전체 이미지를 덮고, 각 필드는 다음 레이어에서 이미지의 특징 표현에 기여합니다. 이것이 바로 CNN의 번역 불변성을 가능하게 하는 것으로, 이미지의 위치에 관계없이 동일한 특징을 감지할 수 있습니다.
    
    그러나 비전 트랜스포머(ViT)에서는 이미지가 다르게 처리됩니다. 이미지를 2D 픽셀 그리드로 처리하는 대신 이미지를 겹치지 않는 패치 그리드로 분할하고 각 패치는 작은 정사각형 하위 이미지로 처리합니다. 그런 다음 이러한 패치는 2D 그리드에서 1D 벡터로 재구성됩니다. 예를 들어, 이미지의 16x16 패치는 256차원 벡터로 재형성됩니다.
    
    이러한 패치가 벡터로 재형성되면 자연어 처리 작업에서 문장이 단어의 시퀀스인 것처럼 하나의 시퀀스로 취급됩니다. 그런 다음 이 패치 벡터 시퀀스는 트랜스포머 모델로 전달됩니다. 트랜스포머 모델은 시퀀스의 여러 부분 간의 상호 작용을 모델링할 수 있습니다. 이 경우 트랜스포머는 이미지에서 서로 다른 패치 간의 상호 작용을 모델링합니다. 이를 통해 모델은 기존 CNN에서는 어려운 방식으로 이미지의 여러 부분 간의 장거리 종속성을 학습하고 활용할 수 있습니다.
    
    트랜스포머가 이러한 패치 시퀀스를 처리한 후 출력은 이미지 분류, 물체 감지, 분할 등과 같은 다양한 작업에 사용할 수 있습니다. 예를 들어 이미지 분류에서는 첫 번째 패치(시퀀스에 추가된 특수 "분류" 토큰인 경우가 많음)에 해당하는 출력을 이미지의 최종 표현으로 사용하고 분류기를 통과하여 이미지의 클래스를 예측할 수 있습니다.
    
- ViT의 위치 인코딩
    
    비전 트랜스포머(ViT)에 위치를 임베딩하는 이 개념은 트랜스포머 모델에서 사용되는 위치 인코딩과 관련이 있습니다.
    
    자연어 처리(NLP)를 위해 설계된 원래의 Transformer 모델에는 시퀀스에서 단어의 순서나 위치를 고려하는 고유한 방법이 없습니다. 이는 입력 데이터가 특정 순서로 처리되는 RNN(순환 신경망) 또는 CNN(컨볼루션 신경망)과 같은 다른 모델과 다릅니다. 트랜스포머 모델에 어순이나 위치에 대한 감각을 부여하기 위해 위치 인코딩이라는 개념이 도입되었습니다.
    
    비전 트랜스포머(ViT)의 맥락에서도 동일한 아이디어가 적용됩니다. 이미지가 일련의 패치로 나뉘고 각 패치가 독립적이기 때문에 ViT 자체는 이미지의 원래 2D 그리드에서 각 패치가 어디에 있는지 본질적으로 이해하지 못합니다. 그러나 각 패치의 위치는 많은 시각적 작업에서 중요합니다.
    
    이를 처리하기 위해 ViT는 위치 인코딩도 사용합니다. 각 패치는 원래 그리드에서 해당 위치를 나타내는 벡터인 위치 인코딩과 연결됩니다. 이 위치 인코딩은 패치가 트랜스포머에 입력되기 전에 패치의 특징 벡터에 추가됩니다. 이렇게 하면 트랜스포머가 이미지를 처리할 때 패치의 상대적 위치를 고려할 수 있습니다.
    
    이를 통해 비전 트랜스포머는 이미지의 여러 부분 간의 공간적 관계를 이해하고 유지할 수 있으며, 이는 많은 시각 작업에서 중요한 요소입니다.