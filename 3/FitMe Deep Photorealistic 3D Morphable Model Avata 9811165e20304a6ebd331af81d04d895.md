# FitMe: Deep Photorealistic 3D Morphable Model Avatars

[https://openaccess.thecvf.com/content/CVPR2023/papers/Lattas_FitMe_Deep_Photorealistic_3D_Morphable_Model_Avatars_CVPR_2023_paper.pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Lattas_FitMe_Deep_Photorealistic_3D_Morphable_Model_Avatars_CVPR_2023_paper.pdf)

[https://arxiv.org/abs/2305.09641](https://arxiv.org/abs/2305.09641)

- May 2023

### 1. Introduction

이 연구에서는 제약이 없는 단일 이미지에서 매우 상세한 3D 얼굴 특징을 재구성하기 위한 3D 모퍼블 모델(3DMM)인 FitMe를 소개합니다. 3D 얼굴 재구성은 컴퓨터 비전 분야에서 지속적인 도전 과제였지만, FitMe는 제한된 데이터 세트, 다양한 지오메트리 부족, 단일 얼굴 이미지의 모호함 등 다양한 이유로 인해 이전 모델이 어려움을 겪었던 사실적인 렌더링을 가능하게 하는 진보를 가져왔습니다.

![FitMe는 반사 모델과 미분 가능한 렌더링을 사용하여 단일(왼쪽) 또는 여러 개(오른쪽)의 제약이 없는 얼굴 이미지에서 얼굴 아바타를 위한 재조명 가능한 모양과 반사도 맵을 재구성합니다. 결과는 일반적인 엔진에서 사실적으로 렌더링할 수 있습니다.](FitMe%20Deep%20Photorealistic%203D%20Morphable%20Model%20Avata%209811165e20304a6ebd331af81d04d895/Untitled.png)

FitMe는 반사 모델과 미분 가능한 렌더링을 사용하여 단일(왼쪽) 또는 여러 개(오른쪽)의 제약이 없는 얼굴 이미지에서 얼굴 아바타를 위한 재조명 가능한 모양과 반사도 맵을 재구성합니다. 결과는 일반적인 엔진에서 사실적으로 렌더링할 수 있습니다.

지금까지는 단일 이미지에서 얼굴 모양과 외모를 얻기 위해 3DMM을 사용해 왔습니다. 하지만 이러한 모델은 사실적인 렌더링에 적합한 텍스처를 생성하지 못했습니다. 생성적 적대 신경망(GAN)과 같은 심층 생성 모델이 등장하면서 사람 얼굴의 고해상도 2D 이미지를 생성하고 의미 있는 잠재 공간을 학습하는 것이 가능해졌습니다.

FitMe는 이러한 발전을 활용하여 고해상도 얼굴 반사 텍스처 맵을 도입함으로써 이를 더욱 향상시켰습니다. 이는 정확한 차별적 렌더링을 활용하여 표준 렌더링 애플리케이션에서 즉시 사용할 수 있는 매우 상세하고 완전한 렌더링이 가능한 재구성을 생성함으로써 달성할 수 있습니다. 얼굴 디퓨즈 알베도, 스페큘러 알베도, 표면 노멀을 동시에 생성할 수 있어 더욱 사실적인 결과물을 얻을 수 있습니다.

![FitMe 메서드 개요. 대상 이미지 I0에 대해, 우리는 생성기 G의 잠재 벡터 W와 모양 식별 ps, 표정 pe, 카메라 pc 및 조명 pl 매개변수를 최적화합니다. 이는 정확한 미분 가능한 흩뜨림 UD 및 반사 US 렌더링 R을 통해 3DMM 맞춤 및 GAN 반전 방법을 결합함으로써 이루어집니다. 그런 다음 최적화된 Wp에서 우리는 동일한 렌더링 프로세스를 통해 생성기 G 가중치를 조정합니다. 재구성된 모양 S와 얼굴 반사(흩뜨림 알베도 AD, 반사 알베도 AS 및 노말 NS)는 훌륭한 정체성 유사성을 달성하고 일반적인 렌더러에서 직접 사용할 수 있어 사실적인 렌더링을 달성할 수 있습니다. 이는 오른쪽에 표시된 바와 같습니다.](FitMe%20Deep%20Photorealistic%203D%20Morphable%20Model%20Avata%209811165e20304a6ebd331af81d04d895/Untitled%201.png)

FitMe 메서드 개요. 대상 이미지 I0에 대해, 우리는 생성기 G의 잠재 벡터 W와 모양 식별 ps, 표정 pe, 카메라 pc 및 조명 pl 매개변수를 최적화합니다. 이는 정확한 미분 가능한 흩뜨림 UD 및 반사 US 렌더링 R을 통해 3DMM 맞춤 및 GAN 반전 방법을 결합함으로써 이루어집니다. 그런 다음 최적화된 Wp에서 우리는 동일한 렌더링 프로세스를 통해 생성기 G 가중치를 조정합니다. 재구성된 모양 S와 얼굴 반사(흩뜨림 알베도 AD, 반사 알베도 AS 및 노말 NS)는 훌륭한 정체성 유사성을 달성하고 일반적인 렌더러에서 직접 사용할 수 있어 사실적인 렌더링을 달성할 수 있습니다. 이는 오른쪽에 표시된 바와 같습니다.

FitMe를 훈련하기 위해 5,000명의 피사체로부터 고품질의 얼굴 반사율 데이터 세트를 생성하고, 공개 MimicMe 데이터 세트에서 AvatarMe++를 사용했습니다. 얼굴의 모양을 캡처하기 위해 FitMe는 대규모 지오메트리 데이터셋으로 훈련된 얼굴 및 머리 PCA 모델을 사용합니다.

요약하자면, FitMe는 사실적인 렌더링을 위해 고해상도 얼굴 반사율과 모양을 생성할 수 있는 최초의 3DMM, 고해상도 3D 얼굴 자산의 멀티모달 스타일 기반 프로그레시브 생성기, 상당한 양의 얼굴 반사율 데이터세트를 획득하고 증강하는 방법을 제공함으로써 3D 얼굴 재구성 분야에서 상당한 진전을 이뤄냈습니다. 피팅 프로세스가 효율적이며 표준 렌더링 엔진에서 사실적으로 렌더링하여 충실도 높은 얼굴 반사율과 인상적인 신원 유사성을 캡처할 수 있습니다.

### 2. Related Work

이 섹션에서는 얼굴 모델링 및 피팅의 맥락에서 3D 모퍼블 모델(3DMM), 심층 생성 네트워크, 얼굴 반사율 획득의 진화에 대해 살펴봅니다.

3D 모퍼블 모델(3DMM): 초기 얼굴 모델링 및 피팅 방법은 얼굴 모양과 외모를 위해 선형 모델을 활용했습니다. 이러한 방법의 확장은 전체 헤드 모델링에도 적용되었습니다. 최근 일부 연구에서는 선형 모델의 일부를 신경망으로 대체하여 비선형성을 포착하기 시작했습니다. 여기에는 얼굴 지오메트리에 대한 가변 자동 인코더 및 GAN 기반 접근 방식을 기반으로 하는 방법이 포함되어 중요한 비선형 얼굴 모양 측면을 캡처할 수 있습니다.

심층 생성 네트워크: 생성적 적대 신경망(GAN)은 시간이 지남에 따라 크게 발전해 왔습니다. 점진적으로 증가하는 해상도로 훈련된 생성기-판별기 쌍을 통해 고해상도 얼굴 생성이 가능해졌습니다. 이후 StyleGAN 및 StyleGAN2와 같은 버전에서는 노이즈 주입과 의미 있는 잠재 표현을 학습하는 매핑 네트워크와 같은 기술을 통해 이를 더욱 향상시켰습니다. 이러한 모델은 현재 작업에서 멀티모달 반사율 생성의 기초를 형성합니다.

얼굴 반사율 획득: 3D 얼굴 스캔을 정확하게 획득한 최초의 장치는 프로그래밍 가능한 조명과 하이엔드 카메라가 장착된 대형 돔인 LightStage였습니다. 그 이후로 비편광 바이너리 패턴이나 수동 조명을 사용하는 간단한 방법도 제안되었습니다. 역 렌더링 접근 방식은 차별적인 광선 추적 알고리즘을 사용하여 얼굴 반사율을 성공적으로 획득했습니다. 그러나 이러한 방법은 계산 비용이 많이 들고 피사체 이미지의 모호함에 따라 최적화하기 어렵습니다. 이러한 모호성을 극복하기 위해 선형 또는 심층 모델을 사전 모델로 사용하거나 얼굴 반사율을 직접 회귀하는 여러 접근 방식이 있습니다. 이후에는 선형 모양 모델과 GAN 기반 텍스처 모델을 결합하거나 이미지 변환 네트워크를 사용하여 GAN 기반 모델에서 생성된 텍스처를 고해상도 얼굴 반사율로 변환하는 방법이 사용되었습니다.

이러한 접근 방식과 달리 본 연구에서는 완전한 얼굴 반사율로 확장된 생성 모델, 추가 모달리티를 위한 분기 생성기 및 판별기 접근 방식, 잠재 공간 및 음영 정규화가 포함된 피팅 파이프라인, 렌더링을 통해 추가로 최적화할 수 있는 편집 가능한 잠재 공간을 소개합니다.

### 3. Method

이 연구에서는 BRDF-GAN이라는 분기형 멀티모달 스타일 기반 생성 네트워크를 기반으로 하는 심층 얼굴 반사율 3D 모퍼블 모델(3DMM)인 FitMe를 소개합니다. 이 모델은 고해상도 UV 파라미터화를 통해 얼굴 확산 알베도, 스페큘러 알베도, 표면 노멀을 동시에 생성합니다. 새로운 분기 판별자가 모델을 훈련하는 데 사용되어 다양한 모달리티 간의 일관성을 보장합니다. 전체적인 목표는 단일 또는 여러 이미지에서 충실도가 높은 얼굴 모양과 반사율 아바타를 정확하게 재구성하는 것입니다.

![BRDF-GAN 개요, 스타일 기반 생성기 [38]로, 잠재 벡터 z를 스타일 W로 변환하는 매핑 네트워크 M가 포함됩니다. 가지 나누어진 다중 모달 합성 네트워크 G는 1024 × 1024 해상도의 흩뜨림 알베도 AD, 반사 알베도 AS 및 노말 NS를 생성합니다. 이 모델은 가지 나누어진 다중 모달 판별기 D와 함께 훈련됩니다. 각 가지는 D가 알베도와 노말 분포를 따로 모델링할 수 있게 합니다. 각 가지의 출력은 마지막 컨볼루션 블록과 D의 완전히 연결된 계층에 들어가기 전에 연결되어 모달 간 피처 일관성을 유지합니다.](FitMe%20Deep%20Photorealistic%203D%20Morphable%20Model%20Avata%209811165e20304a6ebd331af81d04d895/Untitled%202.png)

BRDF-GAN 개요, 스타일 기반 생성기 [38]로, 잠재 벡터 z를 스타일 W로 변환하는 매핑 네트워크 M가 포함됩니다. 가지 나누어진 다중 모달 합성 네트워크 G는 1024 × 1024 해상도의 흩뜨림 알베도 AD, 반사 알베도 AS 및 노말 NS를 생성합니다. 이 모델은 가지 나누어진 다중 모달 판별기 D와 함께 훈련됩니다. 각 가지는 D가 알베도와 노말 분포를 따로 모델링할 수 있게 합니다. 각 가지의 출력은 마지막 컨볼루션 블록과 D의 완전히 연결된 계층에 들어가기 전에 연결되어 모달 간 피처 일관성을 유지합니다.

FitMe 모델은 얼굴 및 헤드 메시 토폴로지에 유니버설 헤드 모델을 사용하며, 3DMM 지오메트리는 특정 아이덴티티 및 표정 파라미터를 사용하여 재구성할 수 있습니다.

StyleGAN2를 기반으로 하는 BRDF-GAN은 매핑 네트워크와 멀티 모달 분기 합성 네트워크로 구성됩니다. StyleGAN2ADA의 아키텍처를 유지하지만 반사율 모드별로 분기되는 각 업샘플링된 해상도의 최종 블록에서 차이가 있습니다. 이러한 변화는 만족스러운 FID 점수를 얻기 위해 필요한 것으로 밝혀졌습니다.

![데이터셋 및 증강. 왼쪽: MimicMe 데이터셋 [50]의 텍스처 T에 AvatarMe++ [41] 네트워크 A를 미세 조정하여 흩뜨림 AD 및 반사 AS 알베도와 노말 NS를 생성합니다. 오른쪽: 우리의 마스크 히스토그램 매칭 h를 사용하여 다른 대상 알베도 A*D (Sec. 3.2)에 대한 알베도 피부톤 증강.](FitMe%20Deep%20Photorealistic%203D%20Morphable%20Model%20Avata%209811165e20304a6ebd331af81d04d895/Untitled%203.png)

데이터셋 및 증강. 왼쪽: MimicMe 데이터셋 [50]의 텍스처 T에 AvatarMe++ [41] 네트워크 A를 미세 조정하여 흩뜨림 AD 및 반사 AS 알베도와 노말 NS를 생성합니다. 오른쪽: 우리의 마스크 히스토그램 매칭 h를 사용하여 다른 대상 알베도 A*D (Sec. 3.2)에 대한 알베도 피부톤 증강.

BRDF-GAN은 분기 판별기를 사용하여 훈련되어 알베도와 노멀의 매우 다른 분포를 정확하게 캡처하는 동시에 생성된 피사체마다 일관된 얼굴 특징을 보장합니다.

모델 학습에는 대규모 얼굴 캡처 데이터 세트가 사용됩니다. 여기에 최첨단 얼굴 생김새 생성 모델을 보완하여 실제 캡처와 유사한 품질의 고해상도 데이터 세트를 생성합니다. 데이터 세트의 피부 톤 불균형은 히스토그램 매칭을 통해 완화되는데, 이 프로세스는 변환에 영향을 줄 수 있는 비피부 특징을 피하는 것입니다.

마지막으로, 이 논문에서는 사실적인 렌더링에 필요한 얼굴 반사율 파라미터를 캡처할 수 있는 빠르고 차별화되며 사실적인 렌더링 방법을 소개합니다. 또한 다양한 알베도와 법선을 가진 래스터화된 픽셀에 대한 보기 방향, 주변 강도, 광원 세트를 정의하고 그에 따라 확산 및 스페큘러 셰이딩 구성 요소를 계산합니다.

FitMe와 관련 방법론의 전반적인 목표는 높은 신원 유사성과 충실도 높은 얼굴 재구성을 달성하는 동시에 일반적인 렌더링 애플리케이션에서 직접 사용할 수 있도록 하는 것입니다. 또한 현재 모델에서 중요한 문제인 편향된 피부 톤 예측을 해결하기 위해 노력합니다.

이 섹션에서는 기존 접근 방식을 개선하여 3D 모퍼블 모델(3DMM)을 피팅하기 위한 최적화 파이프라인에 대해 설명합니다. 주요 개선 사항은 다음과 같습니다:

통계적 텍스처 모델과 주성분 분석(PCA) 기반 최적화를 BRDF-GAN 텍스처 및 GAN 반전 최적화로 대체. BRDF-GAN(양방향 반사율 분포 함수 생성 적대 신경망)은 사실적인 텍스처를 합성하기 위한 머신러닝 기법입니다.
이미지 공간에서 차등 렌더러를 구현하여 BRDF-GAN 반전으로부터 충실도가 높은 결과를 렌더링할 수 있습니다.
이 백서에서는 파이프라인의 두 가지 주요 구성 요소에 대해 설명합니다: BRDF-GAN 반전과 BRDF-GAN 튜닝입니다.

BRDF-GAN 반전

이 방법은 대상 이미지를 다시 생성하기 위해 잠재 코드를 얻는 제너레이터 반전을 사용합니다. 이 반전 방법은 또한 노이즈 벡터를 최적화하며 지각적 LPIPS 손실을 사용합니다.

반전을 보다 정확하고 안정적으로 수행하기 위해 저자는 랜드마크, 광도계, 신원, 지각 손실, BRDF-GAN 정규화, 모양 정규화 등 여러 가지 손실 함수를 도입합니다. 이러한 손실은 모양, 카메라 및 조명 매개변수를 최적화하고 래스터화된 BRDF-GAN 결과를 안내하는 데 도움이 됩니다.

전체 손실은 이러한 손실의 조합으로, 최적화 중에 다양한 손실 조건의 균형을 맞추기 위해 각각 하이퍼파라미터 세트에 가중치를 부여합니다.

BRDF-GAN 튜닝

이 논문에서는 이전 단계에서 사용된 W 기반 반전 방법이 목표 이미지를 완전히 복구하지 못한다고 지적합니다. 대안으로 W를 찾아 동결한 후 대상 이미지에서 제너레이터를 미세 조정하는 피벗 튜닝 반전(PTI)을 사용하는 방법이 있는데, 이 방법은 눈에 보이는 텍스처 부분만 그라데이션을 생성하고 최적화되기 때문에 저자들에게 더 효과적이라고 합니다.

![Digital Emily [2]에 대한 흩뜨림 및 반사 알베도 재구성 및 렌더링 비교, 이전 작업들과 비교. 단일 이미지 및 세 이미지 재구성 모두 특수 하드웨어와 수백 개의 이미지가 필요한 캡처 데이터와 유사한 결과를 달성합니다.](FitMe%20Deep%20Photorealistic%203D%20Morphable%20Model%20Avata%209811165e20304a6ebd331af81d04d895/Untitled%204.png)

Digital Emily [2]에 대한 흩뜨림 및 반사 알베도 재구성 및 렌더링 비교, 이전 작업들과 비교. 단일 이미지 및 세 이미지 재구성 모두 특수 하드웨어와 수백 개의 이미지가 필요한 캡처 데이터와 유사한 결과를 달성합니다.

저자는 BRDF-GAN의 여러 레이어가 이미지의 여러 측면에 영향을 미친다는 사실을 발견했습니다. 예를 들어 첫 번째 레이어는 알베도의 색상을 변경하고, 중간 레이어는 피부의 중간 구조를 변경하며, 마지막 레이어는 미세한 디테일을 변경하지만 대상 이미지의 노이즈를 흡수합니다. 따라서 중간 네 개의 레이어만 미세 조정하고 나머지는 고정된 상태로 유지합니다. 이 미세 조정은 LPIPS, 측광, 수평 플립 및 색도 손실을 포함한 여러 가지 손실에 의해 이루어집니다.

이 백서의 방법론은 텍스처와 렌더링 프로세스를 모두 최적화하여 사실적인 3D 렌더링을 만들기 위한 포괄적인 접근 방식을 제공합니다. 이를 위해 GAN, 반전, 미세 조정 등 다양한 기술을 활용합니다.

### 4. Experiments

이 섹션에서는 3D 모퍼블 모델 피팅을 위해 제안된 최적화 파이프라인의 구현 및 평가에 대해 자세히 설명합니다.

4.1 구현 세부 사항

저자의 제너레이터 코드는 StyleGAN2-ADA의 공개 저장소를 기반으로 하며, 브랜치는 연결을 통해 연결된 동일한 아키텍처를 따릅니다. 차별적인 렌더링을 위해 이전 방법론에 따라 PyTorch3D에서 Blinn-Phong 셰이더를 사용합니다. 피팅 코드의 평균 실행 시간은 엔비디아 2080 GPU 1개가 장착된 머신에서 약 50초입니다. 피팅 프로세스는 반전의 경우 200회, 튜닝의 경우 20회 반복 실행됩니다.

4.2 단일 이미지 재구성

단일 이미지 재구성의 동일성 보존 능력을 평가하기 위해 연구진은 LFW 데이터 세트의 결과를 이전 연구의 결과와 비교했습니다. 사전 학습된 얼굴 인식 네트워크를 사용하여 원본 이미지와 렌더링된 재구성 이미지 간의 코사인 유사도를 측정하고 그 결과를 그림 6에 표시했습니다. 이 방법은 피사체의 신원을 효과적으로 보존하고 고품질의 모양과 반사율을 생성합니다.

또한 학습된 잠재 공간의 기능을 입증하기 위해 서로 다른 피팅 간에 보간을 수행합니다. 이러한 보간은 제너레이터 튜닝 후에도 피팅 간에 원활하게 전환할 수 있습니다.

4.3 다중 이미지 재구성

이전 논의에서는 단일 대상 이미지를 가정했지만, 이 방법은 다중 뷰 재구성도 처리할 수 있습니다. 이 방법은 이미지 배치를 최적화하는 데 사용되며, 카메라 및 조명 매개변수를 개별적으로 최적화하는 동시에 단일 잠재 벡터와 모양 벡터를 최적화합니다.

연구진은 정면 이미지와 두 개의 측면 이미지가 얼굴 캡처와 유사한 고품질 재구성을 생성한다는 사실을 발견했습니다. 다중 이미지 재구성을 다른 작업과 비교한 결과, 이 방법이 다중 뷰 세트에서 모양과 반사율을 빠르게 획득하는 데 성공적으로 사용될 수 있음을 보여주었습니다.

4.4 데이터 세트 증강

데이터 세트 증강 방법은 복잡한 상호 작용을 계산할 필요 없이 물리 기반 피부 모델과 유사한 성능을 달성합니다. 또한 다른 방법의 경우 46.1초가 소요되는 데 비해 1024x1024 알베도 맵을 2.5초 만에 생성하여 다른 실용적인 방법보다 더 효율적입니다.

### 5. Conclusion

귀하는 훈련 데이터의 특징 불균형과 반사율 데이터에 대한 피부와 유사한 재질을 가정하는 등 귀하의 방법인 FitMe의 한계를 인정합니다. 이러한 가정은 특히 눈에서 노이즈 반사를 초래할 수 있습니다. 또한 피팅 과정에서 피부 톤과 조명 강도 사이에 모호한 부분이 있습니다. 향후 연구에서는 이러한 문제를 완화하기 위해 TRUST의 연구 결과와 귀하의 방법을 결합할 수 있습니다.

이러한 한계에도 불구하고 사용자의 방법은 몇 가지 중요한 기여를 하고 있습니다. FitMe는 단일 또는 여러 개의 '실제' 이미지를 기반으로 매우 정확하고 렌더링 가능한 인간 아바타를 생성할 수 있습니다. 이를 위해 다중 분기 스타일 기반 GAN과 PCA 기반 모양 모델로 구성된 심층 얼굴 반사율 모델을 도입했습니다. 또한 간편한 피부 톤 증강 방법과 차등 렌더링 프로세스에 의존하는 새로운 반복적 최적화 절차를 제안했습니다.

일련의 실험을 통해 핏미가 언캐니 밸리를 해소하고 일반 렌더러에서 직접 렌더링할 수 있는 시각적으로 만족스러운 결과물을 생성하는 데 도움이 된다는 사실을 입증했습니다. 이 성과는 단일 또는 여러 이미지에서 3D 모퍼블 모델을 피팅하고 아바타를 생성하는 데 있어 중요한 진전을 이룬 것입니다.

- 요약
    
    개념 소개: 이 백서에서는 다중 분기 스타일 기반 생성적 적대 신경망(GAN)과 PCA 기반 형상 모델로 구성된 심층 얼굴 반사 모델을 사용하는 FitMe의 개념을 소개하는 것으로 시작합니다.
    
    구현 세부 사항: 이 백서에서는 시스템의 기술적 세부 사항을 자세히 설명합니다. 제너레이터 코드의 기본으로 StyleGAN2-ADA를 사용합니다. 또한 이 시스템은 차별화된 렌더링을 위해 파이토치3D의 블린퐁 셰이더를 사용합니다. 피팅 코드가 실행되는 데 걸리는 평균 시간은 NVIDIA 2080 GPU 1개가 장착된 머신에서 50초입니다.
    
    단일 이미지 재구성: 이 백서에서는 시스템이 단일 이미지 재구성을 처리하는 방법을 설명합니다. 이 방법의 효과는 코사인 유사도 분포와 이전 문헌과의 비교를 통해 입증됩니다.
    
    다중 이미지 재구성: FitMe는 N개의 이미지 배치를 따라 최적화하여 멀티뷰 재구성도 처리할 수 있습니다. 각 배치에 대해 카메라 및 조명 매개변수는 개별적으로 최적화되고, 단일 잠재 벡터 W와 모양 벡터 ps는 최적화됩니다. 다중 이미지 재구성 결과는 빠른 형상 및 반사율 획득에 사용할 수 있습니다.
    
    데이터 세트 증강: FitMe는 복잡한 계산 없이도 물리 기반 피부 모델과 비슷한 성능을 달성할 수 있습니다. 이 백서에서는 MimicMe 데이터세트에서 미세 조정된 AvatarMe++ 네트워크를 사용하여 확산 및 스페큘러 알베도와 노멀을 생성하는 과정을 자세히 설명합니다.
    
    한계와 향후 작업: FitMe는 그 효과에도 불구하고 피팅 시 데이터 불균형, 피부 톤과 조명 강도 사이의 모호함 등 몇 가지 한계가 있습니다. 이 논문은 향후 연구에서 이 방법을 다른 기법과 결합하여 이러한 한계를 완화할 수 있다고 제안합니다.
    
    결론: 이 논문은 FitMe가 심층 안면 반사율 모델, 손쉬운 피부 톤 증강 방법, 반복적인 최적화 절차를 사용하여 매우 정확하고 렌더링 가능한 인간 아바타를 생성할 수 있다고 결론지었습니다. 이 방법은 언캐니 밸리를 해소하는 데 도움이 되며 일반적인 렌더러에서 직접 렌더링할 수 있는 만족스러운 결과를 만들어냅니다.