# HyperDreamBooth: HyperNetworks for Fast Personalization of Text-to-Image Models

[https://arxiv.org/abs/2307.06949](https://arxiv.org/abs/2307.06949)

![단일 입력 이미지만을 사용하여 HyperDreamBooth는 네트워크 가중치의 부분 집합에 대한 초기 예측을 생성하는 HyperNetwork(1) 및 상세한 대상의 고해상도를 위한 빠른 세부 조정(2)을 사용하여 DreamBooth [25]보다 25배 빠르게 텍스트-이미지 확산 모델을 개인화할 수 있습니다. 우리의 방법은 모델의 완결성과 스타일의 다양성을 유지하면서 대상의 본질과 세부 사항을 정확하게 근사합니다.](HyperDreamBooth%20HyperNetworks%20for%20Fast%20Personaliza%201a49cd1c5ef6481196afc377968ed195/Untitled.png)

단일 입력 이미지만을 사용하여 HyperDreamBooth는 네트워크 가중치의 부분 집합에 대한 초기 예측을 생성하는 HyperNetwork(1) 및 상세한 대상의 고해상도를 위한 빠른 세부 조정(2)을 사용하여 DreamBooth [25]보다 25배 빠르게 텍스트-이미지 확산 모델을 개인화할 수 있습니다. 우리의 방법은 모델의 완결성과 스타일의 다양성을 유지하면서 대상의 본질과 세부 사항을 정확하게 근사합니다.

### 1 Introduction

최근 드림부스와 같은 텍스트-이미지(T2I) 개인화 기술의 발전으로 다양한 스타일의 맞춤형 이미지, 특히 얼굴 이미지를 제작할 수 있는 길이 열렸습니다. 이 기술은 피사체 얼굴의 고유한 특징을 잃지 않으면서도 독특한 스타일을 만드는 데 효과적입니다. 혁신적인 기능에도 불구하고 드림부스는 크기와 속도 문제로 인해 사용성에 제한이 있습니다. 모델과 인코딩 기능은 안정적인 확산을 위해 1GB가 넘는 대용량이며, 드림부스 모델을 훈련하는 데 약 5분이 소요됩니다.

이러한 단점을 해결하면서도 드림부스의 고유한 특성을 잃지 않기 위해 이 연구에서는 경량 드림부스(LiDB)를 소개합니다. LiDB는 드림부스 모델의 무결성을 유지하면서 맞춤형 부품의 크기를 약 100KB로 줄인 개인화된 텍스트-이미지 모델입니다. 이는 낮은 순위의 적응 가중치 공간 내에서 무작위 직교 불완전 기준으로 생성된 저차원 가중치 공간에서 드림부스 모델을 학습시킴으로써 달성할 수 있습니다.

또한 이 연구에서는 LiDB 구성을 활용하는 새로운 하이퍼네트워크 아키텍처를 제안합니다. 이 새로운 아키텍처는 텍스트-이미지 확산 모델에서 특정 피사체에 대한 가중치의 맞춤형 부분을 보다 빠르고 효율적으로 생성하는 데 도움이 됩니다. 이 새로운 방법은 드림부스보다 최대 25배 빠르면서도 비슷한 결과를 제공합니다.

마지막으로 순위 완화 미세 조정 기법이 도입되었습니다. 이 방법은 최적화 중에 LoRA 드림부스 모델의 순위를 완화하여 피사체 충실도를 높일 수 있습니다. 하이퍼네트워크를 사용한 초기 근사치로 모델을 시작한 다음, 순위 완화 미세 조정을 사용하여 상위 수준의 피사체 세부 사항을 근사화합니다. 이 연구는 특정 피사체의 고충실도 이미지를 생성하려면 생성 모델의 출력 도메인을 변경하고 네트워크 가중치를 수정하여 피사체에 대한 지식을 모델에 포함시켜야 한다는 점을 이해한 데서 출발합니다.

### 2 Related Work

텍스트 프롬프트에서 고품질 이미지를 생성하는 데 효과적인 것으로 입증된 Imagen, DALL-E2, SD(Stable Diffusion), Muse 및 Parti와 같은 여러 텍스트-이미지(T2I) 모델을 사용할 수 있습니다. 또한 SD와 Muse는 인코더 네트워크를 통해 주어진 이미지에 따라 이미지 생성을 조절할 수 있습니다. 이러한 기능에도 불구하고 이러한 모델은 종종 세부적인 피사체 정보를 캡처하는 데 실패합니다. 우리는 SD 모델을 예로 들어 모든 T2I 모델에 사용할 수 있는 새로운 기술인 HyperDreamBooth를 선보입니다.

![HyperDreamBooth 훈련 및 빠른 세부 조정. 단계-1: 얼굴 이미지에서 네트워크 가중치를 예측하여 텍스트-이미지 확산 네트워크가 "a [v] face"라는 문장에서 사람의 얼굴을 출력하는 네트워크 가중치를 예측하는 하이퍼네트워크를 훈련합니다. 우리는 L2 손실뿐만 아니라 바닐라 확산 재구성 손실을 사용하여 사전 계산된 개인화 가중치를 사용하여 감독을합니다. 단계-2: 얼굴 이미지가 주어지면, 우리의 하이퍼네트워크는 네트워크 가중치에 대한 초기 추측을 예측하고, 이들은 재구성 손실을 사용하여 세부 조정되어 선명도를 향상시킵니다.](HyperDreamBooth%20HyperNetworks%20for%20Fast%20Personaliza%201a49cd1c5ef6481196afc377968ed195/Untitled%201.png)

HyperDreamBooth 훈련 및 빠른 세부 조정. 단계-1: 얼굴 이미지에서 네트워크 가중치를 예측하여 텍스트-이미지 확산 네트워크가 "a [v] face"라는 문장에서 사람의 얼굴을 출력하는 네트워크 가중치를 예측하는 하이퍼네트워크를 훈련합니다. 우리는 L2 손실뿐만 아니라 바닐라 확산 재구성 손실을 사용하여 사전 계산된 개인화 가중치를 사용하여 감독을합니다. 단계-2: 얼굴 이미지가 주어지면, 우리의 하이퍼네트워크는 네트워크 가중치에 대한 초기 추측을 예측하고, 이들은 재구성 손실을 사용하여 세부 조정되어 선명도를 향상시킵니다.

제너레이티브 모델의 개인화는 특히 하나 또는 몇 개의 피사체 이미지로 이미지를 생성하는 맥락에서 중점적인 영역이었습니다. 주로 생성적 적대 신경망(GAN)을 기반으로 한 초기 시도에서는 다양한 기법을 사용하여 GAN을 미세 조정했습니다. 그러나 이러한 방법은 피사체 충실도가 떨어지거나 생성된 이미지의 컨텍스트 다양성이 부족한 등의 문제로 어려움을 겪었습니다.

하이퍼네트워크는 네트워크 가중치를 예측하고 특정 신경망의 기능을 수정하는 데 사용되었습니다. 하이퍼네트워크는 이미지의 잠재 코드를 반전시켜 GAN 잠재 공간에서 이미지를 편집하는 것과 유사한 접근 방식인 StyleGAN 반전과 같이 개인화에 가까운 작업에 사용되어 왔습니다.

최근 여러 연구에서 피사체 충실도를 높이는 T2I 모델 개인화 기술을 제안했습니다. 한 가지 예로 전체 T2I 네트워크 가중치를 주어진 피사체에 맞게 조정하는 DreamBooth가 있습니다. 다른 연구에서는 드림부스처럼 전체 네트워크가 아닌 작은 가중치 공간을 최적화하는 방법을 제안하기도 합니다. 그러나 이러한 대부분의 미세 조정 기법은 고품질의 피사체 중심 세대를 생성하지만 속도가 느리고 시간이 많이 소요될 수 있습니다.

최근 여러 연구에서 초기 텍스트 임베딩을 예측하는 인코더를 학습한 후 완전한 네트워크 미세 조정을 수행하거나 표준 DreamBooth를 사용하여 생성된 입력 이미지와 해당 재맥락화 이미지의 대규모 쌍 데이터 세트를 생성하여 T2I 모델을 더 빠르게 개인화하는 방법을 제안했습니다. 그러나 이러한 기법은 원본 T2I 모델의 무결성을 보존하지 못하거나 피사체 충실도가 높지 않다는 등의 한계가 있습니다.

이러한 기존 기법과는 달리, 우리의 접근 방식은 특정 피사체에 대한 하위 네트워크 잔여물을 직접 예측하는 새로운 하이퍼네트워크 기반 방법을 제안합니다. 이를 통해 T2I 모델을 더 빠르고 효율적으로 개인화할 수 있습니다.

### 3 Preliminaries

텍스트-이미지(T2I) 확산 모델은 텍스트 프롬프트를 기반으로 노이즈 맵을 이미지로 변환하는 데 사용됩니다. 텍스트 프롬프트는 텍스트 인코더를 사용하여 입력 텍스트 임베딩으로 변환됩니다. 이 연구에서는 잠복 확산 모델(LDM)의 특정 유형인 안정 확산을 사용합니다.

드림부스는 특정 피사체의 이미지를 생성하기 위해 주어진 T2I 노이즈 제거 네트워크를 미세 조정하는 기법입니다. 이 프로세스에는 원본 모델의 일반화 기능을 유지하면서 몇 개의 주어진 피사체 이미지를 기반으로 모든 확산 네트워크 가중치를 최적화하는 작업이 포함됩니다. 이 방법의 단점은 1GB 이상의 파라미터를 조정해야 하며 단일 피사체에 대해 1,000회의 훈련 반복으로 약 5분이 소요된다는 것입니다.

로우랭크 적응(LoRa)은 드림부스에 더 효율적이고 빠른 방법을 제공합니다. LoRa는 전체 가중치를 미세 조정하는 대신 네트워크 가중치 잔여분을 미세 조정합니다. 가중치 행렬은 낮은 순위의 행렬로 분해되어 필요한 매개변수의 수가 크게 줄어듭니다. 이 낮은 순위 잔차 미세 조정 기법은 기존 드림부스의 많은 유리한 특성을 유지하면서 메모리 효율성과 속도도 높입니다. 안정적인 확산 모델의 경우 LoRa-DreamBooth에는 약 1.6MB 크기에 해당하는 약 386K 개의 파라미터가 있습니다.

### 4 Method

저희의 접근 방식은 세 가지 핵심 구성 요소로 이루어져 있습니다: 경량 드림부스(LiDB), 하이퍼네트워크 트레이닝, 직급에 구애받지 않는 빠른 미세 조정.

![경량 DreamBooth: 우리는 모델 개인화를 위한 새로운 저차원 가중치 공간을 제안합니다. 이는 랜덤한 직교 불완전 기저 내의 LoRA 가중치 공간에서 생성됩니다. 이는 원래 DreamBooth의 0.01% 및 LoRA DreamBooth 크기의 7.5%인 대략 100KB의 크기의 모델을 달성하며, 놀랍게도, 단단한 편집성을 가지고 강력한 개인화 결과를 달성하기에 충분합니다.](HyperDreamBooth%20HyperNetworks%20for%20Fast%20Personaliza%201a49cd1c5ef6481196afc377968ed195/Untitled%202.png)

경량 DreamBooth: 우리는 모델 개인화를 위한 새로운 저차원 가중치 공간을 제안합니다. 이는 랜덤한 직교 불완전 기저 내의 LoRA 가중치 공간에서 생성됩니다. 이는 원래 DreamBooth의 0.01% 및 LoRA DreamBooth 크기의 7.5%인 대략 100KB의 크기의 모델을 달성하며, 놀랍게도, 단단한 편집성을 가지고 강력한 개인화 결과를 달성하기에 충분합니다.

4.1 경량 드림부스(LiDB)

우리의 목표는 하이퍼네트워크를 사용하여 개인화된 가중치의 하위 집합을 직접 생성하는 것이며, 따라서 피사체 충실도, 편집 가능성 및 스타일 다양성에 대한 강력한 결과를 유지하면서 가중치의 수를 최소한으로 줄이는 것을 목표로 합니다. 이를 위해 우리는 모델 개인화를 위한 새로운 저차원 가중치 공간을 제안합니다. 이를 통해 드림부스 모델보다 10,000배, LoRA 드림부스 모델보다 10배 이상 작은 개인화된 확산 모델을 구현할 수 있습니다. 최종 버전은 변수가 3만 개에 불과하고 저장 공간도 120KB밖에 차지하지 않습니다.

라이트웨이트 드림부스(LiDB)의 핵심 아이디어는 무작위 직교 불완전 베이스를 사용하여 1등급 LoRa 잔여의 가중치 공간을 더 세분화하는 것입니다. 그런 다음 LoRa의 다운(A) 및 업(B) 행렬을 각각 두 개의 행렬로 더 분해하고, 보조 레이어를 무작위로 초기화 및 고정하고 트레인 레이어를 학습합니다. a = 100, b = 50인 모델은 학습 가능한 변수가 30만 개에 불과하고 크기가 120KB에 불과하지만 여전히 강력한 개인화 결과를 얻을 수 있습니다.

4.2 텍스트-이미지 모델의 빠른 개인화를 위한 하이퍼네트워크

사전 학습된 T2I 모델을 빠르게 개인화하기 위해 하이퍼네트워크를 제안합니다. 이 하이퍼네트워크는 주어진 이미지를 입력으로 받아 LiDB 하위 랭크 잔여물을 예측합니다. 하이퍼네트워크는 바닐라 확산 노이즈 제거 손실과 가중치 공간 손실이 적용된 도메인별 이미지 데이터 세트에 대해 학습됩니다.

![HyperNetwork 아키텍처: 우리의 하이퍼네트워크는 얼굴 이미지를 잠재적인 얼굴 특징으로 변환하는 시각적 변환기(ViT) 인코더로 구성되며, 이는 레이어 가중치 특징과 연결됩니다. 변환기 디코더는 연결된 특징의 시퀀스를 받아들여 초기 가중치를 델타 예측으로 세부 조정하는 방식으로 가중치 특징의 값을 반복적으로 예측합니다. 최종 레이어 가중치 델타는 디코더 출력을 학습 가능한 선형 계층을 통과시켜 확산 네트워크에 추가됩니다.](HyperDreamBooth%20HyperNetworks%20for%20Fast%20Personaliza%201a49cd1c5ef6481196afc377968ed195/Untitled%203.png)

HyperNetwork 아키텍처: 우리의 하이퍼네트워크는 얼굴 이미지를 잠재적인 얼굴 특징으로 변환하는 시각적 변환기(ViT) 인코더로 구성되며, 이는 레이어 가중치 특징과 연결됩니다. 변환기 디코더는 연결된 특징의 시퀀스를 받아들여 초기 가중치를 델타 예측으로 세부 조정하는 방식으로 가중치 특징의 값을 반복적으로 예측합니다. 최종 레이어 가중치 델타는 디코더 출력을 학습 가능한 선형 계층을 통과시켜 확산 네트워크에 추가됩니다.

하이퍼네트워크 아키텍처는 ViT 이미지 인코더와 트랜스포머 디코더의 두 부분으로 구성됩니다. 초기 예측을 개선하기 위해 중간 가중치 예측이 하이퍼네트워크에 공급되는 반복 학습 및 예측 시나리오에서 하이퍼네트워크가 더 정확하고 확실한 예측을 달성하는 것으로 나타났습니다.

![HyperNetwork + Fast Finetuning은 강력한 결과를 달성합니다. 여기서 우리는 각 참조(행)에 대해 초기 하이퍼네트워크 예측(HyperNetwork Prediction 열)의 출력뿐만 아니라 HyperNetwork 예측 및 빠른 세부 조정 후의 결과(HyperNetwork + Fast Finetuning)를 보여줍니다. 또한 우리는 하이퍼네트워크 예측 요소 없이 생성된 결과를 보여주어 그 중요성을 보여줍니다.](HyperDreamBooth%20HyperNetworks%20for%20Fast%20Personaliza%201a49cd1c5ef6481196afc377968ed195/Untitled%204.png)

HyperNetwork + Fast Finetuning은 강력한 결과를 달성합니다. 여기서 우리는 각 참조(행)에 대해 초기 하이퍼네트워크 예측(HyperNetwork Prediction 열)의 출력뿐만 아니라 HyperNetwork 예측 및 빠른 세부 조정 후의 결과(HyperNetwork + Fast Finetuning)를 보여줍니다. 또한 우리는 하이퍼네트워크 예측 요소 없이 생성된 결과를 보여주어 그 중요성을 보여줍니다.

4.3 순위 완화된 빠른 미세 조정

초기 하이퍼네트워크 예측은 대체로 방향성이 정확하고 목표 얼굴과 유사한 의미적 속성을 가진 얼굴을 일관되게 생성한다는 것을 확인했습니다. 그러나 미세한 디테일은 충분히 포착되지 않습니다. 이 문제를 해결하기 위해 드림부스보다 훨씬 빠르면서도 피사체 충실도, 편집 가능성, 스타일 다양성 측면에서 거의 동일한 결과를 얻을 수 있는 최종 고속 미세 조정 단계를 제안합니다. 빠른 미세 조정 전에 LoRA 모델의 랭크를 r = 1에서 r > 1로 완화하는 랭크 릴렉스 미세 조정을 수행합니다. 이렇게 하면 피사체의 고주파 디테일을 근사화할 수 있는 기능이 확장되어 낮은 가중치 업데이트 랭크에 고정된 방법보다 피사체 충실도가 더 높아집니다. 이 빠른 미세 조정은 40회 반복으로 완료할 수 있으며, 이는 드림부스 및 LoRA 드림부스보다 25배 빠른 속도입니다.

### 5 Experiments

하이퍼드림부스 방식은 뛰어난 성능을 보여주지만, 한계가 없는 것은 아닙니다. 예를 들어, 조명, 포즈 또는 기타 요인으로 인해 분포가 벗어난(OOD) 샘플이 있으면 최적의 결과가 나오지 않을 수 있습니다. 하이퍼네트워크의 초기 예측에 오류가 발생하면 피사체의 시맨틱 정보가 부정확해질 수 있습니다(예: 눈 색깔, 머리 유형 또는 성별이 잘못됨). 빠른 미세 조정 단계에서는 피사체의 디테일을 완벽하게 포착하지 못해 참조 신원과 비슷하지만 정확히 일치하지 않는 샘플이 생성될 수 있습니다. 또한 하이퍼네트워크와 빠른 미세 조정 단계 모두에서 과소 피팅이 발생할 수 있으며, 이로 인해 일부 스타일에 대한 편집 가능성이 낮아질 수 있습니다.

![결과 갤러리: 우리의 방법은 다양한 대상의 소재(입력 이미지 왼쪽에 표시)로서 신선한 예술적이고 스타일화된 결과를 생성할 수 있으며, 대상의 핵심 얼굴 특징에 대한 정확성을 유지하면서 상당한 편집성을 보여줍니다. 출력 이미지는 다음 캡션으로 생성되었습니다(왼쪽 상단에서 오른쪽 하단까지): “인스타그램 셀카의 [V] 얼굴", “픽사 캐릭터의 [V] 얼굴", “나무 껍질 피부의 [V] 얼굴", “[V] 얼굴의 록스타". 가장 오른쪽: “전문 촬영한 [V] 얼굴".](HyperDreamBooth%20HyperNetworks%20for%20Fast%20Personaliza%201a49cd1c5ef6481196afc377968ed195/Untitled%205.png)

결과 갤러리: 우리의 방법은 다양한 대상의 소재(입력 이미지 왼쪽에 표시)로서 신선한 예술적이고 스타일화된 결과를 생성할 수 있으며, 대상의 핵심 얼굴 특징에 대한 정확성을 유지하면서 상당한 편집성을 보여줍니다. 출력 이미지는 다음 캡션으로 생성되었습니다(왼쪽 상단에서 오른쪽 하단까지): “인스타그램 셀카의 [V] 얼굴", “픽사 캐릭터의 [V] 얼굴", “나무 껍질 피부의 [V] 얼굴", “[V] 얼굴의 록스타". 가장 오른쪽: “전문 촬영한 [V] 얼굴".

향후 작업은 이러한 한계를 개선하고 하이퍼드림부스 시스템을 더욱 최적화하는 데 집중될 것입니다. OOD 샘플을 더 잘 처리하고 미세 조정 단계를 개선하여 피사체의 디테일을 더 잘 포착할 수 있는 새로운 방법을 연구할 것입니다. 또한 피사체 과소 피팅의 위험을 줄이기 위해 더욱 진보된 모델과 훈련 기법을 개발할 것입니다. 또한 모델의 편집 기능을 개선하여 생성할 수 있는 스타일의 다양성을 높이는 것을 목표로 하고 있습니다.

![질적 비교: 우리는 두 개의 다른 정체성과 다섯 개의 다른 스타일적인 제시문에 대해 우리의 방법(HyperDreamBooth), DreamBooth 및 Textual Inversion의 무작위로 생성된 샘플을 비교합니다. 우리는 우리의 방법이 일반적으로 아주 강력한 편집성을 달성하면서 동일성을 유지하며, 일반적으로 단일 참조 체제에서 경쟁 방법을 능가함을 관찰합니다.](HyperDreamBooth%20HyperNetworks%20for%20Fast%20Personaliza%201a49cd1c5ef6481196afc377968ed195/Untitled%206.png)

질적 비교: 우리는 두 개의 다른 정체성과 다섯 개의 다른 스타일적인 제시문에 대해 우리의 방법(HyperDreamBooth), DreamBooth 및 Textual Inversion의 무작위로 생성된 샘플을 비교합니다. 우리는 우리의 방법이 일반적으로 아주 강력한 편집성을 달성하면서 동일성을 유지하며, 일반적으로 단일 참조 체제에서 경쟁 방법을 능가함을 관찰합니다.

또한, 저희는 연구에서 윤리적 고려의 중요성을 인식하고 있습니다. 현재 버전의 하이퍼드림부스는 개인정보 보호를 위해 SFHQ 데이터 세트의 합성 얼굴을 사용하지만, 개인화된 이미지를 생성하는 기술이 오용될 수 있다는 점을 잘 알고 있습니다. 따라서 향후 작업을 반복할 때 이 기술을 책임감 있게 사용할 수 있는 강력한 프레임워크를 개발하기 위해 최선을 다하고 있습니다.

### 6 Conclusion

이 백서에서는 텍스트-이미지 모델의 빠르고 가벼운 개인화를 위한 HyperDreamBooth 방법을 소개했습니다. 이 방법은 경량 드림부스(LiDB)의 개념과 하이퍼네트워크 트레이닝 및 순위 제한이 없는 빠른 미세 조정을 결합한 것입니다. 이를 통해 단일 입력 이미지에서 충실도가 높고 편집 가능하며 스타일이 다양한 개인화 이미지를 생성할 수 있습니다. 실험 결과, 텍스트 반전이나 드림부스와 같은 기존 방법보다 우수한 결과를 얻음으로써 이 접근법의 효과를 입증했습니다. 앞으로 이 방법을 통해 AI 시스템의 실시간 온디바이스 개인화에 대한 흥미로운 가능성을 열 수 있을 것으로 기대합니다.