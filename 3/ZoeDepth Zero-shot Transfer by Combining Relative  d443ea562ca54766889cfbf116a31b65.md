# ZoeDepth: Zero-shot Transfer by Combining Relative and Metric Depth

[https://arxiv.org/abs/2302.12288](https://arxiv.org/abs/2302.12288)

### 1. Introduction

이 논문에서는 컴퓨터 비전의 중요한 측면인 단일 이미지 깊이 추정(SIDE)에 대해 설명합니다. 메트릭 깊이 추정(MDE)과 상대적 깊이 추정(RDE)이라는 두 가지 SIDE에 대해 살펴봅니다. MDE는 절대 깊이를 결정하는 데 중점을 두지만, 다양한 유형의 이미지와 데이터 세트에서 가변성을 처리하는 데 어려움을 겪을 수 있으며 종종 과적합으로 이어질 수 있습니다. 반면에 RDE는 상대적 깊이에 초점을 맞추고 배율을 고려하지 않기 때문에 다양한 장면과 데이터 세트에서 다용도로 사용할 수 있지만, 절대 단위로 깊이를 제공하는 실용성이 부족합니다.

![제로샷 전이. 우리의 단일 멀티 도메인 메트릭 깊이 추정 모델은 실내, 실외, 시뮬레이션 또는 실제로 관계없이 다양한 도메인에 적용될 수 있습니다. 상단: 입력 RGB. 하단: 예측된 깊이. 왼쪽에서 오른쪽으로: iBims-1, DIML Outdoor, Hypersim, DIODE Indoor, vKITTI2, SUN-RGBD, DIODE Outdoor 그리고 DDAD.](ZoeDepth%20Zero-shot%20Transfer%20by%20Combining%20Relative%20%20d443ea562ca54766889cfbf116a31b65/Untitled.png)

제로샷 전이. 우리의 단일 멀티 도메인 메트릭 깊이 추정 모델은 실내, 실외, 시뮬레이션 또는 실제로 관계없이 다양한 도메인에 적용될 수 있습니다. 상단: 입력 RGB. 하단: 예측된 깊이. 왼쪽에서 오른쪽으로: iBims-1, DIML Outdoor, Hypersim, DIODE Indoor, vKITTI2, SUN-RGBD, DIODE Outdoor 그리고 DDAD.

이러한 한계를 해결하기 위해 저자는 MDE와 RDE를 결합한 2단계 프레임워크를 제안합니다. 먼저 인코더-디코더 모델을 여러 데이터 세트에 대한 RDE에 맞게 훈련하여 일반화를 개선합니다. 그런 다음 이 모델은 MDE를 위한 도메인별 헤드를 추가하여 미세 조정됩니다. 모델이 작동하는 동안 이미지가 인코더 기능에 따라 적합한 헤드로 자동 라우팅됩니다. 이 조합은 RDE의 일반화의 이점을 누리면서도 MDE의 실용성을 제공합니다.

이 백서에서는 기존 SIDE 모델을 개선한 세 가지 프레임워크 구성을 강조합니다:

실내 깊이 추정에서 현재 최신 기술보다 13.7% 향상된 순수 MDE.
첫 번째 구성에 비해 8.5%의 추가 개선이 이루어졌으며, 최신 상태보다 총 21%의 개선이 이루어진 RDE 사전 훈련이 포함된 MDE.
자동 라우팅과 RDE 사전 학습이 포함된 유니버설 MDE는 학습된 데이터 세트에서 24.3%의 오류 개선과 전례 없는 제로 샷 기능을 보여주었으며, 학습되지 않은 7개의 메트릭 데이터 세트에서 최신 기술을 최대 11배 가까이 능가했습니다.

### 2. Related Work

이 논문에서는 단일 이미지 깊이 추정(SIDE)과 관련된 선행 연구에 대해 설명합니다. SIDE 방법에는 메트릭 깊이 모델과 상대 깊이 모델이라는 두 가지 주요 유형이 있습니다. 메트릭 깊이 모델은 단일 데이터 세트에 대한 학습으로 인해 다양한 환경이나 깊이 범위에 걸쳐 과적합하고 일반화 기능이 떨어지는 경우가 많습니다. 규모와 변화를 알 수 없는 수심을 추정하는 상대적 수심 모델은 다양한 데이터 세트에 대해 학습할 수 있고 일반화 기능이 뛰어나지만 정밀한 수심 측정이 필요한 작업에는 적용성이 제한적입니다.

![ZoeDepth 구조. RGB 이미지가 MiDaS 깊이 추정 프레임워크 [33]에 입력됩니다. MiDaS 디코더의 병목 및 이어지는 네 가지 계층 수준(1/32, 1/16, 1/8, 1/4 및 1/2 MiDaS 입력 및 출력 해상도)이 메트릭 빈 모듈(그림 3 참조)로 연결됩니다. 메트릭 빈 모듈은 픽셀 당 깊이 빈 중심을 계산하고 이를 선형 결합하여 메트릭 깊이를 출력합니다. MiDaS 인코더에는 다양한 트랜스포머 백본을 사용할 수 있으며, 최첨단 예시로는 BEiT384-L [3]이 있습니다.](ZoeDepth%20Zero-shot%20Transfer%20by%20Combining%20Relative%20%20d443ea562ca54766889cfbf116a31b65/Untitled%201.png)

ZoeDepth 구조. RGB 이미지가 MiDaS 깊이 추정 프레임워크 [33]에 입력됩니다. MiDaS 디코더의 병목 및 이어지는 네 가지 계층 수준(1/32, 1/16, 1/8, 1/4 및 1/2 MiDaS 입력 및 출력 해상도)이 메트릭 빈 모듈(그림 3 참조)로 연결됩니다. 메트릭 빈 모듈은 픽셀 당 깊이 빈 중심을 계산하고 이를 선형 결합하여 메트릭 깊이를 출력합니다. MiDaS 인코더에는 다양한 트랜스포머 백본을 사용할 수 있으며, 최첨단 예시로는 BEiT384-L [3]이 있습니다.

최근 연구에서는 이러한 문제를 해결하려는 시도가 있었습니다. 일부 연구에서는 2단계 프레임워크를 사용하여 서로 다른 유형의 수심 추정을 결합하거나 메트릭 수심을 별도의 구성 요소로 분해했습니다. 다른 연구에서는 실내 및 실외 영역을 모두 포함하는 범용 깊이 예측과 깊이 회귀를 분류 작업으로 처리하는 아이디어를 조사했습니다.

이 논문에서는 메트릭 SIDE에 대한 분포 학습도 강조합니다. 단안 깊이 추정 방법은 일반적으로 인코더-디코더 아키텍처를 사용하며 깊이 추정을 픽셀당 회귀 작업으로 처리합니다. 최근 연구에서는 깊이 추정을 분류와 회귀를 결합한 문제로 재구성하려고 시도하고 있습니다. 이러한 접근 방식은 이미지 전체의 깊이 값 분포를 추론하며, 다양한 연구에서 예측된 깊이 범위를 구간차원으로 이산화하고 이미지별로 구간폭을 조정하는 등 이를 구현하기 위한 다양한 전략을 제안했습니다. 일부 모델은 트랜스포머 기반 모듈 또는 컨볼루션을 사용하고, 다른 모델은 픽셀의 로컬 이웃을 고려하거나 보조 장면 분류를 통합합니다.

### 3. Methodology

저자는 단일 이미지 깊이 추정(SIDE)을 위한 새로운 방법론을 제시합니다. 제안된 방법은 상대적 깊이 예측을 위해 MiDaS 훈련 전략을 사용하며, DPT 인코더-디코더 아키텍처가 기본 모델 역할을 합니다. 상대적 깊이 예측을 위해 MiDaS 모델을 사전 학습한 후, 메트릭 깊이 추정을 위해 메트릭 빈 모듈을 추가합니다. 메트릭 빈 모듈은 적응형 비닝 원리를 채택하고 성능을 향상시키기 위해 LocalBins의 설계 수정을 제안합니다.

저자는 깊이 간격에서 예측된 어트랙터 포인트를 기반으로 구간차원을 조정하는 새로운 개념의 어트랙터 레이어를 제시하여 로컬 제약 없이 구간차원 값을 세분화할 수 있도록 합니다. 또한 구간 사이의 서수 관계를 고려하여 소프트맥스 함수가 아닌 로그 이항 분포를 사용하여 구간 중심에 대한 확률 분포를 예측합니다.

![메트릭 빈 모듈. 다양한 깊이 계층에 해당하는 5개의 들어오는 채널(그림 2 참조)이 MLP, 업샘플링 및 덧셈 작업과 결합하여 1차원 빈 임베딩(녹색 상자)으로 변환됩니다. 최하위 빈 임베딩은 메트릭 빈 중심(푸른색, 수직선; 실제 수량 64를 대표하지 않음)을 생성하고, 나머지 임베딩은 각 계층 수준에 대한 아트랙터를 제공합니다(녹색 점). 메트릭 빈 모듈을 올라가면서, 아트랙터는 식 (2)와 (3)에 따라 빈 중심을 당깁니다.](ZoeDepth%20Zero-shot%20Transfer%20by%20Combining%20Relative%20%20d443ea562ca54766889cfbf116a31b65/Untitled%202.png)

메트릭 빈 모듈. 다양한 깊이 계층에 해당하는 5개의 들어오는 채널(그림 2 참조)이 MLP, 업샘플링 및 덧셈 작업과 결합하여 1차원 빈 임베딩(녹색 상자)으로 변환됩니다. 최하위 빈 임베딩은 메트릭 빈 중심(푸른색, 수직선; 실제 수량 64를 대표하지 않음)을 생성하고, 나머지 임베딩은 각 계층 수준에 대한 아트랙터를 제공합니다(녹색 점). 메트릭 빈 모듈을 올라가면서, 아트랙터는 식 (2)와 (3)에 따라 빈 중심을 당깁니다.

훈련 전략에는 MiDAS 백본에 대한 상대적 깊이 사전 훈련과 예측 헤드에 대한 메트릭 깊이 미세 조정의 두 단계가 포함됩니다. 저자는 상대적 깊이 추정을 위해 사전 학습된 백본이 여러 데이터 세트에 대한 미세 조정의 어려움을 덜어준다는 가설을 세우고, 다양한 장면 유형에 맞게 여러 메트릭 빈 모듈을 사용할 것을 제안합니다.

또한 저자들은 모델에 여러 메트릭 헤드가 있는 경우 라우팅 메커니즘을 제안합니다. 장면 유형에서 메트릭 헤드로 수동으로 매핑하는 레이블 라우터, 병목 현상을 기반으로 장면 유형을 예측하는 학습된 라우터, 학습 또는 추론 중에 장면 유형 레이블이 필요 없는 자동 라우터 등 세 가지 변형을 살펴봅니다. 이러한 학습 가능한 라우터 유형은 전체 모델에 대해 엔드투엔드 방식으로 학습됩니다.

제안된 방법에 대한 자세한 설명과 비교는 다음 섹션에서 다룰 예정입니다.

### 4. Experimental Setup

저자들은 실험에서 실내 및 실외 장면에 대한 데이터 세트 조합을 활용했습니다. 주요 훈련 데이터 세트는 실내 장면용 NYU Depth v2와 실외 장면용 KITTI입니다. 상대 뎁스 백본의 사전 학습을 위해 HRWSI, BlendedMVS, ReDWeb, DIML-Indoor 등의 추가 데이터 세트를 포함하여 12개의 서로 다른 데이터 세트가 혼합되어 사용됩니다.

모델의 일반화 가능성을 평가하기 위해 실내 도메인의 경우 SUN RGB-D, iBims, DIODE Indoor, HyperSim을, 실외 도메인의 경우 DDAD, DIML Outdoor, DIODE Outdoor, Virtual KITTI 2와 같은 실내 및 실외 환경의 실제 및 합성 데이터 세트를 사용합니다.

모델은 상대 깊이 사전 훈련과 미터법 깊이 미세 조정에 사용되는 데이터 세트를 나타내는 규칙에 따라 이름이 지정됩니다. 연구진은 5가지 모델을 실험했는데, 그 중 일부는 미터법 수심에 대해 직접 미세 조정하고 다른 일부는 상대적 수심 추정을 위한 사전 학습을 포함합니다.

이러한 모델의 평가에는 절대 상대 오차, 평균 제곱 오차, 평균 로그10 오차 및 임계값 정확도와 같은 여러 지표가 포함됩니다. 데이터 세트와 메트릭 간의 상대적 개선을 측정하기 위해 각각 두 가지 메트릭이 정의되어 있습니다.

![NYU Depth v2에서의 질적 비교. 우리의 방법은 일관되게 훨씬 적은 오류로 더 나은 예측을 생성합니다. 깊이 맵을 자세히 살펴보면, 우리의 예측이 훨씬 더 선명하고 명확한 가장자리를 가지고 있음을 알 수 있습니다. ∆는 최소(진한 파란색)에서 최대(진한 빨간색)까지 예측하는 사각 오류를 나타냅니다. 유효하지 않은 영역은 회색으로 표시됩니다.](ZoeDepth%20Zero-shot%20Transfer%20by%20Combining%20Relative%20%20d443ea562ca54766889cfbf116a31b65/Untitled%203.png)

NYU Depth v2에서의 질적 비교. 우리의 방법은 일관되게 훨씬 적은 오류로 더 나은 예측을 생성합니다. 깊이 맵을 자세히 살펴보면, 우리의 예측이 훨씬 더 선명하고 명확한 가장자리를 가지고 있음을 알 수 있습니다. ∆는 최소(진한 파란색)에서 최대(진한 빨간색)까지 예측하는 사각 오류를 나타냅니다. 유효하지 않은 영역은 회색으로 표시됩니다.

깊이 예측은 이미지의 깊이 예측과 실사 해상도로 평가된 미러 이미지의 예측의 평균으로 계산됩니다.

### 5. Results

5.1. NYU Depth V2의 SOTA와 비교

연구진의 새로운 아키텍처는 사전 학습을 위한 추가 데이터 없이도 현재의 최첨단(SOTA)을 능가하는 성능을 발휘합니다. 연구진이 개발한 모델인 ZoeD-X-N은 NYU Depth v2 데이터 세트에서 평가한 결과, 절대 상대 오차(REL)에서 NeWCRF를 13.7% 능가하는 성능을 보였습니다. 상대적 심도 사전 훈련이 적용된 모델인 ZoeD-M12-N은 SOTA보다 약 21% 더 뛰어난 성능을 보였으며, 생성된 심도 맵의 경계가 더 선명했습니다.

저자들은 이 아키텍처가 다른 모델에도 도움이 될 수 있지만, 이점을 충분히 활용하려면 수정이 필요하다는 사실을 입증했습니다. 이러한 수정에도 불구하고 이러한 아키텍처는 여전히 저자의 완전한 프레임워크의 성능과 일치하지 않습니다.

5.2. 범용 메트릭 측면

저자들은 두 개의 서로 다른 데이터 세트에 대해 학습되고 실내 및 실외 도메인 모두에 일반화할 수 있는 모델 ZoeD-M12-NK를 사용하여 범용 메트릭 깊이 추정 프레임워크에 대한 진행 상황을 평가합니다. 이 모델은 NYU Depth v2의 이전 SOTA보다 18.9% 더 뛰어난 성능을 발휘합니다. NYU Depth v2(ZoeD-M12-N)에서만 미세 조정된 모델만큼 성능이 뛰어나지는 않지만, 성능과 도메인 간 일반화 사이의 매력적인 균형을 제공합니다.

실내 및 실외 데이터 세트 모두에서 훈련된 다른 모델과 비교했을 때, 공유 헤드를 사용할 때 ZoeD-M12-NK는 8%의 성능 저하만 기록하며 뛰어난 성능을 보였습니다. 투헤드 모델인 ZoeD-M12-NK를 사용하면 그 격차는 2.6%로 더욱 줄어듭니다. 저자들은 여러 데이터 세트에서 성공적으로 학습하려면 다른 모델에 변화가 필요하다고 결론지었습니다.

저자들의 프레임워크의 일부를 이전 모델에 구현한 후에도 이러한 모델은 여전히 부족했습니다. 이는 빈 기반 아키텍처(예: ZoeD-M12-NK)가 다중 도메인 훈련에 더 적합하며 상대적 깊이 사전 훈련을 더 효과적으로 활용할 수 있음을 시사합니다. 저자들의 모델은 여러 데이터 세트에서 가장 우수한 성능을 보이며 향상된 도메인 적응 및 일반화 능력을 보여줍니다. 저자들은 이 제로 샷 성능을 더 조사할 예정입니다.

5.3. 제로 샷 일반화

저자들은 8개의 보이지 않는 실내 및 실외 데이터 세트에 대해 미세 조정 없이 일반화할 수 있는 모델의 능력을 조사했습니다. 저자들이 개발한 모델인 ZoeD-M12-NK는 다양한 실내 데이터 세트에서 5.3%에서 46.3%에 이르는 평균 상대적 개선율을 보이며 이전의 최신 모델에 비해 상당히 우수한 성능을 보여주었습니다.

흥미롭게도 이 모델은 실내 데이터 세트와 유사한 실외 시나리오의 클로즈업 이미지가 포함된 실외 데이터 세트 DIML에서도 976.4%의 높은 개선율을 보였습니다. 이 모델은 NYU Depth v2에 대한 학습을 통해 실내 도메인에 대한 지식을 활용할 수 있었으며, 더 나은 일반화를 위해 여러 도메인에 걸쳐 모델을 미세 조정하는 것의 이점을 강조합니다.

5.4. 절제 연구

제거 연구에서 저자들은 모델에서 다양한 디자인 요소의 중요성을 분석했습니다.

그 결과 매개변수가 많은 백본이 클수록 성능이 향상되고, 백본의 이미지 분류 성능은 깊이 추정 모델의 성능과 밀접한 상관관계가 있다는 사실을 발견했습니다. 이는 이들의 아키텍처가 향후 이미지 분류의 발전으로부터 직접적인 혜택을 받을 수 있음을 시사합니다.

이 설계의 메트릭 빈 모듈은 전체 성능에 결정적인 영향을 미치는 것으로 나타났으며, 가장 우수한 변형은 메트릭 빈 모듈이 없는 설계에 비해 21% 향상된 성능을 보였습니다. 모든 어트랙터 변형은 스플리터 디자인 변형보다 훨씬 더 나은 성능을 보였습니다.

또한 상대 피처를 미터법 헤드로 라우팅하기 위해 세 가지 변형을 테스트했습니다. 놀랍게도, 추론 중에 도메인 레이블을 사용할 수 없음에도 불구하고, 훈련된 라우터가 레이블 라우터보다 NYU Depth v2에서 더 나은 성능을 보였습니다. 이는 도메인 수준의 차별적 감독이 더 나은 표현을 학습하는 데 도움이 될 수 있음을 나타냅니다.

마지막으로 로그 이항 분포 사용의 효과를 평가한 결과, 약 2%의 개선 효과가 있는 것으로 나타나 서수 문제에서 단모수 분포의 중요성을 강조했습니다.

### 6. Conclusion

저자들은 그간의 성과를 요약하고 향후 계획을 설명하며 논문을 마무리합니다. 저자들이 제안한 프레임워크인 ZoeDepth는 2단계 프로세스를 통합하여 상대적 깊이 추정과 메트릭 깊이 추정 간의 격차를 성공적으로 해소합니다. 첫 번째 단계에서는 데이터 집합에 대한 상대적 깊이를 사용하여 모델을 사전 학습합니다. 두 번째 단계에서는 새로운 메트릭 빈 모듈을 기반으로 하는 도메인별 헤드가 디코더에 추가되고, 메트릭 깊이 예측을 위해 하나 이상의 데이터 세트에서 모델이 미세 조정됩니다.

ZoeDepth 아키텍처는 특히 상대적 오류(REL) 지표에서 21% 개선된 성능을 보여줌으로써 NYU Depth v2 벤치마크에서 최신 기술을 능가합니다. 또한, 이 모델은 보이지 않는 데이터에 대해서도 일반화할 수 있는 속성인 제로 샷 전송에서 상당한 개선이 이루어졌음을 보여줍니다.

저자들은 앞으로 이 모델을 개선할 수 있는 잠재적인 개선 사항을 제안합니다. 특히 실내와 실외를 넘어 더 세분화된 도메인을 정의하고 더 많은 메트릭 데이터 세트에 대해 모델을 미세 조정할 것을 제안합니다.

또한 향후 작업에는 온디바이스 사진 편집에 적용할 수 있는 ZoeDepth의 모바일 아키텍처 버전에 대한 조사도 포함됩니다. 또한 저자들은 로봇 공학 및 자율 주행과 같은 분야에서 특히 유용할 수 있는 스테레오 이미지 깊이 추정으로 작업을 확장하는 데에도 관심을 표명했습니다.

![SUN RGB-D 데이터셋 [38]에 대한 제로샷 전이. 유효하지 않은 영역은 회색으로 표시됩니다.](ZoeDepth%20Zero-shot%20Transfer%20by%20Combining%20Relative%20%20d443ea562ca54766889cfbf116a31b65/Untitled%204.png)

SUN RGB-D 데이터셋 [38]에 대한 제로샷 전이. 유효하지 않은 영역은 회색으로 표시됩니다.

### A. Appendix

A.1. 데이터 세트 개요

저자들은 조이뎁스 아키텍처를 미세 조정하고 평가하는 데 사용한 데이터 세트에 대한 개요를 제공합니다. 여기에는 실내 데이터 세트인 SUN RGBD, iBims 벤치마크, DIODE Indoor 및 HyperSim이 포함됩니다. 실외 데이터 세트의 경우 DDAD, DIML Outdoor, DIODE Outdoor, Virtual KITTI 2를 사용했습니다. 모든 아키텍처는 훈련 해상도에 맞게 입력 크기를 조정하여 평가했습니다.

A.2. 훈련 세부 사항

저자들은 ZoeDepth 아키텍처에 적용된 다양한 훈련 전략을 나열한 표를 제공합니다. 이러한 전략은 상대적 깊이 사전 훈련에 사용되는 데이터 세트, 메트릭 깊이 미세 조정에 사용되는 데이터 세트, 사용된 메트릭 헤드의 수에 따라 다릅니다.

A.3. 세부 결과

저자는 훈련 중에 볼 수 없었던 실내 및 실외 데이터 세트에 대한 제로 샷 전송에 대한 자세한 정량적 결과를 제공합니다. 이러한 결과에는 임계값 정확도와 평균 로그10 오류가 포함됩니다. 실내 데이터 세트의 경우, NeWCRF 모델이 깊이를 과소평가하는 경향이 있는 반면, Zoe-M12-NK 및 Zoe-M12-N 모델은 실측 데이터에 훨씬 더 가깝다는 사실을 발견했습니다. 실외 데이터 세트의 경우, ZoeD-M12-NK 모델이 NeWCRF 모델보다 훨씬 뛰어난 성능을 보였습니다.

A.4. 다양한 백본을 사용한 ZoeDepth

저자들은 MiDAS 인코더에 대해 다양한 백본을 사용하여 ZoeDepth의 성능을 평가했습니다. 대형 BEiT384-L 백본에서 최고의 성능을 달성했습니다. 그러나 ZoeDepth의 파라미터 수는 선택한 MiDaS 인코더 백본에 따라 크게 영향을 받는다는 점에 주목했습니다. 따라서 다른 백본도 시도해보고 해당 결과를 보고했습니다. 기본 BEiT384-B 트랜스포머 또는 계층형 트랜스포머 Swin2와 같은 다른 백본을 사용한 결과 ZoeDepth의 파라미터 수가 크게 줄어든 것으로 나타났습니다.

- 모델의 입력과 출력
    
    ZoeDepth는 이미지의 깊이를 예측하는 모델입니다. 따라서 이 모델의 입력(Input)과 출력(Output)은 다음과 같습니다:
    
    - 입력(Input): ZoeDepth 모델의 입력은 RGB 이미지입니다. 이 이미지는 실내 혹은 실외에서 촬영된 사진일 수 있으며, 해당 이미지를 통해 모델은 객체들 사이의 상대적인 깊이를 이해하고, 구체적인 깊이 값을 예측하려고 시도합니다.
    - 출력(Output): ZoeDepth 모델의 출력은 입력 이미지에 대한 깊이 맵입니다. 이 깊이 맵은 모든 픽셀에 대해 해당 픽셀의 깊이를 나타내는 값들로 이루어져 있습니다. 이러한 깊이 맵은 3D 재구성, 로봇이나 자율 주행 차량의 내비게이션, 가상 현실 등 다양한 응용 분야에서 사용될 수 있습니다.
- 의의
    
    ZoeDepth는 다음과 같은 주요 차별점을 가지고 있는 깊이 예측 모델입니다.
    
    1. **상대적 및 메트릭 깊이 추정간의 차이 극복**: 이전의 일부 깊이 추정 방법들은 상대적 깊이 또는 메트릭 깊이에 중점을 두었는데, ZoeDepth는 이 두 가지를 모두 포함하는 방식으로 새로운 프레임워크를 제안합니다.
    2. **인플레이션 모듈 활용**: ZoeDepth는 인플레이션 모듈을 사용하여 2D 피처 맵을 3D 공간으로 변환하며, 이를 통해 이전 작업에서 발생했던 일부 깊이 추정의 문제를 해결합니다.
    3. **단일 멀티 도메인 메트릭 깊이 추정**: ZoeDepth는 실내, 실외, 시뮬레이션 또는 실제 등 다양한 도메인에서 깊이를 추정할 수 있습니다. 이는 제로샷 전이 즉, 모델이 본 적 없는 새로운 도메인에 대해서도 예측을 할 수 있다는 것을 의미합니다.
    4. **모듈러 구조**: ZoeDepth는 모듈러 구조를 사용하여 모델의 다양한 부분을 쉽게 바꿀 수 있습니다. 예를 들어, 모델의 백본을 다른 백본으로 바꿔 모델의 성능을 향상시키거나 파라미터의 수를 줄일 수 있습니다.
    5. **현장 전이 성능 향상**: ZoeDepth는 인공적으로 만들어진 데이터셋 뿐만 아니라 실세계의 복잡한 조건에서도 작동하는 모델을 만드는 것을 목표로 하고 있습니다. 이는 특히 로보틱스나 자율주행 자동차 등 실세계 응용 분야에서 중요합니다.
    
    이러한 특징들 덕분에 ZoeDepth는 이전의 깊이 추정 방법들과 비교했을 때 성능이 향상되며, 다양한 응용 분야에서 사용될 수 있습니다.