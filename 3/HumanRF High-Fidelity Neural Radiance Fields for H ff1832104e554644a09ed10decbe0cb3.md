# HumanRF: High-Fidelity Neural Radiance Fields for Humans in Motion

[https://arxiv.org/abs/2305.06356](https://arxiv.org/abs/2305.06356)

[https://synthesiaresearch.github.io/humanrf/](https://synthesiaresearch.github.io/humanrf/)

1 INTRODUCTION

이 연구는 컴퓨터 그래픽 분야에서 큰 난제인 움직이는 사람의 사실적인 이미지나 동영상을 만드는 것입니다. 일반적으로 그래픽의 3D 모델은 아티스트가 수작업으로 만들지만, 최근에는 실제 관찰을 기반으로 이러한 모델을 자동으로 만들려는 노력이 많이 이루어지고 있습니다.

이 과정은 여러 가지 이유로 어렵습니다. 첫째, 인체에는 정확하게 캡처해야 하는 디테일이 많기 때문입니다. 사람의 눈은 다른 사람을 보는 데 매우 익숙하기 때문에 작은 디테일이라도 잘못 포착하면 눈치채기 쉽습니다. 둘째, 사람의 외모와 움직임을 동시에 캡처하는 것은 어렵습니다. 마지막으로, 빠르고 복잡한 움직임을 실제처럼 보이도록 충분히 높은 해상도로 캡처하는 것은 여전히 해결되지 않은 문제입니다.

하지만 최근의 발전은 이러한 문제를 해결하는 데 도움이 되었습니다. 신경 방사 필드(NeRF)라고 하는 한 가지 접근 방식은 머신 러닝을 사용하여 빛이 장면의 물체 표면과 상호 작용하는 방식을 설명하는 3D 필드를 생성합니다. 그런 다음 이 3D 필드를 사용하여 다양한 관점에서 장면의 새로운 이미지를 생성할 수 있습니다.

원래의 NeRF 접근 방식은 정적인 장면에 가장 효과적이었지만, 최근 버전은 사람처럼 물체가 움직이는 장면을 처리하기 위해 개발되었습니다. 이러한 방법은 인상적이지만, 특히 복잡한 사람의 움직임이 긴 시퀀스를 처리할 때는 여전히 몇 가지 한계가 있습니다.

이번 연구에서는 이러한 한계를 극복하기 위해 노력하고 있습니다. 연구팀은 160대의 동기화된 카메라로 촬영한 다양한 각도에서 움직이는 사람의 고품질 비디오 녹화를 포함하는 ActorsHQ라는 새로운 데이터 세트를 소개합니다. 또한 이 데이터를 처리하는 새로운 방법을 제안하여 복잡한 동작의 긴 시퀀스를 더 작은 세그먼트로 분할하여 처리할 수 있습니다.

요약하자면, 연구진은 움직이는 사람의 고해상도 멀티뷰 비디오 데이터 세트를 새로 생성하고 기존 기술의 한계를 극복하는 새로운 데이터 처리 방법을 제안했습니다. 이 모든 것의 목표는 컴퓨터로 생성된 사람의 이미지와 비디오의 사실감과 디테일을 개선하는 것입니다.

2 RELATED WORK

이 섹션에서는 3D 및 4D 신경 표현을 생성하고 사람의 연기를 캡처하는 최신 기술에 대해 설명합니다. 다음은 이러한 주제에 대한 간단한 설명입니다:

3D 신경 표현: 이 연구 분야는 3차원 장면을 디지털로 재현하는 것을 목표로 합니다. 전통적으로 이 분야는 어려운 과제였지만, 최근 딥러닝의 발전으로 이 분야가 재정의되었습니다. 예를 들어, 마일든홀 외[2020]가 소개한 '신경 방사 필드(NeRF)'는 머신러닝 기법(MLP)을 사용하여 빛이 장면의 표면과 상호 작용하는 방식을 설명하는 3D 필드를 인코딩하는 획기적인 기술입니다. 그러나 스파스 그리드, 낮은 순위 텐서 분해, 해시 데이터 구조와 같은 다른 대안도 3D 재구성에 도움이 될 수 있습니다.

4D 동적 표현: 시청자가 어떤 각도에서든 장면을 볼 수 있는 '자유 시점' 동영상을 제작하는 것입니다. 수년 동안 멀티 카메라 돔 사용, 텍스처 메시 추적, 레이어드 메시 표현을 사용한 비디오 재구성 및 압축, 최근에는 딥 러닝 기반 방법 등 다양한 접근 방식이 제안되어 왔습니다. 특히 시간과 움직임을 모델에 인코딩하는 다양한 방법을 통해 NeRF를 시간적 영역으로 확장하는 데 중점을 두고 있습니다.

신경 인간 성능 캡처: 이 연구의 궁극적인 목표는 매우 사실적인 인간 디지털 표현을 만드는 것입니다. 이를 달성하기 위한 몇 가지 방법이 있는데, 특정 개인이나 포즈에 맞게 조정할 수 있는 인간의 '표준' 표현(일종의 '평균' 또는 '전형적' 모델)을 학습하는 경우가 많습니다. 이러한 방법 중 일부는 템플릿 모델 또는 스켈레톤을 사용하여 이 과정을 안내합니다. 하지만 이러한 템플릿 기반 접근 방식은 옷감의 움직임이나 미묘한 표정 등 세밀한 디테일을 포착하는 데 어려움을 겪는 경우가 많습니다. 따라서 최근 일부 연구에서는 최상의 시각적 품질을 목표로 하는 템플릿 없는 접근 방식을 모색하고 있습니다.

이 연구에서 저자들은 이러한 다양한 작업의 요소를 차용하되, 특히 복잡하고 빠른 모션 처리, 긴 시퀀스로의 확장, 시각적 품질을 극대화하기 위한 고해상도 디테일 캡처에 중점을 둔 접근 방식을 제안합니다. 이들은 4D 분해에 3D 텐서와 1D 텐서의 조합을 활용하고, 시퀀스를 관리 가능한 세그먼트로 분할하여 최신 GPU에서 효율적으로 훈련할 수 있도록 합니다.

3 METHOD

HumanRF라는 이름의 프로젝트는 멀티뷰 카메라 설정을 사용하여 움직이는 사람 배우의 고충실도 및 시간적으로 일관된 새로운 뷰 합성을 생성하는 것을 목표로 합니다. 이를 위해 4차원(4D) 씬 표현을 활용하고 차등 볼륨 렌더링을 통해 학습한 다음 멀티뷰 2D 측광 및 마스크 손실로 감독하여 렌더링된 이미지와 입력 RGB 이미지 및 전경 마스크 간의 차이를 최소화합니다.

![HumanRF 개요: 훈련에 앞서, 우리의 방법은 3D에서 유사한 유니온 점유를 가진 4D 세그먼트로 시간 영역을 분할하는 것으로 시작합니다. (§3.2). 각 세그먼트는 텐서 분해와 해시 그리드를 활용하여 콤팩트하게 표현된 4D 특징 그리드로 모델링됩니다(§3.1). 훈련하는 동안 다양한 시간 프레임과 카메라에 걸쳐 광선 배치를 샘플링합니다. 볼륨 렌더링을 통해 각 픽셀 색상을 예측한 후(§3.3), 광도계를 적용하여 제약 조건을 적용하고 전경 마스크를 통해 광선 행진 가중치를 정규화합니다(§3.4).](HumanRF%20High-Fidelity%20Neural%20Radiance%20Fields%20for%20H%20ff1832104e554644a09ed10decbe0cb3/Untitled.png)

HumanRF 개요: 훈련에 앞서, 우리의 방법은 3D에서 유사한 유니온 점유를 가진 4D 세그먼트로 시간 영역을 분할하는 것으로 시작합니다. (§3.2). 각 세그먼트는 텐서 분해와 해시 그리드를 활용하여 콤팩트하게 표현된 4D 특징 그리드로 모델링됩니다(§3.1). 훈련하는 동안 다양한 시간 프레임과 카메라에 걸쳐 광선 배치를 샘플링합니다. 볼륨 렌더링을 통해 각 픽셀 색상을 예측한 후(§3.3), 광도계를 적용하여 제약 조건을 적용하고 전경 마스크를 통해 광선 행진 가중치를 정규화합니다(§3.4).

이를 위해 다층 퍼셉트론(MLP)과 결합된 스파스 피처 해시 그리드를 사용하는 방식으로 접근합니다. 이 접근 방식은 시간 영역을 최적으로 분산된 시간 세그먼트로 분할하며, 각 세그먼트는 컴팩트한 4D 피처 그리드로 표현되므로 모든 길이의 멀티뷰 데이터에 대해 효율적인 사실적인 뉴럴 렌더링을 구현할 수 있습니다.

시간에 따라 변화하는 4D 피처 그리드를 지원하는 텐소RF 벡터-매트릭스 분해 기술을 확장하고 각 시간 세그먼트가 커버하는 3D 공간 볼륨이 비슷한 크기를 유지하도록 하는 적응형 시간 분할 기법을 제안합니다. 이를 통해 시간적 컨텍스트에 관계없이 뛰어난 표현력을 얻을 수 있습니다.

또한 공유 MLP는 피처를 밀도 및 뷰에 따른 광도로 변환하여 결과물 전반에 걸쳐 시간적 일관성을 보장합니다. 렌더링 파이프라인의 효율성을 측정하기 위해 2D 전용 손실이 사용되며, 렌더링된 이미지와 입력된 RGB 이미지 및 전경 마스크 간의 오류를 계산합니다.

4D 피처 그리드 분해의 경우 4D 세그먼트를 최적으로 분할하여 동적 3D 장면을 표현합니다. 4개의 3D 및 4개의 1D 피처 그리드로 분해하는 방법을 제안하며, 이를 통해 밀도가 높은 3D 데이터를 보다 컴팩트하게 표현할 수 있다고 제안합니다.

적응형 시간 분할에서는 매우 긴 시퀀스에 특히 유용한 훈련 전에 세그먼트의 크기를 선택하는 욕심 알고리즘을 제안합니다. 이 알고리즘은 여유 공간을 조각내어 점유 그리드를 계산한 다음 확장 계수에 따라 새로운 세그먼트를 생성하는 방식으로 작동합니다.

공유 MLP 및 볼륨 렌더링 접근 방식은 방출 및 흡수와 함께 볼륨 렌더링 공식을 사용합니다. 두 개의 얕은 MLP를 활용하여 전체 시퀀스에서 공유되는 밀도 및 뷰에 따른 광원을 모델링합니다.

마지막으로, 손실 접근 방식은 기준색과 예측 픽셀 색상 간의 후버 손실과 기준색 마스크와 누적된 볼륨 렌더링 가중치 간의 이진 교차 엔트로피 손실을 사용하여 볼륨 점유를 정규화합니다. 이렇게 하면 훈련 초기에 빈 공간을 정리하여 훈련 반복 속도를 높일 수 있습니다.

이는 사람의 움직임을 모델링하고 멀티뷰 카메라 데이터에서 새로운 뷰 합성을 생성하는 강력하고 포괄적인 접근 방식처럼 보입니다.

4 DATASET

이 데이터 세트인 ActorsHQ는 컴퓨터 애니메이션, 비디오 게임 개발, 로봇 공학, 생체 역학 등 다양한 분야에 매우 유용할 수 있는 포괄적인 인간 모션 캡처 데이터 세트를 제공하는 것으로 보입니다.

글로벌 조명을 위한 프로그래밍 가능한 LED 어레이와 함께 25fps로 녹화하는 160개의 12MP Ximea 카메라를 사용하여 피사체의 움직임을 고품질의 디테일하게 캡처할 수 있는 것으로 보입니다. 또한 멀티뷰 스테레오 재구성을 위해 에픽게임즈의 리얼리티캡쳐 소프트웨어를 사용하면 모션 캡처 데이터의 디테일과 정확도가 한층 더 높아질 것으로 보입니다.

다양한 의상을 입은 여성 배우 4명과 남성 배우 4명의 다양한 모션을 캡처하면 데이터 세트의 다양성과 범위도 늘어납니다. 각 배우가 정밀하게 안무된 동작과 일상적이고 자연스러운 동작으로 구성된 두 가지 동작 세트를 수행하도록 하면 데이터 세트에 다양하고 사실적인 범위의 인간 움직임을 담을 수 있습니다.

보다 구체적인 맥락이나 일련의 질문이 없으면 더 이상 언급하기 어렵습니다. 그러나 몇 가지 잠재적인 질문과 탐색해야 할 측면은 다음과 같습니다:

데이터 품질: 제공된 기술 사양을 고려할 때 모션 캡처의 전반적인 데이터 품질과 충실도는 어느 정도인가요? 여기에는 공간적 해상도(즉, 디테일)와 시간적 해상도(즉, 움직임의 부드러움과 연속성)가 모두 포함됩니다.

애플리케이션: 이 데이터 세트는 어떤 애플리케이션에 특히 적합할까요? 캡처된 모션의 범위와 디테일 수준을 고려할 때 여러 분야에서 유용할 수 있습니다.

벤치마킹: ActorsHQ 데이터 세트는 크기, 다양성, 품질, 유용성 측면에서 다른 유사한 모션 캡처 데이터 세트와 어떻게 비교되나요?

향후 개선 사항: 향후 데이터세트에 개선할 수 있는 사항은 무엇인가요? 캡처 시스템이나 방법을 개선할 수 있을까요, 아니면 추가 유형의 데이터를 캡처할 수 있을까요?

데이터 접근성: 연구자나 개발자가 이 데이터 세트에 어떻게 액세스할 수 있으며, 데이터 사용에 대한 제한이나 요구사항이 있나요?

데이터 처리: 데이터 집합의 사용자는 데이터를 어떻게 처리하거나 해석해야 하나요? 사용자가 알아야 할 잠재적인 문제나 어려움이 있나요?

이는 몇 가지 잠재적인 관심 사항일 뿐입니다. 데이터 집합의 다양한 측면의 구체적인 관련성과 중요성은 상황과 사용자의 특정 관심사에 따라 달라질 수 있습니다.

5 EVALUATION

이 자세한 설명은 HumanRF 방법과 ActorsHQ 데이터 세트와의 상호 작용에 관한 프로세스, 평가 및 결론을 간략하게 설명합니다. 여러 섹션으로 나누어 살펴보겠습니다:

방법 비교: 이 연구에서는 HumanRF를 6개의 최신 기준선(변형 기반 방법 3개, 사람별 방법 2개, 추가 기준선 1개)과 비교했습니다. 평가 결과, HumanRF가 이러한 기준선보다 지속적으로 우수한 성능을 발휘하여 더 선명한 결과를 제공하고 사실적이고 유동적인 사람의 움직임을 캡처하는 데 중요한 시간적 안정성을 유지하는 것으로 나타났습니다.

평가 프로토콜: 연구원들은 훈련, 검증 및 테스트에 동일한 카메라 세트를 사용했습니다. 정량적 평가를 위해 이미지 및 비디오 품질 메트릭(PSNR, LPIPS, SSIM, VMAF)을 조합하여 사용했습니다. 특히, 일부 기준선은 전체 해상도에서 합리적인 결과를 제공하지 못했는데, 이는 HumanRF가 미세한 디테일을 캡처하고 재현하는 데 더 나은 성능을 발휘한다는 것을 나타냅니다.

디자인 선택: 이 섹션에서는 HumanRF의 몇 가지 디자인 선택에 대해 설명합니다. 이들이 수행한 절제 연구는 4D 특징 그리드 표현, 그리드 해상도, 특징 차원 및 HumanRF 모델의 기타 측면의 효과를 강조합니다. 이는 HumanRF의 모델 설계가 여러 면에서 다른 대안보다 우수하다는 것을 보여줍니다.

입력 해상도: 실험 결과, 고해상도 데이터로 훈련할 때 HumanRF의 성능이 향상되는 것으로 나타났습니다. 이는 이 모델이 사실적인 컴퓨터 그래픽을 만들거나 정확한 로봇 모델을 훈련하는 등 다양한 애플리케이션에서 중요할 수 있는 미세한 디테일을 캡처하고 재현하는 데 특히 적합하다는 것을 나타냅니다.

동적 모피 동물 데이터 세트: 연구원들은 또한 동적 털복숭이 동물(DFA) 데이터 세트에서 HumanRF를 테스트하여 모델의 유연성과 적응성을 입증했습니다. 이 데이터 세트에서 우수한 성능을 보였다는 사실은 이 모델이 사람의 동작에만 국한되지 않고 다양한 모션 캡처 애플리케이션에 사용될 수 있다는 것을 보여줍니다.

한계와 향후 작업: 저자들은 HumanRF가 효과적이기는 하지만 배우의 관절을 제어할 수 없다는 점과 ActorsHQ와 같은 매우 상세한 데이터 세트에 의존해야 한다는 점 등 몇 가지 한계가 있음을 인정합니다. 또한 이러한 문제를 해결하기 위해 명시적 파라미터를 제어하거나 렌더링 시간을 단축하는 방법을 모색하는 등 향후 작업을 위한 몇 가지 잠재적인 방법을 제안합니다.

전반적으로 이 요약은 HumanRF가 사람의 움직임을 캡처하고 재현하는 데 매우 효과적인 방법이며, 기존의 다른 방법보다 성능이 뛰어나다는 것을 나타냅니다. 이 결과는 이 기법의 가능성을 보여 주지만, 추가 연구 및 개발이 필요한 부분도 강조합니다.

6 CONCLUSION

주요 내용은 다음과 같습니다:

휴먼RF: 저자들은 인간의 움직임을 충실하게 포착하는 시공간적 복사장을 재구성하는 새로운 방법인 휴먼RF를 소개했습니다. 사람의 움직임을 사실적이고 고품질로 표현하는 것은 어려울 수 있기 때문에 이 방법은 매우 중요합니다. 연구진은 다중 해상도 해시 그리드에 기반한 4D 표현을 사용하여 디테일을 포착하고 적응형 분할 기법을 사용하여 실제 메모리 예산 내에서 긴 시퀀스를 처리했습니다.

액터스 HQ: 연구진은 160대의 카메라로 12MP로 촬영한 최초의 공개용 멀티뷰 데이터세트인 ActorsHQ도 선보였습니다. 이 고해상도 데이터 세트는 향후 이 분야의 연구를 위한 벤치마크 역할을 하며, HumanRF 방법의 장점을 입증하는 데 사용되었습니다.

결과 및 향후 작업: 연구 결과, 휴먼RF 방식이 고품질의 자유 시점 비디오를 제작할 수 있음을 보여주었으며, 이는 프로덕션 수준의 새로운 시점 합성을 향한 중요한 단계입니다. 이는 기본적으로 이 방법이 실제 제작 환경에서 고품질 비디오 콘텐츠를 제작하는 데 사용될 수 있음을 의미합니다.

오픈소스 기여: 연구진은 ActorsHQ 데이터 세트와 HumanRF의 소스 코드를 모두 공개했습니다. 이는 연구 커뮤니티에 중요한 기여를 하는 것으로, 다른 연구자들이 연구진의 작업을 기반으로 가상 인물을 사실적으로 재구성하는 분야에서 더욱 발전할 수 있도록 지원할 수 있기 때문입니다.

전반적으로 휴먼RF 방법과 ActorsHQ 데이터 세트는 연구 커뮤니티가 인간 모션 캡처 및 렌더링의 최첨단 기술을 발전시킬 수 있는 새롭고 흥미로운 도구를 제공합니다.

- 요약
    
    1단계: 문제 파악
    이 논문의 저자는 디지털 공간에서 사람의 움직임을 사실적이고 고품질의 디테일로 표현하는 문제를 해결하는 것을 목표로 합니다. 기존 방식은 특히 긴 시퀀스의 경우 사람 움직임의 복잡성과 디테일을 캡처하는 데 어려움을 겪을 수 있습니다.
    
    2단계: 솔루션 개발
    연구진은 시공간 복사장을 재구성하도록 설계된 HumanRF라는 새로운 방법을 개발했습니다. 이 방법은 사람의 연기를 높은 충실도로 캡처합니다. HumanRF는 다중 해상도 해시 그리드에 기반한 4D 표현을 사용하여 디테일을 캡처합니다. 또한 적응형 분할 기법을 도입하여 실제 메모리 예산 내에서 긴 시퀀스를 효율적으로 처리합니다.
    
    3단계: 데이터 세트 생성
    저자들은 방법을 검증하기 위해 새로운 데이터 세트인 ActorsHQ를 생성합니다. 이 데이터 세트는 160대의 카메라가 12MP로 녹화하여 캡처한 공개적으로 사용 가능한 멀티뷰 데이터 세트입니다. 이 데이터 세트는 HumanRF의 성능을 평가하기 위한 벤치마크 역할을 합니다.
    
    4단계: 실험 및 평가
    저자는 ActorsHQ 데이터 세트를 사용하여 광범위한 정량적 및 정성적 실험을 수행합니다. 그리고 6개의 최신 기준선과 자신들의 방법을 비교합니다. 각 방법의 성능을 평가하기 위해 다양한 성능 메트릭을 사용합니다. 그 결과 휴먼RF가 품질과 디테일 측면에서 기준선보다 지속적으로 우수한 성능을 발휘하는 것으로 나타났습니다.
    
    5단계: 추가 사용 사례 탐색
    또한 저자는 HumanRF가 ActorsHQ 데이터세트와 함께 작동하도록 설계되었지만 전경 오브젝트와 마스크가 있는 모든 씬에 적용될 수 있음을 보여줍니다. 저자들은 움직이는 털복숭이 동물이 포함된 다른 데이터 세트에서 이 방법을 테스트했으며, 그 결과 다른 방법의 품질을 능가하는 결과를 얻었습니다.
    
    6단계: 한계와 향후 작업 논의하기
    저자들은 이 방법의 한계를 인정하고 향후 연구를 위한 잠재적인 길을 제시합니다. 여기에는 하이엔드 레코딩에 대한 훈련 모델 탐색, 렌더링 시간을 단축하는 방법 모색, 시간적으로 일관된 배경 매팅 기법 개발 등이 포함됩니다.
    
    7단계: 결론
    저자들은 휴먼RF가 프로덕션 수준의 새로운 뷰 합성을 향한 중요한 단계라고 결론지었습니다. 이들은 ActorsHQ 데이터세트와 휴먼RF의 소스 코드 공개를 통해 가상 인물의 사실적인 재구성 분야에서 더욱 발전할 수 있기를 바랍니다.