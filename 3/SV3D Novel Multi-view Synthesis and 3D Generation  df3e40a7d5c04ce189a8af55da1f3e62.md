# SV3D: Novel Multi-view Synthesis and 3D Generation from a Single Image using Latent Video Diffusion

[https://arxiv.org/abs/2403.12008](https://arxiv.org/abs/2403.12008)

[https://sv3d.github.io/](https://sv3d.github.io/)

- Mar 2024

### 1. Introduction

![Stable Video 3D (SV3D). 단일 이미지로부터 SV3D는 일관된 새로운 다시점 이미지를 생성합니다. 그 후 우리는 SV3D로 생성된 시점을 이용하여 3D 표현을 최적화하여 고품질의 3D 메시를 얻습니다.](SV3D%20Novel%20Multi-view%20Synthesis%20and%203D%20Generation%20%20df3e40a7d5c04ce189a8af55da1f3e62/Untitled.png)

Stable Video 3D (SV3D). 단일 이미지로부터 SV3D는 일관된 새로운 다시점 이미지를 생성합니다. 그 후 우리는 SV3D로 생성된 시점을 이용하여 3D 표현을 최적화하여 고품질의 3D 메시를 얻습니다.

단일 이미지에서의 3D 객체 재구성은 컴퓨터 비전 분야에서 오랜 기간 도전적인 문제로 여겨져 왔으며, 게임 디자인, 증강 현실/가상 현실, 전자 상거래, 로봇 공학 등 다양한 분야에서 중요한 응용을 가지고 있습니다. 이 문제를 해결하는 것은 2D 픽셀을 3D 공간으로 확장하고, 물체의 보이지 않는 부분에 대해 추론하는 과정을 포함하기 때문에 매우 어렵고 불완전한 문제로 여겨집니다.

이러한 배경 하에서, 최근 생성적 AI의 발전으로 인해 이 문제에 대한 실용적인 해결 방안이 제시되고 있습니다. 대규모 사전 학습을 통해 충분한 일반화를 달성한 생성 모델을 활용하여, 이전에는 도달할 수 없었던 성과를 달성하고 있습니다. 특히, 이미지 기반 2D 생성 모델들을 사용하여 주어진 객체의 새로운 시점에 대한 3D 최적화 손실 함수를 제공하고, 이러한 2D 생성 모델을 재활용하여 단일 이미지로부터 새로운 시점 합성(NVS)을 수행한 후, 생성된 새로운 시점을 3D 생성에 활용하는 접근 방식이 소개되고 있습니다.

이 논문은 기존의 사진 측량 기반 3D 객체 캡처 파이프라인을 모방하되, 명시적인 다시점 캡처 대신 생성 모델을 사용한 새로운 시점 합성으로 대체하는 혁신적인 방법을 제안합니다. 이를 통해, 기존 방법들이 겪었던 다시점 일관성의 부족과 같은 문제를 해결하고자 하며, 고해상도 이미지 조건의 비디오 확산 모델을 적용하여 NVS와 이어지는 3D 생성을 개선합니다.

본 논문의 핵심은 비디오 확산 모델, 특히 안정된 비디오 확산(SVD) 모델을 새로운 시점의 다시점 합성에 적용함으로써, 포즈 제어 가능성, 다시점 일관성, 일반화 능력을 향상시키는 새로운 방법론을 제시한다는 점에 있습니다. 이를 통해 고품질의 3D 메쉬를 직접 생성할 수 있으며, 보이지 않는 부분의 3D 품질을 더욱 향상시키기 위한 기술을 도입합니다.

### 2. Background

"Background" 장에서는 단일 이미지에서 3D 객체를 재구성하는 문제를 해결하기 위한 기존 접근 방법들과 그들의 주요 측면인 일반화, 제어 가능성, 그리고 다시점(3D) 일관성에 대해 자세히 설명합니다.

![ SV3D 아키텍처. 우리는 카메라 궤도의 고도와 방위각(sin, a)의 사인 곡선 임베딩을 잡음 단계 t의 그것과 더하고, 이 합을 UNet의 컨볼루션 블록에 입력합니다. 단일 입력 이미지의 CLIP 임베딩을 주의 블록에 입력하고, 그것의 잠재적 임베딩을 잡음 상태 zt와 연결합니다..](SV3D%20Novel%20Multi-view%20Synthesis%20and%203D%20Generation%20%20df3e40a7d5c04ce189a8af55da1f3e62/Untitled%201.png)

 SV3D 아키텍처. 우리는 카메라 궤도의 고도와 방위각(sin, a)의 사인 곡선 임베딩을 잡음 단계 t의 그것과 더하고, 이 합을 UNet의 컨볼루션 블록에 입력합니다. 단일 입력 이미지의 CLIP 임베딩을 주의 블록에 입력하고, 그것의 잠재적 임베딩을 잡음 상태 zt와 연결합니다..

![정적 대 동적 궤도. 우리는 SV3D 모델을 훈련하기 위해 두 종류의 궤도를 사용합니다.](SV3D%20Novel%20Multi-view%20Synthesis%20and%203D%20Generation%20%20df3e40a7d5c04ce189a8af55da1f3e62/Untitled%202.png)

정적 대 동적 궤도. 우리는 SV3D 모델을 훈련하기 위해 두 종류의 궤도를 사용합니다.

**일반화**

최근 확산 모델은 다양한 이미지와 비디오를 생성할 수 있는 강력한 생성적 모델로서 주목받고 있습니다. 특히, 대규모 데이터셋에서 학습된 Stable Diffusion (SD)과 Stable Video Diffusion (SVD) 모델은 뛰어난 일반화 능력을 보여주며, 다양한 생성 작업, 예를 들어 새로운 시점 합성(NVS)에 활용됩니다.

**제어 가능성**

이상적으로, 제어 가능한 NVS 모델은 임의의 관점에 해당하는 이미지를 생성할 수 있어야 합니다. 이와 관련하여, 이미지 확산 모델을 새로운 시점 합성기로 재활용하고, 입력 및 목표 시점 간의 포즈 차이에 조건을 두어 이미지를 생성하는 방법이 소개되었습니다. 그러나 이러한 방법들은 한 번에 하나의 새로운 시점만을 생성하므로, 본질적으로 다시점 일관성을 갖추도록 설계되지 않았습니다.

**다시점 일관성**

고품질의 NVS와 3D 생성을 위해서는 다시점 일관성이 가장 중요한 요구 사항입니다. 이전 연구들은 특정 시점을 동시에 생성하도록 제안하여 일관성 문제를 해결하려 했으나, 이러한 방법들은 특정 시점만 생성할 수 있고 임의의 관점을 생성할 수 없는 한계가 있었습니다. 또한, 이들은 이미지 기반 확산 모델을 미세 조정함으로써 다시점 일관성을 이미지 기반 확산에 부과하려 했으나, 이는 학습된 이미지 모델의 일반화 능력과 학습에 사용된 3D 데이터셋에 의해 한계가 있었습니다.

**비디오 확산 모델의 활용**

일부 연구에서는 NVS를 위해 비디오 확산 모델의 시간적 선행을 활용하여 보다 나은 일반화 및 다시점 일관성을 달성하려 하였습니다. 비디오 확산 모델은 동일한 고도에서만 360도 시점을 생성하는 등의 제한이 있었으나, SV3D는 이러한 한계를 극복하고 임의의 3D 객체 시점을 렌더링할 수 있는 첫 번째 비디오 확산 기반 프레임워크를 제안합니다.

본 장에서는 NVS와 3D 생성을 위한 기존 방법론들의 한계를 극복하고자 하는 SV3D의 접근 방식과 그 배경에 대한 이해를 제공하며, SV3D가 비디오 확산 모델의 일반화 능력, 제어 가능성, 다시점 일관성을 어떻게 활용하는지를 설명합니다.

### 3. SV3D: Novel Multi-view Synthesis

"SV3D: Novel Multi-view Synthesis" 챕터는 SV3D, 즉 단일 이미지에서 다양한 시점을 생성하여 3D 객체의 일관성 있는 시각화를 가능하게 하는 새로운 다시점 합성 방법에 대해 설명합니다. 이 접근 방식의 핵심은 비디오 확산 모델을 활용하여 시간적 일관성을 공간적 3D 일관성으로 전환하는 것입니다.

![선형 대 삼각형 CFG 스케일링. 선형 스케일링에서 마지막 프레임에 비해 우리가 제안한 삼각형 스케일링에서의 과도한 선명함 증가를 주목하세요.](SV3D%20Novel%20Multi-view%20Synthesis%20and%203D%20Generation%20%20df3e40a7d5c04ce189a8af55da1f3e62/Untitled%203.png)

선형 대 삼각형 CFG 스케일링. 선형 스케일링에서 마지막 프레임에 비해 우리가 제안한 삼각형 스케일링에서의 과도한 선명함 증가를 주목하세요.

![ LPIPS 대 프레임 번호. 우리는 SV3D가 프레임 당 최상의 재구성 메트릭을 가지고 있음을 발견했습니다](SV3D%20Novel%20Multi-view%20Synthesis%20and%203D%20Generation%20%20df3e40a7d5c04ce189a8af55da1f3e62/Untitled%204.png)

 LPIPS 대 프레임 번호. 우리는 SV3D가 프레임 당 최상의 재구성 메트릭을 가지고 있음을 발견했습니다

**SV3D의 도입**

SV3D는 비디오 확산 모델, 특히 Stable Video Diffusion (SVD) 모델을 기반으로 하며, 명시적인 카메라 포즈 조건을 사용하여 주어진 객체의 다양한 새로운 시점을 생성합니다. 이러한 접근 방식은 대규모 이미지 및 비디오 데이터에 대한 SVD 모델의 우수한 다시점 일관성 및 일반화 능력을 활용합니다.

**SV3D 아키텍처**

SV3D의 구조는 SVD의 U-Net 구조를 기반으로 하며, 여러 층에 걸쳐 있는 3D 컨볼루션 레이어와 변환 블록을 포함합니다. 카메라 포즈와 잡음 시간 단계를 입력으로 사용하여, 비디오 시퀀스의 각 프레임에 대해 시각적으로 일관된 이미지를 생성합니다. SV3D는 카메라 포즈 조건을 사용하여 동적 궤도를 생성할 수 있으며, 이는 객체 주변을 루프 형태로 순환하는 카메라 경로를 의미합니다.

**SV3D의 학습**

SV3D는 Objaverse 데이터셋에서 학습되었으며, 이 데이터셋은 다양한 3D 객체를 포함하고 있습니다. 학습 과정은 576×576 해상도에서 객체 주변을 21개의 프레임으로 렌더링하여 진행됩니다. SV3D 모델은 동적 궤도와 정적 궤도를 모두 처리할 수 있으며, 이는 다양한 시점에서 객체를 포착할 수 있음을 의미합니다.

**실험 및 결과**

SV3D는 GSO 및 OmniObject3D 데이터셋에서의 정적 및 동적 궤도를 통해 평가되었습니다. 다양한 메트릭을 사용하여 생성된 이미지의 품질을 평가하며, SV3D는 다른 최신 NVS 방법들과 비교하여 우수한 성능을 보여주었습니다. 사용자 연구를 통해 실제 세계 이미지에서 생성된 비디오 시퀀스의 선호도도 평가되었습니다. SV3D로 생성된 이미지는 다시점 일관성, 제어 가능성, 그리고 실제 이미지에 대한 일반화 능력을 보여주었습니다.

![새로운 다시점 합성의 시각적 비교. SV3D는 이전 작업들과 비교했을 때, 조건 이미지에 더 충실하고, 다시점 일관성이 있는, 더 상세한 새로운 다시점을 생성할 수 있습니다.](SV3D%20Novel%20Multi-view%20Synthesis%20and%203D%20Generation%20%20df3e40a7d5c04ce189a8af55da1f3e62/Untitled%205.png)

새로운 다시점 합성의 시각적 비교. SV3D는 이전 작업들과 비교했을 때, 조건 이미지에 더 충실하고, 다시점 일관성이 있는, 더 상세한 새로운 다시점을 생성할 수 있습니다.

SV3D 접근 방식은 비디오 확산 모델의 잠재력을 새로운 시점 합성에 적용하여, 단일 이미지에서 다양한 시점을 생성하는 과제에 대한 새로운 솔루션을 제공합니다. 이를 통해, 사용자가 임의의 시점에서 객체를 시각화할 수 있게 하며, 이는 3D 객체 생성 및 시각화 분야에서 중요한 발전을 의미합니다.

### 4. 3D Generation from a Single Image Using SV3D

"3D Generation from a Single Image Using SV3D" 챕터는 SV3D를 사용하여 단일 이미지로부터 3D 객체를 생성하는 방법을 설명합니다. 이 절차는 SV3D의 다시점 합성 기능을 기반으로 하여 고품질의 3D 메시를 직접 생성할 수 있는 방법론을 제시합니다.

**3D 생성 프로세스**

SV3D를 사용한 3D 생성 과정은 크게 두 가지 방식으로 진행됩니다. 첫째는 SV3D에 의해 생성된 정적/동적 궤도 샘플을 직접 재구성 대상으로 사용하는 것이고, 둘째는 SV3D를 확산 가이드로 사용하여 Score Distillation Sampling (SDS) 손실을 적용하는 방법입니다. SV3D에 의해 생성된 이미지들은 다시점 일관성이 우수하기 때문에, 이를 기반으로 한 3D 재구성은 기존 방법보다 높은 품질의 3D 모델을 생성할 수 있습니다.

![3D 최적화 파이프라인. 우리는 두 단계 최적화를 수행합니다. 짧은 첫 번째 단계에서, 우리는 SV3D로 생성된 다시점 이미지로부터 일반적인 형태, 질감, 조명을 추출합니다. 두 번째 단계에서, 우리는 마칭 큐브를 사용하여 메시를 추출하고 DMTet를 사용하여 형태, 질감, 조명을 더욱 최적화합니다. 우리는 SV3D로 생성된 이미지뿐만 아니라 보이지 않는 영역에 대해 부드러운 마스크 SDS 손실을 사용합니다. 점선 빨간 선은 차별화 렌더링 파이프라인으로의 역전파를 나타냅니다.](SV3D%20Novel%20Multi-view%20Synthesis%20and%203D%20Generation%20%20df3e40a7d5c04ce189a8af55da1f3e62/Untitled%206.png)

3D 최적화 파이프라인. 우리는 두 단계 최적화를 수행합니다. 짧은 첫 번째 단계에서, 우리는 SV3D로 생성된 다시점 이미지로부터 일반적인 형태, 질감, 조명을 추출합니다. 두 번째 단계에서, 우리는 마칭 큐브를 사용하여 메시를 추출하고 DMTet를 사용하여 형태, 질감, 조명을 더욱 최적화합니다. 우리는 SV3D로 생성된 이미지뿐만 아니라 보이지 않는 영역에 대해 부드러운 마스크 SDS 손실을 사용합니다. 점선 빨간 선은 차별화 렌더링 파이프라인으로의 역전파를 나타냅니다.

**코스-투-파인 훈련**

3D 메시 생성을 위한 코스-투-파인(coarse-to-fine) 훈련 접근 방식은 먼저 낮은 해상도에서 SV3D로 생성된 이미지를 이용하여 NeRF 표현을 훈련시키고, 이후 DMTet 표현을 사용하여 세밀한 3D 메시를 최적화합니다. 이 과정에서, SDS 기반의 확산 가이드를 사용하여 비가시 영역에서의 3D 품질을 추가로 향상시킬 수 있습니다.

**조명 모델 분리**

조명 효과를 분리하는 것은 실제 조명 변화를 모사하여 3D 메시의 질감을 보다 현실적으로 만들기 위해 중요합니다. SV3D는 일관된 조명 하에서 비디오를 생성하기 때문에, 간단한 조명 모델을 적용하여 이러한 조명 효과를 3D 메시의 질감에서 분리하고, 조명이 객체에 미치는 영향을 최소화합니다.

![일정한 대 SGs 조명. 우리의 SGs 기반 재구성은 버스의 측면에서 어두움을 보이지 않으며, 이는 하류 애플리케이션에 대해 더 쉽고 설득력 있는 재조명을 가능하게 합니다.](SV3D%20Novel%20Multi-view%20Synthesis%20and%203D%20Generation%20%20df3e40a7d5c04ce189a8af55da1f3e62/Untitled%207.png)

일정한 대 SGs 조명. 우리의 SGs 기반 재구성은 버스의 측면에서 어두움을 보이지 않으며, 이는 하류 애플리케이션에 대해 더 쉽고 설득력 있는 재조명을 가능하게 합니다.

**최적화 전략과 손실 함수**

3D 객체의 재구성은 여러 손실 함수를 사용하여 최적화됩니다. 이에는 광도 손실, 마스크 손실, 인지적 손실(LPIPS) 등이 포함되며, 이러한 손실 함수들은 NeRF나 DMTet로 렌더링된 이미지에 적용됩니다. 또한, SDS 손실을 통해 SV3D가 제공하는 확산 가이드를 활용하여 3D 모델의 품질을 추가로 향상시킵니다.

![훈련 궤도의 영향. 우리는 동적 궤도를 사용하는 것이 다양한 시점에서 완전한 3D 생성에 중요함을 보여줍니다.](SV3D%20Novel%20Multi-view%20Synthesis%20and%203D%20Generation%20%20df3e40a7d5c04ce189a8af55da1f3e62/Untitled%208.png)

훈련 궤도의 영향. 우리는 동적 궤도를 사용하는 것이 다양한 시점에서 완전한 3D 생성에 중요함을 보여줍니다.

![. SDS의 영향. 우리의 마스크 SDS 손실을 사용함으로써, 우리는 훈련 궤도에서 보이지 않는 표면을 채워, 순진한 SDS에 의해 발생하는 과포화나 흐릿한 아티팩트 없이 보다 깨끗한 결과를 생성할 수 있습니다.](SV3D%20Novel%20Multi-view%20Synthesis%20and%203D%20Generation%20%20df3e40a7d5c04ce189a8af55da1f3e62/Untitled%209.png)

. SDS의 영향. 우리의 마스크 SDS 손실을 사용함으로써, 우리는 훈련 궤도에서 보이지 않는 표면을 채워, 순진한 SDS에 의해 발생하는 과포화나 흐릿한 아티팩트 없이 보다 깨끗한 결과를 생성할 수 있습니다.

**실험 및 결과**

SV3D를 사용한 3D 생성 방법은 GSO 데이터셋에서 평가되었으며, 다양한 메트릭을 사용하여 생성된 3D 모델의 품질을 측정합니다. 이러한 실험을 통해, SV3D를 사용하는 방식이 다시점 일관성 및 실제 이미지에 대한 일반화 측면에서 기존 방법보다 우수함을 입증합니다. 또한, SV3D를 사용하여 생성된 3D 메시는 복잡한 기하학적 및 질감 세부 사항을 포착할 수 있음을 보여줍니다.

![ 3D 메시의 시각적 비교. 각 객체에 대해, 우리는 조건 이미지(왼쪽)와 두 가지 다른 시점에서 렌더링된 출력 메시를 보여줍니다. 우리가 생성한 메시는 입력 이미지에 더 충실하고, 3D에서 일관성이 있으며, 더 많은 세부 사항을 포함하고 있습니다. 이는 우리의 SV3D 모델에 의한 새로운 다시점 합성의 품질을 입증합니다.](SV3D%20Novel%20Multi-view%20Synthesis%20and%203D%20Generation%20%20df3e40a7d5c04ce189a8af55da1f3e62/Untitled%2010.png)

 3D 메시의 시각적 비교. 각 객체에 대해, 우리는 조건 이미지(왼쪽)와 두 가지 다른 시점에서 렌더링된 출력 메시를 보여줍니다. 우리가 생성한 메시는 입력 이미지에 더 충실하고, 3D에서 일관성이 있으며, 더 많은 세부 사항을 포함하고 있습니다. 이는 우리의 SV3D 모델에 의한 새로운 다시점 합성의 품질을 입증합니다.

![실제 세계 3D 결과. 야외에서 다양한 이미지로부터 우리의 재구성이 정확한 형태와 세부 사항을 보여주는 것을 주목하세요.](SV3D%20Novel%20Multi-view%20Synthesis%20and%203D%20Generation%20%20df3e40a7d5c04ce189a8af55da1f3e62/Untitled%2011.png)

실제 세계 3D 결과. 야외에서 다양한 이미지로부터 우리의 재구성이 정확한 형태와 세부 사항을 보여주는 것을 주목하세요.

**결론**

SV3D를 사용한 3D 생성은 단일 이미지에서 고품질의 3D 객체를 생성할 수 있는 새로운 접근 방법을 제공합니다. 이 방법은 SV3D의 다시점 합성 기능을 활용하여 3D 객체의 일관된 시각화를 가능하게 하며, 고도의 제어 가능성과 일반화 능력을 바탕으로 다양한 실제 및 합성 이미지에 대해 효과적으로 작동합니다.

### 5. Conclusion

SV3D는 단일 이미지에서 3D 객체를 재구성하는 새로운 접근 방법을 제안합니다. 이 모델은 비디오 확산 모델을 활용하여 높은 해상도에서 임의의 카메라 궤도에 대한 다시점 합성을 가능하게 함으로써, 기존에는 해결하기 어려웠던 다양한 도전적인 문제들을 극복합니다. SV3D는 카메라 포즈 조건을 통해 제어 가능하며, 다시점 일관성과 실세계 이미지에 대한 일반화 능력을 갖추고 있어, 최신 기술 대비 우수한 성능을 보입니다.

- **제어 가능성**: SV3D는 사용자가 지정한 카메라 포즈에 따라 다양한 시점에서 객체를 시각화할 수 있게 합니다.
- **다시점 일관성**: 생성된 이미지는 시각적으로 일관되며, 이는 특히 3D 모델링과 같은 응용 분야에서 중요한 특성입니다.
- **일반화 능력**: SV3D는 다양한 실세계 이미지에 대해 효과적으로 작동하며, 이는 광범위한 응용 가능성을 시사합니다.

또한, 논문은 SV3D 모델과 관련된 몇 가지 한계와 미래 연구의 가능성을 탐구합니다. 카메라의 자유도를 확장하고, 반사 표면 같은 특수한 경우를 더 잘 처리하기 위한 방법, 그리고 Lambertian 반사 모델을 넘어서는 조명 및 질감 표현에 대한 연구가 필요함을 언급합니다. 이러한 방향으로의 추가 연구는 SV3D의 적용 범위를 넓히고, 더 다양한 시나리오에서의 사용성을 향상시킬 것으로 기대됩니다.

SV3D는 단일 이미지에서의 3D 객체 생성 분야에 있어 중요한 발전을 나타냅니다. 이는 비디오 확산 모델을 기반으로 한 새로운 다시점 합성 방법론을 통해 제어 가능하고, 다시점 일관성이 뛰어나며, 실세계 이미지에 대해 높은 일반화 능력을 보여줍니다. 논문은 SV3D 모델을 공개할 계획임을 밝히며, 이를 통해 3D 객체 생성 분야에서의 추가 연구와 응용이 활성화될 것으로 기대합니다.