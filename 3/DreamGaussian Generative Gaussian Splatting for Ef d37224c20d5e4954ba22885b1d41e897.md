# DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation

[https://dreamgaussian.github.io/](https://dreamgaussian.github.io/)

[https://github.com/dreamgaussian/dreamgaussian](https://github.com/dreamgaussian/dreamgaussian)

[https://arxiv.org/abs/2309.16653](https://arxiv.org/abs/2309.16653)

- Sep 2023

### 1 INTRODUCTION

![드림가이션은 이미지와 텍스트를 3D로 변환하는 작업의 최적화 프로세스를 가속화하는 것을 목표로 합니다. 몇 분 안에 고품질의 텍스처 메시를 생성할 수 있습니다.](DreamGaussian%20Generative%20Gaussian%20Splatting%20for%20Ef%20d37224c20d5e4954ba22885b1d41e897/Untitled.png)

드림가이션은 이미지와 텍스트를 3D로 변환하는 작업의 최적화 프로세스를 가속화하는 것을 목표로 합니다. 몇 분 안에 고품질의 텍스처 메시를 생성할 수 있습니다.

3D 디지털 콘텐츠를 자동으로 제작할 수 있는 기능은 비디오 게임, 광고, 영화, 그리고 새롭게 떠오르는 메타버스와 같은 분야에 혁신을 불러일으키고 있습니다. 기존에는 이러한 3D 콘텐츠를 제작하려면 숙련된 아티스트가 많은 수작업을 거쳐야 했지만, 이미지에서 3D로, 텍스트에서 3D로 변환하는 등의 최신 기술을 통해 프로세스가 간소화되었습니다. 이 분야의 최근 발전은 2D 콘텐츠 생성의 발전에 영향을 받았으며, 직접 3D 생성 방법과 2D에서 3D로 변환하는 기술의 두 가지 주요 전략으로 분류할 수 있습니다.

직접 3D 생성 기법은 준 앤 니콜 등의 작품에서 언급된 것처럼 3D 에셋을 빠르게 제작할 수 있습니다. 하지만 방대한 3D 데이터 세트에 대한 광범위한 교육이 필요하며, 제작에 노동 집약적이고 다양성과 사실감이 부족한 경우가 많습니다. 반면, 드림퓨전 같은 프로젝트에서 영감을 얻은 2D에서 3D로 변환하는 방법은 2D 모델을 활용하여 다양한 3D 데이터 세트의 부족을 극복합니다. 하지만 이 방식은 데이터 불일치와 같은 문제에 직면하며, 주로 계산 집약적인 신경 방사 필드(NeRF) 렌더링으로 인해 처리하는 데 시간이 오래 걸립니다. 안타깝게도 NeRF 속도를 높이는 기존 기술은 이러한 생성 시나리오에서 제대로 작동하지 않습니다.

이 연구에서는 드림가우시안 프레임워크라는 새로운 접근 방식을 제시합니다. 이 프레임워크는 2D 이미지를 3D 콘텐츠로 변환하는 프로세스를 개선하여 단일 이미지에서 단 2분 만에 사실적인 3D 결과물을 생성합니다. 이러한 효율성은 최적화 프로세스를 간소화하는 기술인 3D 가우시안 스플래팅을 통합하여 달성할 수 있습니다. 특히 이 프레임워크는 기본 3D 모양을 빠르게 생성하고 표준 GPU 하드웨어에서 약 500개의 처리 단계를 거쳐 디테일한 마감을 완성합니다.

이 새로운 방법의 문제점은 데이터 변환 및 처리의 복잡성으로 인해 초기 3D 출력물이 흐릿하게 보일 수 있다는 것입니다. 텍스처와 디테일을 향상시키기 위해 프레임워크에는 텍스처를 명시적으로 다듬는 단계가 포함되어 있습니다. 먼저 흐릿한 출력에서 디테일한 3D 메시를 추출한 다음 UV 공간에서 텍스처 품질을 향상시키는 방식으로 진행됩니다. 디퓨전 기반 이미지 편집 기법에서 영감을 얻은 이 텍스처 개선 프로세스는 이미지 품질을 효율적으로 개선합니다.

### 2 RELATED WORK

3D 표현:

수년에 걸쳐 다양한 작업을 위한 여러 가지 3D 표현이 등장했습니다. 가장 널리 사용되는 것 중 하나는 2D 데이터에서 3D 모델을 생성하기 위해 볼류메트릭 렌더링을 사용하는 신경 방사 필드(NeRF)입니다. 이 기술은 3D 재구성 및 생성에 적용되었습니다. 그러나 NeRF를 최적화하는 것은 오랜 시간이 걸리는 과정이며, 속도를 높이기 위한 노력이 있었지만 주로 재구성을 위한 것이지 생성을 위한 것이 아니었습니다. 새로운 기술인 3D 가우시안 스플래팅은 효율성과 품질로 인해 3D 재구성에서 가능성을 보여주었습니다. 이 연구는 3D 가우시안 스플래팅을 생성 작업에 적용하여 최적화 프로세스를 개선합니다.

텍스트에서 3D로 생성:

텍스트에서 3D 에셋을 생성하는 텍스트-3D 생성은 최근 몇 년 동안 괄목할 만한 발전을 이루었습니다. 2D 확산 모델은 텍스트에서 이미지로 생성하는 데 성공했지만, 이를 3D에 적용하는 데는 대량의 3D 데이터 세트를 확보하기 어렵다는 어려움이 있습니다. 현재의 3D 확산 모델은 특정 오브젝트 유형에 가장 잘 작동하는 제한적인 경향이 있으며 다양성이 부족한 경우가 많습니다. 일부 접근 방식은 2D 모델을 사용하여 3D 생성에 영향을 미침으로써 이를 개선하려고 시도합니다. 이러한 방법은 생성 프로세스의 측면을 개선했지만 일반적으로 최적화 시간이 길어집니다. 이 연구에서는 3D 가우시안(3D Gaussians)을 차별화 가능한 3D 표현으로 선택하여 더 간단하고 효율적인 최적화 환경을 보여줍니다.

이미지에서 3D로 생성:

2D 이미지를 3D 모델로 변환하는 것은 이미지에서 3D로 생성하는 또 다른 흥미로운 영역입니다. 종종 단일 뷰 3D 재구성으로 접근하지만 결과가 흐릿할 수 있습니다. 텍스트 대 3D에 사용되는 일부 방법은 이미지 캡션 모델을 활용하여 이미지 대 3D에도 적용될 수 있습니다. 최근 기술인 0-1-3은 2D 확산 모델에서 카메라 변환을 사용하여 3D 품질을 개선하지만 여전히 시간이 많이 걸립니다. 또 다른 방법인 1-2-3-45는 더 빠른 결과를 제공하지만 품질이 떨어집니다. 반면 이 연구에서는 고품질의 결과물을 유지하면서 이미지에서 3D로 변환하는 시간을 단 2분으로 대폭 단축하는 방법을 제시합니다.

### 3 OUR APPROACH

소개하는 프레임워크는 이미지와 텍스트로 3D 콘텐츠를 효율적으로 제작하는 데 중점을 둡니다. 프로세스는 두 가지 주요 단계로 나뉩니다. 먼저 이 방법은 초기 생성을 위해 3D 가우시안 스플래팅을 통합합니다. 그런 다음 시스템은 3D 가우시안에서 텍스처 메시를 생성합니다. 마지막으로, 이 메시의 텍스처는 익스포트할 준비가 되기 전에 디퍼런셜 렌더링을 통해 다듬어집니다.

![드림가우시안 프레임워크. 3D 가우시안 프레임워크는 단일 단계 SDS 손실을 사용하여 지오메트리와 외관을 효율적으로 초기화하는 데 사용됩니다. 그런 다음 텍스처 메시를 추출하고 다단계 MSE 손실로 텍스처 이미지를 개선합니다.](DreamGaussian%20Generative%20Gaussian%20Splatting%20for%20Ef%20d37224c20d5e4954ba22885b1d41e897/Untitled%201.png)

드림가우시안 프레임워크. 3D 가우시안 프레임워크는 단일 단계 SDS 손실을 사용하여 지오메트리와 외관을 효율적으로 초기화하는 데 사용됩니다. 그런 다음 텍스처 메시를 추출하고 다단계 MSE 손실로 텍스처 이미지를 개선합니다.

제너레이티브 가우시안 스플래팅:

3D 가우시안 스플래팅 기법은 3D 데이터를 묘사하는 데 사용됩니다. 이 방법은 위치, 스케일, 회전, 불투명도, 색상으로 설명되는 3D 가우시안으로 3D 비주얼을 렌더링합니다. 이를 설정하기 위해 구형 도메인 내에서 3D 가우시안 값을 초기화합니다. 최적화하는 동안 가우시안 밀도는 주기적으로 증가합니다. 입력 유형(이미지 또는 텍스트)에 따라 다른 확산 기법이 적용됩니다. 하지만 이렇게 생성된 가우시안에는 디테일이 부족하고 흐릿하게 보일 수 있다는 한 가지 한계가 있습니다.

효율적인 메시 추출:

가우시안에서 3D 메시를 추출하는 것은 어렵고 미개척 분야입니다. 이 문제를 해결하기 위해 블록 단위의 로컬 밀도 쿼리 방법이 제안되었습니다. 이 방법은 3D 공간을 블록으로 나누고 관련 없는 가우시안들을 컬링한 다음, 각 블록 내의 밀도가 높은 그리드에 마칭 큐브 알고리즘을 적용하여 메시를 추출하는 과정을 포함합니다. 렌더링된 이미지의 색상을 메시로 다시 투영하여 메시의 모양이나 질감을 구현합니다.

다각형 메쉬는 3D 표현의 일반적인 형태이며, 특히 산업 분야에서 선호됩니다. 역사적으로 많은 연구자들은 특히 더 높은 해상도에서 미세 조정하기 위해 NeRF(신경 방사 필드) 표현을 이 메시 기반 형식으로 전환하는 데 관심을 기울여 왔습니다. 논의된 작업의 주요 목표는 생성된 3D 가우시안들을 메시로 변환한 후 관련 텍스처를 개선하는 것입니다. 특히 3D 가우시안에서 다각형 메시를 추출하는 이 작업은 거의 미지의 영역으로 남아 있었습니다. 3D 공간은 수많은 가우시안으로 조밀하게 채워져 있기 때문에 이 조밀한 그리드를 쿼리하는 직접 또는 '무차별 대입' 방식은 번거롭고 비효율적일 수 있습니다. 또한 색상 혼합은 본질적으로 투영된 2D 가우시안과 연결되어 있기 때문에 3D 외관을 묘사하는 것도 모호합니다.

제안된 솔루션은 텍스처 메시를 추출하는 효율적인 방법을 개발하여 이 문제를 해결합니다. 이 방법은 주로 두 가지 프로세스를 중심으로 이루어집니다:

- 로컬 밀도 쿼리: 여기서 목표는 3D로 표면을 재구성하는 표준 기법인 마칭 큐브 알고리즘으로 처리할 수 있는 밀도가 높은 그리드를 획득하는 것입니다. 가우시안 스플래팅 메커니즘의 주목할 만한 점은 최적화 단계에서 지나치게 큰 가우시안을 분할하거나 제거할 수 있다는 점입니다. 이를 통해 3D 공간은 163개의 개별 블록으로 분할됩니다. 이 블록에서 중앙에 집중되지 않은 가우시안들은 무시되어 쿼리 프로세스가 최적화됩니다. 그런 다음 각 블록은 8^3 밀도 그리드를 가져와 전체 128^3 밀도 그리드에서 정점을 이룹니다. 유지된 모든 3D 가우시안 불투명도의 가중치가 계산되고 경험적 임계값이 설정됩니다. 마칭 큐브를 사용하여 메시 표면을 추출한 후 메시의 부드러움을 향상시키기 위해 데시메이션과 리메싱을 거칩니다.
- 컬러 백 프로젝션: 메시 지오메트리를 얻었으면 다음 단계는 RGB 컬러 정보를 이 메시 위에 다시 매핑하여 텍스처로 사용할 수 있도록 하는 것입니다. 이를 위해 메시의 UV(텍스처 매핑을 위한 좌표계)를 언래핑하고 초기 빈 텍스처 이미지를 설정합니다. 그런 다음 미리 정해진 여러 시점에서 씬을 렌더링합니다. 이렇게 렌더링된 이미지의 모든 픽셀은 UV 위치에 따라 초기화된 텍스처에 다시 매핑됩니다. 특히 메시 테두리 근처에서 투사 불안정성을 유발할 가능성이 있는 픽셀은 모두 제거됩니다. 이렇게 백 투영된 텍스처는 이후 메시 텍스처 다듬기 단계를 위해 프라이밍됩니다.

UV-공간 텍스처 다듬기:

추출 프로세스에도 불구하고 메시의 텍스처가 흐릿할 수 있습니다. 이를 방지하기 위해 UV 공간에서 리파이닝 단계를 제안합니다. 그러나 직접 리파이닝하면 원치 않는 아티팩트가 발생할 수 있습니다. 따라서 이미지 간 합성 기법을 사용하여 흐릿한 텍스처를 렌더링하고 노이즈로 교란한 다음 확산 기법을 사용하여 노이즈를 제거합니다. 이렇게 정제된 이미지는 원본 메시 텍스처를 미세 조정하는 데 사용되어 선명도와 디테일이 향상됩니다.

![다양한 텍스처 미세 조정 목표. SDS 손실은 UV 공간 텍스처 최적화를 위한 아티팩트를 생성하는 반면, 제안된 MSE 손실은 이를 방지한다는 것을 보여줍니다.](DreamGaussian%20Generative%20Gaussian%20Splatting%20for%20Ef%20d37224c20d5e4954ba22885b1d41e897/Untitled%202.png)

다양한 텍스처 미세 조정 목표. SDS 손실은 UV 공간 텍스처 최적화를 위한 아티팩트를 생성하는 반면, 제안된 MSE 손실은 이를 방지한다는 것을 보여줍니다.

요약하면, 이 프레임워크는 이미지와 텍스트로부터 3D 콘텐츠를 생성하기 위한 종합적인 솔루션을 제공합니다. 초기 생성을 위해 가우시안 스플래팅을 효율적으로 통합하고, 텍스처 메시를 추출하고, 텍스처를 개선하여 선명도를 높입니다.

### **4 EXPERIMENTS**

4.1 구현 세부 사항:

연구의 초기 단계에는 500개의 훈련 단계가 포함되었고, 이후 단계에서는 50개의 훈련 단계가 포함되었습니다. 3D 가우시안 초기화, 렌더링 해상도, 무작위 샘플링 프로세스에 대한 파라미터가 설정되었습니다. RGB 및 투명도와 같은 다양한 가중치는 훈련 중에 선형적으로 증가했습니다. 카메라 포즈도 고정된 파라미터로 샘플링하고 배경 설정도 세밀하게 조정했습니다. 이미지에서 3D로, 텍스트에서 3D로 작업하는 데 걸린 시간은 각 단계당 각각 1분, 2분이었습니다. 입력된 이미지는 배경을 제거하고 전경 물체의 중심을 다시 조정하는 방식으로 처리되었습니다. 또한 메시 추출에는 마칭 큐브(Marching Cubes)라는 방법이 사용되었습니다. 모든 실험에는 8GB 미만의 메모리를 소비하는 NVIDIA V100 GPU가 사용되었습니다. 자세한 내용은 보충 자료에서 확인할 수 있습니다.

4.2 정성적 비교:

이 연구에서는 제안된 이미지-3D 방식을 세 가지 기준 접근 방식과 비교했습니다. 생성된 모델은 다각형 메시 구조를 기반으로 평가하고 주변 조명 아래에서 렌더링했습니다. 특히 제안된 방법은 생성 품질과 속도 간에 균형을 이루었으며, 3D 지오메트리 및 외관 충실도 측면에서 추론만 사용하는 접근 방식보다 더 나은 성능을 보였습니다. 이러한 경향은 텍스트에서 3D로 변환하는 작업에서도 나타났습니다. 익스포트된 메시의 품질이 강조되어 리깅 및 애니메이션과 같은 애플리케이션에 대한 적합성이 강조되었습니다.

![이미지 대 3D 비교. 우리의 방법은 다양한 이미지에서 생성 속도와 메시 품질 간에 더 나은 균형을 이룹니다.](DreamGaussian%20Generative%20Gaussian%20Splatting%20for%20Ef%20d37224c20d5e4954ba22885b1d41e897/Untitled%203.png)

이미지 대 3D 비교. 우리의 방법은 다양한 이미지에서 생성 속도와 메시 품질 간에 더 나은 균형을 이룹니다.

![텍스트 대 3D 비교. 드림퓨전에서는 2D 선행으로 안정적 확산을 사용하는 Guo et al.(2023)의 구현을 사용합니다.](DreamGaussian%20Generative%20Gaussian%20Splatting%20for%20Ef%20d37224c20d5e4954ba22885b1d41e897/Untitled%204.png)

텍스트 대 3D 비교. 드림퓨전에서는 2D 선행으로 안정적 확산을 사용하는 Guo et al.(2023)의 구현을 사용합니다.

![메시 익스포트. 3D 가우시안에서 고품질 텍스처 메시를 익스포트하여 리깅된 애니메이션과 같은 다운스트림 애플리케이션에서 원활하게 사용할 수 있습니다.](DreamGaussian%20Generative%20Gaussian%20Splatting%20for%20Ef%20d37224c20d5e4954ba22885b1d41e897/Untitled%205.png)

메시 익스포트. 3D 가우시안에서 고품질 텍스처 메시를 익스포트하여 리깅된 애니메이션과 같은 다운스트림 애플리케이션에서 원활하게 사용할 수 있습니다.

4.3 정량적 비교:

이 연구에서는 다양한 이미지에서 3D로 변환하는 방법에 대한 클립 유사성 점수 및 생성 시간 메트릭을 포함한 정량적 결과를 표 1에 제시했습니다. 표 2에 자세히 설명된 사용자 연구에서는 생성된 모델의 품질을 평가했습니다. 2단계 프로세스는 뷰 일관성 및 생성 품질에서 추론 전용 방법보다 우수한 성능을 보였습니다. 그러나 메시 품질은 다른 최적화 기반 기법에 비해 약간 뒤처졌지만 속도는 10배 이상 빨라졌습니다.

![제거 연구. 1단계 훈련에서 디자인 선택 사항을 제거합니다.](DreamGaussian%20Generative%20Gaussian%20Splatting%20for%20Ef%20d37224c20d5e4954ba22885b1d41e897/Untitled%206.png)

제거 연구. 1단계 훈련에서 디자인 선택 사항을 제거합니다.

4.4 제거 연구:

주로 생성 가우시안 스플래팅 훈련 측면에 초점을 맞춘 제거 연구를 수행했습니다. 3D 가우시안 주기적 밀도화, SDS 손실에 대한 타임스텝의 선형 어닐링, 레퍼런스 뷰 손실 LRef의 영향 등 세 가지 요소를 분석했습니다. 분석 결과, 이러한 요소 중 하나라도 무시하면 초기 단계에서 생성된 모델의 품질이 저하되어 미세 조정 단계에 영향을 미치는 흐릿하고 부정확한 결과를 초래하는 것으로 나타났습니다.

### **5 LIMITATIONS AND CONCLUSION**

본 연구에서는 3D 콘텐츠 제작 프로세스를 개선하기 위해 설계된 혁신적인 3D 콘텐츠 생성 프레임워크인 '드림가우션'을 소개합니다. 유니티의 접근 방식은 세 가지 핵심 요소에 기반을 두고 있습니다. 첫째, 가우시안 스플래팅 파이프라인을 구축하여 3D 콘텐츠 생성의 효율성을 높였습니다. 둘째, 효과적인 메시 추출 기법을 도입하여 3D 가우시안 메시를 텍스처 메시로 변환할 수 있도록 했습니다. 마지막으로 텍스처 정제 단계를 통해 단일 이미지 또는 텍스트 설명을 즉시 사용할 수 있는 고품질 3D 에셋으로 변환하여 단 몇 분 만에 이 모든 과정을 완료할 수 있습니다.

우리의 프레임워크는 다양한 이점을 제공하지만 한계도 있습니다. 이전의 텍스트-3D 모델과 마찬가지로 멀티페이스 야누스 문제와 구운 조명 문제가 발생합니다. 하지만 최근 멀티뷰 2D 확산 모델과 잠재적인 BRDF 자동 인코더가 개발되어 잠재적인 해결책을 제시하고 있다는 사실에 위안을 삼을 수 있습니다. 또한 이미지에서 3D로 변환하는 과정에서 다소 흐릿하게 보이는 백뷰 텍스처가 생성되는 사소한 결함이 있습니다. 이 문제를 해결할 수 있는 방법은 두 번째 단계에서 훈련 기간을 늘리는 것입니다.