# BlazeFace: Sub-millisecond Neural Face Detection on Mobile GPUs

*이 논문에서는 모바일 기기에서 실시간 얼굴 검출에 적합한 가벼운 신경망 아키텍처인 BlazeFace를 제시하고 있습니다. BlazeFace는 효과적으로 얼교과 관련된 컴퓨터 비전 응용 프로그램의 첫 단계로 작용하며, 향후 작업에 필요한 얼굴의 위치와 방향을 추정하고 출력합니다.*

*주요 설계 고려사항은 BlazeBlock라는 특정 구조를 활용하는 것이며, 이 구조는 신경망의 병목 현상을 줄이고 이동 및 회전 불변성을 개선합니다. 이 모델은 입력 이미지에서 더 큰 수용 필드를 확보하고, 처리 시간을 줄이기 위해 5x5 커널을 사용합니다.*

*또한, 얼굴 검출에 효과적인 앵커 체계를 도입하였으며, 이는 얼굴의 크기와 비율이 비교적 일정하기 때문에 가능하였습니다. 이렇게 생성된 결과는 비디오 프레임 간의 얼굴 위치 변화를 최소화하는 데 사용됩니다.*

*다양한 모바일 기기에서의 성능 실험 결과, BlazeFace는 기존 모델에 비해 더 높은 정확도를 보였으며, 추론 시간은 대폭 감소하였습니다. 이러한 성능 향상은 AR 어플리케이션과 모바일 기기의 AR 개발자 API에 크게 기여하였습니다.*

[https://arxiv.org/abs/1907.05047](https://arxiv.org/abs/1907.05047)

- Jul 2019

### 1. Introduction

이 백서에서는 싱글 샷 멀티박스 검출기(SSD) 모델을 기반으로 모바일 GPU에 최적화된 새로운 얼굴 감지 프레임워크인 BlazeFace를 소개합니다. 이 프레임워크의 목표는 모바일 애플리케이션의 비디오 처리에서 중요한 첫 단계인 실시간 물체 감지를 용이하게 하는 것입니다.

이 연구의 주요 기여는 크게 두 가지입니다:

추론 속도 향상:

저자들은 가벼운 객체 감지를 위해 특별히 설계된 MobileNetV1/V2와 유사한 구조의 소형 특징 추출기를 제안합니다. 이를 통해 정확도를 크게 떨어뜨리지 않으면서도 물체를 더 빠르게 감지할 수 있습니다.
새로운 GPU 친화적인 앵커 방식이 도입되었습니다. 앵커 또는 선행은 네트워크 예측의 기초를 형성하는 사전 정의된 정적 바운딩 박스입니다. 저자들의 새로운 방식은 GPU를 보다 효과적으로 사용하기 위한 것입니다.
예측 품질 개선:

저자는 비최대 억제에 대한 대안적인 동점 해결 전략을 도입하여 겹치는 예측을 보다 안정적이고 부드럽게 해결합니다. 즉, 이미지에서 여러 개의 가능한 물체가 감지될 때 시스템이 어떤 것이 가장 정확한 감지인지 판단하는 방법이 개선되었습니다.
블레이즈페이스는 표준 실시간 벤치마크를 뛰어넘는 우수한 성능을 제공하는 것을 목표로 하며, 특히 세분화, 추적 또는 지오메트리 추론과 같은 애플리케이션에 유용합니다.

### 2. Face detection for AR pipelines

이 연구 논문은 휴대폰 카메라의 뷰파인더에서 얼굴을 감지하기 위해 제안된 BlazeFace 프레임워크의 적용에 특히 중점을 두고 있습니다. 전면 카메라와 후면 카메라의 서로 다른 초점 거리와 캡처되는 물체의 일반적인 크기를 고려하기 위해 별도의 모델이 개발되었습니다.

블레이즈페이스는 축에 맞춰 정렬된 얼굴 직사각형을 예측하는 것 외에도 눈의 중심, 귓바퀴, 입의 중심, 코끝 등 6개의 얼굴 키포인트도 식별합니다. 이 정보는 얼굴의 회전(롤 각도)을 추정하는 데 사용할 수 있습니다. 결과적으로 회전된 얼굴 직사각형을 비디오 처리 파이프라인의 후속 단계로 전달할 수 있으므로 이후 처리 단계에서 광범위한 번역 및 회전 불변성의 필요성을 줄일 수 있습니다. 이 기능은 다른 애플리케이션 중에서도 증강 현실(AR) 파이프라인의 작업을 크게 최적화할 수 있습니다.

### 3. Model architecture and design

BlazeFace 모델 아키텍처는 네 가지 주요 설계 고려 사항을 기반으로 구성됩니다:

수신 필드 크기: 연구원들은 대부분의 최신 컨볼루션 신경망 아키텍처가 3x3 컨볼루션 커널을 선호하지만, 깊이로 분리 가능한 컨볼루션 계산은 점 단위로 이뤄진다는 점에 주목했습니다. 블레이즈페이스 모델은 더 큰 5x5 커널을 사용하여 특정 수용 필드 크기에 필요한 총 병목 현상을 줄입니다.

![BlazeBlock (왼쪽) 및 더블 BlazeBlock](BlazeFace%20Sub-millisecond%20Neural%20Face%20Detection%20on%20c55664de6d4b46d9b93be57ccc5fdb3d/Untitled.png)

BlazeBlock (왼쪽) 및 더블 BlazeBlock

![앵커 계산: SSD (왼쪽) vs. BlazeFace](BlazeFace%20Sub-millisecond%20Neural%20Face%20Detection%20on%20c55664de6d4b46d9b93be57ccc5fdb3d/Untitled%201.png)

앵커 계산: SSD (왼쪽) vs. BlazeFace

모델 아키텍처 병목 현상: 블레이즈페이스 모델에서 연구원들은 모바일넷V2에서 볼 수 있는 깊이 증가 및 깊이 감소 단계의 순서를 바꿨습니다. 이 수정은 중간 텐서에서 더 적은 수의 채널을 처리하는 데 도움이 됩니다. 또한 이 모델은 수신 필드 크기 진행을 가속화하기 위해 추가적인 깊이별 컨볼루션 레이어를 도입하여 BlazeFace의 상위 추상화 레이어에 선호되는 병목 현상인 이중 BlazeBlock을 생성합니다.

특징 추출기: 이 모델은 전면 카메라 모델에 고유한 특징 추출기를 사용합니다. 128x128 RGB 입력을 처리하는 이 특징 추출기는 2D 컨볼루션과 5개의 단일 및 6개의 더블 블레이즈블록으로 구성됩니다. 가장 높은 텐서 깊이는 96이고 가장 낮은 공간 해상도는 8x8입니다.

앵커 방식: 블레이즈페이스는 앵커라고 하는 사전 정의된 고정 크기의 기본 바운딩 박스가 있는 SSD와 유사한 객체 감지 모델을 사용합니다. 앵커는 중앙 오프셋 및 치수 조정과 같은 예측된 회귀 매개 변수를 사용하여 좁은 경계 사각형에 맞도록 조정됩니다. BlazeFace 앵커 방식은 8x8 피처 맵 크기에서 멈추고, 8x8, 4x4 및 2x2 해상도 각각에서 픽셀당 2개의 앵커를 8x8에서 6개의 앵커로 대체합니다.

후처리: 이 모델은 비최대 억제 알고리즘을 바운딩 박스의 회귀 파라미터를 겹치는 예측 간의 가중 평균으로 추정하는 블렌딩 전략으로 대체합니다. 이렇게 하면 시간적 지터가 감소하고 얼굴 감지 작업의 정확도가 10% 향상됩니다. 지터의 양은 동일한 입력 이미지의 약간 오프셋된 여러 버전을 네트워크에 전달하고 모델 결과를 관찰하여 정량화했습니다. 이 수정 후 지터 메트릭은 정면 카메라 데이터 세트에서 40%, 작은 얼굴이 포함된 후방 카메라 데이터 세트에서 30% 감소했습니다.

### 4. Experiments

연구진은 66K 이미지로 구성된 훈련 데이터 세트를 사용하여 실험을 수행하고 지리적으로 다양한 2K 이미지 데이터 세트에서 모델을 평가했습니다. 전면 카메라 모델의 경우 이미지 영역의 20% 이상을 차지하는 얼굴만 고려했습니다(후면 카메라 모델의 경우 5%).

안구 간 거리(IOD)로 정규화된 회귀 매개변수 오류를 측정한 결과, 절대 오류의 중앙값은 IOD의 7.4%로 나타났습니다. 앞서 설명한 대로 평가한 지터 메트릭은 IOD의 3%였습니다.

표 1은 동일한 앵커 코딩 체계를 사용하는 MobileNetV2 기반 객체 감지기와 비교한 정면 카메라 얼굴 감지 작업에서 모델의 성능을 보여줍니다. 제안된 블레이즈페이스 모델은 iPhone XS에서 평균 98.61%의 정밀도와 0.6밀리초의 모바일 GPU 추론 시간을 달성하여 MobileNetV2-SSD의 성능을 뛰어넘었습니다.

표 2는 다양한 플래그십 디바이스에서 두 네트워크 모델에 대한 GPU 추론 속도에 대한 정보를 제공합니다. 블레이즈페이스는 애플 아이폰 7, 애플 아이폰 XS, 구글 픽셀 3, 화웨이 P20, 삼성 갤럭시 S9+를 포함한 모든 테스트 기기에서 일관되게 빠른 추론 시간을 보였습니다.

표 3은 모델 크기가 작을수록 회귀 파라미터 예측 품질에 미치는 영향을 보여줍니다. 블레이즈페이스는 모바일넷V2-SSD에 비해 회귀 오류와 지터 지표가 더 높지만, 전체 AR 파이프라인의 품질이 비례적으로 저하되는 것은 아닙니다.

### 5. Applications

블레이즈페이스 모델은 거의 모든 얼굴 관련 컴퓨터 비전 애플리케이션의 기반이 될 수 있습니다. 여기에는 2D/3D 얼굴 키포인트, 윤곽 또는 표면 지오메트리 추정, 얼굴 특징 또는 표정 분류, 얼굴 영역 분할 등이 포함됩니다. 따라서 컴퓨터 비전 파이프라인의 다음 단계는 정확한 얼굴 크롭의 관점에서 정의할 수 있습니다. 블레이즈페이스가 제공하는 얼굴 키포인트 추정치와 함께 이 크롭은 얼굴이 중앙에 위치하도록 회전하고, 스케일을 정규화하며, 롤 각도가 0에 가까워지도록 회전할 수도 있습니다. 이렇게 하면 작업별 모델에서 상당한 변환 및 회전 불변성의 필요성이 줄어들어 계산 리소스를 더 효율적으로 할당할 수 있습니다.

![파이프라인 예시 (색상으로 보는 것이 가장 좋음).빨강: BlazeFace 출력. 초록:작업 특정 모델 출력.](BlazeFace%20Sub-millisecond%20Neural%20Face%20Detection%20on%20c55664de6d4b46d9b93be57ccc5fdb3d/Untitled%202.png)

파이프라인 예시 (색상으로 보는 것이 가장 좋음).빨강: BlazeFace 출력. 초록:작업 특정 모델 출력.

이 접근법의 한 가지 구체적인 응용 분야는 얼굴 윤곽 추정입니다. 연구진은 블레이즈페이스의 출력, 즉 예측된 바운딩 박스와 얼굴의 6개의 키포인트가 약간 확장된 크롭에 적용된 더 복잡한 얼굴 윤곽 추정 모델에 의해 어떻게 더 세분화되는지 보여줍니다. 이러한 세부 키포인트는 얼굴 감지기를 다시 실행하지 않고도 다음 프레임에서 추적에 재사용할 수 있는 보다 정밀한 바운딩 박스 추정치를 제공합니다.

또한 윤곽 모델은 얼굴이 실제로 존재하고 제공된 직사각형 크롭에 합리적으로 정렬되어 있는지 평가하여 이 계산 절약 전략의 실패를 감지하는 데 도움을 줍니다. 이러한 조건이 충족되지 않으면 블레이즈페이스 얼굴 감지기는 전체 비디오 프레임에 대해 다시 실행됩니다.

이 백서에 설명된 기술은 현재 휴대폰의 주요 AR 셀프 표현 애플리케이션과 AR 개발자 API를 구동하고 있습니다.

- 모델의 입력과 출력
    
    BlazeFace 모델의 입력과 출력은 다음과 같습니다:
    
    입력: BlazeFace 모델의 입력은 모바일 카메라로 캡처된 RGB 이미지입니다. 프론트 카메라 모델을 위한 특정 예시에서는, 이 모델은 128x128 픽셀의 RGB 이미지를 입력으로 사용합니다.
    
    출력: BlazeFace 모델은 다음의 두 가지 정보를 출력합니다.
    
    1. 얼굴 직사각형: 이는 이미지에서 얼굴 위치를 표시하는 경계 상자입니다. 이것은 이미지나 비디오 프레임의 얼굴을 감지하는 데 사용됩니다.
    2. 페이셜 키포인트 좌표: 이는 눈 중심, 귀 트라기온, 입 중심, 그리고 코 끝 등의 6개 페이셜 키포인트의 좌표입니다. 이 정보는 얼굴 회전(롤 각도)을 추정하는 데 사용되며, 이를 통해 후속 작업 특정 단계로 회전된 얼굴 직사각형을 전달할 수 있습니다. 이는 후속 처리 단계에서의 상당한 변환과 회전 불변성 요구를 줄여줍니다.
- 의의
    
    BlazeFace는 기존의 얼굴 검출 방법들과 다음과 같은 주요 차별점을 가지고 있습니다.
    
    1. **경량화된 아키텍처**: BlazeFace는 MobileNetV2 등의 기존 모델에 비해 훨씬 가볍습니다. 이는 특히 모바일 기기에서의 실시간 얼굴 검출에 필수적인 조건입니다. 이를 통해 모델은 높은 정확도를 유지하면서도 빠른 추론 시간을 보장합니다.
    2. **변경된 앵커 체계**: BlazeFace는 표준 SSD 방식과는 다르게 8x8 피쳐 맵까지만 다운샘플링하며, 사람 얼굴의 종횡비가 일정하다는 점을 활용하여 효과적인 앵커 체계를 제안하고 있습니다. 이로써 계산 과정을 최적화하면서도 높은 검출 성능을 유지할 수 있습니다.
    3. **회전된 얼굴 사각형의 예측**: BlazeFace는 축 정렬된 얼굴 사각형뿐만 아니라 6개의 얼굴 키포인트 좌표를 예측하여 얼굴의 회전(roll angle)을 추정합니다. 이로 인해 후속 작업에 대한 변환과 회전 불변성 요구사항이 감소됩니다.
    4. **안정적인 출력**: BlazeFace는 일반적인 non-maximum suppression 방식 대신 더욱 안정적인 blending 전략을 사용하여 잡음을 줄입니다. 이로 인해 시간에 따른 예측의 변동성을 줄이고, 비디오 프레임 간의 얼굴 위치의 일관성을 유지할 수 있습니다.
    5. **다양한 AR 응용 프로그램으로의 활용성**: BlazeFace의 출력은 얼굴 관련 컴퓨터 비전 응용 프로그램의 첫 단계로 사용될 수 있으며, 추후의 작업은 적절한 얼굴 crop에 따라 정의될 수 있습니다. 이를 통해, 다양한 AR 응용 프로그램과 모바일 기기의 AR 개발자 API에 활용될 수 있습니다.