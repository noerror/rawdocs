# DeepFashion2: A Versatile Benchmark for Detection, Pose Estimation, Segmentation and Re-Identification of Clothing Images

[https://arxiv.org/abs/1901.07973](https://arxiv.org/abs/1901.07973)

[https://github.com/switchablenorms/DeepFashion2](https://github.com/switchablenorms/DeepFashion2)

- Jan 2019

![Untitled](DeepFashion2%20A%20Versatile%20Benchmark%20for%20Detection,%20%20ca5951a918ca413bb8f327537bf61f54/Untitled.png)

### 1. Introduction

이 논문에서는 패션 이미지 분석을 위한 새롭고 포괄적인 데이터 세트인 DeepFashion2를 소개하며, 이 분야의 다양한 과제를 해결하기 위해 노력하고 있습니다. DeepFashion과 같은 기존 데이터 세트는 이미지당 의류 아이템이 하나뿐이고, 랜드마크 정의가 희박하며, 픽셀당 마스크 주석이 없어 개발된 모델을 실제 적용하는 데 어려움을 겪는 등 몇 가지 한계가 있었습니다.

![(a) DeepFashion과 (b) DeepFashion2 사이의 비교. (a)는 이미지 당 단일 항목만 가지며, 4 ~ 8개의 희소한 랜드마크로 주석 처리되어 있습니다. 경계 상자는 표시된 랜드마크로부터 추정되어 노이즈가 있습니다. (b)에서는 각 이미지가 최소한 하나의 항목을 가지며, 최대 7개의 항목을 가집니다. 각 항목은 경계 상자, 마스크, 밀집 랜드마크(평균적으로 항목 당 20개), 그리고 상업-고객 이미지 쌍으로 수동으로 주석 처리됩니다.](DeepFashion2%20A%20Versatile%20Benchmark%20for%20Detection,%20%20ca5951a918ca413bb8f327537bf61f54/Untitled%201.png)

(a) DeepFashion과 (b) DeepFashion2 사이의 비교. (a)는 이미지 당 단일 항목만 가지며, 4 ~ 8개의 희소한 랜드마크로 주석 처리되어 있습니다. 경계 상자는 표시된 랜드마크로부터 추정되어 노이즈가 있습니다. (b)에서는 각 이미지가 최소한 하나의 항목을 가지며, 최대 7개의 항목을 가집니다. 각 항목은 경계 상자, 마스크, 밀집 랜드마크(평균적으로 항목 당 20개), 그리고 상업-고객 이미지 쌍으로 수동으로 주석 처리됩니다.

반면, DeepFashion2는 13개의 인기 의류 카테고리에 걸쳐 49만 1천 개의 이미지로 구성되어 있으며, 의류 감지 및 인식, 랜드마크 및 포즈 추정, 분할, 검증, 검색과 같은 작업을 지원하는 풍부한 주석을 포함하고 있습니다. 이러한 이미지는 43.8K 개의 의류 아이덴티티(비슷한 재단, 패턴, 디자인을 가진 의류)로 그룹화할 수 있으며, 801K 개의 의류 항목으로 구성되어 있으며, 각 항목에는 배율, 오클루전, 확대/축소, 시점, 경계 상자, 고밀도 랜드마크 및 픽셀당 마스크가 레이블로 지정되어 있습니다. 또한 이 데이터 세트에는 고객과 상업용 쇼핑 매장의 이미지가 모두 포함되어 있으며, 이전 데이터 세트인 DeepFashion보다 3.5배 더 큰 쌍을 이룹니다.

이 논문은 세 가지 주요 공헌을 제시합니다. 첫째, 패션 이미지 분석을 위한 포괄적인 주석과 작업으로 기존 데이터세트를 훨씬 능가하는 대규모 벤치마크를 만들었습니다. 둘째, 제안된 데이터 세트에 업계 최초의 의류 포즈 추정 작업을 포함한 전체 작업 스펙트럼을 정의했습니다. 마지막으로, 시각 인식을 위한 최신 고급 프레임워크인 마스크 R-CNN을 평가하고 의류 카테고리, 포즈, 마스크의 특징을 통합하여 의류 이미지 검색을 개선하는 새로운 매치 R-CNN을 제안합니다.

딥패션2와 매치 R-CNN의 구현은 공개적으로 사용할 수 있습니다. 이 데이터 세트는 다양한 작업에 대한 벤치마크와 프레임워크를 통합하여 패션 이미지 분석 분야의 연구자와 개발자에게 종합적인 도구를 제공하는 것을 목표로 합니다.

### 2. DeepFashion2 Dataset and Benchmark

패션을 이해하는 다양한 작업을 위해 설계된 데이터 세트인 DeepFashion2는 샘플 크기, 활용성, 표현력, 다양성 측면에서 기존 패션 데이터 세트를 능가합니다.

![DeepFashion2의 예시. 첫 번째 열은 네 가지 카테고리의 밀집 랜드마크와 스켈레톤의 정의를 보여줍니다. (1)부터 (4)까지, 각 행은 'scale', 'occlusion', 'zoom-in', 그리고 'viewpoint'를 포함한 다양한 변형을 가진 옷 이미지를 나타냅니다. 각 행에서 이미지를 두 그룹으로 나누며, 왼쪽 세 열은 상업용 매장에서 온 옷을 나타내고, 오른쪽 세 열은 고객으로부터 온 것입니다. 각 그룹에서 세 이미지는 해당 변형에 대한 세 가지 난이도 수준을 나타내며, 이에는 (1) 'small', 'moderate', 'large' scale, (2) 'slight', 'medium', 'heavy' occlusion, (3) 'no', 'medium', 'large' zoom-in, (4) 'not on human', 'side', 'back' viewpoint가 포함됩니다. 또한, 각 행에서, 이 두 그룹의 이미지 내의 항목은 같은 옷의 신원에서 오지만, 두 가지 다른 도메인, 즉 상업적인 것과 고객으로부터 오는 것입니다. 같은 신원의 항목은 색상과 인쇄와 같은 다른 스타일을 가질 수 있습니다. 각 항목은 랜드마크와 마스크로 주석 처리됩니다.](DeepFashion2%20A%20Versatile%20Benchmark%20for%20Detection,%20%20ca5951a918ca413bb8f327537bf61f54/Untitled%202.png)

DeepFashion2의 예시. 첫 번째 열은 네 가지 카테고리의 밀집 랜드마크와 스켈레톤의 정의를 보여줍니다. (1)부터 (4)까지, 각 행은 'scale', 'occlusion', 'zoom-in', 그리고 'viewpoint'를 포함한 다양한 변형을 가진 옷 이미지를 나타냅니다. 각 행에서 이미지를 두 그룹으로 나누며, 왼쪽 세 열은 상업용 매장에서 온 옷을 나타내고, 오른쪽 세 열은 고객으로부터 온 것입니다. 각 그룹에서 세 이미지는 해당 변형에 대한 세 가지 난이도 수준을 나타내며, 이에는 (1) 'small', 'moderate', 'large' scale, (2) 'slight', 'medium', 'heavy' occlusion, (3) 'no', 'medium', 'large' zoom-in, (4) 'not on human', 'side', 'back' viewpoint가 포함됩니다. 또한, 각 행에서, 이 두 그룹의 이미지 내의 항목은 같은 옷의 신원에서 오지만, 두 가지 다른 도메인, 즉 상업적인 것과 고객으로부터 오는 것입니다. 같은 신원의 항목은 색상과 인쇄와 같은 다른 스타일을 가질 수 있습니다. 각 항목은 랜드마크와 마스크로 주석 처리됩니다.

대규모 샘플 크기: 이 데이터 세트에는 43.8K 개의 의류 아이덴티티를 나타내는 491K 개의 이미지가 포함되어 있으며, 각 아이덴티티에는 다양한 스타일의 평균 12.7개의 아이템이 포함되어 있습니다. 총 80만 1천 개의 아이템이 각기 다른 주석과 연결되어 있어, DeepFashion2는 현재까지 가장 큰 규모의 패션 데이터베이스입니다.

다양성: 데이터 세트 내의 풍부한 주석은 의류 감지 및 분류, 고밀도 랜드마크 및 포즈 추정, 인스턴스 세분화, 교차 도메인 인스턴스 수준 의류 검색 등 다양한 작업을 지원합니다.

표현력: 각 이미지에 최대 하나의 항목만 포함되는 DeepFashion 데이터 세트와 달리, DeepFashion2는 단일 이미지에 여러 항목을 포함할 수 있습니다. 또한 13가지 카테고리에 대해 13가지 랜드마크와 포즈에 대한 다양한 정의를 제공합니다. 각 카테고리당 평균 23개의 랜드마크가 정의되어 있습니다.

다양성: 딥패션2는 까다로운 벤치마크를 위해 스케일, 오클루전, 줌인, 시점의 네 가지 속성의 변형을 고려하여 데이터 세트를 수집합니다. 각 의류 아이템은 이러한 속성에 따라 세 가지 난이도 수준 중 하나에 할당됩니다.

DeepFashion2의 원시 데이터는 두 가지 소스에서 수집됩니다: DeepFashion과 온라인 쇼핑 웹사이트입니다. 데이터를 정리하기 위해 소비자가 직접 촬영한 사진이 없는 이미지와 오클루전이 크거나 축척이 작고 해상도가 낮은 이미지가 제거됩니다. 최종 데이터 세트에는 49만1천 개의 이미지, 80만1천 개의 상품, 87만3천 개의 상업-소비자 쌍이 포함됩니다.

![(a)는 DeepFashion2의 다양한 변형의 통계를 보여줍니다. (b)는 DeepFashion2의 13개 카테고리의 항목 수입니다. (c)는 DeepFashion [14]의 카테고리가 모호함을 보여줍니다. 예를 들어, 'cardigan'과 'coat', 그리고 'joggers'와 'sweatpants'를 구분하는 것이 어렵습니다. 그들은 데이터 라벨링 시 모호성을 초래합니다. (d) 위: 복잡한 자세가 표현될 때 마스크가 부정확할 수 있습니다. 아래: 마스크는 사람에 의해 개선될 것입니다.](DeepFashion2%20A%20Versatile%20Benchmark%20for%20Detection,%20%20ca5951a918ca413bb8f327537bf61f54/Untitled%203.png)

(a)는 DeepFashion2의 다양한 변형의 통계를 보여줍니다. (b)는 DeepFashion2의 13개 카테고리의 항목 수입니다. (c)는 DeepFashion [14]의 카테고리가 모호함을 보여줍니다. 예를 들어, 'cardigan'과 'coat', 그리고 'joggers'와 'sweatpants'를 구분하는 것이 어렵습니다. 그들은 데이터 라벨링 시 모호성을 초래합니다. (d) 위: 복잡한 자세가 표현될 때 마스크가 부정확할 수 있습니다. 아래: 마스크는 사람에 의해 개선될 것입니다.

스케일, 오클루전, 줌인, 시점의 측면에서 변형을 설명합니다. 50%의 상품만이 중간 정도의 스케일을 가지고 있고, 50% 이상의 상품이 중간 또는 무거운 오클루전을 가지고 있으며, 30% 이상의 상품이 확대되어 있고, 78%의 옷이 정면 시점의 사람 위에 놓여 있습니다. 이러한 변형으로 인해 데이터 세트는 패션 이미지 분석 분야에서 강력한 모델 개발을 위한 풍부한 리소스가 됩니다.

DeepFashion2 데이터 세트는 패션 이해의 여러 작업에서 벤치마킹에 사용할 수 있도록 꼼꼼하게 레이블이 지정되고 구조화되어 있습니다.

2.1. 데이터 라벨링:
데이터 세트 라벨링 프로세스는 몇 가지 주요 단계로 구성됩니다:

- 카테고리 및 바운딩 박스: 어노테이터는 각 의류 항목 주위에 경계 상자를 그리고 카테고리 레이블을 할당합니다. 이 프로세스는 모호함 없이 13개의 인기 카테고리를 포함하도록 DeepFashion에서 개선되었습니다.
- 옷 랜드마크, 윤곽선, 골격: 각 의류 항목에 대해 어노테이터는 옷의 포즈, 모양, 구조를 나타내는 랜드마크에 라벨을 지정합니다. 이러한 랜드마크는 '표시됨' 또는 '가려짐'으로 분류되며 윤곽과 골격을 자동으로 생성하도록 연결됩니다. 랜드마크는 윤곽점 또는 교차점으로 더 구분할 수 있습니다.

![랜드마크와 스켈레톤의 정의.](DeepFashion2%20A%20Versatile%20Benchmark%20for%20Detection,%20%20ca5951a918ca413bb8f327537bf61f54/Untitled%204.png)

랜드마크와 스켈레톤의 정의.

- 마스크: 각 의류 아이템에는 두 단계에 걸쳐 반자동으로 생성되는 픽셀별 마스크가 제공됩니다. 초기 마스크는 윤곽선에서 자동으로 생성된 다음 정확성을 보장하기 위해 사람이 수동으로 다듬습니다.
- 스타일: 데이터 세트의 각 의류 아이덴티티에는 색상, 프린트, 로고와 같은 스타일 특성이 레이블로 지정됩니다.

2.2. 벤치마크:
DeepFashion2는 이미지와 라벨을 훈련, 검증, 테스트 단계로 나누어 4개의 벤치마크를 구축하는 데 사용됩니다. 이 벤치마크는 다음과 같은 패션 이해의 다양한 측면을 평가하도록 설계되었습니다:

- 옷 감지: 이 작업은 경계 상자 및 카테고리 레이블을 예측하여 이미지에서 옷을 감지하는 모델의 능력을 평가합니다. 성능은 바운딩 박스의 평균 정밀도를 기준으로 평가됩니다.
- 랜드마크 추정: 이 작업은 감지된 각 의류 항목의 랜드마크를 예측하는 것을 목표로 합니다. 성능은 키포인트의 평균 정밀도로 측정됩니다.세분화: 이 작업은 항목의 각 픽셀에 카테고리 레이블을 할당하는 기능을 평가합니다. 성능은 마스크에 대해 계산된 평균 정밀도를 사용하여 측정됩니다.
    
    ![Untitled](DeepFashion2%20A%20Versatile%20Benchmark%20for%20Detection,%20%20ca5951a918ca413bb8f327537bf61f54/Untitled%205.png)
    

![Untitled](DeepFashion2%20A%20Versatile%20Benchmark%20for%20Detection,%20%20ca5951a918ca413bb8f327537bf61f54/Untitled%206.png)

- 상업용 소비자 의류 검색: 이 작업은 소비자가 촬영한 사진에서 감지된 품목에 해당하는 상업용 이미지를 찾는 것을 목표로 합니다. 성능은 상위 k 검색 정확도를 사용하여 평가됩니다.
    
    ![Untitled](DeepFashion2%20A%20Versatile%20Benchmark%20for%20Detection,%20%20ca5951a918ca413bb8f327537bf61f54/Untitled%207.png)
    

전체적으로 딥패션2는 세부적이고 엄격한 데이터 라벨링 프로세스를 통해 패션 이해의 다양한 작업에 대한 포괄적인 벤치마킹 시스템을 제공합니다.

### 3. Match R-CNN

Match R-CNN은 DeepFashion2를 위해 개발된 기준 모델입니다. 이 모델은 Mask R-CNN을 기반으로 구축되어 옷 감지, 랜드마크 추정, 인스턴스 세분화, 소비자 간 검색을 동시에 학습하는 엔드투엔드 학습 프레임워크를 생성합니다. 이는 다양한 스트림과 샴 모듈을 사용하여 학습된 특징을 집계함으로써 달성됩니다.

![특징 추출 네트워크(FN), 인식 네트워크(PN), 그리고 매치 네트워크(MN)를 포함하는 세 가지 주요 구성 요소를 가진 Match R-CNN의 다이어그램입니다.](DeepFashion2%20A%20Versatile%20Benchmark%20for%20Detection,%20%20ca5951a918ca413bb8f327537bf61f54/Untitled%208.png)

특징 추출 네트워크(FN), 인식 네트워크(PN), 그리고 매치 네트워크(MN)를 포함하는 세 가지 주요 구성 요소를 가진 Match R-CNN의 다이어그램입니다.

Match R-CNN 아키텍처는 세 가지 주요 구성 요소로 이루어져 있습니다:

- 피처 네트워크(FN): 여기에는 ResNet-FPN 백본, 지역 제안 네트워크(RPN), RoIAlign 모듈이 포함됩니다. 첫 번째 단계에서는 이미지가 처음에 ResNet50에 공급되어 피처를 추출한 다음 FPN에서 피처 맵의 피라미드를 구축하는 데 사용됩니다. 그런 다음 RoIAlign은 이 피라미드 맵의 여러 레벨에서 특징을 추출합니다.
- 인식 네트워크(PN): 이 두 번째 단계에는 랜드마크 추정, 옷 감지, 마스크 예측을 포함한 세 가지 네트워크 스트림이 포함됩니다. 첫 번째 단계에서 추출한 RoI 기능은 PN의 이 세 가지 스트림에 개별적으로 공급됩니다.
- 매칭 네트워크(MN): 세 번째 단계에는 옷 검색을 위한 특징 추출기와 유사도 학습 네트워크가 포함됩니다. FN 구성 요소 이후에 학습된 RoI 기능은 옷 카테고리, 포즈, 마스크와 관련하여 높은 변별력을 갖습니다. 이러한 특징들은 검색을 위한 특징 벡터를 얻기 위해 MN에 공급됩니다.

옷 분류를 위한 교차 엔트로피(CE) 손실, 경계 상자 회귀를 위한 평활 손실, 랜드마크 추정을 위한 CE 손실, 옷 세분화를 위한 CE 손실, 옷 검색을 위한 CE 손실 등 5가지 손실 함수가 최적화되어 Match R-CNN을 훈련합니다.

이 모델은 8-GPU 설정을 사용하여 구현됩니다. 각 이미지는 짧은 가장자리가 800픽셀, 긴 가장자리가 1333픽셀을 초과하지 않도록 크기가 조정됩니다. 학습 속도는 0.02에서 시작하여 8, 11 에포크 이후 0.1씩 감소하여 12 에포크 후에 종료됩니다.

추론하는 동안 이미지의 크기는 훈련 단계와 동일한 방식으로 조정됩니다. 검출 확률이 높은 상위 1000개의 제안이 경계 상자 분류 및 회귀를 위해 선택됩니다. 그런 다음 이러한 제안에 비최대 억제가 적용되어 랜드마크 및 마스크 분기에 개별적으로 공급됩니다. 검색 작업의 경우, 소비자가 촬영한 이미지에서 가장 높은 신뢰도를 가진 고유하게 감지된 각각의 의류 항목이 쿼리로 선택됩니다.

### 4. Experiments

DeepFashion2의 효과는 마스크 R-CNN과 매치 R-CNN을 모두 사용하여 옷 감지 및 분류, 랜드마크 추정, 인스턴스 세분화, 소비자 간 옷 검색 등 여러 작업을 수행하여 평가합니다.

4.1. 옷 감지:
옷 감지 결과, 중간 정도의 스케일, 약간의 오클루전, 줌인 없음, 정면 시점의 옷이 가장 높은 감지율을 보였습니다. 옷의 크기가 작거나 크거나, 가려진 부분이 많거나, 확대가 큰 옷을 감지하는 데는 어려움이 있었습니다. 인체에 부착되지 않은 의류 품목도 감지하기 어려웠는데, 이는 비강체 변형이 크기 때문일 가능성이 높습니다.

![(a)는 옷 탐지에서의 실패 사례를 보여주고, (b)는 옷 분할에서의 실패 사례를 보여줍니다. (a)와 (b)에서, 누락된 경계 상자는 빨간색으로 그려져 있고, 올바른 카테고리 레이블도 빨간색입니다. 부정확한 마스크도 (b)에서 화살표로 강조되어 있습니다. 예를 들어, 너무 작은 스케일, 너무 큰 스케일, 큰 비강성 변형, 심한 가리개, 큰 줌인, 측면 또는 후면 시점에서 옷을 탐지하거나 분할하지 못하는 경우가 있습니다.](DeepFashion2%20A%20Versatile%20Benchmark%20for%20Detection,%20%20ca5951a918ca413bb8f327537bf61f54/Untitled%209.png)

(a)는 옷 탐지에서의 실패 사례를 보여주고, (b)는 옷 분할에서의 실패 사례를 보여줍니다. (a)와 (b)에서, 누락된 경계 상자는 빨간색으로 그려져 있고, 올바른 카테고리 레이블도 빨간색입니다. 부정확한 마스크도 (b)에서 화살표로 강조되어 있습니다. 예를 들어, 너무 작은 스케일, 너무 큰 스케일, 큰 비강성 변형, 심한 가리개, 큰 줌인, 측면 또는 후면 시점에서 옷을 탐지하거나 분할하지 못하는 경우가 있습니다.

4.2. 랜드마크 및 포즈 추정:
마스크 R-CNN은 랜드마크 추정에서 전체 평균 정밀도(AP)가 0.563으로 상당히 낮은 것으로 나타났는데, 이는 이 작업이 COCO에서 사람의 포즈 추정보다 더 어렵다는 것을 시사합니다. 오클루전이 심하고 확대하면 성능이 크게 저하되었습니다.

![(a)는 랜드마크와 자세 추정의 결과를 보여줍니다. (b)는 옷 분할의 결과를 보여줍니다. (c)는 상위 5개의 검색된 의류 항목이 포함된 쿼리를 보여줍니다. 첫 번째 열은 검출 모듈에 의해 예측된 경계 상자가 있는 고객의 이미지이며, 두 번째에서 여섯 번째 열은 상점에서 검색된 결과를 보여줍니다. (d)는 (1) 감지된 상자 (2) 실제 상자를 가진 전체 쿼리 검증 세트의 검색 정확도입니다. 평가 지표는 top-1, -5, -10, -15, 그리고 -20 검색 정확도입니다.](DeepFashion2%20A%20Versatile%20Benchmark%20for%20Detection,%20%20ca5951a918ca413bb8f327537bf61f54/Untitled%2010.png)

(a)는 랜드마크와 자세 추정의 결과를 보여줍니다. (b)는 옷 분할의 결과를 보여줍니다. (c)는 상위 5개의 검색된 의류 항목이 포함된 쿼리를 보여줍니다. 첫 번째 열은 검출 모듈에 의해 예측된 경계 상자가 있는 고객의 이미지이며, 두 번째에서 여섯 번째 열은 상점에서 검색된 결과를 보여줍니다. (d)는 (1) 감지된 상자 (2) 실제 상자를 가진 전체 쿼리 검증 세트의 검색 정확도입니다. 평가 지표는 top-1, -5, -10, -15, 그리고 -20 검색 정확도입니다.

4.3. 옷 세분화:
세분화 성능은 크고 작은 스케일, 무거운 오클루전, 큰 줌인, 측면 또는 후면 시점을 가진 의류 아이템을 처리할 때도 저하되었습니다. 이러한 경향은 이전 작업에서 관찰된 것과 일치합니다.

4.4. 소비자-매장 간 의류 검색:
검색 작업에서 매치 R-CNN은 실측 바운딩 박스를 제공했을 때 0.7 미만의 상위 20위권 정확도를 달성하여 벤치마크의 어려움을 보여주었습니다. 탐지된 박스를 사용하면 성능이 더 떨어졌습니다. 학습된 특징의 다양한 조합 중에서 포즈와 클래스의 특징이 더 나은 결과를 얻었으며, 랜드마크 위치는 시나리오 전반에서 더 견고한 것으로 나타났습니다.

작은 스케일, 심하게 가려진 의류 아이템, 크게 확대된 의류 아이템이 표시될 때 문제가 발생했습니다. 측면 또는 후면 시점의 의류 아이템은 식별할 수 있는 특징이 부족하기 때문에 정면 시점의 의류 아이템보다 성능이 떨어졌습니다.

### 5. Conclusions

이 작업에서는 광범위한 주석과 작업을 포함하는 포괄적인 대규모 패션 이미지 벤치마크인 DeepFashion2를 소개합니다. DeepFashion2는 스타일, 스케일, 오클루전, 확대/축소, 시점, 바운딩 박스, 고밀도 랜드마크 및 포즈, 픽셀 수준 마스크, 소비자 및 상업 매장의 동일한 품목 이미지 쌍과 같은 속성으로 풍부하게 레이블이 지정된 491K개의 이미지로 구성되어 있습니다.

이 작업에서 설정된 벤치마크는 옷 감지, 랜드마크 및 포즈 추정, 옷 세분화, 소비자-매장 간 확인 및 검색과 같은 패션 이해의 다양한 작업을 다룹니다. 이러한 맥락에서 마스크 R-CNN을 확장하고 앞서 언급한 작업을 엔드투엔드 방식으로 해결하는 새로운 매치 R-CNN 프레임워크가 제안되었습니다. 딥패션2 환경 내에서 광범위한 평가가 수행되었습니다.

DeepFashion2의 풍부한 데이터와 레이블은 패션 이미지 이해를 위한 알고리즘 개발에 큰 도움이 될 것으로 기대됩니다. 향후 작업에서는 생성적 적대 신경망(GAN)을 사용하여 의류 이미지를 합성하는 등 보다 까다로운 작업을 DeepFashion2를 통해 탐색하는 것이 목표입니다. 패션 트렌드의 잦은 변화로 인해 의류 이미지가 다양하게 변하기 때문에 의류 이미지에 대한 다중 도메인 학습도 관심의 대상입니다. 마지막으로 딥패션2에 딥 모델의 크기, 런타임, 메모리 소비량 등 더 많은 평가 지표를 도입하면 실제 시나리오에서 패션 이미지에 대한 이해를 높이는 데 도움이 될 것입니다.

- 모델의 입력과 출력
    
    DeepFashion2의 핵심인 Match R-CNN 모델에 대해 말씀하신 것으로 가정하겠습니다.
    
    입력:
    Match R-CNN 모델의 입력은 패션 관련 이미지입니다. 이 이미지는 하나 또는 그 이상의 패션 아이템이 포함되어 있을 수 있으며, 각 아이템에 대한 라벨(경계 상자, 픽셀 수준 마스크, 밀집 랜드마크 등)과 더불어 상업용 및 고객 이미지 쌍도 포함됩니다. 또한 이 모델은 다양한 패션 아이템, 그리고 그것들의 스타일, 스케일, 가려짐 정도, 확대/축소 정도, 시점 등에 대한 정보를 처리하도록 설계되었습니다.
    
    출력:
    Match R-CNN 모델은 다음의 출력을 제공합니다:
    
    1. Clothes Detection: 모델은 이미지에서 옷을 검출하고, 각 옷의 위치와 카테고리를 파악합니다. 출력은 각각의 옷에 대한 경계 상자와 카테고리 레이블입니다.
    2. Landmark and Pose Estimation: 모델은 각 옷의 랜드마크(특징점)과 포즈(자세)를 예측합니다. 출력은 랜드마크와 포즈에 대한 정보입니다.
    3. Clothes Segmentation: 모델은 이미지에서 옷의 정확한 모양과 위치를 파악하기 위해 옷을 세분화합니다. 출력은 각 옷에 대한 픽셀 수준 마스크입니다.
    4. Consumer-to-Shop Retrieval: 모델은 고객이 업로드한 이미지와 상점 이미지 간의 매칭을 수행합니다. 출력은 고객의 이미지에 대응하는 상점의 이미지들입니다.
    
    이 모든 작업은 end-to-end 방식으로 이루어집니다, 즉, 모델은 원시 이미지를 입력으로 받아들이고, 필요한 모든 정보를 직접적으로 출력합니다. 이러한 방식은 일련의 연속적인 작업을 통합적으로 처리할 수 있어, 더 효과적이고 정확한 패션 이미지 이해를 가능하게 합니다.
    
- 활용
    
    DeepFashion2 데이터셋은 패션 관련 작업을 위한 딥러닝 모델 학습에 사용됩니다. 이 데이터셋은 다양한 패션 아이템에 대한 다양한 주제와 각종 정보들을 포함하고 있어, 이를 이용해 패션 이미지 이해와 관련된 다양한 문제를 해결할 수 있습니다.
    
    1. **의류 탐지:** 이는 이미지 내에 존재하는 특정 옷의 위치와 종류를 식별하는 것입니다. 예를 들어, 이미지 내에 셔츠, 바지, 신발 등이 있는 위치와 종류를 식별하고, 경계 상자를 그려 이를 구분하는 것입니다. 이는 일반적으로 객체 탐지 모델, 예를 들어, Mask R-CNN 등을 활용해 수행됩니다.
    2. **랜드마크 및 포즈 추정:** 이는 각각의 옷이나 인물의 특정 지점들, 랜드마크의 위치를 예측하는 것입니다. 예를 들어, 옷의 칼라, 소매, 단추 등의 위치 또는 인물의 손, 발, 머리 등의 위치를 예측하는 것입니다. 이는 일반적으로 키포인트 감지 또는 포즈 추정 알고리즘을 활용해 수행됩니다.
    3. **의류 분할:** 이는 픽셀 수준에서 각각의 옷을 분리하고 구분하는 것입니다. 예를 들어, 어떤 픽셀이 셔츠에 속하는지, 어떤 픽셀이 바지에 속하는지를 식별하는 것입니다. 이는 일반적으로 인스턴스 분할 알고리즘, 예를 들어, Mask R-CNN 등을 활용해 수행됩니다.
    4. **고객-상점 옷 검색:** 이는 고객이 착용하고 있는 옷과 같은 상점의 옷을 검색하는 것입니다. 예를 들어, 고객이 찍은 사진을 기반으로 같은 옷을 판매하고 있는 상점을 찾는 것입니다. 이는 일반적으로 이미지 검색 알고리즘을 활용해 수행됩니다.
    
    DeepFashion2는 위와 같은 작업을 포괄하도록 설계되어 있으며, 매우 다양한 범위의 응용 분야에서 활용할 수 있습니다. 예를 들어, 온라인 쇼핑 사이트에서 사용자가 착용하고 있는 옷과 유사한 상품을 추천하거나, 소셜 미디어 플랫폼에서 이미지를 분석하여 사용자의 패션 스타일을 이해하는데 사용될 수 있습니다.
    
- 의의
    
    DeepFashion2는 몇 가지 주요 차별점을 가진 패션 이미지 벤치마크입니다.
    
    1. **규모와 다양성:** DeepFashion2는 대규모의 데이터셋으로, 약 491,000개의 이미지가 포함되어 있습니다. 이들 이미지는 스케일, 가려짐, 확대/축소, 시점 등 다양한 요인들에 따라 다른 변형을 가지고 있어, 다양한 상황에서 알고리즘이 일관된 성능을 내도록 도와줍니다.
    2. **풍부한 라벨링:** DeepFashion2의 각 이미지는 스타일, 스케일, 가려짐, 확대/축소, 시점, 경계 상자, 밀집 랜드마크와 포즈, 픽셀 수준 마스크, 고객과 상점 이미지 쌍 등에 대한 정보가 풍부하게 라벨링되어 있습니다. 이는 패션 이미지를 이해하는 데 필요한 정보를 제공합니다.
    3. **다양한 태스크:** DeepFashion2는 의류 검출, 랜드마크 및 포즈 예측, 의류 세분화, 고객-상점 매칭 및 검색 등 다양한 태스크를 지원합니다. 이것은 패션 이미지를 이해하는 데 필요한 다양한 측면을 포괄하도록 설계되었습니다.
    4. **Match R-CNN:** DeepFashion2는 새로운 알고리즘인 Match R-CNN을 도입했습니다. 이는 Mask R-CNN을 기반으로 하여, 위에서 언급한 다양한 태스크를 end-to-end 방식으로 수행할 수 있게 합니다.
    
    이러한 특징들은 DeepFashion2를 패션 이미지 이해에 있어서 기존 모델들과 차별화시킵니다. 기존의 대부분의 패션 모델들은 보통 단일 태스크에 초점을 맞추거나, 덜 다양한 라벨링이나 데이터 규모를 가지고 있습니다. 이에 반해, DeepFashion2는 보다 광범위하고 깊은 패션 이미지 이해를 가능하게 합니다.