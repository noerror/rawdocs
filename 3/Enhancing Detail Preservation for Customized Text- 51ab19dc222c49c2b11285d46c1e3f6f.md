# Enhancing Detail Preservation for Customized Text-to-Image Generation:A Regularization-Free Approach

*이 논문에서는 맞춤형 이미지 생성을 위한 새로운 프레임워크인 ProFusion을 소개합니다. 정규화 기법을 사용했던 이전 방법과 달리 ProFusion은 정규화 없이 맞춤형 생성을 수행하므로 더 적은 학습 시간으로 세밀한 디테일을 보존할 수 있습니다.*

*프로퓨전 프레임워크는 FFHQ 데이터세트에 대해 사전 학습된 후 테스트 이미지에 대해 미세 조정된 PromptNet이라는 모델을 사용합니다. 실험 결과, 이 프레임워크는 이미지 생성 작업에서 탁월한 성능을 보여줬으며, 이전 방법보다 더 높은 품질의 결과와 텍스트 프롬프트를 더 잘 준수하는 것으로 나타났습니다.*

[https://arxiv.org/pdf/2305.13579.pdf](https://arxiv.org/pdf/2305.13579.pdf)

[https://github.com/drboog/ProFusion](https://github.com/drboog/ProFusion)

1 Introduction

텍스트 이미지 생성은 최근 상당한 진전을 이루었으며, 이제 연구자들은 어떤 텍스트 입력으로도 이미지를 생성할 수 있게 되었습니다. 이는 방대한 웹 규모의 데이터 세트에서 대규모 모델을 학습시킴으로써 달성할 수 있습니다. 이러한 발전에는 DALL-E와 CogView, 그리고 그 후속 방법들이 포함됩니다. 이러한 모델은 이미지 조작 및 비디오 생성과 같은 다른 분야에도 적용되었습니다.

![제안된 프레임워크로 맞춤형 생성. 하나의 테스트 이미지만 주어지면 임의의 특정 요구 사항을 충족하고 세밀한 디테일을 보존하는 맞춤형 생성을 수행할 수 있습니다.](Enhancing%20Detail%20Preservation%20for%20Customized%20Text-%2051ab19dc222c49c2b11285d46c1e3f6f/Untitled.png)

제안된 프레임워크로 맞춤형 생성. 하나의 테스트 이미지만 주어지면 임의의 특정 요구 사항을 충족하고 세밀한 디테일을 보존하는 맞춤형 생성을 수행할 수 있습니다.

그러나 이러한 모델은 사용자가 지정한 새롭고 고유한 개념을 생성하는 데 어려움을 겪습니다. 사전 학습된 텍스트-이미지 모델을 개별 요구에 맞게 조정하기 위해 다양한 방법이 시도되었습니다. 일부 연구자들은 과적합을 방지하기 위해 다양한 정규화 방법을 적용하면서 적은 수의 샘플로 사전 학습된 모델을 미세 조정할 것을 제안합니다. 다른 방법으로는 최적화 방법이나 인코더 네트워크를 사용하여 단어 임베딩에 사용자 입력 이미지의 새로운 개념을 인코딩하는 방법이 있습니다.

이러한 발전에도 불구하고 일부 연구자들은 정규화를 사용하면 맞춤형 생성이 제한되고 세밀한 디테일이 손실될 수 있다고 주장합니다. 이에 대한 대응책으로 PromptNet이라는 인코더와 퓨전 샘플링이라는 새로운 샘플링 방법을 포함하는 ProFusion이라는 새로운 프레임워크가 제안되었습니다. 프로퓨전은 정규화가 필요하지 않기 때문에 추론 단계에서 퓨전 샘플링을 사용하여 잠재적인 과적합 문제를 극복합니다. 따라서 정규화를 위해 하이퍼파라미터를 조정할 필요가 없어 훈련 시간이 절약될 뿐만 아니라 더 세밀한 디테일을 보존할 수 있습니다.

ProFusion의 주요 기능은 다음과 같습니다:

- 맞춤형 생성을 위한 새로운 프레임워크로, 단일 GPU에서 약 30초의 미세 조정만으로 모든 텍스트 입력을 기반으로 고유한 개념에 맞는 맞춤형 출력을 생성할 수 있습니다.
- 정규화 방법을 제거하여 훈련 시간을 단축하고 세밀한 디테일을 보존합니다.
- 프레임워크의 구성 요소를 더 잘 이해하기 위한 추가 제거 연구와 함께 정성적, 정량적, 인적 평가를 통해 ProFusion의 효과적인 적용이 입증되었습니다.

2 Methodology

제안된 프로퓨전 프레임워크에는 프롬프트넷이라는 신경망과 퓨전 샘플링이라는 새로운 샘플링 방법이 포함되어 있습니다.

![사용자 지정 생성의 성능은 정규화 수준에 따라 영향을 받습니다.](Enhancing%20Detail%20Preservation%20for%20Customized%20Text-%2051ab19dc222c49c2b11285d46c1e3f6f/Untitled%201.png)

사용자 지정 생성의 성능은 정규화 수준에 따라 영향을 받습니다.

PromptNet은 입력 이미지 x를 기반으로 단어 임베딩(S∗)을 생성하는 인코더로, S∗를 어떤 텍스트와 결합해 창의적인 콘텐츠를 생성하는 프롬프트를 생성할 수 있다는 장점이 있습니다. 예를 들어 슈퍼히어로 영화에서 스크린샷을 찍어 텍스트와 결합하여 독특한 프롬프트를 만들 수 있습니다.

퓨전 샘플링은 입력 이미지의 세밀한 디테일을 유지하면서 지정된 텍스트 요구 사항을 충족하는 콘텐츠를 생성하는 방법입니다. 즉, 원본 이미지의 디테일을 유지하면서 사용자의 텍스트 입력을 따르는 맞춤형 콘텐츠를 만들 수 있습니다.

유사한 작업에서 자주 사용되는 정규화 기법은 세부 정보가 손실되어 성능이 저하될 수 있습니다. 프로퓨전은 정규화 없이 프롬프트넷을 학습시켜 원본 이미지의 디테일을 보존하는 방식으로 이 문제를 해결합니다.

그런 다음 정규화 없이 얻은 S∗를 사용하여 성공적인 맞춤형 생성을 수행하는 방법이 과제입니다. 이를 해결하기 위해 퓨전 샘플링이 도입되었습니다. 퓨전 샘플링은 조건 S∗와 C가 있는 조건부 생성 작업으로 공식화되며, 여기서 C는 임의의 사용자 입력 텍스트를 나타냅니다.

퓨전 샘플링 방식은 각 타임스텝마다 두 단계로 구성되는데, S∗와 C의 정보를 업데이트된 x˜t로 인코딩하는 융합 단계와 특정 방정식을 기반으로 xt-1을 예측하는 정제 단계가 있습니다. 이 방법은 또한 독립 조건과 종속 조건을 고려하여 그에 따라 작동을 조정합니다. 이 방법은 더 복잡한 시나리오를 허용하고 생성 조건 목록을 수용합니다.

전체 방법은 원본 입력 이미지의 세부 사항을 보존하면서 고도로 맞춤화된 콘텐츠를 생성할 수 있도록 설계되었습니다.

3 Experiments

연구원들은 ProFusion이라는 새로운 프레임워크를 개발하여 광범위하게 테스트했습니다. 연구진은 데이터 증강 없이 배치 크기 64로 8개의 NVIDIA A100 GPU를 사용하여 80,000회 반복하여 FFHQ 데이터세트에 대한 PromptNet을 훈련했습니다. 또한 사전 학습된 다른 모델의 프롬프트넷과 모든 주의 레이어를 50단계에 걸쳐 미세 조정했습니다. 이 미세 조정 프로세스는 단 30분의 시간과 단일 GPU만 필요하므로 효율적입니다.

질적 결과 측면에서 ProFusion 프레임워크는 입력 이미지의 세밀한 디테일을 보존하면서 특정 텍스트 요구 사항을 충족하는 이미지를 효과적으로 생성했습니다. 또한 이러한 디테일을 보존하는 측면에서도 다른 모델보다 우수한 성능을 보였습니다.

정량적 평가를 위해 사전 학습된 다양한 CLIP 모델을 사용하여 생성된 이미지와 입력 텍스트 간의 유사도를 계산했습니다. 프로퓨전은 모든 모델에서 더 높은 점수를 받아 프롬프트에 더 잘 부합하고 편집 능력이 뛰어났음을 입증했습니다. 또한 생성된 이미지와 입력 이미지 간의 동일성 유사도를 계산한 결과, ProFusion이 다시 한 번 우수한 성능을 보이며 우수한 동일성 보존을 입증했습니다.

아마존 메카니컬 터크(Amazon Mechanical Turk)에서도 사람에 의한 평가가 이루어졌는데, ProFusion은 다른 방법보다 높은 선호도를 기록했습니다.

제거 연구에서 연구원들은 퓨전 샘플링 프로세스가 기준선 분류기 없는 샘플링에 비해 사전 학습된 모델과 미세 조정된 모델 모두에서 결과를 크게 개선한다는 사실을 발견했습니다. 또한 융합 또는 미세 조정 단계를 제거하면 세부 정보가 손실되거나 이미지 구조가 흐트러지는 등 결과가 더 나빠지는 것을 발견했습니다. 또한 미세 조정 중에 데이터 증강을 사용하면 성능이 향상되는 것을 관찰했습니다.

![절제 연구 예시 생성, 프롬프트 "S ∗ 는 슈퍼맨 코스튬을 입고 있습니다”](Enhancing%20Detail%20Preservation%20for%20Customized%20Text-%2051ab19dc222c49c2b11285d46c1e3f6f/Untitled%202.png)

절제 연구 예시 생성, 프롬프트 "S ∗ 는 슈퍼맨 코스튬을 입고 있습니다”

4 Discussion

연구원들은 프레임워크인 ProFusion이 고품질의 맞춤형 생성에 성공했지만 개선이 필요한 부분이 있다고 지적합니다. 예를 들어, 정규화 하이퍼파라미터를 조정할 필요가 없어 학습 시간을 단축할 수 있음에도 불구하고 ProFusion의 퓨전 샘플링 기법은 각 샘플링 단계를 두 단계로 나누기 때문에 실제로 추론 시간이 늘어납니다. 앞으로 팀은 퓨전 샘플링을 더 효율적으로 사용할 수 있는 방법을 찾고자 합니다.

또한 모든 대규모 텍스트-이미지 생성 모델과 마찬가지로 ProFusion은 긍정적이든 부정적이든 잠재적인 윤리적 영향을 미칠 수 있다는 점을 인정합니다. 맞춤형 생성은 민감한 정보가 포함된 이미지를 생성하거나 잘못된 정보를 퍼뜨리는 데 사용될 수 있지만, 모델 편향성을 줄일 수 있는 잠재력도 있습니다.

이 백서에서는 맞춤형 생성을 위한 고유한 프레임워크인 프로퓨전을 소개합니다. 정규화를 사용하는 다른 방법과 달리 ProFusion은 정규화 없이 작동하므로 더 적은 학습 시간으로 더 세밀한 디테일을 보존할 수 있습니다. 실험 결과에 따르면 ProFusion은 설계 목적에 맞는 효과적인 솔루션으로 입증되었습니다.

A Experiment Details

이 논문에서 실험 세부 사항 섹션을 통해 데이터 증강, 프롬프트넷 모델, 사람 평가에 대한 자세한 내용을 확인할 수 있습니다.

데이터 증강의 경우 입력 이미지를 마스킹하여 대상 얼굴이나 물체만 보이게 하는 기법을 사용합니다. 이렇게 마스킹된 이미지는 안정적 확산이라는 사전 학습된 모델에 입력되며, 이 모델은 인페인팅 기법을 적용하여 다양한 배경을 가진 여러 가지 이미지 변형을 생성합니다. 이 과정에서 프롬프트라고 하는 특정 안내 문구가 인페인팅 모델의 출력을 조정하는 데 사용됩니다.

저자에 따르면 프롬프트넷은 5개의 인코더 블록으로 구성된 인코더 모델로, 스테이블 디퓨전 2 모델의 일부와 유사합니다. 이 모델은 사전 학습된 스테이블 디퓨전 2 모델의 파라미터로 초기화됩니다. 주목할 만한 차이점은 크로스 어텐션 레이어에 텍스트 임베딩이 아닌 사전 학습된 CLIP 모델의 이미지 임베딩을 사용한다는 점입니다. PromptNet에 대한 입력은 서로 다른 컨볼루션 레이어에 의해 처리되며, 그 출력은 합산되어 후속 블록에 대한 입력을 형성합니다.

인간의 평가를 위해 저자들은 자신들의 작업을 E4T라는 기존 방법과 비교했습니다. 저자들은 공정한 비교를 위해 E4T 논문에서 사용된 것과 동일한 프롬프트를 사용하여 이미지를 생성합니다. 이 이미지는 Amazon Mechanical Turk에서 각각 최소 10,000개의 승인된 과제를 완료한 5명의 전문 작업자가 평가합니다.