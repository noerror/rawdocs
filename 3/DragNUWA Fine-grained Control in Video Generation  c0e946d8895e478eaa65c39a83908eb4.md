# DragNUWA: Fine-grained Control in Video Generation by Integrating Text, Image, and Trajectory

[https://arxiv.org/abs/2308.08089](https://arxiv.org/abs/2308.08089)

[https://www.microsoft.com/en-us/research/project/dragnuwa/](https://www.microsoft.com/en-us/research/project/dragnuwa/)

- Aug 2023

### 1 INTRODUCTION

연구자들은 콘텐츠에서 제어하거나 안내할 수 있는 동영상을 만드는 데 열중해 왔습니다. 초기의 방법은 동영상의 첫 번째 이미지를 사용하여 나머지 동영상을 안내하는 방식이었습니다. 하지만 이는 향후 프레임이 어떻게 보여야 하는지를 완전히 규정하지는 못했습니다. 새로운 접근 방식에서는 텍스트 설명을 사용하여 비디오 콘텐츠를 구성했습니다. 일부 연구자들은 더 나은 결과를 위해 이미지와 텍스트를 결합하는 방법을 시도했습니다. 하지만 두 가지 방법 모두 비디오의 모션을 제어하는 데는 효과적이지 않았습니다.

새로운 아이디어가 떠올랐습니다. 모션 경로, 즉 '궤적'을 사용하여 동영상 콘텐츠를 안내하는 것입니다. 이를 중심으로 몇 가지 방법이 개발되었지만 문제가 있었습니다. 예를 들어, 자연스러운 동작을 만들 수 없거나 사람의 모습에만 적용할 수 있었고, 텍스트 사용의 잠재적 이점을 무시했습니다.

![DragNUWA는 문맥적, 공간적 및 시간적 관점에서 제어 가능한 비디오 생성을 달성하기 위해 텍스트, 이미지 및 궤적 컨트롤을 통합합니다. 세 가지 예제 그룹은 다른 두 가지를 고정하면서 하나의 제어를 변경하는 영향을 보여줍니다. 첫 번째 그룹 (행 1-2)은 복잡한 동작 (빨간색 곡선 화살표) 및 카메라 움직임 (빨간색 오른쪽 화살표)을 포함하여 복잡한 궤적의 제어를 표시합니다. 두 번째 그룹 (행 3-4)은 동일한 이미지와 궤적에 다른 텍스트를 연결하여 이미지에 새로운 객체를 도입하는 효과를 달성하기 위해 언어 제어의 영향을 보여줍니다. 세 번째 그룹 (행 5-6)은 이미지 제어의 영향을 보여주며, 실제 세계 및 예술적인 비디오 생성을 보여줍니다.](DragNUWA%20Fine-grained%20Control%20in%20Video%20Generation%20%20c0e946d8895e478eaa65c39a83908eb4/Untitled.png)

DragNUWA는 문맥적, 공간적 및 시간적 관점에서 제어 가능한 비디오 생성을 달성하기 위해 텍스트, 이미지 및 궤적 컨트롤을 통합합니다. 세 가지 예제 그룹은 다른 두 가지를 고정하면서 하나의 제어를 변경하는 영향을 보여줍니다. 첫 번째 그룹 (행 1-2)은 복잡한 동작 (빨간색 곡선 화살표) 및 카메라 움직임 (빨간색 오른쪽 화살표)을 포함하여 복잡한 궤적의 제어를 표시합니다. 두 번째 그룹 (행 3-4)은 동일한 이미지와 궤적에 다른 텍스트를 연결하여 이미지에 새로운 객체를 도입하는 효과를 달성하기 위해 언어 제어의 영향을 보여줍니다. 세 번째 그룹 (행 5-6)은 이미지 제어의 영향을 보여주며, 실제 세계 및 예술적인 비디오 생성을 보여줍니다.

![DragNUWA에서 생성된 샘플이 제시되며, 첫 번째 열은 세 가지 입력 컨트롤을 보여줍니다: 텍스트, 이미지, 궤적. 두 번째, 세 번째 및 네 번째 열은 각각 출력 비디오의 5번째, 10번째 및 15번째 프레임을 보여줍니다. 총 16 프레임과 576 × 320의 해상도가 있습니다. DragNUWA는 카메라, 여러 객체 및 복잡한 궤적의 동시 제어를 할 수 있어, 실제 장면과 예술적인 그림이 특징인 비디오를 생성할 수 있습니다.](DragNUWA%20Fine-grained%20Control%20in%20Video%20Generation%20%20c0e946d8895e478eaa65c39a83908eb4/Untitled%201.png)

DragNUWA에서 생성된 샘플이 제시되며, 첫 번째 열은 세 가지 입력 컨트롤을 보여줍니다: 텍스트, 이미지, 궤적. 두 번째, 세 번째 및 네 번째 열은 각각 출력 비디오의 5번째, 10번째 및 15번째 프레임을 보여줍니다. 총 16 프레임과 576 × 320의 해상도가 있습니다. DragNUWA는 카메라, 여러 객체 및 복잡한 궤적의 동시 제어를 할 수 있어, 실제 장면과 예술적인 그림이 특징인 비디오를 생성할 수 있습니다.

연구진은 최상의 비디오 제어를 위해서는 텍스트, 이미지, 궤적을 함께 사용해야 한다고 생각했습니다. 이렇게 하면 콘텐츠의 의미, 시각적 요소, 동작을 모두 캡처할 수 있습니다. 또한 기존의 궤적 방식이 너무 기본적이어서 복잡한 장면을 처리하는 데 어려움을 겪고 있다는 사실을 알게 되었습니다.

그래서 새로운 동영상 제작 시스템인 드래그누와를 도입했습니다. 이 도구는 텍스트, 이미지, 궤적을 혼합하여 세부적인 동영상 제어가 가능합니다. 궤적을 더 잘 활용할 수 있는 새로운 기능을 추가하여 다양한 종류의 동영상에 다용도로 사용할 수 있습니다. 테스트 결과, 드래그누와는 동영상 제작 능력에서 효과적이고 진보된 것으로 입증되었습니다.

### 2 RELATED WORKS

2.1 비디오 합성의 텍스트/이미지 제어

- 초기에는 특정 장면에 대해 가능한 한 가지 미래를 가정하여 이미지를 비디오로 변환하는 연구에 집중했습니다.
- 그러나 실제 비디오에는 다양한 가능성이 존재하기 때문에 텍스트-비디오 생성이 인기를 얻게 되었습니다. 텍스트는 비디오의 내용을 지시하는 방법을 제공합니다.
- MAGE 및 GEN-1과 같은 일부 도구는 보다 정확한 동영상 제작 프로세스를 위해 텍스트와 이미지를 혼합했습니다. 페나키와 누와-XL과 같은 긴 동영상 생성 도구도 이미지와 텍스트를 결합했습니다.
- 하지만 텍스트와 이미지가 동영상 콘텐츠를 설명하는 데는 효과적이지만, 모션을 묘사하는 데는 취약하다는 문제가 있었습니다. 바로 이 점에 착안하여 '궤적'으로 모션을 안내하는 기능을 추가한 것이 바로 드래그누와입니다.

2.2 비디오 합성의 궤적 제어

- 이전 프레임을 기반으로 비디오의 움직임을 예측하는 방법도 있고, 기존 비디오의 스타일을 변경하는 데 초점을 맞춘 방법도 있습니다.
- 유망한 방법 중 하나는 이미지 내의 궤적을 사용하여 비디오 콘텐츠를 안내하는 것입니다. CVG 및 C2M과 같은 일부 도구는 궤적을 사용하여 비디오 동작을 예측했습니다.
- 하지만 문제가 있었습니다. 일부 방법은 비현실적인 비디오 움직임을 생성하는 반면, 다른 방법은 기본적인 사람의 움직임만 처리할 수 있었습니다.
- 최근의 도구인 비디오 컴포저는 다른 기술을 사용하여 모션을 안내하지만 제어할 수 있는 항목이 제한적이었습니다.
- 드래그누와는 다른 도구와 차별화됩니다. 이 도구는 혁신적인 동영상 제어 방법을 제공하여 사용자가 카메라 움직임을 고려하면서 이미지의 모든 개체를 이동하고, 여러 개체를 처리하고, 복잡한 모션을 안내할 수 있습니다.

### 3 METHOD

드래그누와 방식은 텍스트, 이미지, 궤적을 입력으로 수용하여 비디오 생성을 제어하는 고급 접근 방식입니다. 이 방법은 강력하고 적응력 있는 비디오 출력을 보장하는 포괄적인 프로세스를 제공합니다. 다음은 주요 사항을 간결하게 요약한 내용입니다:

![DragNUWA의 훈련 과정 개요. DragNUWA는 텍스트 p, 이미지 s 및 궤적 g 세 가지 선택적 입력을 지원하며, 궤적을 세 가지 관점에서 설계하는 데 중점을 둡니다. 먼저 궤적 샘플러 (TS)는 오픈 도메인 비디오 흐름에서 동적으로 궤적을 샘플링합니다. 둘째, 다중 규모 퓨전 (MF)은 UNet 아키텍처의 각 블록 내에서 텍스트와 이미지와 궤적을 깊게 통합합니다. 마지막으로, 적응형 훈련 (AT)은 광학 흐름 조건에서 사용자 친화적인 궤적으로 모델을 적응시킵니다. 결국, DragNUWA는 여러 객체와 그 복잡한 궤적이 있는 오픈 도메인 비디오를 처리할 수 있습니다.](DragNUWA%20Fine-grained%20Control%20in%20Video%20Generation%20%20c0e946d8895e478eaa65c39a83908eb4/Untitled%202.png)

DragNUWA의 훈련 과정 개요. DragNUWA는 텍스트 p, 이미지 s 및 궤적 g 세 가지 선택적 입력을 지원하며, 궤적을 세 가지 관점에서 설계하는 데 중점을 둡니다. 먼저 궤적 샘플러 (TS)는 오픈 도메인 비디오 흐름에서 동적으로 궤적을 샘플링합니다. 둘째, 다중 규모 퓨전 (MF)은 UNet 아키텍처의 각 블록 내에서 텍스트와 이미지와 궤적을 깊게 통합합니다. 마지막으로, 적응형 훈련 (AT)은 광학 흐름 조건에서 사용자 친화적인 궤적으로 모델을 적응시킵니다. 결국, DragNUWA는 여러 객체와 그 복잡한 궤적이 있는 오픈 도메인 비디오를 처리할 수 있습니다.

방법 개요:

- DragNUWA는 텍스트, 이미지, 궤적 기반 제어를 통합합니다.
- 궤적 모델링, 제어의 멀티스케일 융합, 적응형 훈련이라는 세 가지 주요 측면을 강조합니다.

궤적 샘플러(TS):

- 오픈 도메인 비디오 광학 흐름에서 직접 궤적을 추출합니다.
- 유니매치 광학 흐름 추정기를 사용합니다.
- 앵커는 흐름 맵에 균일하게 분포되어 있으며, 무작위 섭동을 통해 강력한 샘플링을 보장합니다.
- 가우시안 필터를 적용하여 결과 궤적 맵을 향상시킵니다.

멀티스케일 퓨전(MF):

- 비디오 인코딩: 이미지 자동 인코더를 사용하여 비디오 프레임을 인코딩합니다.
- 텍스트 제어 인코딩: 텍스트 프롬프트에 클립 텍스트 인코더를 사용합니다.
- 이미지 제어 인코딩: 비디오의 첫 번째 프레임을 가져와 인코딩합니다.
- 궤적 제어 인코딩: TS에서 얻은 궤적을 인코딩합니다.
- MF는 텍스트, 이미지, 궤적을 다운샘플링하고 UNet 아키텍처에 통합합니다.

적응형 훈련(AT):

- 2단계 프로세스:
    - 먼저 비디오 생성을 안정화하기 위해 조밀한 광 흐름을 조건으로 합니다.
    - 그런 다음 희박한 궤적을 학습하여 모델을 조정합니다.
- 시각적 일관성을 유지하면서 동적으로 일관된 비디오를 보장합니다.

추론:

- 드래그누와는 제공된 텍스트, 이미지, 궤적을 기반으로 사실적인 동영상을 생성할 수 있습니다.
- 텍스트에는 CLIP 텍스트 인코더를 활용하고, 이미지와 궤적을 처리하며, 이미지 자동 인코더를 사용하여 비디오 픽셀로 디코딩합니다.

드래그누와의 접근 방식은 컨트롤을 보다 원활하게 통합하고 생성된 비디오가 동적이고 시각적으로 일관성을 유지하도록 함으로써 이전 방법에서 볼 수 있었던 잠재적인 문제를 해결한다는 점에서 두드러집니다.

### 4 EXPERIMENTS

4.1 데이터 세트

- 두 가지 데이터 세트, WebVid와 VideoHD가 DragNUWA를 훈련하는 데 사용됩니다.
- WebVid에는 다양한 모션 패턴과 캡션이 포함된 천만 개의 웹 비디오가 포함되어 있습니다.
- VideoHD는 웹의 75K 고해상도 비디오로 생성되며 수동 오류 필터링과 함께 BLIP2를 사용하여 주석을 달았습니다.

4.2 구현 세부 사항

- 두 가지 버전의 DragNUWA: DragNUWA-LD와 DragNUWA-HD는 프레임 수와 해상도가 다릅니다.
- 궤적 샘플러(TS)의 파라미터는 최대 궤적 수 8개, 앵커 간격 16, 가우시안 커널 크기 99, 시그마 값 10으로 설정할 수 있습니다.
- 훈련 중 텍스트, 이미지 및 궤적의 무작위 생략은 0.1의 확률로 사용됩니다.
- 특정 배치 크기와 학습률로 훈련할 때는 아담 옵티마이저를 사용합니다.

4.3 궤적 제어 가능성

- 드래그누와는 궤적 제어를 강조합니다.
- 명시적인 모델링 없이도 수평, 수직, 줌 동작과 같은 다양한 카메라 움직임을 모델링할 수 있습니다.
- DragNUWA는 복잡한 모션 궤적을 성공적으로 모델링합니다.
- 곡선 궤적을 지원합니다.
- 모션 진폭에 영향을 주는 다양한 궤적 길이를 허용합니다.
- 여러 개체의 궤적을 제어할 수 있으며, 이는 기존 모델과 비교할 때 고유한 특징입니다.
    
    ![동일한 텍스트와 이미지를 사용하면서 드래그 궤적을 변경하여 다양한 카메라 움직임 효과를 달성할 수 있습니다. 예를 들어, 확대 및 축소 효과는 원하는 확대 위치에서 방향 궤적을 그림으로써 표현할 수 있습니다.](DragNUWA%20Fine-grained%20Control%20in%20Video%20Generation%20%20c0e946d8895e478eaa65c39a83908eb4/Untitled%203.png)
    
    동일한 텍스트와 이미지를 사용하면서 드래그 궤적을 변경하여 다양한 카메라 움직임 효과를 달성할 수 있습니다. 예를 들어, 확대 및 축소 효과는 원하는 확대 위치에서 방향 궤적을 그림으로써 표현할 수 있습니다.
    

4.4 세 가지 제어의 필수 요소

- 드래그누와는 텍스트, 이미지, 궤적 제어를 통합하여 동영상의 의미적, 공간적, 시간적 측면을 표현합니다.
    
    ![동일한 텍스트와 이미지를 사용하면서 드래그 궤적을 변경하여 다양한 복잡한 궤적 효과를 달성할 수 있습니다. DragNUWA는 복잡한 곡선 궤적을 지원하며, 다양한 궤적 길이를 허용하고, 여러 객체에 대한 궤적의 동시 제어를 지원합니다.](DragNUWA%20Fine-grained%20Control%20in%20Video%20Generation%20%20c0e946d8895e478eaa65c39a83908eb4/Untitled%204.png)
    
    동일한 텍스트와 이미지를 사용하면서 드래그 궤적을 변경하여 다양한 복잡한 궤적 효과를 달성할 수 있습니다. DragNUWA는 복잡한 곡선 궤적을 지원하며, 다양한 궤적 길이를 허용하고, 여러 객체에 대한 궤적의 동시 제어를 지원합니다.
    
    ![DragNUWA는 세 가지 핵심 컨트롤인 텍스트, 이미지, 및 궤적을 통합하여 미세한 비디오 생성을 달성합니다. 이것은 각각 문맥적, 공간적, 및 시간적 측면에 해당합니다.](DragNUWA%20Fine-grained%20Control%20in%20Video%20Generation%20%20c0e946d8895e478eaa65c39a83908eb4/Untitled%205.png)
    
    DragNUWA는 세 가지 핵심 컨트롤인 텍스트, 이미지, 및 궤적을 통합하여 미세한 비디오 생성을 달성합니다. 이것은 각각 문맥적, 공간적, 및 시간적 측면에 해당합니다.
    
- S2V, P2V, GS2V, PS2V 및 PGS2V와 같은 다양한 컨트롤 조합이 테스트되었습니다.
    - s2v 및 p2v는 개별 이미지 및 텍스트 컨트롤의 제약을 보여줍니다.
    - GS2V와 PS2V는 텍스트와 궤적의 중요성을 강조합니다.
    - pgs2v는 세 가지 조건이 모두 결합된 효과를 나타냅니다.
- 일부 연구에서는 비디오를 조건으로 사용하지만, 이 연구에서는 필수 조건에 초점을 맞춥니다. 비디오를 조건으로 사용하는 것은 실제 애플리케이션에서 제한적이고 어려울 수 있습니다.

### 5 CONCLUSION

드래그누와는 텍스트, 이미지, 궤적 입력을 통합하는 포괄적인 동영상 생성 모델로 소개되었습니다. 이러한 통합을 통해 콘텐츠(의미론적), 위치(공간적), 시간(시간적) 측면에서 미묘한 제어가 가능합니다. 궤적 샘플러(TS), 멀티스케일 퓨전(MF), 적응형 훈련(AT)과 같은 모델의 고유한 궤적 모델링 기능은 오픈 도메인 궤적 제어에서 발생하는 문제를 해결합니다. 그 결과 드래그누와는 복잡한 궤적에 잘 맞는 영상을 제작할 수 있습니다. 비교 실험을 통해 기존 방식에 비해 향상된 모델의 성능을 확인할 수 있었으며, 세밀한 동영상 제작에 효과적임을 확인했습니다.

- 생성모델 정리
    
    텍스트(p), 이미지(s), 그리고 궤적(g)의 세 가지 입력을 기반으로 합니다. 이 모델의 특징 중 하나는 궤적, 즉 비디오 내의 움직임을 정교하게 제어할 수 있는 기능에 있습니다.
    
    1. **Trajectory Sampler (TS)**
        - DragNUWA는 오픈 도메인 비디오에서 궤적을 직접 샘플링하는 궤적 샘플러를 설계했습니다.
        - 기존 방법들이 주요 포인트에서 궤적을 추출하는데 초점을 둔 반면, 이 모델은 비디오의 광학 흐름을 사용하여 궤적을 샘플링합니다.
        - 광학 흐름의 강도에 따라 궤적을 직접 샘플링하는 대신, 표본점(anchor points)을 균일하게 분포시켜 궤적 정보를 효과적으로 얻을 수 있습니다.
    2. **Multiscale Fusion (MF)**
        - 이 방법은 다양한 크기의 조건(텍스트, 이미지, 궤적)을 병합하기 위한 것입니다.
        - 각 컨트롤(텍스트, 이미지, 궤적)을 인코딩하고, UNet 아키텍처 내에서 이들을 결합합니다. 이 아키텍처는 여러 다운샘플링 및 업샘플링 블록을 포함합니다.
        - 특히, 궤적 및 이미지 조건은 선형 투영을 통해 숨겨진 상태로 통합되며, 텍스트 조건은 크로스 어텐션을 사용하여 숨겨진 상태에 주입됩니다.
    3. **Adaptive Training (AT)**
        - DragNUWA의 최적화를 위해 적응형 훈련 전략이 사용됩니다.
        - 첫 번째 단계에서는 모델에 광학 흐름과 첫 프레임을 조건으로 제공하여 시각적으로 일관된 비디오를 생성하도록 모델을 최적화합니다.
        - 두 번째 단계에서는 궤적 샘플러를 사용하여 광학 흐름에서 궤적을 샘플링하고, 이를 사용하여 모델을 더욱 최적화합니다. 이 단계에서는 사용자 친화적인 궤적을 통해 동적으로 일관된 비디오를 생성하는 능력을 향상시킵니다.