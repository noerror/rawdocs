# PersonLab: Person Pose Estimation and Instance Segmentation with a Bottom-Up, Part-Based, Geometric Embedding Model

[https://arxiv.org/abs/1803.08225](https://arxiv.org/abs/1803.08225)

- 22 Mar 2018

### 1 Introduction

이 연구는 제약이 없는 환경에서 여러 사람 감지, 2D 포즈 추정, 인스턴스 분할 작업을 다루며, 주어진 이미지에서 모든 사람을 식별하고, 주요 특징을 매핑하고, 고유한 분할 마스크를 추정하는 것을 목표로 합니다. 이러한 기능은 스마트 사진 편집, 활동 인식, 증강 현실, 로봇 공학 등 다양한 분야에서 활용되고 있습니다.

이 작업에는 경계 상자를 통해 개체를 식별하는 것으로 시작하는 하향식 접근 방식과 신원이 없는 개체(키포인트 또는 세분화 레이블)를 찾아 그룹화하는 것으로 시작하는 상향식 접근 방식이 존재합니다. 이 논문에서는 이미지의 모든 사람에 대한 모든 키포인트를 예측한 다음 그룹화하는 상향식 방법을 사용합니다. 이 방법의 계산 비용은 장면에 있는 사람의 수와 거의 무관하며 주로 특징 추출 프로세스의 비용에 따라 달라집니다.

이 시스템은 키포인트 외에도 각 사람에 대한 고밀도 인스턴스 분할 마스크를 예측하여 기하학적 임베딩 표현을 생성합니다. 효율적인 연관 알고리즘을 사용하여 모든 키포인트의 예측된 위치와 키포인트 감지 확률을 기반으로 각 픽셀을 사람에게 할당합니다.

이 시스템은 COCO 키포인트 데이터 세트에 대해 학습되며, 키포인트 평균 정밀도(AP)를 0.655에서 0.687로 개선하여 이전의 최상의 상향식 접근 방식보다 뛰어난 성능을 발휘합니다. 또한 COCO 인스턴스 세분화 작업의 사람 클래스에서 0.417의 마스크 AP로 경쟁력 있는 결과를 달성합니다. 이 방법은 간단하고 빠르며 두 번째 정제 단계나 클러스터링 알고리즘이 필요하지 않으므로 휴대폰 배포를 포함한 다양한 애플리케이션에 적합합니다.

### 2 Related work

이 연구의 접근 방식은 포즈 추정과 인스턴스 세분화라는 두 가지 주요 분야의 선행 연구와 관련이 있습니다.

포즈 추정의 경우, 이 연구는 사람을 구성 가능한 부분의 집합으로 표현하는 부분 기반 그래픽 모델을 사용한 초기의 성공적인 모델을 인정합니다. 최근에는 대규모 컨볼루션 네트워크를 사용하는 모델이 각광을 받고 있습니다. 사람 경계 상자를 먼저 식별하는 하향식과 신체 부위를 먼저 감지한 다음 사람 인스턴스로 그룹화하는 상향식의 두 가지 주요 접근 방식이 있습니다. 이 연구는 상향식 접근 방식을 따르고 있습니다.

인스턴스 세분화 방법도 하향식과 상향식으로 분류할 수 있습니다. 하향식 방법은 감지 모델을 사용하여 마스크 제안을 분류하거나 바운딩 박스 제안을 구체화하여 마스크 세분화 결과를 얻습니다. 상향식 접근 방식은 본 연구에서 사용한 방법과 유사하게 픽셀 수준 예측을 각 객체 인스턴스에 연결합니다. 언급된 상향식 방법에는 제안이 없는 네트워크를 사용하여 의미적 분할 결과를 클러스터링하는 방법부터 각 픽셀이 인스턴스 중심을 향하는 방향을 예측하고 템플릿 매칭을 사용하여 결과를 디코딩하고 클러스터링하는 방법까지 다양합니다. 다른 기법으로는 객체 깊이 순서를 인코딩하여 인스턴스 ID를 예측하고, 예측 인스턴스 클러스터링에 Hough 변환과 유사한 접근 방식을 사용하는 것 등이 있습니다. 이 연구에서는 이러한 상향식 방법 중 일부와 유사하게 여러 예측에 대한 Hough 투표를 활용합니다.

### 3 Methods

이 단원에서는 사람 감지 및 포즈 추정에 대한 상향식 접근 방식에 대해 설명합니다. 이 접근 방식은 키포인트 감지와 키포인트를 사람 인스턴스로 그룹화하는 두 단계로 나뉩니다.

![우리의 PersonLab 시스템은 다음을 예측하는 CNN 모델로 구성되어 있다: (1) 키포인트 히트맵, (2) 단거리 오프셋, (3) 중거리 쌍 오프셋, (4) 사람 분할 맵, 그리고 (5) 장거리 오프셋. 처음 세 가지 예측값은 자세 추정 모듈(Pose Estimation Module)에 의해 사용되어 인간의 자세를 감지하며, 후자 두 가지는 인간의 자세 감지와 함께 인스턴스 분할 모듈(Instance Segmentation Module)에 의해 사용되어 사람 인스턴스 분할 마스크를 예측한다.](PersonLab%20Person%20Pose%20Estimation%20and%20Instance%20Segm%20c7e9e314100a43d78b10ea22716af985/Untitled.png)

우리의 PersonLab 시스템은 다음을 예측하는 CNN 모델로 구성되어 있다: (1) 키포인트 히트맵, (2) 단거리 오프셋, (3) 중거리 쌍 오프셋, (4) 사람 분할 맵, 그리고 (5) 장거리 오프셋. 처음 세 가지 예측값은 자세 추정 모듈(Pose Estimation Module)에 의해 사용되어 인간의 자세를 감지하며, 후자 두 가지는 인간의 자세 감지와 함께 인스턴스 분할 모듈(Instance Segmentation Module)에 의해 사용되어 사람 인스턴스 분할 마스크를 예측한다.

키포인트 감지: 이 단계에서는 이미지에 있는 모든 사람의 눈에 보이는 키포인트를 감지합니다. 이 경우 키포인트는 17개의 얼굴 및 신체 부위입니다. 하이브리드 분류 및 회귀 접근 방식을 사용하여 히트맵(키포인트당 하나)과 오프셋(수평 및 수직 방향의 변위에 대해 키포인트당 두 개)을 생성합니다. 키포인트는 이미지에서 특정 키포인트 유형의 사람 주위에 반경 R의 디스크를 예측하여 감지됩니다. 또한 시스템은 단거리 오프셋 벡터를 예측하여 키포인트 위치 정확도를 향상시킵니다. 그런 다음 히트맵과 단거리 오프셋을 허우 투표를 사용하여 2-D 허우 점수 맵으로 집계합니다.

키포인트를 사람 감지 인스턴스로 그룹화합니다: 여기에는 감지된 키포인트를 개별 사람 인스턴스와 연결하는 작업이 포함됩니다. 이를 위해 시스템은 중간 범위 쌍별 오프셋과 반복 오프셋 개선 기법을 사용합니다. 중간 범위 쌍별 오프셋은 키포인트 쌍을 연결하도록 설계된 별도의 2D 오프셋 필드 출력입니다. 반복 오프셋 개선은 보다 정확한 단거리 오프셋을 사용하여 중간 범위 쌍별 오프셋을 개선함으로써 대규모 인물 인스턴스에 대한 정확한 회귀를 생성하는 데 따르는 어려움을 해결합니다. 빠른 욕심 디코딩 알고리즘은 키포인트를 감지된 사람 인스턴스로 그룹화하는 데 사용됩니다.

![중거리 오프셋. (a) RightElbow 키포인트를 시작으로 RightShoulder 키포인트를 가리키는 초기 중거리 오프셋. (b) 단거리 오프셋을 사용한 중거리 오프셋 정제. (c) 정제 후의 중거리 오프셋.](PersonLab%20Person%20Pose%20Estimation%20and%20Instance%20Segm%20c7e9e314100a43d78b10ea22716af985/Untitled%201.png)

중거리 오프셋. (a) RightElbow 키포인트를 시작으로 RightShoulder 키포인트를 가리키는 초기 중거리 오프셋. (b) 단거리 오프셋을 사용한 중거리 오프셋 정제. (c) 정제 후의 중거리 오프셋.

키포인트 및 인스턴스 수준 감지 점수: 탐지에 점수를 할당하는 데는 두 가지 방법이 사용됩니다. 첫 번째 방법은 각 키포인트에 신뢰도 점수를 할당합니다. 두 번째 접근 방식은 객체 키포인트 유사성(OKS) 평가 메트릭을 기반으로 서로 다른 키포인트 유형의 점수를 보정하려고 시도합니다. 예상되는 OKS 키포인트 수준 점수를 계산하고, 키포인트 점수의 평균을 인스턴스 수준 점수로 사용합니다.

![사람 분할 마스크에서 정의된 장거리 오프셋. (a) 예상된 사람 분할 맵. (b) Nose 목표 키포인트를 위한 초기 장거리 오프셋: 사람 분할 마스크의 전경의 각 픽셀은 해당 인스턴스의 Nose 키포인트를 가리킨다. (c) 단거리 오프셋으로 정제된 후의 장거리 오프셋.](PersonLab%20Person%20Pose%20Estimation%20and%20Instance%20Segm%20c7e9e314100a43d78b10ea22716af985/Untitled%202.png)

사람 분할 마스크에서 정의된 장거리 오프셋. (a) 예상된 사람 분할 맵. (b) Nose 목표 키포인트를 위한 초기 장거리 오프셋: 사람 분할 마스크의 전경의 각 픽셀은 해당 인스턴스의 Nose 키포인트를 가리킨다. (c) 단거리 오프셋으로 정제된 후의 장거리 오프셋.

이 시스템은 COCO 데이터 세트의 얼굴 및 신체 부위에 대한 지상 실측 주석을 사용하여 학습되었습니다. 실험 결과, 이 방법은 인물의 많은 부분이 가려진 상황을 포함하여 사람 감지 및 포즈 추정의 정확도를 향상시키는 것으로 나타났습니다.

설명한 인스턴스 수준 사람 세분화 접근 방식에는 시맨틱 사람 세분화와 연관성이라는 두 가지 주요 모듈이 포함됩니다.

의미론적 사람 세분화는 완전 컨볼루션 접근 방식을 통해 이루어집니다. 이는 각 픽셀에서 로지스틱 회귀를 수행하여 해당 픽셀이 사람에 속할 가능성을 결정하는 단일 1x1 컨볼루션 레이어로 구성된 시맨틱 세그먼테이션 헤드를 사용합니다. 훈련 중에 로지스틱 손실의 평균이 계산되고 사람 세분화 주석이 있는 모든 영역에 대해 역전파됩니다.

![시맨틱 분할에서 인스턴스 분할까지: (a) 이미지; (b) 사람 분할; (c) Nose 키포인트로의 장거리 오프셋에 의해 정의된 중력 분포 영역; (d) 인스턴스 분할 마스크.](PersonLab%20Person%20Pose%20Estimation%20and%20Instance%20Segm%20c7e9e314100a43d78b10ea22716af985/Untitled%203.png)

시맨틱 분할에서 인스턴스 분할까지: (a) 이미지; (b) 사람 분할; (c) Nose 키포인트로의 장거리 오프셋에 의해 정의된 중력 분포 영역; (d) 인스턴스 분할 마스크.

연관 단계는 의미적 분할 모듈에 의해 사람의 일부로 식별된 각 픽셀을 사람 감지 및 포즈 추정 모듈의 키포인트 수준 감지에 연결하는 것을 목표로 합니다. 이는 임베딩 기반 방식을 통해 이루어집니다. 사람 인스턴스의 세분화 마스크 내의 각 픽셀 위치에서 해당 픽셀에서 해당 키포인트의 위치를 가리키는 장거리 오프셋 벡터가 정의됩니다. 훈련 중에 장거리 오프셋 회귀 오류는 L1 손실을 사용하여 페널티를 받습니다.

그러나 이러한 장거리 오프셋을 예측하는 것은 특히 이미지 전체를 덮는 큰 물체의 경우 어려울 수 있습니다. 이를 해결하기 위해 장거리 오프셋은 반복적으로 개선됩니다. 장거리 오프셋 예측 정확도가 개선된 것은 반복적인 세분화 때문입니다.

설명한 접근 방식은 주어진 픽셀이 속한 사람 인스턴스의 모든 키포인트의 절대 위치에 대한 로컬 추정치의 측정값으로 임베딩 벡터 G(x)를 사용합니다. 픽셀이 특정 사람 인스턴스에 속하는지 여부를 결정하기 위해 임베딩 거리 메트릭이 계산됩니다.

인스턴스 분할을 완료하기 위해 시맨틱 분할 맵에서 "사람"으로 표시된 모든 픽셀 위치를 찾고 각 사람 픽셀을 임베딩 거리 메트릭이 특정 기준을 충족하는 모든 감지된 사람 인스턴스와 연결하는 프로세스가 포함됩니다.

또한 작은 사람 인스턴스에 대한 COCO 데이터 세트의 키포인트 주석이 누락되는 문제를 해결하기 위해 1인 포즈 추정기를 사용하여 키포인트를 할당했습니다. 이 단계는 작은 사람 인스턴스의 인스턴스 세분화 성능에 매우 중요합니다. 그러나 이 과정에서는 COCO 훈련 세트 이미지와 주석만 사용되었으며 추가 데이터는 통합되지 않았습니다.

### 4 Experimental evaluation

섹션 4에서는 저자들이 제안한 PersonLab 시스템에 대한 실험적 평가를 제공합니다. 실험은 사람 클래스에 대한 COCO 키포인트 작업과 COCO 인스턴스 분할에 대해 수행되었습니다.

실험을 위한 훈련 세트에는 사람이 포함된 2017년 COCO 훈련 세트 이미지의 하위 집합이 포함되었으며, 총 64115개의 이미지가 포함되었습니다. 검증 세트는 5000개의 이미지로 구성된 2017 COCO 검증 세트였습니다.

저자들은 이미지넷 분류 작업에 대해 사전 훈련된 ResNet-101 및 ResNet-152 CNN 백본을 사용했습니다. 모델의 최종 레이어는 폐기하고 각 모델별 레이어에 대해 1x1 컨볼루션 레이어를 추가했습니다. 훈련 과정에서 이미지의 무작위 크기 조정, 변환, 뒤집기 등 다양한 데이터 증강 기법을 사용했습니다. 학습률은 1e-3, 모멘텀 값은 0.9로 설정한 확률론적 경사 하강을 사용하여 모델을 훈련하고 Polyak-Ruppert 모델 파라미터 평균을 사용했습니다.

그 결과, 단일 규모 추론 결과가 CMU-Pose 및 연관 임베딩과 같은 상향식 방법과 Mask-RCNN 및 G-RMI와 같은 하향식 방법 모두의 결과보다 우수한 것으로 나타났습니다. 그러나 이 모델의 성능은 2017년 키포인트 챌린지(Megvii)의 우승자들에 비해서는 여전히 뒤처졌습니다.

인스턴스 세분화 측면에서 저자들의 방법은 단일 규모 및 다중 규모 추론 설정 모두에서 FCIS보다 성능이 뛰어났으며, 중간 규모 및 대규모 사람 인스턴스에서는 Mask-RCNN과 비슷한 성능을 보였으나 소규모 사람 인스턴스에서는 성능이 떨어졌습니다.

또한 저자들은 단일 규모 추론으로 모델이 생성한 COCO val 이미지에 대한 대표적인 사람 포즈 및 인스턴스 분할 결과를 보여주는 정성적 평가도 제공했습니다.

### 5 Conclusions

결론에서 저자는 통합된 부분 기반 모델링 접근 방식을 통해 사람 감지, 포즈 추정, 인스턴스 세분화 작업을 처리할 수 있는 상향식 모델을 개발하는 성과를 다시 한 번 강조합니다. 이 방법의 효과는 까다로운 COCO 사람 키포인트 및 인스턴스 세분화 작업에 대한 테스트를 통해 검증되었습니다.

그러나 이 접근 방식에는 인스턴스 세분화 작업에 대한 학습을 위해 키포인트 수준 주석에 의존한다는 중요한 한계가 있음을 인정하고 있습니다. 이는 잠재적으로 이러한 정밀한 주석을 사용할 수 없는 다른 컨텍스트에 대한 방법의 확장성이나 적용 가능성을 제한할 수 있습니다.

앞으로 저자들은 이러한 한계를 극복하기 위한 해결책을 모색할 의사를 밝혔습니다. 한 가지 잠재적인 방향은 약하게 감독되는 부분 검색을 사용하는 것인데, 이는 모델 학습 과정에서 덜 상세한 주석이나 레이블이 없는 데이터까지 활용할 수 있는 방법을 제공할 수 있습니다. 이렇게 하면 이 방법을 더 유연하고 광범위하게 적용할 수 있어 잠재적으로 이 접근법의 새로운 사용 영역을 열 수 있습니다.

### Appendix

저자들은 다양한 모델 선택이 시스템 성능에 미치는 영향을 평가하기 위해 일련의 제거 실험을 수행했습니다. 모든 절제 테스트에는 ResNet-101 모델과 단일 척도 추론이 사용되었습니다. 요약된 결과는 다음과 같습니다:

A.1 - 입력 이미지 크기와 출력 활성화 보폭을 변경한 결과, 저자들은 출력 활성화를 더 조밀하게 계산할 때(즉, 출력 보폭을 32픽셀에서 16픽셀로 줄임) 모델 성능이 크게 증가하는 것을 관찰했습니다. 8픽셀로 더 줄이면 성능이 약간 향상되었지만 계산 비용이 상당히 증가했습니다. 큰 사람 인스턴스의 크기를 601 또는 801픽셀로 조정하면 키포인트 AP 성능은 허용 가능한 수준이었지만, 작은 사람 인스턴스를 캡처하려면 더 높은 해상도의 입력 이미지가 필요했습니다.

![COCO val 이미지 시각화. 마지막 행은 일부 실패 사례를 보여준다: 누락된 키포인트 검출, 거짓 양성 키포인트 검출, 그리고 누락된 분할.](PersonLab%20Person%20Pose%20Estimation%20and%20Instance%20Segm%20c7e9e314100a43d78b10ea22716af985/Untitled%204.png)

COCO val 이미지 시각화. 마지막 행은 일부 실패 사례를 보여준다: 누락된 키포인트 검출, 거짓 양성 키포인트 검출, 그리고 누락된 분할.

A.2 - 두 가지 키포인트 점수 매기기법을 비교한 결과, 저자들은 제안된 예상-OKS 키포인트 점수 매기기법과 소프트-NMS 모두 대안에 비해 AP가 크게 개선되었음을 발견했습니다.

A.3 - 중장거리 오프셋 개선은 모델 키포인트 AP를 3.3%, 세분화 AP를 2.2% 향상시키는 것으로 나타났습니다. 대형 오브젝트 인스턴스의 경우 키포인트는 +5.4%, 세분화는 +9.1%로 가장 큰 개선이 관찰되었습니다.

A.4 - 작은 COCO 사람 인스턴스의 키포인트를 임포트하여 모델 훈련에 사용하면 이러한 인스턴스는 COCO 키포인트 평가 프로토콜에 포함되지 않기 때문에 COCO 키포인트 작업의 성능이 0.8% 약간 감소했습니다. 그러나 COCO 세분화 작업의 경우 키포인트 대입을 통해 성능이 4.4% 크게 향상되었으며, 특히 AP가 7.6%에서 16.4%로 두 배 이상 증가한 작은 물체의 경우 성능이 크게 향상되었습니다.

이러한 실험을 통해 가장 효과적인 구성과 접근 방식을 파악하여 시스템 성능을 최적화하는 데 도움이 되었습니다.