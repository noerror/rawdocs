# NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis

[https://arxiv.org/abs/2003.08934](https://arxiv.org/abs/2003.08934)

[https://www.matthewtancik.com/nerf](https://www.matthewtancik.com/nerf)

이 글에서는 장면을 연속적인 체적 함수로 표현하는 심층 네트워크를 사용하여 복잡한 장면의 새로운 뷰를 만드는 방법을 소개합니다. 네트워크는 5D 좌표(공간적 위치 및 보는 방향)를 입력받아 해당 지점의 밀도와 색상을 출력합니다. 새로운 뷰는 카메라 광선을 따라 좌표를 쿼리하고 볼륨 렌더링을 사용하여 출력 색상과 밀도를 이미지에 투영하여 생성됩니다. 이 표현을 최적화하는 데 필요한 유일한 입력은 카메라 위치가 알려진 이미지 세트입니다. 이 문서에서는 이 방법이 뉴럴 렌더링 및 뷰 합성에 대한 이전 작업보다 성능이 뛰어나다는 것을 보여줍니다. 더 나은 이해를 위해 보충 동영상을 시청하는 것이 좋습니다.

1

![Untitled](NeRF%20Representing%20Scenes%20as%20Neural%20Radiance%20Fields%2069855d8d4bed40dbb3cbb159a683f4b2/Untitled.png)

이 글에서는 캡처한 이미지 세트에서 사실적인 장면 이미지를 만드는 새로운 방법을 소개합니다. 이 방법은 장면을 공간의 각 지점에 대한 광도와 밀도를 출력하는 연속적인 5D 함수로 표현합니다. 이 표현을 최적화하기 위해 신경망을 사용하고, 카메라 광선을 장면을 통과하면서 신경망을 사용하여 색상과 밀도를 계산하고, 고전적인 볼륨 렌더링을 사용하여 2D 이미지로 결합하는 방식으로 이미지를 렌더링합니다. 이 방법은 위치 인코딩과 계층적 샘플링 전략을 사용하여 저해상도 및 높은 스토리지 비용 문제를 극복합니다. 이 기사에서는 이 방법이 이전 방법보다 성능이 뛰어나며 캡처한 RGB 이미지에서 실제 물체와 장면의 사실적인 이미지를 만들 수 있음을 보여줍니다.

2 Related Work

이 문서에서는 MLP의 가중치로 장면과 객체를 인코딩하여 도형의 암시적 표현을 생성하기 위한 컴퓨터 비전의 최근 개발에 대해 설명합니다. 그러나 이러한 방법은 아직 트라이앵글 메시나 복셀 그리드와 같은 이산 표현을 사용하는 기술만큼 복잡한 기하학적 구조를 가진 사실적인 장면을 정확하게 생성할 수 없었습니다. 이 문서에서는 이러한 이전 방법의 한계를 검토하고 네트워크를 최적화하여 5D 방사 필드를 인코딩하여 복잡한 장면의 고해상도 지오메트리와 사실적인 새로운 뷰를 생성하는 새로운 접근 방식을 소개합니다. 또한 메시 및 볼류메트릭 표현을 위한 차별적인 렌더링 및 패스트레이싱 기법에 대해 설명하며 복잡한 모양과 머티리얼에 볼류메트릭 표현을 사용할 때의 이점을 강조합니다. 그러나 이러한 방법은 이산 샘플링으로 인해 시간과 공간의 복잡성이 떨어지는 반면, 새로운 접근 방식은 완전히 연결된 심층 신경망 내에서 연속적인 볼륨을 인코딩하여 더 낮은 스토리지 비용으로 더 높은 품질의 렌더링을 제공합니다.

3 Neural Radiance Field Scene Representation

![신경 방사 필드 장면 표현 및 차별적 렌더링 절차의 개요. 카메라 광선을 따라 5D 좌표(위치, 보는 방향)를 샘플링하여 (위치 및 보는 방향)을 샘플링하여 이미지를 합성하고(a), 해당 위치를 MLP에 공급하여 MLP에 공급하여 색상 및 볼륨 밀도를 생성하고(b), 볼륨 렌더링 기법을 사용하여 이러한 값을 이미지에 합성합니다(c). 이 렌더링 함수는 차별화 가능하므로 합성된 이미지와 실측 관측 이미지 사이의 잔차를 최소화하여 장면 표현을 최적화할 수 있습니다(d).](NeRF%20Representing%20Scenes%20as%20Neural%20Radiance%20Fields%2069855d8d4bed40dbb3cbb159a683f4b2/Untitled%201.png)

신경 방사 필드 장면 표현 및 차별적 렌더링 절차의 개요. 카메라 광선을 따라 5D 좌표(위치, 보는 방향)를 샘플링하여 (위치 및 보는 방향)을 샘플링하여 이미지를 합성하고(a), 해당 위치를 MLP에 공급하여 MLP에 공급하여 색상 및 볼륨 밀도를 생성하고(b), 볼륨 렌더링 기법을 사용하여 이러한 값을 이미지에 합성합니다(c). 이 렌더링 함수는 차별화 가능하므로 합성된 이미지와 실측 관측 이미지 사이의 잔차를 최소화하여 장면 표현을 최적화할 수 있습니다(d).

이 문서에서는 입력은 3D 위치와 2D 보는 방향이고 출력은 방출된 색상과 볼륨 밀도인 5D 벡터값 함수로 연속 장면을 표현하는 방법을 소개합니다. 이 방법은 MLP 네트워크를 사용하여 이 표현을 근사화하고 가중치를 최적화하여 각 입력 좌표를 해당 색상과 밀도에 매핑합니다. 이 표현은 밀도를 위치의 함수로만 예측하고 색상은 위치와 보는 방향 모두의 함수로 예측하여 멀티뷰 일관성을 유지하도록 설계되었습니다. MLP 네트워크는 먼저 완전히 연결된 레이어로 위치 입력을 처리하고 밀도와 특징 벡터를 출력한 다음, 카메라 광선의 보기 방향과 연결하여 완전히 연결된 다른 레이어로 전달하여 보기에 따라 달라지는 RGB 색상을 출력합니다. 이 기사에서는 이 방법이 보는 방향을 사용하면 스페큘러와 같은 비램버시안 효과를 표현하는 능력이 향상된다는 것을 보여줍니다.

4 Volume Rendering with Radiance Fields

이 문서에서는 5D 신경 방사 필드로 표현되는 씬의 뷰를 렌더링하는 방법에 대해 설명합니다. 이 필드는 공간의 모든 지점에서의 볼륨 밀도와 방향성 방출 광원을 나타냅니다. 뷰를 렌더링하기 위해 이 문서에서는 씬을 통과하는 카메라 광선의 예상 색상을 광선을 따라 체적 밀도와 방향 방출 방사광의 적분을 추정하여 계산하는 고전적인 볼륨 렌더링 원리를 사용합니다. 이 문서에서는 계층화된 샘플링 접근 방식을 사용하여 이 연속 적분을 수치적으로 추정하며, 적분은 구적법 규칙을 사용하여 추정됩니다. 이를 통해 최적화 중에 연속 위치에서 MLP 네트워크가 평가되므로 연속 장면을 표현할 수 있습니다. 이 문서에서는 (색상, 밀도) 값 집합에서 카메라 광선의 예상 색상을 계산하는 이 함수가 미분 가능하며 알파 값을 사용한 기존 알파 합성으로 축소된다는 것을 보여줍니다.

5 Optimizing a Neural Radiance Field

이 섹션에서는 신경 방사장을 사용하여 고해상도의 복잡한 장면을 보다 효과적으로 표현하기 위한 두 가지 개선 사항을 소개합니다.

첫째, 위치 인코딩을 사용하여 다층 퍼셉트론(MLP)이 고주파 함수를 더 잘 표현할 수 있도록 합니다. 이는 입력 좌표를 고차원 공간에 매핑하여 MLP가 고주파 함수에 더 쉽게 근사화할 수 있도록 함으로써 달성됩니다.

둘째, 렌더링 효율성을 개선하기 위해 계층적 샘플링 절차가 제안됩니다. 단일 네트워크를 사용하는 대신 두 개의 네트워크("거친" 및 "미세")가 동시에 최적화됩니다. "거친" 네트워크는 각 광선을 따라 정보에 입각한 포인트 샘플링을 제공하고, "미세" 네트워크는 첫 번째와 두 번째 샘플 세트의 합에서 평가하여 보다 정확한 렌더링을 생성합니다.

이러한 개선 사항을 통해 보이는 콘텐츠가 있는 영역에 더 많은 샘플을 할당할 수 있으므로 렌더링 효율성이 향상되고 최첨단 품질을 구현할 수 있습니다.

6 Results

제안된 방법은 모든 시나리오에서 장면당 별도의 네트워크를 최적화하는 기준선(NV 및 SRN)을 크게 능가하며, 거의 모든 지표에서 LLFF보다 더 나은 결과를 제공합니다. 두 방법의 주요 단점은 시간과 공간입니다. LLFF는 작은 입력 데이터 세트를 빠르게 처리할 수 있지만 저장 공간이 엄청나게 많이 필요합니다. 제안된 방법은 네트워크 가중치에 5MB만 필요하며, 이는 단일 장면에 대한 입력 이미지만 사용하는 것보다 훨씬 적은 메모리입니다.

제거 연구는 알고리즘의 설계 선택과 매개변수를 검증합니다. 위치 인코딩(PE), 뷰 의존성(VD), 계층적 샘플링(H)을 한 번에 하나씩 제거한 결과, PE와 VD가 가장 큰 양적 이점을 제공하고 계층적 샘플링이 그 뒤를 잇는 것으로 나타났습니다. 이 방법의 성능은 입력 이미지 수가 감소함에 따라 감소하지만 모든 메트릭에서 여전히 NV, SRN 및 LLFF를 능가합니다. 위치 인코딩에 사용되는 최대 주파수 L도 검증되며, 2L이 샘플링된 입력 이미지에 존재하는 최대 주파수를 초과하면 L 증가의 이점이 제한됩니다.

이 연구는 MLP를 사용하여 물체와 장면을 연속 함수로 표현하는 이전 방법의 단점을 해결합니다. 제안된 5D 신경 방사 필드는 이산화된 복셀 표현을 출력하는 딥 컨볼루션 네트워크보다 더 나은 렌더링을 생성합니다. 계층적 샘플링 전략은 렌더링의 샘플 효율을 높이기 위해 제안되었지만, 신경 방사 필드를 효율적으로 최적화하고 렌더링하는 데는 아직 더 많은 진전이 있어야 합니다. 향후 연구에서는 실제 이미지에서 최적화된 신경 방사 필드로 복잡한 장면을 구성하는 실제 이미지 기반 그래픽 파이프라인을 개발하고 해석 가능성에 초점을 맞출 수 있습니다. 저자들은 사실적인 합성 데이터 세트에 대한 지원과 의견, 기여를 해주신 여러 개인과 조직에 감사를 표합니다.

- MLP
    
    MLP는 인공 신경망의 일종인 다층 퍼셉트론(Multi-Layer Perceptron)의 약자입니다. 서로 연결된 여러 계층의 노드 또는 뉴런으로 구성되며, 각 계층은 이전 계층에서 입력을 받아 다음 계층으로 출력을 전달합니다. MLP에는 일반적으로 입력 레이어, 하나 이상의 숨겨진 레이어, 출력 레이어의 세 가지 유형의 레이어가 있습니다.
    
    MLP의 주요 기능은 입력 데이터와 출력 레이블 또는 값 사이의 비선형 매핑을 학습하는 것입니다. 이는 예측된 출력과 실제 출력 간의 오차에 따라 네트워크의 가중치를 조정하여 학습하는 역전파라는 프로세스를 통해 이루어집니다. MLP는 분류, 회귀, 패턴 인식 등 다양한 머신 러닝 작업에 널리 사용됩니다.
    
    MLP의 중요한 특징은 입력과 출력 간의 복잡한 비선형 관계를 학습할 수 있어 다양한 애플리케이션에 적합하다는 점입니다. 그러나 네트워크에 숨겨진 레이어나 뉴런이 많은 경우 특히 과적합이 발생하기 쉽습니다. 이 문제를 해결하기 위해 훈련 과정에서 정규화 기법과 조기 중지 방법이 자주 사용됩니다.
    
- MLP의 입력과 출력
    
    MLP(다층 퍼셉트론)는 상호 연결된 여러 계층을 통해 데이터를 처리하는 인공 신경망의 일종입니다. 입력을 받아 이러한 계층을 통해 처리한 후 출력을 생성합니다. 다음은 MLP의 입력과 출력에 대한 간략한 설명입니다:
    
    - 입력: MLP의 입력은 네트워크에서 처리할 데이터를 나타내는 특징 또는 값의 집합입니다. 이러한 특징은 이미지의 픽셀 값과 같은 원시 데이터일 수도 있고, 일부 특징 추출 기법의 결과와 같이 사전 처리된 데이터일 수도 있습니다. 입력은 네트워크에 벡터로 표시되며, 벡터의 각 요소는 특정 특징에 해당합니다. MLP의 입력 계층은 입력 데이터의 특징 수와 동일한 수의 노드를 갖습니다. 입력 계층의 각 노드는 단일 특징 값을 수신하고 선택적 가중치를 적용한 후 다음 계층인 첫 번째 숨겨진 계층으로 전달합니다.
    - 출력: MLP의 출력은 해결하도록 설계된 문제에 따라 달라집니다. 분류 문제의 경우 출력 계층은 일반적으로 클래스당 하나의 노드를 가지며 출력은 클래스에 대한 확률 분포입니다. 이 경우 출력 계층에 사용되는 활성화 함수는 일반적으로 소프트맥스 함수이며, 이 함수는 출력 값을 정규화하여 합이 1이 되도록 합니다. 회귀 문제의 경우, 출력 레이어에는 일반적으로 단일 노드가 있으며 출력은 예측된 목표 값을 나타내는 연속 값입니다. 이 경우 출력 계층의 활성화 함수는 문제 영역에 따라 선형 또는 다른 적절한 함수일 수 있습니다.
    
    MLP에서 입력을 출력으로 변환하는 과정에는 상호 연결된 여러 계층의 노드 또는 뉴런을 통해 데이터를 전달하는 과정이 포함됩니다. 각 뉴런은 이전 레이어에서 입력을 수신하고, 각 입력에 가중치를 적용하고, 가중치가 적용된 입력을 합산하고, 바이어스 항을 추가한 다음 활성화 함수를 적용합니다. 그런 다음 결과가 다음 레이어로 전달됩니다. 가중치와 바이어스는 훈련 과정에서 학습되므로 MLP가 원하는 입력-출력 관계를 근사화할 수 있습니다.
    
- Nerf MLP의 입력과 출력
    
    NeRF(신경 방사 필드)의 맥락에서 멀티 레이어 퍼셉트론(MLP)은 3D 씬의 방사 필드를 표현하는 데 사용됩니다. NeRF MLP의 입력 및 출력은 다음과 같습니다:
    
    - 입력: NeRF MLP에 대한 입력은 공간의 한 점을 나타내는 3D 공간 좌표(x, y, z)와 점을 관찰하는 방향을 나타내는 2D 보기 방향(θ, φ)으로 구성된 5D 벡터입니다. 3D 공간 좌표는 씬 내 포인트의 위치를 나타내며, 2D 시청 방향은 씬의 반사 및 하이라이트와 같은 뷰 의존적 효과를 설명합니다.
    - 출력: NeRF MLP의 출력은 볼륨 밀도(σ)와 뷰에 따라 달라지는 방출 광도(RGB)의 두 가지 구성 요소로 구성됩니다. 볼륨 밀도는 주어진 3D 공간 좌표에 존재하는 머티리얼의 불투명도 또는 양을 나타냅니다. 뷰 종속 방출 광도는 지정된 보기 방향의 지점에서 방출되는 빛의 색상과 강도를 나타냅니다.
    
    NeRF MLP는 다양한 시점에서 캡처한 2D 이미지 세트에서 3D 장면의 복사장을 근사화하는 방법을 학습합니다. 다양한 공간 좌표와 보기 방향을 입력하면 원래 훈련 세트에 포함되지 않았더라도 NeRF MLP는 장면의 새로운 뷰를 생성할 수 있습니다. 이를 통해 고품질의 뷰를 합성하고 뷰 종속 효과가 있는 복잡한 장면을 재구성할 수 있습니다.
    
- Nerf 의 밀도 학습
    
    밀도에 대한 NeRF(신경 방사 필드)를 훈련한다는 것은 모델에 씬의 3D 구조를 이해하도록 가르치는 것을 의미합니다. 프로세스에 대한 간단한 설명은 다음과 같습니다:
    
    - 이미지 수집: 다양한 각도와 위치에서 장면의 이미지 세트를 캡처합니다. 이러한 이미지는 모델 학습을 위한 기준 데이터로 사용됩니다.
    - 광선 샘플링: 각 입력 이미지에 대해 카메라의 위치에서 시작하여 이미지의 각 픽셀을 통과하는 광선 세트를 만듭니다. 이 광선은 카메라로 들어오는 빛의 경로를 나타냅니다.
    - 포인트 샘플링: 각 광선을 따라 카메라에서 서로 다른 거리에 있는 여러 3D 포인트를 샘플링합니다. 이 포인트는 광선을 따라 장면의 밀도와 색상을 추정하는 데 사용됩니다.
    - 보기 방향 계산: 각 3D 포인트에 대해 포인트에서 카메라까지의 방향을 나타내는 단위 벡터를 계산합니다. 이를 보기 방향이라고 하며 반사와 같은 보기에 따른 효과를 설명하기 위해 NeRF 모델에서 사용됩니다.
    - NeRF 모델 입력: 3D 포인트 좌표와 해당 보기 방향을 다층 퍼셉트론(MLP)인 NeRF 모델에 입력합니다. 모델은 각 포인트에 대한 밀도(볼륨 밀도)와 방출된 광원(색상)을 출력합니다.
    - 볼륨 렌더링: 각 광선에 대해 샘플링된 포인트의 밀도와 색상을 통합하여 이미지의 해당 픽셀에 대한 최종 색상 기여도를 계산합니다. 이 프로세스는 오클루전과 광선을 따라 흐르는 머티리얼의 밀도를 고려합니다.
        
        NeRF(신경 방사 필드)에서 광선을 따라 오클루전 및 머티리얼의 밀도를 처리하는 프로세스에는 볼륨 렌더링이라는 기술이 포함됩니다. 이 기술은 각 광선을 따라 샘플링된 지점의 밀도와 색상 값을 통합하여 이미지의 해당 픽셀에 대한 최종 색상 기여도를 생성하는 데 사용됩니다. 단계별 설명은 다음과 같습니다:
        
        - 포인트 샘플링: 각 광선을 따라 카메라로부터 서로 다른 거리에 있는 여러 3D 포인트를 샘플링합니다. 이 포인트는 광선을 따라 장면의 밀도(부피 밀도)와 색상(방출된 방사광)을 추정하는 데 사용됩니다.
        - NeRF 모델 평가: 각 3D 포인트에 대해 해당 좌표와 해당 보기 방향을 NeRF 모델(다층 퍼셉트론)에 입력합니다. 모델은 각 포인트에 대한 밀도와 방출된 방사광을 출력합니다.
        - 투과율 계산: 각 광선을 따라 연속적으로 샘플링된 점 사이의 투과율을 계산합니다. 투과율은 흡수되거나 산란되지 않고 재료를 통과하는 빛의 비율을 나타냅니다. 투과율은 밀도와 연속된 점 사이의 거리의 음의 곱의 지수를 취하여 계산합니다.
            
            투과율 계산은 볼륨 렌더링의 중요한 단계로, 흡수되거나 산란되지 않고 매체를 통과하는 빛의 양을 결정하는 데 도움이 됩니다. NeRF(신경 방사 필드)의 경우, 투과율 계산은 연속적으로 샘플링된 지점에 대해 각 광선을 따라 수행됩니다.
            
            투과율 계산 프로세스에 대한 자세한 설명은 다음과 같습니다:
            
            - 광선을 따라 샘플 포인트: 각 광선에 대해 카메라로부터 서로 다른 거리에서 여러 3D 포인트가 샘플링됩니다. 이러한 포인트는 광선을 따라 씬의 밀도(볼륨 밀도)를 추정하는 데 사용됩니다.
            - 밀도 얻기: 각 3D 포인트에 대해 포인트의 좌표와 해당 보기 방향이 입력으로 제공되면 NeRF 모델(다층 퍼셉트론)이 밀도 값을 출력합니다.
            - 세그먼트 길이 계산: 광선을 따라 연속적으로 샘플링된 점 사이의 거리를 계산합니다. 이 거리는 점 사이의 세그먼트 길이를 나타냅니다.
            - 광학 깊이를 계산합니다: 각 포인트의 밀도 값에 해당 세그먼트 길이를 곱합니다. 결과는 각 세그먼트의 광학 깊이로, 빛이 해당 세그먼트를 통과할 때 감쇠되는 정도를 측정합니다.
            - 투과율을 계산합니다: 투과율은 흡수되거나 산란되지 않고 매체를 통과하는 빛의 비율입니다. 광선을 따라 연속된 점 사이의 투과율을 계산하려면 각 세그먼트에 대한 광학 깊이의 음수의 지수를 구합니다. 수학적으로 투과율 T는 T = exp(-옵티컬_뎁스)로 나타낼 수 있습니다.
            
            광선을 따라 투과율을 계산하면 씬의 각 지점에서 얼마나 많은 빛이 흡수되거나 산란되는지 파악할 수 있습니다. 이 정보는 NeRF와 같은 기술을 사용하여 장면을 렌더링할 때 정확하고 사실적인 이미지를 생성하는 데 매우 중요합니다.
            
        - 가중치 색상 누적: 광선을 따라 샘플링된 각 지점에 대해 방출된 광도에 해당 지점까지의 투과율(카메라에서)을 곱하여 가중 색상 기여도를 계산합니다. 이 단계에서는 광선을 따라 소재의 밀도와 해당 지점에 도달하기 전에 흡수되거나 산란되는 빛의 양을 고려합니다.
        - 색상 통합: 광선을 따라 샘플링된 모든 지점의 가중치 있는 색상 기여도를 합산하여 이미지의 해당 픽셀에 대한 최종 색상 기여도를 계산합니다. 이 통합 단계에서는 오클루전을 고려하는데, 투과율이 높은 밀도가 높은 가까운 포인트가 최종 색상에 더 많이 기여하므로 카메라에서 멀리 떨어진 포인트는 효과적으로 오클루전됩니다.
        
        볼륨 렌더링을 사용하여 샘플링된 포인트의 밀도와 색상 값을 통합함으로써 NeRF는 광선을 따라 오클루전 및 머티리얼의 밀도를 고려한 고품질 이미지를 생성할 수 있습니다.
        
    - 손실 계산: 생성된 이미지(광선으로부터 계산된 색상 포함)를 실제 입력 이미지와 비교합니다. 일반적으로 평균 제곱 오차(MSE)와 같은 메트릭을 사용하여 두 이미지의 차이로 손실을 계산합니다.
    - 모델 업데이트: 경사 하강과 같은 최적화 알고리즘을 사용하여 손실을 최소화하기 위해 NeRF 모델의 매개변수(가중치)를 업데이트합니다. 즉, 정확한 밀도와 색상을 더 잘 예측할 수 있도록 모델을 조정합니다.
    
    이러한 단계를 수행하면 NeRF 모델이 장면의 밀도를 표현하는 방법을 학습하여 새로운 관점에서 장면의 고품질 이미지를 생성할 수 있습니다.
    
- Positional Encoding
    
    위치 인코딩은 모델이 장면의 고주파 디테일을 캡처하는 능력을 향상시키기 위해 NeRF(신경 방사 필드) 프레임워크에서 사용되는 필수 기술입니다. 여기에는 입력 좌표(3D 위치 및 2D 보기 방향)를 인코딩한 후 장면을 나타내는 MLP(다층 퍼셉트론)에 공급하는 과정이 포함됩니다.
    
    NeRF에서는 주파수가 다른 사인 및 코사인 함수를 사용하여 위치 인코딩을 적용합니다. 이 인코딩의 목적은 원래 좌표를 고차원 공간으로 변환하여 입력 피처의 표현력을 높이고, 모델이 입력과 예측하는 광도 및 밀도 값 사이의 복잡한 관계를 더 잘 포착할 수 있도록 하는 것입니다.
    
    NeRF에서 위치 인코딩을 적용하는 과정은 다음과 같습니다:
    
    1. 주파수를 정의합니다: 입력 좌표를 인코딩하는 데 사용할 주파수 세트를 선택합니다. 이러한 주파수는 일반적으로 낮은 주파수부터 높은 주파수까지 다양하므로 모델이 장면에서 다양한 수준의 디테일을 캡처할 수 있습니다.
    2. 사인 및 코사인 함수를 적용합니다: 각 입력 좌표(3D 위치 또는 2D 보기 방향)에 대해 좌표 값의 사인과 코사인에 각 주파수를 곱한 값을 계산합니다. 이렇게 하면 각 좌표-주파수 쌍에 대해 두 개의 값이 생성됩니다.
    3. 인코딩을 연결합니다: 모든 좌표와 주파수에 대해 2단계에서 얻은 사인과 코사인 값을 결합합니다. 이렇게 하면 MLP에 인코딩된 입력으로 사용되는 고차원 벡터가 형성됩니다.
    4. 인코딩된 입력을 MLP에 입력: 연결된 위치 인코딩을 MLP의 입력으로 사용하여 주어진 3D 위치 및 시청 방향에 대한 조도 및 밀도 값을 예측합니다.
    
    위치 인코딩은 입력 좌표와 원하는 출력 값 사이의 복잡한 관계를 학습하는 모델의 능력을 향상시키기 때문에 NeRF의 중요한 구성 요소입니다. 위치 인코딩이 없으면 모델이 고주파 디테일을 캡처하는 데 어려움을 겪어 렌더링의 정확도가 떨어지고 현실감이 떨어질 수 있습니다.