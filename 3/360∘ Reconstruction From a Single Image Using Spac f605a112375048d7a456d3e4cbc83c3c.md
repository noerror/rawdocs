# 360∘ Reconstruction From a Single Image Using Space Carved Outpainting

[https://arxiv.org/abs/2309.10279](https://arxiv.org/abs/2309.10279)

[http://cg.postech.ac.kr/research/POP3D/](http://cg.postech.ac.kr/research/POP3D/)

- Sep 2023

### 1 INTRODUCTION

![단일 RGB 이미지인 (a)에서 전체 360° 뷰 3D 복원 예시. (a)의 오른쪽 아래 이미지는 입력 이미지에 해당하는 실제 메시이며, (b)-(e)의 다른 오른쪽 아래 이미지는 각 방법으로 재구성된 메시입니다. (b) 및 (c)의 결과는 디스틸레이션 손실과 신경 밀도 필드의 단순한 사용이 최적이 아닌 새로운 뷰와 낮은 충실도의 표면을 초래한다는 것을 보여줍니다 [Melas-Kyriazi et al. 2023; Xu et al. 2023]. 반면에, 우리의 프레임워크는 원래 입력 이미지를 닮은 새로운 뷰를 성공적으로 생성하고 3D 객체의 표면을 높은 충실도로 재구성합니다. 이것은 우리가 (d) 및 (e)에서 관찰합니다.](360%E2%88%98%20Reconstruction%20From%20a%20Single%20Image%20Using%20Spac%20f605a112375048d7a456d3e4cbc83c3c/Untitled.png)

단일 RGB 이미지인 (a)에서 전체 360° 뷰 3D 복원 예시. (a)의 오른쪽 아래 이미지는 입력 이미지에 해당하는 실제 메시이며, (b)-(e)의 다른 오른쪽 아래 이미지는 각 방법으로 재구성된 메시입니다. (b) 및 (c)의 결과는 디스틸레이션 손실과 신경 밀도 필드의 단순한 사용이 최적이 아닌 새로운 뷰와 낮은 충실도의 표면을 초래한다는 것을 보여줍니다 [Melas-Kyriazi et al. 2023; Xu et al. 2023]. 반면에, 우리의 프레임워크는 원래 입력 이미지를 닮은 새로운 뷰를 성공적으로 생성하고 3D 객체의 표면을 높은 충실도로 재구성합니다. 이것은 우리가 (d) 및 (e)에서 관찰합니다.

컴퓨터 그래픽과 증강/가상 현실에서는 최소한의 입력, 특히 단일 이미지로 3D 모델을 생성하는 것이 매우 중요합니다. 기존 방식은 객체에 대한 여러 뷰를 필요로 하는데, 이는 항상 실용적이지 않습니다. 사용자가 단 하나의 뷰만 가지고 있다면 3D 모델을 만드는 것이 매우 중요하지만, 현재의 기술은 충분히 일반적이지 않거나 물체를 충실하게 재현하지 못합니다.

이 논문에서는 POP3D(프로그레시브 아웃페인팅 3D)라는 솔루션을 제시합니다. POP3D의 접근 방식은 많은 이미지가 필요하지 않고 대신 빅데이터 세트에서 학습한 데이터와 패턴을 활용합니다. 단 하나의 RGB 입력으로 시작하여 기하학적 특징을 추론합니다. 그런 다음 시스템은 물체의 추가 뷰를 '페인팅'하여 각 단계마다 3D 모델을 개선합니다. 이러한 점진적인 구축 과정을 통해 고품질 이미지와 충실한 재구성을 보장합니다.

POP3D의 장점:

- 풍부한 데이터 학습 덕분에 다양한 물체 범주에서 작동합니다.
- 추가 학습 데이터가 필요하지 않습니다.
- 점진적 접근 방식은 품질과 충실한 복제를 보장합니다.
- 의사 실측 데이터는 잘 정의된 고품질 3D 표면을 보장합니다.

전반적으로 POP3D는 단 하나의 이미지로 360° 3D 모델을 재구성하는 새로운 시스템으로, 모양과 외관이 모두 뛰어나며 이 연구 분야에서 새로운 표준을 제시하고 있습니다.

### 2 RELATED WORKS

2.1 몇 뷰에서 3D로 재구성하기:

- NeRF와 같은 기술은 각각의 카메라 포즈를 가진 여러 이미지에서 3D 장면을 재구성하는 데 탁월한 결과를 얻었습니다.
- 몇 개의 뷰만 제공되면 모델에 지오메트리가 깨지고 흐릿한 아티팩트가 생성될 수 있습니다.
- 최신 방법에서는 고품질 재구성에 필요한 뷰 수가 줄어들었지만 여전히 하나 이상의 뷰가 필수적입니다.

2.2 단일 뷰에서 3D로 재구성:

- 이전 방법에서는 음영 및 텍스처와 같은 시각적 단서에 의존하여 하나의 이미지에서 3D 모델을 만들었습니다.
- 최근의 기술은 3D 데이터 세트를 사용하여 이미지에서 보이지 않는 부분을 생성합니다. 하지만 다양한 실제 이미지에서 효과적으로 작동하려면 대규모 3D 데이터 세트가 필요합니다.
- 일부 새로운 방법은 여러 이미지 컬렉션에서 3D 구조를 학습할 수 있지만, 추가 주석이나 정확한 카메라 세부 정보가 필요한 경우가 많습니다.
- 일부에서는 2D 확산 모델을 시작점으로 직접 사용하는 3D 확산 모델로의 전환이 이루어지고 있습니다. 하지만 품질, 해상도, 지오메트리 표현과 관련된 문제에 직면해 있습니다.
- 최근의 추세는 단일 이미지를 컬러화된 포인트 클라우드로 변환하는 것입니다. 이러한 모델은 우수한 외관을 가진 상세한 신경 암시 표면을 생성하는 것을 목표로 하는 논의된 프레임워크와는 다릅니다.
- 다른 작업은 하나의 이미지에서 3D 사진 촬영에 중점을 둡니다. 하지만 물체의 전체 구조, 특히 물체의 뒷면을 캡처하는 데 실패하는 경우가 많습니다.
- 일부 모델은 단일 입력 이미지와 상대적인 포즈에서 3D 원근감을 생성하는 것을 목표로 합니다. 하지만 이러한 모델은 고품질의 형상 재구성을 보장하지 않습니다.

요약하자면, 멀티뷰에서 싱글뷰 3D 재구성을 위한 여정에는 다양한 방법과 과제가 있었습니다. 이상적인 솔루션은 여전히 찾기 어려우며, 각 접근 방식은 특정한 장점과 한계를 제공합니다.

### 3 METHOD

이 논문에서는 단일 이미지에서 물체의 360° 모양과 외관을 재구성하는 기술인 POP3D를 소개합니다. 이 프레임워크의 핵심 아이디어는 물체의 보이지 않는 부분을 색상과 형상 측면에서 점진적으로 채워나가는 것입니다. 이 과정은 다섯 가지 주요 단계로 설명할 수 있습니다:

1. 초기화: 입력 이미지의 깊이와 노멀 맵을 추정하여 초기 3D 뷰를 생성합니다.
2. 카메라 위치 업데이트: 카메라를 새로운 위치로 이동하여 이전에 볼 수 없었던 뷰포인트를 캡처합니다.
3. 아웃페인팅 마스크 획득: '공간 조각'을 기반으로 하는 방법을 사용하여 아웃페인팅이 필요한 영역을 식별합니다.
4. 아웃페인팅: 이전 단계에서 식별된 영역을 잠재 확산 모델(LDM)을 사용하여 채웁니다. 이렇게 하면 기본적으로 보이지 않는 부분에 대한 색상 및 기하학적 정보가 생성됩니다.
5. 3D 모델 업데이트: 개체의 3D 모델이 새로 칠해진 정보로 업데이트됩니다.
    
    ![프레임워크 개요. POP3D는 다섯 개의 연결된 단계에서 작동합니다. 초기에 단일 RGB 입력을 처리하여 초기 의사 지상 진실 데이터 세트를 생성하고 이 데이터를 사용하여 3D 모델을 초기화합니다. 그런 다음 대상 객체의 완전한 360° 뷰를 커버하려는 단계의 루프를 통해 진행됩니다. 이 루프에는 다음이 포함됩니다: 미리 결정된 일정에 따라 카메라 위치 업데이트; 의사 지상 진실 데이터 세트에서 시각적 선체를 추출하여 본 영역을 빼고 아웃페인팅 마스크 획득; 훈련된 3D 모델에서의 초기 새로운 뷰, 아웃페인팅 마스크, 및 적절한 텍스트 프롬프트를 사용하여 의사 지상 진실 새로운 뷰 생성; 및 업데이트된 의사 지상 진실 데이터 세트를 사용하여 3D 모델 훈련. 이 프로세스는 객체의 360° 뷰를 포함 할 때까지 계속됩니다](360%E2%88%98%20Reconstruction%20From%20a%20Single%20Image%20Using%20Spac%20f605a112375048d7a456d3e4cbc83c3c/Untitled%201.png)
    
    프레임워크 개요. POP3D는 다섯 개의 연결된 단계에서 작동합니다. 초기에 단일 RGB 입력을 처리하여 초기 의사 지상 진실 데이터 세트를 생성하고 이 데이터를 사용하여 3D 모델을 초기화합니다. 그런 다음 대상 객체의 완전한 360° 뷰를 커버하려는 단계의 루프를 통해 진행됩니다. 이 루프에는 다음이 포함됩니다: 미리 결정된 일정에 따라 카메라 위치 업데이트; 의사 지상 진실 데이터 세트에서 시각적 선체를 추출하여 본 영역을 빼고 아웃페인팅 마스크 획득; 훈련된 3D 모델에서의 초기 새로운 뷰, 아웃페인팅 마스크, 및 적절한 텍스트 프롬프트를 사용하여 의사 지상 진실 새로운 뷰 생성; 및 업데이트된 의사 지상 진실 데이터 세트를 사용하여 3D 모델 훈련. 이 프로세스는 객체의 360° 뷰를 포함 할 때까지 계속됩니다
    
    ![시각적 선체 추출. 두 개의 카메라 뷰에서 시각적 선체를 획득하는 것을 보여줍니다. 우리는 오른쪽에서 본 음영된 영역을 보존합니다. 이는 대상 객체의 본 및 볼 수 없는 영역을 구성합니다.](360%E2%88%98%20Reconstruction%20From%20a%20Single%20Image%20Using%20Spac%20f605a112375048d7a456d3e4cbc83c3c/Untitled%202.png)
    
    시각적 선체 추출. 두 개의 카메라 뷰에서 시각적 선체를 획득하는 것을 보여줍니다. 우리는 오른쪽에서 본 음영된 영역을 보존합니다. 이는 대상 객체의 본 및 볼 수 없는 영역을 구성합니다.
    

이 논문에서는 VolSDF를 사용하여 3D 객체를 표현합니다. 이 방법에는 두 개의 신경망이 사용됩니다. 하나는 부호화된 거리 함수(SDF)를 사용하여 물체의 형상을 모델링하고, 다른 하나는 광도 함수를 사용하여 외관을 캡처합니다.

하나의 이미지로 3D 모델을 생성하는 데는 고유한 어려움이 있기 때문에 큐브 내에서 물체의 경계를 설정하고 가상 카메라를 사용하여 재구성하는 등의 특정 가정이 필요합니다.

이 논문에서는 3D 모델을 초기화하고, 카메라 위치를 조정하고, 아웃페인팅할 영역을 식별하고, '의사 실측' 이미지를 생성하는 등 각 단계를 자세히 설명합니다. 이 마지막 단계는 최종 재구성된 모델의 일관성과 일관성을 보장하기 위해 개인화 기술과 결합된 최첨단 생성 모델을 사용하여 이루어집니다.

### 4 EXPERIMENTS

이 섹션에서는 제안된 프레임워크의 재구성 품질을 평가한 실험 결과를 제공합니다. 연구진은 특정 카메라 스케줄을 사용했지만, 이 방법이 이 스케줄에 국한되지 않는다는 점을 강조했습니다. 또한 보충 자료에서 다양한 카메라 궤적을 사용한 더 많은 결과를 제공했습니다. 이 평가는 물체 재구성의 다른 최근 접근법과 그들의 방법을 비교했습니다.

- 카메라 일정: 연구진은 특정 극각과 방위각을 활용했지만, 이 방법은 이 설정에만 국한되지 않습니다.
- 비교 기준: 연구진은 사진 측량 및 기타 최신 360° 외형 및 모양 재구성 방법을 사용하여 재구성한 물체와 프레임워크를 비교했습니다.
- 입력 뷰 재구성: 표준 이미지 품질 메트릭(PSNR, SSIM, LPIPS)을 사용한 결과, 이 방법이 다른 방법보다 성능이 우수했습니다. 다른 작업은 증류 손실과 관련된 문제로 인해 성능이 낮았지만, 멀티뷰 의사 실측 데이터를 사용하는 프레임워크는 이러한 문제에 직면하지 않았습니다.
    
    ![입력 이미지 복원에 대한 질적 비교. 단일 입력 이미지 (a)가 주어지면, 우리의 방법은 (b)에서 볼 수 있는 참조 뷰를 성공적으로 재구성합니다. 그러나, RealFusion [Melas-Kyriazi et al. 2023] 및 NeuralLift360 [Xu et al. 2023]은 RGB 복원 손실을 사용할 때도 입력 뷰를 신뢰할 수 있게 재구성하지 않습니다.](360%E2%88%98%20Reconstruction%20From%20a%20Single%20Image%20Using%20Spac%20f605a112375048d7a456d3e4cbc83c3c/Untitled%203.png)
    
    입력 이미지 복원에 대한 질적 비교. 단일 입력 이미지 (a)가 주어지면, 우리의 방법은 (b)에서 볼 수 있는 참조 뷰를 성공적으로 재구성합니다. 그러나, RealFusion [Melas-Kyriazi et al. 2023] 및 NeuralLift360 [Xu et al. 2023]은 RGB 복원 손실을 사용할 때도 입력 뷰를 신뢰할 수 있게 재구성하지 않습니다.
    
- 새로운 시각 합성: 목표는 단일 뷰에서 새로운 뷰를 얼마나 잘 생성할 수 있는지 평가하는 것이었습니다. 클립 유사성 및 NIQE 점수와 같은 메트릭을 사용한 이 방법은 고품질의 새로운 뷰를 생성하는 데 탁월했습니다. 다른 방법과 달리 이 프레임워크는 자연스러운 뷰를 생성하고 특정 아티팩트를 줄였습니다.
- 절제:
    - 카메라 스케줄 간격: 이론적으로는 모든 카메라 스케줄을 사용할 수 있지만 잠재적인 함정이 있습니다. 아웃페인팅 마스크가 너무 작거나 너무 크면 문제가 발생합니다. 연구진은 45°의 간격 크기가 효과적으로 작동한다는 것을 발견했지만, 이는 물체마다 다를 수 있습니다.
        
        ![카메라 간격의 아웃페인팅 결과에 대한 영향. 단일 RGB 입력 (a)에 대해, 과도하게 작은 카메라 간격 (b) 및 과도하게 큰 간격 (c)은 각각 Sec. 4.2.1에서 설명된대로 고유한 단점이 있습니다. 입력 RGB: 확산 모델을 사용하여 생성](360%E2%88%98%20Reconstruction%20From%20a%20Single%20Image%20Using%20Spac%20f605a112375048d7a456d3e4cbc83c3c/Untitled%204.png)
        
        카메라 간격의 아웃페인팅 결과에 대한 영향. 단일 RGB 입력 (a)에 대해, 과도하게 작은 카메라 간격 (b) 및 과도하게 큰 간격 (c)은 각각 Sec. 4.2.1에서 설명된대로 고유한 단점이 있습니다. 입력 RGB: 확산 모델을 사용하여 생성
        
    - LDM 개인화를 사용하지 않은 경우: 이 모델은 여러 개의 의사 실측 뷰를 사용하므로 사전 학습된 LDM을 개인화할 수 있습니다. 개인화된 LDM을 사용하면 보다 자연스러운 새로운 시각을 얻을 수 있는 반면, 개인화하지 않으면 일관성 없는 결과가 나올 수 있습니다.
        
        ![확산 모델 개인화의 영향. 카메라 뷰를 (a)에서 (b)로 업데이트 한 후, 우리는 LDM에 동일한 입력으로 대상 객체를 아웃페인트합니다. 그러나, LDM의 단순한 사용은 의사 지상 진실 데이터 세트의 이미지를 고려하지 않는 아웃페인팅 결과를 초래할 수 있으며, 이는 (c)의 중복 얼굴로 있는 인형보다는 (d)에서 보여진대로 자연스럽게 인형의 모자를 아웃페인팅하는 것입니다.](360%E2%88%98%20Reconstruction%20From%20a%20Single%20Image%20Using%20Spac%20f605a112375048d7a456d3e4cbc83c3c/Untitled%205.png)
        
        확산 모델 개인화의 영향. 카메라 뷰를 (a)에서 (b)로 업데이트 한 후, 우리는 LDM에 동일한 입력으로 대상 객체를 아웃페인트합니다. 그러나, LDM의 단순한 사용은 의사 지상 진실 데이터 세트의 이미지를 고려하지 않는 아웃페인팅 결과를 초래할 수 있으며, 이는 (c)의 중복 얼굴로 있는 인형보다는 (d)에서 보여진대로 자연스럽게 인형의 모자를 아웃페인팅하는 것입니다.
        

### 5 CONCLUSION AND FUTURE WORK

이 연구에서는 단 하나의 RGB 이미지로 360° 재구성을 위한 새로운 프레임워크인 POP3D를 소개합니다. 이 프레임워크는 현장에서 문제가 되었던 일반화 및 충실도 문제를 성공적으로 해결합니다. 이 프레임워크는 방대한 데이터 세트로 학습된 최첨단 모델을 사용하여 다양한 이미지에서 작동할 수 있습니다. POP3D의 강점은 주어진 이미지를 단순히 재현하는 데 그치지 않고 새롭고 사실적인 뷰를 생성하여 멀티뷰 데이터세트를 생성할 수 있다는 점입니다. 기존 방법과 비교했을 때 POP3D는 성능이 뛰어나 3D 재구성에 유망한 기술입니다.

한계:

- 기존 모델에 대한 의존성: 이 시스템은 기존 모델을 기반으로 구축되었기 때문에 모델 중 하나가 실패하거나 문제가 발생하면 전체 프로세스에 영향을 미칠 수 있습니다. 예를 들어, 깊이 예측에 문제가 있으면 최종 형상에 문제가 발생할 수 있습니다.
- 품질 문제: 오브젝트의 뒷면에서 재현된 뷰가 원본 뷰만큼 좋지 않을 때가 있습니다. 이는 아웃페인팅 프로세스에서 누적된 문제 때문일 수 있습니다.
    
    ![제한 사항. 왼쪽에 주어진 입력 RGB (a)에 대해, 우리의 모델은 카메라 일정을 따라 타당한 새로운 뷰 (b)를 생성합니다. 그러나, 우리의 모델은 때때로 입력 단일 RGB와 비교했을 때 부족한 완전한 뒷면 이미지를 생성하는 경우가 있습니다, (c)에서 볼 수 있습니다.](360%E2%88%98%20Reconstruction%20From%20a%20Single%20Image%20Using%20Spac%20f605a112375048d7a456d3e4cbc83c3c/Untitled%206.png)
    
    제한 사항. 왼쪽에 주어진 입력 RGB (a)에 대해, 우리의 모델은 카메라 일정을 따라 타당한 새로운 뷰 (b)를 생성합니다. 그러나, 우리의 모델은 때때로 입력 단일 RGB와 비교했을 때 부족한 완전한 뒷면 이미지를 생성하는 경우가 있습니다, (c)에서 볼 수 있습니다.
    
- 시간 소모: 시스템에서 더 많은 뷰를 생성할수록 처리 시간이 더 오래 걸립니다. 현재 하나의 오브젝트에 대한 3D 모델을 생성하는 데는 하이엔드 GPU에서 약 7시간이 소요됩니다. 그러나 프레임워크에는 유연성이 있어 잠재적인 업그레이드 또는 교체로 속도를 개선할 수 있습니다.

향후 방향:

- 연구진은 향후 연구에서 인공물을 줄이고, 재구성 방법을 개선하며, 프로세스를 더 빠르게 만드는 것을 목표로 앞서 언급한 한계를 해결할 계획입니다.

![질적 비교. 우리는 위에 주어진 단일 RGB 이미지의 360° 형태와 외관을 다양한 모델로 재구성하고 우리의 결과와 비교합니다. NL, RF, MCC, P-e, 및 SS3D는 NeuralLift [Xu et al. 2023], RealFusion [Melas-Kyriazi et al. 2023], MCC [Wu et al. 2023a], Point-E [Nichol et al. 2022], 및 SS3D [Vasudev et al. 2022]를 의미합니다. SS3D [Vasudev et al. 2022]는 객체의 외관을 재구성하지 않기 때문에 그 형태 출력만 보여줍니다. 더 나은 시각화를 위해, MCC [Wu et al. 2023a]에 대해 우리는 포인트 클라우드를 샘플링하는 데 사용되는 동일한 점유 임계 값으로 표면을 추출하기 위해 marching cubes를 사용합니다. Point-E [Nichol et al. 2022]의 경우, 저자가 제공하는 포인트 클라우드-투-메시 변환을 사용합니다.](360%E2%88%98%20Reconstruction%20From%20a%20Single%20Image%20Using%20Spac%20f605a112375048d7a456d3e4cbc83c3c/Untitled%207.png)

질적 비교. 우리는 위에 주어진 단일 RGB 이미지의 360° 형태와 외관을 다양한 모델로 재구성하고 우리의 결과와 비교합니다. NL, RF, MCC, P-e, 및 SS3D는 NeuralLift [Xu et al. 2023], RealFusion [Melas-Kyriazi et al. 2023], MCC [Wu et al. 2023a], Point-E [Nichol et al. 2022], 및 SS3D [Vasudev et al. 2022]를 의미합니다. SS3D [Vasudev et al. 2022]는 객체의 외관을 재구성하지 않기 때문에 그 형태 출력만 보여줍니다. 더 나은 시각화를 위해, MCC [Wu et al. 2023a]에 대해 우리는 포인트 클라우드를 샘플링하는 데 사용되는 동일한 점유 임계 값으로 표면을 추출하기 위해 marching cubes를 사용합니다. Point-E [Nichol et al. 2022]의 경우, 저자가 제공하는 포인트 클라우드-투-메시 변환을 사용합니다.

![또 다른 질적 비교. 우리는 위에 주어진 단일 RGB 이미지의 360° 형태와 외관을 다양한 모델로 재구성하고 우리의 결과와 비교합니다. NL, RF, MCC, P-e, 및 SS3D는 NeuralLift [Xu et al. 2023], RealFusion [Melas-Kyriazi et al. 2023], MCC [Wu et al. 2023a], Point-E [Nichol et al. 2022], 및 SS3D [Vasudev et al. 2022]를 의미합니다. SS3D [Vasudev et al. 2022]는 객체의 외관을 재구성하지 않기 때문에 그 형태 출력만 보여줍니다. 더 나은 시각화를 위해, MCC [Wu et al. 2023a]에 대해 우리는 포인트 클라우드를 샘플링하는 데 사용되는 동일한 점유 임계 값으로 표면을 추출하기 위해 marching cubes를 사용합니다. Point-E [Nichol et al. 2022]의 경우, 저자가 제공하는 포인트 클라우드-투-메시 변환을 사용합니다.](360%E2%88%98%20Reconstruction%20From%20a%20Single%20Image%20Using%20Spac%20f605a112375048d7a456d3e4cbc83c3c/Untitled%208.png)

또 다른 질적 비교. 우리는 위에 주어진 단일 RGB 이미지의 360° 형태와 외관을 다양한 모델로 재구성하고 우리의 결과와 비교합니다. NL, RF, MCC, P-e, 및 SS3D는 NeuralLift [Xu et al. 2023], RealFusion [Melas-Kyriazi et al. 2023], MCC [Wu et al. 2023a], Point-E [Nichol et al. 2022], 및 SS3D [Vasudev et al. 2022]를 의미합니다. SS3D [Vasudev et al. 2022]는 객체의 외관을 재구성하지 않기 때문에 그 형태 출력만 보여줍니다. 더 나은 시각화를 위해, MCC [Wu et al. 2023a]에 대해 우리는 포인트 클라우드를 샘플링하는 데 사용되는 동일한 점유 임계 값으로 표면을 추출하기 위해 marching cubes를 사용합니다. Point-E [Nichol et al. 2022]의 경우, 저자가 제공하는 포인트 클라우드-투-메시 변환을 사용합니다.