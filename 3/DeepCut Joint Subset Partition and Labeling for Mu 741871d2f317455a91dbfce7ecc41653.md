# DeepCut: Joint Subset Partition and Labeling for Multi Person Pose Estimation

[https://arxiv.org/abs/1511.06645](https://arxiv.org/abs/1511.06645)

[http://pose.mpi-inf.mpg.de](http://pose.mpi-inf.mpg.de/)

- Nov 2015 (CVPR2016)

### 1. Introduction

이 연구에서는 인체 포즈 추정의 발전에 대해 설명합니다. 이전의 방법은 이미지에서 한 사람의 포즈를 추정하는 데는 강력한 결과를 얻었지만, 여러 사람이 포함된 시나리오, 특히 사람들이 서로 가까이 있거나 부분적으로 가려져 있는 경우에는 부족했습니다. 실제 사진에는 여러 사람이 포함된 경우가 많다는 점을 고려할 때 이는 중요한 문제입니다.

![(a) 초기 감지(= 부분 후보)와 모든 감지 사이의 쌍대 용어(그래프)가 (b) 공동으로 클러스터링되어 한 사람에게 속함(한 색의 부분그래프 = 한 사람) 그리고 각 부분은 그 부분 클래스에 따라 라벨이 지정됩니다(다른 색상과 기호는 다른 신체 부위를 나타냄); (c) 예측된 포즈 스틱을 보여줍니다.](DeepCut%20Joint%20Subset%20Partition%20and%20Labeling%20for%20Mu%20741871d2f317455a91dbfce7ecc41653/Untitled.png)

(a) 초기 감지(= 부분 후보)와 모든 감지 사이의 쌍대 용어(그래프)가 (b) 공동으로 클러스터링되어 한 사람에게 속함(한 색의 부분그래프 = 한 사람) 그리고 각 부분은 그 부분 클래스에 따라 라벨이 지정됩니다(다른 색상과 기호는 다른 신체 부위를 나타냄); (c) 예측된 포즈 스틱을 보여줍니다.

이 문제를 해결하기 위해 저자들은 정수 선형 프로그래밍을 사용하여 이미지에 등장하는 모든 사람의 포즈를 공동으로 추정하는 새로운 접근 방식을 제안합니다. 이 공식은 불특정 다수의 사람이 포함된 시나리오를 처리하며, 상충하는 부분 가설을 병합하거나 비활성화하여 신체 부위 중첩 및 폐색을 효과적으로 관리할 수 있습니다. 또한 이 시스템은 이미지에 포함된 사람의 수를 추론할 수도 있습니다.

저자들은 이 방법이 먼저 개인을 감지한 다음 독립적으로 포즈를 추정하는 기존의 2단계 프로세스에 비해 개선된 방법이라고 주장합니다. 이러한 기존 전략은 동일한 신체 부위 후보를 여러 사람에게 할당할 수 있기 때문에 겹치는 신체 부위나 근접한 개인을 처리하는 데 어려움을 겪습니다. 반면 새로운 공식은 이미지 내에서 신체 부위가 서로 어떻게 연관되어 있는지 보다 미묘하게 이해할 수 있게 해줍니다.

이 논문에서는 대표적인 신체 부위 후보 집합을 생성하기 위한 두 가지 컨볼루션 신경망(CNN) 변형을 제시합니다. 제안된 모델과 결합하면 1인 및 여러 사람의 포즈 추정 모두에서 다양한 데이터 세트에 대해 인상적인 결과를 얻을 수 있습니다.

저자들은 이 분야의 관련 연구에 대해서도 논의합니다. 기존의 많은 선행 연구는 1인 포즈 추정을 대상으로 했으며, 기존의 일부 다인 포즈 추정 접근법은 사람을 먼저 감지한 다음 신체 포즈를 독립적으로 추정하는 방식을 사용했습니다. 이 연구는 여러 사람의 포즈를 동시에 추정하는 공동 목표를 제안한다는 점에서 차별화됩니다.

제안된 방법은 포즈 추정에 정수 선형 프로그래밍을 사용하는 이전 작업의 연장선상에 있지만, 이미지당 사람 수와 사람당 신체 부위를 알 수 없다는 점에서 독특합니다. 이미지 분할에 사용되는 최소 비용 다중 컷 문제와 유사하지만 포즈 추정에 적용한다는 점에서 새로운 방법입니다.

### 2. Problem Formulation

여기에 설명된 문제는 이미지에서 불특정 다수의 사람들의 관절이 있는 포즈를 추정하는 것을 목표로 합니다. 기본적으로 세 가지 특정 작업을 동시에 해결하도록 구성된 최적화 문제입니다:

이미지에서 추정된 잠재적인 신체 부위 후보 집합에서 신체 부위의 하위 집합을 선택합니다.
선택한 각 신체 부위에 '팔', '다리', '몸통' 등과 같은 신체 부위 클래스 중 하나로 레이블을 지정합니다.
같은 사람에 속하는 신체 부위를 분할합니다.
이러한 문제에 대한 가능한 해결책은 각각 특정 영역과 해석을 가진 (x, y, z)의 이항 랜덤 변수의 삼중으로 표현됩니다. 또한 저자는 이러한 솔루션이 잘 정의되고 유효한 사람의 포즈를 나타낼 수 있도록 특정 선형 부등식을 적용했습니다.

이미지에 사람이 한 명만 있는 경우, 한 사람의 포즈가 잘 정의되도록 하기 위해 추가 부등식을 적용했습니다.

목적 함수는 신체 부위 d가 클래스 c에 속할 확률을 추정하도록 설계되었습니다. 신체 부위 d와 d', 클래스 c와 c' 각 쌍에 대해 조건부 확률을 고려합니다. 이 작업은 실현 가능한 솔루션 집합에 대해 이 함수를 최소화하는 것입니다.

저자는 최적화 프로세스를 위해 Gurobi라는 최신 정수 선형 프로그래밍(ILP) 솔버를 사용합니다. 제약 조건이 없는 문제에서 시작하여 모든 부등식을 만족하고 최적성 격차가 1% 미만인 정수 해에 도달할 때까지 위반된 부등식을 도입하여 문제를 반복적으로 강화합니다.

본질적으로 이 방법은 이미지에서 한 명 이상의 신체 부위를 정확하게 식별하고 라벨을 붙이고, 어떤 부위가 같은 사람의 것인지 정확하게 결정하는 것을 목표로 합니다.

### 3. Pairwise Probabilities

컴퓨터 비전에서 물체 감지 및/또는 인체 부위 감지와 관련된 특정 문제에 대한 쌍별 확률을 추정하는 방법에 대한 자세한 설명인 것으로 보입니다. 이 설명은 서로 다른 '감지'(아마도 관심 대상의 감지된 인스턴스) 간의 공간 및 모양 관계를 설명하는 데 사용되는 특징의 계산과 이러한 특징이 머신 러닝 모델에서 특정 확률을 추정하는 데 어떻게 사용되는지 설명합니다.

기본 개념은 두 개의 감지(d와 d')가 주어지면 상대적 거리, 스케일, 겹침과 같은 공간적 관계와 모양을 기반으로 특징을 계산하는 것입니다. 그런 다음 이러한 특징을 모델에 입력하여 두 검출이 같은 클래스(예: 같은 신체 부위) 및/또는 같은 인스턴스(예: 같은 사람)에 속할 확률을 추정합니다. 그런 다음 이 정보를 사용하여 개별 탐지를 일관된 전체로 집계할 수 있습니다.

이 접근 방식에 대한 몇 가지 주목할 만한 세부 사항:

두 탐지가 같은 클래스에 속한다고 가정하는지 아니면 다른 클래스에 속한다고 가정하는지에 따라 사용되는 기능 세트가 달라집니다. 동일한 클래스의 경우 거리, 스케일, 경계 상자 중첩과 같은 공간적 특징이 사용됩니다. 다른 클래스의 경우, 감지 사이의 거리와 각도, 그리고 각 감지에 대한 CNN 기반 감지기의 출력이 사용됩니다.

특징은 비선형 관계를 포착하기 위해 이차 및 지수 변환으로 보강됩니다.

서로 다른 클래스의 경우 2D 히스토그램을 사용하여 탐지 간의 거리와 각도의 공동 분포를 캡처하고 거리와 각도가 주어졌을 때 각 클래스에 속하는 탐지의 사후 확률을 특징으로 사용합니다.

확률 추정치는 목적 함수의 계수를 정의하는 데 사용되며, 이 계수는 후속 감지 처리에 사용됩니다.

모델의 매개 변수는 최대 가능성 추정을 사용하여 매개 변수에 가우시안 사전이 있는 로지스틱 회귀 모델을 사용하여 학습합니다.

추론은 학습된 모델 파라미터와 탐지에서 추출된 특징을 사용하여 두 개의 탐지가 주어졌을 때 이루어집니다.

이 방법이 사용되는 나머지 시스템에 대한 자세한 컨텍스트나 정보가 없으면 보다 구체적인 인사이트를 제공하기가 어렵습니다. 그러나 이것은 컴퓨터 비전과 머신 러닝의 복잡한 문제에 대한 신중한 접근 방식인 것 같습니다. 이 영역에서 불확실한 정보를 이해하기 위해 확률 모델을 사용하는 것은 매우 일반적이며, 저자들은 이 작업에 유용한 기능을 정의하는 방법에 대해 신중하게 생각했습니다.

### 4. Body Part Detectors

신체 부위를 감지하고 예측하는 딥러닝 기반 방법, 즉 적응형 고속 R-CNN(AFR-CNN)과 고밀도 아키텍처(Dense-CNN)에 대해 설명합니다.

AFR-CNN은 제안 생성 및 감지 영역 크기를 변경하여 신체 부위 감지에 적합하도록 Fast R-CNN을 수정합니다. 제안은 DPM 기반 부품 감지기를 사용하여 생성됩니다. 바운딩 박스의 크기가 커져 각 부위 주변의 컨텍스트를 더 많이 캡처할 수 있어 성능이 크게 향상되는 것으로 나타났습니다. AFR-CNN은 포즈 추정 작업을 위해 미세 조정된 ImageNet 모델을 기본으로 사용합니다.

Dense-CNN은 부품 확률 스코어맵을 위한 완전한 컨볼루션 아키텍처를 제공합니다. 정밀한 부품 로컬라이제이션을 위해 VGG 모델 보폭을 조정하고, 최적의 이미지 스케일링을 결정하며, 소프트맥스 대신 교차 엔트로피 손실 함수를 사용하고, 정밀도 향상을 위해 위치 세분화 기능을 도입합니다. 또한 Dense-CNN은 각 신체 부위가 다른 모든 부위 위치로 회귀하는 보조 작업을 도입합니다. 이 모델은 정밀한 훈련 일정과 학습 속도 조정을 통해 훈련에 확률적 경사 하강(SGD)을 활용합니다.

두 모델 모두 '리즈 스포츠 포즈(LSP)', 'LSP 확장(LSPET)', 'MPII 휴먼 포즈' 등 여러 데이터 세트에서 평가되었습니다. 평가 결과, AFR-CNN은 LSP에서 최신 기술을 크게 능가하는 성능을 보였으며, Dense-CNN은 MPII 데이터 세트에서 매우 우수한 성능을 보였습니다.

마지막으로, 저자들은 딥컷 모델에서 이러한 모델을 사용하는 방법을 소개합니다. 저자들은 부분 집합 분할 라벨링 문제(SPLP)가 NP-하드 문제이며, 이는 모델에서 생성된 대표적 탐지의 하위 집합에서 효율적인 솔루션을 선택해야 한다는 것을 의미한다고 설명합니다. 또한 소프트맥스 및 시그모이드 탐지 단항 점수가 각각 AFR-CNN 및 Dense-CNN 모델에서 사용되는 다양한 방식에 대해 설명합니다.

### 5. DeepCut Results

포즈 추정 작업은 이미지에서 사람 또는 사람 그룹에서 특정 관심 지점(예: 관절)을 찾는 작업으로 구성됩니다.

![우리의 공동 공식화 DeepCut MP Dense-CNN(중간)을 전통적인 두 단계 접근법인 Dense-CNN det ROI(상단)와 Chen&Yuille [8]의 접근법(하단)과의 WAF 데이터셋에서의 질적 비교. det ROI와 달리, DeepCut MP는 여러 개인이 또는 잠재적으로 겹치는 개인을 구분하고 독립적인 감지를 타당한 신체 부위 구성으로 올바르게 조립할 수 있습니다. [8]과 달리, DeepCut MP는 가려짐을 더 잘 예측할 수 있습니다(이미지 2 사람 1 - 4 왼쪽, 상단 행; 이미지 4 사람 1, 4; 이미지 5, 사람 2) 강한 관절 움직임과 단축 현상에 대해 더 잘 대처할 수 있습니다(이미지 1, 사람 1, 3; 이미지 2 사람 1 하단 행; 이미지 3, 사람 1-2). 더 많은 예시는 부록 B를 참조하십시오.](DeepCut%20Joint%20Subset%20Partition%20and%20Labeling%20for%20Mu%20741871d2f317455a91dbfce7ecc41653/Untitled%201.png)

우리의 공동 공식화 DeepCut MP Dense-CNN(중간)을 전통적인 두 단계 접근법인 Dense-CNN det ROI(상단)와 Chen&Yuille [8]의 접근법(하단)과의 WAF 데이터셋에서의 질적 비교. det ROI와 달리, DeepCut MP는 여러 개인이 또는 잠재적으로 겹치는 개인을 구분하고 독립적인 감지를 타당한 신체 부위 구성으로 올바르게 조립할 수 있습니다. [8]과 달리, DeepCut MP는 가려짐을 더 잘 예측할 수 있습니다(이미지 2 사람 1 - 4 왼쪽, 상단 행; 이미지 4 사람 1, 4; 이미지 5, 사람 2) 강한 관절 움직임과 단축 현상에 대해 더 잘 대처할 수 있습니다(이미지 1, 사람 1, 3; 이미지 2 사람 1 하단 행; 이미지 3, 사람 1-2). 더 많은 예시는 부록 B를 참조하십시오.

한 사람 포즈 추정: 딥컷은 두 가지 1인 데이터 세트에 대해 테스트되었습니다: LSP와 MPII. 이 모델은 이미지에 모든 신체 부위가 존재한다는 암묵적인 가정에도 불구하고 이러한 데이터 세트에서 효과적으로 작동했습니다. 예를 들어, DeepCut SP AFR-CNN 모델은 단수 전용 방법보다 향상된 성능을 보였습니다(쌍으로 연결하면 배경에서 고득점 탐지 항목을 필터링하는 데 도움이 됨). DeepCut SP Dense-CNN의 성능은 단수 전용과 거의 동일하여 더 강력한 부품 감지기의 성능을 보여줍니다.

최첨단 비교(1인 기준): 딥컷 모델은 LSP 및 MPII 데이터 세트 모두에서 최첨단 1인 포즈 추정 모델보다 훨씬 뛰어난 성능을 보였습니다. 예를 들어, DeepCut SP Dense-CNN 모델은 LSP 데이터 세트에서 가장 잘 알려진 결과보다 13.7% PCK가 개선된 것으로 나타났습니다.

다중 인원 포즈 추정: 딥컷은 두 개의 다중 인원 데이터 세트에서 평가되었습니다: "우리는 가족입니다"(WAF)와 "MPII 휴먼 포즈". MP 변형은 이전 방법에 비해 상당한 개선을 보여주었습니다. DeepCut MP AFR-CNN은 WAF 데이터 세트에서 82.2%의 mPCP 개선을 보였습니다. DeepCut MP Dense-CNN은 84.7%의 mPCP와 86.5%의 AOP로 최고의 성능을 달성했습니다.

최첨단 비교(다중 인원): 딥컷 모델은 다중 인원 포즈 추정에서 이전의 모든 방법보다 우수한 성능을 보였습니다. 예를 들어, WAF 데이터 세트에서 DeepCut 모델은 mPCP와 AOP 측정값 모두에서 딥러닝 방법[8]보다 우수한 성능을 보였습니다.

저자들은 여러 사람에 걸친 부품 상호 작용을 추론할 수 있고 가능한 오클루전 패턴의 수에 제한을 받지 않는 등 기존 방식에 비해 DeepCut이 갖는 장점에 대해 설명합니다. 또한 딥컷이 가려진 부분에 대한 감지를 비활성화하여 효과적으로 오클루전을 추론하는 기능에 대해서도 강조합니다.

전반적으로 딥컷 모델은 1인 및 다인 포즈 추정 작업 모두에서 기존의 최첨단 방법보다 우수한 성능을 보였습니다.

### 6. Conclusion

결론적으로, 이 논문에서는 제약이 없는 실제 이미지에서 여러 사람의 포즈를 추정하는 새로운 공식을 제시했으며, 이를 공동 하위 집합 분할 및 라벨링 문제(SPLP)로 인식했습니다. 이 접근 방식은 일반적으로 감지와 포즈 추정을 분리하는 기존의 2단계 전략과는 다릅니다. SPLP 모델은 개인의 수, 포즈, 공간적 근접성, 파트 레벨 오클루전을 동시에 추론합니다.

네 가지의 까다롭고 다양한 데이터 세트에 대한 테스트 결과, 우리의 접근 방식은 여러 사람의 포즈 추정뿐만 아니라 한 사람의 경우에서도 이전의 모든 방법보다 훨씬 뛰어난 성능을 보였습니다. 특히 다인용 WAF 데이터 세트에서는 기존의 2단계 방법보다 30% 향상된 PCP를 보였습니다. 이러한 결과는 중복될 가능성이 있는 다수의 개인을 구별하는 데 있어 공동 공식의 중요성을 강조합니다.

### Appendices

리즈 스포츠 포즈(LSP) 데이터 세트와 WAF 데이터 세트에 대한 추가 결과를 제공하여 모델의 성능을 보다 자세히 평가하고 비교할 수 있습니다.

부록 A에서는 LSP 데이터 세트에 대한 보다 포괄적인 성능 분석이 수행됩니다. 여기에는 사람 중심(PC) 및 관찰자 중심(OC) 설정을 사용한 평가가 포함되며, 두 가지 평가 척도인 정답 키포인트 비율(PCK)과 정답 부품 비율(PCP)이 사용됩니다. 그 결과, 이 모델은 다른 방법보다 성능이 훨씬 우수할 뿐만 아니라 추가 개선 가능성도 있는 것으로 나타났습니다. 이 모델은 관찰자 중심 주석에서 특히 성능이 우수하여 대부분의 경우 왼쪽/오른쪽 팔다리에 정확하게 라벨을 붙이는 능력을 보여주었습니다.

부록 B는 WAF 데이터 세트에 대한 추가적인 정성적 결과를 제공하여 기존의 2단계 접근 방식 및 기타 기존 방법과 비교하여 공동 포뮬레이션 DeepCut MP Dense-CNN의 효능을 더욱 강화합니다.

부록 C에서는 여러 개인, 폐색 및 절단이 있는 시나리오에서 제안된 모델의 효과를 보여주는 MPII 다중 개인 데이터 세트에 대한 정성적 비교를 제공합니다. 결과는 이 모델이 이미지당 알려지지 않은 사람 수와 알려지지 않은 사람당 보이는 신체 부위 수를 성공적으로 처리할 수 있음을 시사합니다.

![우리의 공동 공식화 DeepCut MP Dense-CNN(행 2, 5)을 전통적인 두 단계 접근법인 Dense-CNN det ROI(행 1, 4)와 Chen&Yuille [8]의 접근법(행 3, 6)과의 WAF 데이터셋에서의 질적 비교. det ROI는 가려짐에 대해 추론하지 않고 종종 가까이 있는 사람들을 가로질러 부위를 연결함으로써 일관성 없는 신체 부위 구성을 예측합니다(이미지 4, 사람 2의 오른쪽 어깨와 손목이 사람 3의 오른쪽 팔꿈치와 연결됨; 이미지 5, 사람 4의 왼쪽 팔꿈치가 사람 3의 왼쪽 손목과 연결됨). 반면에, DeepCut MP는 신체 부분의 가려짐을 예측하고, 여러 사람과 잠재적으로 겹치는 사람들을 구분하고, 독립적인 감지를 타당한 신체 부위 구성으로 올바르게 조립합니다(이미지 4, 사람들 1-3의 왼쪽 팔이 올바르게 가려짐으로 예측됨; 이미지 5, 사람 3과 4 사이의 신체 부위 연결이 수정됨; 이미지 7, 신체 부위의 가려짐이 올바르게 예측되고 보이는 부분은 정확하게 추정됨). Chen&Yuille [8]에 비해, DeepCut MP는 가까이 있는 사람들에 의한 신체 부위의 가려짐을 더 잘 예측합니다(이미지 1, 3-9), 그러나 다른 물체에 의해서도 마찬가지입니다(이미지 2, 사람 1의 왼쪽 팔이 의자에 의해 가려짐). 또한, DeepCut MP는 강한 관절 움직임과 단축 현상에 더 잘 대처할 수 있습니다(이미지 1, 사람 6; 이미지 3, 사람 2; 이미지 5, 사람 4; 이미지 7, 사람 4; 이미지 8, 사람 1). DeepCut MP의 전형적인 실패 사례는 이미지 10에 표시되어 있습니다: 사람 3의 오른쪽 상완부와 사람 4의 양팔은 부분 검출 후보가 누락되어 추정되지 않았습니다.](DeepCut%20Joint%20Subset%20Partition%20and%20Labeling%20for%20Mu%20741871d2f317455a91dbfce7ecc41653/Untitled%202.png)

우리의 공동 공식화 DeepCut MP Dense-CNN(행 2, 5)을 전통적인 두 단계 접근법인 Dense-CNN det ROI(행 1, 4)와 Chen&Yuille [8]의 접근법(행 3, 6)과의 WAF 데이터셋에서의 질적 비교. det ROI는 가려짐에 대해 추론하지 않고 종종 가까이 있는 사람들을 가로질러 부위를 연결함으로써 일관성 없는 신체 부위 구성을 예측합니다(이미지 4, 사람 2의 오른쪽 어깨와 손목이 사람 3의 오른쪽 팔꿈치와 연결됨; 이미지 5, 사람 4의 왼쪽 팔꿈치가 사람 3의 왼쪽 손목과 연결됨). 반면에, DeepCut MP는 신체 부분의 가려짐을 예측하고, 여러 사람과 잠재적으로 겹치는 사람들을 구분하고, 독립적인 감지를 타당한 신체 부위 구성으로 올바르게 조립합니다(이미지 4, 사람들 1-3의 왼쪽 팔이 올바르게 가려짐으로 예측됨; 이미지 5, 사람 3과 4 사이의 신체 부위 연결이 수정됨; 이미지 7, 신체 부위의 가려짐이 올바르게 예측되고 보이는 부분은 정확하게 추정됨). Chen&Yuille [8]에 비해, DeepCut MP는 가까이 있는 사람들에 의한 신체 부위의 가려짐을 더 잘 예측합니다(이미지 1, 3-9), 그러나 다른 물체에 의해서도 마찬가지입니다(이미지 2, 사람 1의 왼쪽 팔이 의자에 의해 가려짐). 또한, DeepCut MP는 강한 관절 움직임과 단축 현상에 더 잘 대처할 수 있습니다(이미지 1, 사람 6; 이미지 3, 사람 2; 이미지 5, 사람 4; 이미지 7, 사람 4; 이미지 8, 사람 1). DeepCut MP의 전형적인 실패 사례는 이미지 10에 표시되어 있습니다: 사람 3의 오른쪽 상완부와 사람 4의 양팔은 부분 검출 후보가 누락되어 추정되지 않았습니다.

이러한 모든 추가 결과와 평가는 제안된 접근 방식의 강력한 성능을 입증합니다. 이는 이 방법이 복잡한 실제 시나리오를 효과적으로 처리할 수 있음을 증명하며, 더 폭넓게 적용하고 더 개선할 수 있는 사례를 제시합니다.