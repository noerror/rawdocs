# 4K4D: Real-Time 4D View Synthesis at 4K Resolution

### 1. Introduction

다이나믹 뷰 합성은 비디오 녹화에서 실제와 같은 3D 장면을 재현하는 프로세스입니다. 궁극적인 목표는 실시간 고품질 가상 재생을 달성하는 것입니다. 이 기술은 가상 현실(VR), 증강 현실(AR), 스포츠 중계, 심지어 예술 공연 캡처에 이르기까지 방대한 잠재력을 가지고 있습니다. 지금까지 이러한 3D 재구성은 텍스처 메시 시퀀스로 표현되었습니다. 하지만 이러한 기존 방식은 특수 하드웨어가 필요하고 엄격하게 제어된 설정 내에서 작동해야 하는 경우가 많았습니다. 최근에는 신경 표현을 사용하여 일반 RGB 비디오에서 동적인 3D 장면을 재현하는 기술이 발전했습니다. 이러한 획기적인 발전에도 불구하고 이러한 방법 중 상당수는 고해상도 이미지를 렌더링하는 데 상당한 시간(때로는 몇 분)이 소요됩니다.

![동적 3D 장면의 사실적인 실시간 렌더링. 우리가 제안한 방법은 멀티뷰 비디오에서 4D 신경 표현을 재구성하여 1125×1536 해상도로 RTX 3090 GPU를 사용하여 200 FPS 이상의 속도로 렌더링할 수 있으며 DNA-Rendering [11] 데이터세트에서 최첨단 품질을 유지할 수 있습니다. 또한 RTX 4090으로 4K 이미지를 렌더링할 때 80 FPS 이상에 도달한다는 점도 주목할 만합니다. 다른 GPU를 사용한 다양한 해상도에서의 자세한 성능은 탭에서 확인할 수 있습니다. 7.](4K4D%20Real-Time%204D%20View%20Synthesis%20at%204K%20Resolution%208e942a00010e411da6a6906fe1418b77/Untitled.png)

동적 3D 장면의 사실적인 실시간 렌더링. 우리가 제안한 방법은 멀티뷰 비디오에서 4D 신경 표현을 재구성하여 1125×1536 해상도로 RTX 3090 GPU를 사용하여 200 FPS 이상의 속도로 렌더링할 수 있으며 DNA-Rendering [11] 데이터세트에서 최첨단 품질을 유지할 수 있습니다. 또한 RTX 4090으로 4K 이미지를 렌더링할 때 80 FPS 이상에 도달한다는 점도 주목할 만합니다. 다른 GPU를 사용한 다양한 해상도에서의 자세한 성능은 탭에서 확인할 수 있습니다. 7.

 4K4D라는 새로운 신경 표현을 소개합니다. 이 방식은 이미지 품질 저하 없이 렌더링 속도가 기존 방식보다 훨씬 빠릅니다. 4K4D의 핵심은 하이브리드 외형 모델과 결합된 4D 포인트 클라우드 표현을 활용합니다. 작동 방식은 다음과 같습니다. 먼저 기본 포인트 클라우드 시퀀스를 사용하여 동적 장면을 매핑합니다. 그런 다음 각 점을 학습 가능한 벡터로 처리합니다. 그런 다음 4D 피처 그리드를 도입하여 각 포인트에 피처 벡터를 부여한 다음 일련의 신경망을 통과하여 포인트의 다양한 속성을 결정합니다. 이 방법은 이러한 포인트 클라우드를 고유하게 최적화하여 안정성과 견고성을 보장합니다. 또한 4K4D 모델에서는 하드웨어를 활용하는 새로운 알고리즘을 사용하여 비교할 수 없는 렌더링 속도를 구현합니다.

역동적인 장면, 특히 변화하는 장면의 외관을 정확하게 표현하는 것은 어려울 수 있습니다. 우리의 솔루션은 기존의 MLP 기반 구형 고조파(SH) 모델과 새로운 이미지 블렌딩 모델이라는 두 가지 모델을 통합합니다. 렌더링 속도를 높이기 위해 설계된 이 블렌딩 모델은 시야각과 독립적으로 작동합니다. 즉, 사전 계산을 통해 프로세스 속도를 더욱 높일 수 있습니다. 하지만 이는 보는 방향에 따라 고정되기 때문에 자체적인 문제가 있습니다. 우리는 이를 연속 SH 모델과 병합하여 극복했습니다. 이 조합을 통해 우리 시스템은 사용 가능한 모든 정보를 효율적으로 사용하여 최종 렌더링 품질을 향상시킵니다.

우리는 동적 뷰 합성을 위해 맞춤화된 여러 유명 데이터 세트를 사용하여 4K4D를 테스트했습니다. 결과는 놀라웠습니다. 4K4D는 다른 방식보다 이미지를 기하급수적으로 빠르게 렌더링했을 뿐만 아니라 시각적 품질 면에서도 다른 방식을 능가했습니다. 실제로 하이엔드 GPU를 사용하여 1080p 해상도 이미지의 경우 초당 400프레임, 4K 해상도의 경우 초당 80프레임이라는 놀라운 속도를 달성했습니다.

### 2. Related Work

씬의 새로운 시점이나 뷰를 생성하기 위해 여러 가지 기법이 제시되어 왔습니다. 초기에는 멀티뷰 이미지와 라이트 필드 기법을 사용하는 것부터 표면이나 볼륨을 명시적으로 디자인하는 것까지 다양한 방법이 사용되었습니다. 주목할 만한 예로는 깊이 센서를 사용하고 다양한 시점을 결합하여 통일된 장면 지오메트리를 생성하여 인상적인 볼륨 비디오를 만드는 방법이 있습니다. 하지만 이러한 기술은 복잡하고 특수 장비가 필요해 일상적으로 사용하기에는 접근성이 떨어졌습니다.

특히 신경망을 사용하여 정적 장면의 래디언스 필드를 인코딩하는 NeRF라는 획기적인 접근 방식을 통해 암시적 신경 장면 표현이 도입되면서 변화가 일어났습니다. 이를 통해 탁월한 품질의 뷰 합성이 가능해졌습니다. 이를 기반으로 여러 연구에서 이러한 신경 표현을 확장하여 동적 장면을 포함하도록 했습니다. 대표적인 예로, 시간 차원을 추가하여 시간에 따른 변화를 포착할 수 있도록 한 DyNeRF가 있습니다. 하지만 이러한 NeRF 기반 방법은 인상적이긴 하지만 계산이 많이 필요했습니다. 그 결과 표준 해상도 이미지를 렌더링하는 데도 비현실적으로 오랜 시간이 걸렸습니다. 또 다른 연구에서는 개별 이미지 특징을 NeRF 시스템에 통합하려고 시도했습니다. 이를 통해 역동적인 장면에 더 쉽게 접근할 수 있게 되었지만, 고해상도 이미지의 경우 속도가 크게 느려지는 등 여러 가지 문제가 발생했습니다.

속도 문제를 해결하기 위해 많은 연구에서 렌더링 프로세스를 가속화하는 방법을 모색했습니다. 이러한 연구들은 NeRF의 복잡한 신경망을 복셀 그리드나 포인트 기반 시스템과 같은 보다 간단한 구조로 변환하여 이를 달성했습니다. 주목할 만한 방법 중 하나인 3D 가우시안 스플래팅(3DGS)은 스플래팅 알고리즘을 사용하여 빠르고 고품질의 렌더링을 달성했습니다. 하지만 속도에 초점을 맞춘 이 방법은 정적인 장면에만 국한된다는 단점이 있었습니다.

정적 장면에서의 성공에서 영감을 얻은 연구원들은 동적 장면에서도 실시간 렌더링을 구현할 수 있는 방법을 모색해 왔습니다. 이러한 방법 중 하나인 HyperReel은 표준 해상도 이미지의 실시간 렌더링 속도를 관리했지만 해상도가 높아짐에 따라 효율성이 떨어졌습니다. 일부 최신 기술은 3DGS 방식을 채택하여 실시간 속도를 관리했지만, 움직임이 빠르거나 광범위한 데이터 세트에서는 어려움을 겪었습니다. 바로 이 부분에서 우리의 4K4D 모델이 빛을 발합니다. 4K4D는 이전 방식과 달리 초고해상도 4K 해상도에서도 실시간 렌더링을 관리할 수 있고 움직임이 많은 장면을 처리할 수 있어 이 분야에서 새로운 표준을 제시하고 있습니다.

### 3. Proposed Approach

이 연구의 목적은 멀티뷰 비디오를 통해 캡처한 동적 3D 장면을 재구성하여 실시간 뷰 합성을 수행하는 것입니다. 먼저 공간 카빙 알고리즘을 사용하여 장면의 거친 포인트 클라우드를 추출합니다. 그런 다음 포인트 클라우드는 신경 장면 표현의 기초를 형성합니다. 이 표현은 견고함을 목표로 하며 하드웨어 가속을 통해 빠른 렌더링을 촉진합니다.

![제안한 파이프라인의 개요. (a) 공간 카빙 알고리즘[33]을 적용하여 목표 장면의 초기 클라우드 시퀀스 x, t를 추출합니다. 4D 특징 그리드[17]를 미리 정의하여 각 점에 특징 벡터를 할당하고, 이를 장면 지오메트리와 모양을 위해 MLP에 공급합니다. (b) 지오메트리 모델은 반투명 포인트 클라우드를 형성하는 포인트 위치, 반경, 밀도를 기반으로 합니다. (c) 외형 모델은 조각 단위로 상수인 IBR 용어 cibr과 연속적인 SH 모델 csh로 구성됩니다. (d) 제안된 표현은 차등 깊이 필링 알고리즘을 통해 멀티뷰 RGB 비디오로부터 학습됩니다.](4K4D%20Real-Time%204D%20View%20Synthesis%20at%204K%20Resolution%208e942a00010e411da6a6906fe1418b77/Untitled%201.png)

제안한 파이프라인의 개요. (a) 공간 카빙 알고리즘[33]을 적용하여 목표 장면의 초기 클라우드 시퀀스 x, t를 추출합니다. 4D 특징 그리드[17]를 미리 정의하여 각 점에 특징 벡터를 할당하고, 이를 장면 지오메트리와 모양을 위해 MLP에 공급합니다. (b) 지오메트리 모델은 반투명 포인트 클라우드를 형성하는 포인트 위치, 반경, 밀도를 기반으로 합니다. (c) 외형 모델은 조각 단위로 상수인 IBR 용어 cibr과 연속적인 SH 모델 csh로 구성됩니다. (d) 제안된 표현은 차등 깊이 필링 알고리즘을 통해 멀티뷰 RGB 비디오로부터 학습됩니다.

포인트 클라우드로 동적 장면 모델링하기:

- 4D 임베딩: 장면의 동적 특성을 포착하기 위해 6개의 특징 면이 사용됩니다. 이는 시간에 걸쳐 장면의 모든 지점을 나타내는 특징 필드를 생성하는 데 사용됩니다. 이 표현은 K-플레인이라는 방법을 사용하여 이러한 평면을 결합합니다.
- 지오메트리 모델: 동적 씬의 지오메트리는 이러한 포인트 클라우드로 구성됩니다. 클라우드의 각 점에는 위치, 반경, 밀도라는 세 가지 속성이 있습니다. 이러한 속성은 신경망을 사용하여 최적화되고 예측됩니다.
- 모양 모델: 장면의 모양, 즉 외관은 이미지 블렌딩 기법과 구형 고조파를 혼합하여 캡처합니다. 이 모델을 사용하면 장면의 불연속적 및 연속적 보기 의존적 외관을 모두 캡처할 수 있습니다. 불연속적인 외관은 빠른 렌더링의 이점을 제공하며, 연속적인 뷰는 모든 방향에서 장면의 외관을 캡처할 수 있습니다.

차별적인 뎁스 필링:

이 연구는 뎁스 필링 알고리즘을 사용하여 동적 장면 표현을 이미지로 변환하는 방법을 제시합니다. 포인트 클라우드를 활용하는 이 방법은 하드웨어 가속을 활용하여 렌더링 프로세스를 가속화합니다. 이 방식은 여러 번의 렌더링 패스를 통해 각 픽셀에 대해 카메라에 가장 가까운 점을 결정한 다음 이 점을 사용하여 해당 픽셀의 색상을 결정합니다. 또한 이 프로세스를 차별화하여 입력 비디오에 따라 최적화할 수 있습니다.

훈련:

모델은 렌더링하는 색상을 원본 비디오의 실제 색상과 비교하여 학습합니다. 이 작업은 평균 제곱 오류 손실과 추가적인 지각 손실을 사용하여 수행되며, 렌더링된 이미지의 인지된 품질을 향상시킵니다. 추가 정규화 단계는 모델이 장면의 동적인 부분에 올바르게 초점을 맞출 수 있도록 합니다.

추론:

훈련 후에는 여러 가지 기술을 사용하여 모델의 렌더링 속도를 높입니다. 실제 렌더링 전에 포인트 클라우드의 주요 속성이 미리 계산되어 저장됩니다. 렌더링 중에 이러한 사전 계산된 속성은 그래픽 카드로 전송되어 더 빠르게 액세스할 수 있습니다. 또한 모델 데이터는 효율적인 메모리 사용을 위해 압축되며, 렌더링 패스 횟수는 시각적 품질 저하 없이 속도에 최적화됩니다.

요약하면, 이 연구는 멀티뷰 비디오에서 동적 3D 장면을 실시간으로 재구성하고 렌더링하는 방법을 제시합니다. 포인트 클라우드 기반의 신경 표현을 도입하고 렌더링에 깊이 필링 알고리즘을 사용하여 품질과 속도를 모두 최적화합니다.

### 4. Implementation Details

4K4D 모델은 PyTorch 프레임워크를 사용하여 훈련됩니다. 학습 속도가 설정된 Adam 옵티마이저를 사용합니다. 시퀀스 길이가 200프레임인 경우 모델은 일반적으로 800만 번의 반복 끝에 수렴하며, 특정 그래픽 카드(RTX 4090 GPU)에서 약 24시간이 소요됩니다. 학습 중에는 포인트 위치에 대한 학습 속도, 렌더링 패스 수, 가장 가까운 입력 뷰 수 등 다양한 파라미터에 대한 특정 설정이 이루어집니다. 렌더링 속도와 관련된 모든 성능 측정은 달리 언급되지 않는 한 주로 RTX 3090 GPU에서 수행됩니다.

우선 모델은 기존의 멀티뷰 재구성 기술을 활용하여 초기 포인트 클라우드를 설정합니다. 동적인 영역의 경우 세분화 방법을 사용하여 입력 이미지에서 마스크를 식별합니다. 그런 다음 모델은 공간 조각 알고리즘을 사용하여 기본 형상을 도출합니다. 반면에 정적 영역의 경우 모델은 마스크를 사용하여 모든 프레임에서 배경 픽셀의 평균을 계산하여 전경 요소를 제외한 이미지를 효과적으로 생성합니다. 그런 다음 이러한 결과 이미지에 대해 Instant-NGP 모델을 학습시켜 초기 포인트 클라우드를 생성합니다. 이 초기화 프로세스가 끝나면 동적 영역에는 일반적으로 각 프레임당 약 25만 개의 포인트가 포함되며, 정적 영역에는 일반적으로 약 30만 개의 포인트가 포함됩니다.

### 5. Experiments

데이터 세트 및 메트릭.

4K4D 방식은 DNA-Rendering, ENeRF-Outdoor, NHR, Neural3DV와 같이 널리 사용되는 여러 멀티뷰 데이터 세트에서 테스트되었습니다. 특히 DNA-렌더링은 고화질 카메라를 사용하여 역동적인 사람과 물체의 짧은 비디오 클립을 캡처하며, 복잡한 콘텐츠로 인해 특히 까다롭습니다. 데이터 세트에는 카메라 해상도, 초당 프레임 수(FPS) 등 다양한 녹화 설정이 있었습니다. 평가를 위해 이러한 데이터 세트의 이미지는 원래 해상도를 기준으로 크기를 조정했습니다. 실험의 각 데이터 세트에는 특정 해상도가 사용되었습니다. 이러한 데이터 세트 설정에 대한 자세한 정보는 부록 A에서 확인할 수 있습니다.

![960 × 540 이미지가 포함된 ENeRF-Outdoor [43] 데이터 세트에 대한 정성적 비교. 우리의 방법은 훨씬 더 높은 렌더링 품질을 달성하고 ENeRF [43]보다 24배 빠르게 렌더링할 수 있습니다. 보다 동적인 결과는 보충 비디오에서 확인할 수 있습니다.](4K4D%20Real-Time%204D%20View%20Synthesis%20at%204K%20Resolution%208e942a00010e411da6a6906fe1418b77/Untitled%202.png)

960 × 540 이미지가 포함된 ENeRF-Outdoor [43] 데이터 세트에 대한 정성적 비교. 우리의 방법은 훨씬 더 높은 렌더링 품질을 달성하고 ENeRF [43]보다 24배 빠르게 렌더링할 수 있습니다. 보다 동적인 결과는 보충 비디오에서 확인할 수 있습니다.

![1352×1224 이미지가 포함된 Neural3DV [38] 데이터 세트에 대한 정성적 비교. 우리의 방법은 동적 물체의 고주파 디테일을 복구할 수 있을 뿐만 아니라 오클루전 주변의 선명한 가장자리도 유지할 수 있습니다.](4K4D%20Real-Time%204D%20View%20Synthesis%20at%204K%20Resolution%208e942a00010e411da6a6906fe1418b77/Untitled%203.png)

1352×1224 이미지가 포함된 Neural3DV [38] 데이터 세트에 대한 정성적 비교. 우리의 방법은 동적 물체의 고주파 디테일을 복구할 수 있을 뿐만 아니라 오클루전 주변의 선명한 가장자리도 유지할 수 있습니다.

5.1. 비교 실험.

4K4D 방법의 결과를 다른 주목할 만한 기법과 비교했습니다. 렌더링 속도 측면에서 4K4D는 최첨단 ENeRF 방법보다 30배 이상 성능이 뛰어났으며 렌더링 품질도 우수했습니다. 다른 동시 방식과 비교했을 때 4K4D는 13배 빠른 속도를 달성하면서도 일관되게 더 나은 품질의 이미지를 제공했습니다. 일부 방법은 고품질 비주얼을 생성하지만 오클루전 및 가장자리 주변의 흐릿함으로 인해 어려움을 겪었지만 4K4D는 200FPS 이상의 속도로 충실도 높은 이미지를 렌더링할 수 있었습니다. 4K4D의 우수성을 보여주는 다른 데이터 세트의 추가 결과는 부록 B에서 확인할 수 있습니다.

5.2. 절제 연구.

4K4D 방법의 다양한 구성 요소의 기여도를 이해하기 위해 DNA 렌더링 데이터세트에 대한 자세한 조사가 수행되었습니다. 4D 임베딩 또는 하이브리드 외관 모델과 같은 특정 기능을 제거하면 화질이 저하되었습니다. 이 연구는 또한 특정 손실 함수의 중요성을 강조했습니다. 예를 들어 Llpips 용어를 생략하면 렌더링의 지각 품질에 영향을 미쳤습니다. 스토리지 분석 결과 4K4D 방식의 최종 스토리지 비용은 소스 비디오를 포함하여 프레임당 2MB 미만인 것으로 나타났습니다. 인코딩 후 스토리지 오버헤드는 최소화되었고 렌더링 품질은 거의 변하지 않았습니다.

![1024×1224(및 1125×1536) 이미지가 포함된 DNA 렌더링 [11] 데이터 세트에 대한 정성적 비교. 다른 경쟁업체는 매우 역동적인 장면에서 고품질의 결과물을 생성하지 못하는 반면, 유니티의 방법은 200 FPS 이상의 고충실도 이미지를 생성할 수 있습니다.](4K4D%20Real-Time%204D%20View%20Synthesis%20at%204K%20Resolution%208e942a00010e411da6a6906fe1418b77/Untitled%204.png)

1024×1224(및 1125×1536) 이미지가 포함된 DNA 렌더링 [11] 데이터 세트에 대한 정성적 비교. 다른 경쟁업체는 매우 역동적인 장면에서 고품질의 결과물을 생성하지 못하는 반면, 유니티의 방법은 200 FPS 이상의 고충실도 이미지를 생성할 수 있습니다.

![DNA 렌더링 데이터 세트의 0013 01 서열에서 제안된 구성 요소의 제거 연구 [11]. 제안된 컴포넌트를 제거하면 구성 요소를 제거하면 지오메트리가 노이즈가 발생하고 모양이 흐릿해집니다. 우리의 방법은 지각적으로 정확한 모양과 색상으로 충실도가 높은 결과를 생성합니다. 색상. 자세한 설명은 섹션 5.2를 참조하십시오.](4K4D%20Real-Time%204D%20View%20Synthesis%20at%204K%20Resolution%208e942a00010e411da6a6906fe1418b77/Untitled%205.png)

DNA 렌더링 데이터 세트의 0013 01 서열에서 제안된 구성 요소의 제거 연구 [11]. 제안된 컴포넌트를 제거하면 구성 요소를 제거하면 지오메트리가 노이즈가 발생하고 모양이 흐릿해집니다. 우리의 방법은 지각적으로 정확한 모양과 색상으로 충실도가 높은 결과를 생성합니다. 색상. 자세한 설명은 섹션 5.2를 참조하십시오.

5.3. 렌더링 속도 분석.

렌더링 속도를 높이기 위해 4K4D 방식에 다양한 최적화 기법이 도입되었습니다. 이러한 기법은 4K4D의 하이브리드 지오메트리와 외형 표현을 활용했습니다. 모든 포인트에 대한 데이터를 미리 계산하고 캐싱함으로써 10배의 속도 향상을 달성했습니다. 또한 제안된 차등적 깊이 필링 알고리즘은 기존 CUDA 기반 기법보다 7배 이상 빠른 성능을 발휘했습니다. 다른 여러 가속 기술도 전반적인 속도 향상에 기여했습니다. 마지막으로, 다양한 GPU와 해상도에서 테스트한 결과 4K4D는 표준 하드웨어에서 4K 이미지에 대해서도 실시간 렌더링 속도를 유지했습니다.

### 6. Conclusion and Discussion

이 연구에서는 4K 해상도에서 동적 3D 장면을 실시간으로 렌더링하는 데 적합한 4K4D라는 새로운 신경 포인트 클라우드 표현을 소개했습니다. 이 모델은 포인트를 효과적으로 조절하는 데 도움이 되는 4D 피처 그리드에 기반을 두고 있습니다. 이와 함께 고품질 렌더링을 제공하기 위해 고유한 하이브리드 외형 모델이 고안되었습니다. 주목할 만한 특징은 하드웨어 래스터화 파이프라인을 활용하는 차별적인 깊이 필링 알고리즘을 통합하여 제안된 모델의 최적의 성능과 효율적인 렌더링을 보장한다는 것입니다. 실험 결과, 렌더링 품질 측면에서 4K4D의 우수성이 강조되었으며, 동시에 렌더링 속도도 30배 이상 빨라져 RTX 3090에서 1080p에서 200FPS를 초과하는 속도를 달성하는 등 상당한 향상을 보였습니다.

유망한 결과에도 불구하고 4K4D에는 몇 가지 과제가 있습니다. 특히 이 모델은 특정 애플리케이션에서 매우 중요한 기능인 프레임 간 점의 대응을 생성하는 데 어려움을 겪고 있습니다. 또한 비디오 프레임 수가 증가함에 따라 4K4D에 필요한 스토리지 용량이 선형적으로 증가합니다. 따라서 방대한 용량의 비디오를 처리하는 데 효율성이 떨어집니다. 이러한 문제를 해결하는 것, 즉 대응 모델링과 긴 동영상에 대한 스토리지 관리는 향후 잠재적인 연구의 흥미로운 분야입니다.

### Appendix

A. 데이터 세트 개요

이 연구는 실험에 다양한 데이터 세트를 활용했습니다. 각 데이터 세트의 시퀀스, 뷰, 프레임 수에 대한 자세한 분석은 탭에 문서화되어 있습니다. A1. 이 연구에서 개발된 이미지 기반 기준선과 방법의 경우, 훈련 뷰는 이미지 기반 렌더링(IBR) 프로세스의 소스 뷰를 겸합니다. 특히 소스 뷰로 제공되는 테스트 뷰는 없습니다.

B. 확장된 실험

B.1. NHR 데이터 세트에 대한 확장 분석

NHR 데이터 세트를 사용하여 여러 기준 방법에 대해 정량적 및 정성적 비교를 수행했습니다. 결과는 탭. A2와 그림 A1에서 볼 수 있듯이 특정 방법, 즉 KPlanes와 DyNeRF는 특히 빠른 모션 장면에서 선명한 이미지를 렌더링하는 데 한계가 있으며 느린 프레임 속도(각각 2.0 및 0.2 FPS)에서 작동하는 것으로 나타났습니다. 반면 ENeRF와 MlpMaps는 중간 정도의 해상도에서 인터랙티브한 프레임 속도를 제공합니다. 그러나 이 백서에서 소개하는 방법은 훨씬 빠른 속도(238FPS 대비 30FPS)로 더 높은 품질의 렌더링을 제공함으로써 이들보다 성능이 뛰어납니다.

B.2. SH 컬러 시각화

그림 A2는 DNA 렌더링 데이터 세트에서 특정 염기서열의 회전 뷰에서 SH 색상을 보여줍니다. SH 모델은 복잡한 외관을 캡처하여 연속적인 뷰 의존적 효과를 촉진하는 기능으로 강조됩니다.

B.3. 3DGS 방법에 대한 검사

3DGS 방식에 대한 추가 테스트, 특히 ENeRFOutdoor 데이터 세트의 특정 시퀀스의 첫 번째 프레임에 대한 테스트를 통해 다양한 인사이트를 얻을 수 있었습니다. 제안된 방법의 스토리지 요구 사항은 학습된 모델과 원본 이미지의 파일 크기를 모두 고려합니다. 사전 계산 후, 반복을 고려하더라도 메인 메모리 사용량은 3DGS에 비해 여전히 낮습니다. 시각적 품질을 검사할 때 3DGS는 초기 프레임에 지나치게 집중하는 경향이 있어 새로운 뷰에 적응하는 능력이 떨어집니다. 저장 효율성 측면에서 3DGS는 프레임당 상당한 저장 공간을 필요로 하는 반면, 제안된 방식은 훨씬 더 컴팩트합니다. 이러한 효율성은 4D 피처 그리드와 IBR 모델이 채택한 혁신적인 압축 메커니즘에 기인합니다. 새로운 방법의 최적화 및 사전 계산 절차는 압축 및 압축 해제 단계로 이해할 수 있으며, 동적 3D 장면을 효과적으로 인코딩 및 디코딩합니다. 또한 이 방식에서 사용하는 하이브리드 이미지 기반 외형 모델은 3DGS에서 사용하는 기법에 비해 더 풍부한 표현력을 제공합니다.