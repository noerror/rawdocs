# DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation

[https://arxiv.org/pdf/2208.12242.pdf](https://arxiv.org/pdf/2208.12242.pdf)

[https://dreambooth.github.io/](https://dreambooth.github.io/)

[https://smilegate.ai/2022/09/04/dreambooth-personalized-text-to-image-diffusion-model/](https://smilegate.ai/2022/09/04/dreambooth-personalized-text-to-image-diffusion-model/)

[https://namu.wiki/w/Dreambooth](https://namu.wiki/w/Dreambooth)

대규모 텍스트 이미지 AI 모델은 텍스트 프롬프트에서 고품질 이미지를 생성할 수 있지만 다양한 맥락에서 특정 피사체의 새로운 이미지를 생성하는 데 어려움을 겪습니다. 이러한 모델을 개인화할 수 있는 방법을 소개합니다. 피사체의 이미지를 몇 장 입력하면 사전 학습된 모델이 피사체에 고유 식별자를 연결하도록 조정합니다. 이를 통해 모델은 다양한 장면, 포즈, 조명에서 피사체의 새롭고 사실적인 이미지를 생성할 수 있습니다. 이 기술은 피사체의 주요 특징을 유지하면서 피사체 재맥락화, 텍스트 가이드 뷰 합성, 예술적 렌더링에 사용할 수 있습니다. 또한 피사체 중심 생성을 위한 새로운 데이터 세트와 평가 프로세스를 제공합니다.

![Untitled](DreamBooth%20Fine%20Tuning%20Text-to-Image%20Diffusion%20Mod%20a62b218116354a43950c6b0229fef37d/Untitled.png)

1. Introduction

전 세계를 여행하는 반려견, 파리 고급 쇼룸에 있는 좋아하는 가방, 앵무새가 동화책 속 캐릭터로 등장한다고 상상해 보세요. 이러한 이미지를 생성하려면 특정 피사체를 새로운 컨텍스트에 배치해야 하기 때문에 어려운 작업입니다. 대형 텍스트-이미지 모델은 텍스트 프롬프트에서 고품질 이미지를 생성할 수 있지만 다양한 컨텍스트에 있는 피사체를 모방하는 데 어려움을 겪습니다.

우리는 텍스트-이미지 모델을 개인화하여 사용자가 특정 피사체를 생성할 수 있는 새로운 접근 방식을 제시합니다. 피사체에 대한 고유 식별자를 모델에 삽입하여 주요 특징을 보존하면서 다양한 장면에서 사실적인 이미지를 만들 수 있습니다. 이 '마법의 사진 부스' 효과는 몇 가지 입력 이미지와 고유 식별자 및 클래스 이름이 포함된 텍스트 프롬프트를 사용하여 모델을 미세 조정함으로써 얻을 수 있습니다.

이 방법은 피사체 재맥락화, 속성 수정, 원본 아트 렌더링과 같은 다양한 텍스트 기반 이미지 생성 작업에 적용됩니다. 다른 접근 방식과 비교하여 피사체 및 프롬프트 충실도를 평가하기 위해 사용자 연구를 수행합니다. 이는 피사체 중심 생성을 다루는 최초의 기술로, 사용자가 피사체의 고유한 특징을 유지하면서 다양한 맥락에서 새로운 피사체 이미지를 생성할 수 있습니다.

또한 이 작업을 위해 다양한 맥락의 다양한 피사체를 포함하는 새로운 데이터 세트를 생성하고 피사체 및 프롬프트 충실도를 측정하기 위한 평가 프로토콜을 제안합니다. 데이터 세트와 평가 프로토콜은 프로젝트 웹페이지에서 공개적으로 사용할 수 있습니다.

2. Related work
이미지 합성 기술은 피사체를 새로운 배경에 혼합하지만 장면 통합이 좋지 않고 새로운 장면을 생성할 수 없는 등의 단점이 있습니다. 3D 재구성 기술은 딱딱한 물체에서 작동하며 더 많은 뷰가 필요합니다. 텍스트-대-이미지 편집 및 합성 방법은 GAN과 이미지-텍스트 표현을 사용하여 개선되었지만 다양한 데이터 세트와 피사체의 정체성을 유지하는 데 어려움을 겪습니다. 제어 가능한 생성 모델은 어느 정도 제어가 가능하지만 피사체의 신원을 보존하는 새로운 샘플 생성에는 부족합니다.

우리의 접근 방식은 이러한 한계를 극복하고 새로운 포즈와 새로운 컨텍스트에서 피사체를 생성할 수 있습니다. 다른 방법과 달리, 우리의 미세 조정 방식은 피사체를 모델의 출력 영역에 포함시켜 피사체의 주요 시각적 특징을 보존하는 새로운 이미지를 생성합니다. 따라서 우리의 방식은 독특한 피사체, 장면 통합 또는 피사체 디테일 보존에 어려움을 겪는 기존 기법과는 차별화됩니다.

3. Method

우리의 목표는 우연히 캡처한 몇 장의 이미지만으로 텍스트 프롬프트에 따라 피사체의 디테일과 변형이 높은 새로운 이미지를 생성하는 것입니다. 이를 위해 텍스트-이미지 확산 모델을 사용합니다. 피사체 인스턴스를 모델의 출력 영역에 이식하기 위해 피사체에 대한 몇 장의 사진 데이터 세트를 사용하여 모델을 미세 조정합니다. 입력 이미지에 고유 식별자와 클래스 설명자(예: 고양이, 개)로 레이블을 지정하는 프롬프트를 디자인합니다.

![Untitled](DreamBooth%20Fine%20Tuning%20Text-to-Image%20Diffusion%20Mod%20a62b218116354a43950c6b0229fef37d/Untitled%201.png)

일반적인 영어 단어와 혼동을 피하기 위해 희귀 식별자를 사용합니다. 언어 드리프트에 대응하고 출력의 다양성을 장려하기 위해 클래스별 사전 보존 손실을 제안합니다. 이는 자체적으로 생성된 샘플로 모델을 감독하여 클래스에 대한 사전 지식을 유지합니다. 이 방법을 사용하면 과적합의 위험 없이 새로운 시점, 포즈, 관절 표현으로 피사체의 다양한 이미지를 생성할 수 있습니다.

4. Experiments

이 연구에서는 몇 개의 참조 이미지와 텍스트 프롬프트만으로 피사체의 새로운 이미지를 생성하는 방법을 소개합니다. 이 목표를 달성하기 위해 텍스트-이미지 확산 모델을 사용하여 피사체에 대한 고유 식별자를 사용하여 모델을 미세 조정합니다. 이들은 언어 드리프트와 출력 다양성 감소 문제를 완화하기 위해 클래스별 사전 보존 손실을 제안합니다.

이들이 사용하는 데이터 세트에는 사물과 살아있는 피사체/애완동물로 구분된 30개의 피사체가 포함됩니다. 평가를 위해 피사체와 프롬프트당 4개의 이미지, 총 3,000개의 이미지를 생성합니다. 두 가지 지표를 사용하여 피사체 충실도를 측정합니다: CLIP-I와 DINO, 그리고 CLIP-T를 사용한 프롬프트 충실도입니다.

드림부스라고 불리는 이 방법을 최근 동시 작업인 텍스트 반전과 비교했을 때, 피사체와 프롬프트 충실도 모두에서 상당한 개선이 있었습니다. 사용자 연구에서도 피사체의 정체성을 유지하고 프롬프트에 더 충실하다는 측면에서 드림부스에 대한 선호도가 높은 것으로 나타났습니다.

연구진은 텍스트 프롬프트와 몇 가지 참조 이미지를 사용하여 피사체의 새로운 이미지를 생성하는 방법을 제시합니다. 연구진은 접근 방식의 효과를 테스트하기 위해 여러 가지 제거 연구를 수행했습니다. 연구진은 사전 보존 손실(PPL)을 사용하면 언어 드리프트에 대응하고 다양한 이미지를 생성하는 능력을 유지하며 더 높은 다양성을 달성하는 데 도움이 된다는 사실을 발견했습니다. 또한 미세 조정 시 정확한 클래스 명사를 사용하면 피사체 충실도가 훨씬 높아진다는 사실도 발견했습니다.

![Untitled](DreamBooth%20Fine%20Tuning%20Text-to-Image%20Diffusion%20Mod%20a62b218116354a43950c6b0229fef37d/Untitled%202.png)

이 방법은 재맥락화, 아트 렌더링, 새로운 뷰 합성, 속성 수정 등 다양한 용도로 활용되고 있습니다. 그러나 특정 프롬프트 컨텍스트 생성의 어려움, 컨텍스트와 외관의 얽힘, 실제 이미지에 대한 과적합 등 몇 가지 한계가 있습니다. 또한 일부 피사체는 다른 피사체보다 학습하기 쉬우며, 사전 모델의 강도와 의미 수정의 복잡성에 따라 피사체의 충실도에 차이가 있습니다.

5. Conclusions

연구진은 몇 개의 참조 이미지와 텍스트 프롬프트만으로 피사체의 새로운 버전을 생성하는 방법을 개발했습니다. 피사체에 고유 식별자를 할당하고 모델을 미세 조정함으로써 다양한 맥락에서 피사체의 새로운 표현을 생성할 수 있습니다. 이 기법은 3~5개의 피사체 이미지만 필요하기 때문에 접근성이 뛰어납니다. 이 방법은 동물과 사물에 사용할 수 있으며, 실제 이미지처럼 보이는 사실적인 장면을 생성할 수 있습니다.