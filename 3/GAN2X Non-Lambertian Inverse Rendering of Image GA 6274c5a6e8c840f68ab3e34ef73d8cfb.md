# GAN2X: Non-Lambertian Inverse Rendering of Image GANs

*획기적인 비지도 역 렌더링 방식인 GAN2X는 GAN을 사용하여 페어링되지 않은 이미지에서 3D 모양, 알베도, 스페큘러 속성을 정확하게 복구할 수 있는 의사 페어링 데이터를 생성합니다. 이를 통해 3D 오브젝트 조작 및 편집의 가능성이 무한히 열립니다. #AI #3DRendering*

[https://people.mpi-inf.mpg.de/~xpan/GAN2X/data/paper.pdf](https://people.mpi-inf.mpg.de/~xpan/GAN2X/data/paper.pdf)

[https://people.mpi-inf.mpg.de/~xpan/GAN2X/](https://people.mpi-inf.mpg.de/~xpan/GAN2X/)

![이미지 GAN의 비램버시안 역 렌더링을 연구합니다. 쌍을 이루지 않은 이미지 컬렉션에 대해 사전 훈련된 GAN이 생성한 이미지의 경우 페어링되지 않은 이미지 컬렉션에서 생성된 이미지의 경우, 그에 해당하는 의사 페어링 이미지를 활용하여 기본 오브젝트 모양을 복구합니다, 알베도, 스페큘러 속성 및 조명을 복구합니다. 이를 통해 새로운 시점이나 조명 조건에서 오브젝트를 다시 렌더링할 수 있습니다.](GAN2X%20Non-Lambertian%20Inverse%20Rendering%20of%20Image%20GA%206274c5a6e8c840f68ab3e34ef73d8cfb/Untitled.png)

이미지 GAN의 비램버시안 역 렌더링을 연구합니다. 쌍을 이루지 않은 이미지 컬렉션에 대해 사전 훈련된 GAN이 생성한 이미지의 경우 페어링되지 않은 이미지 컬렉션에서 생성된 이미지의 경우, 그에 해당하는 의사 페어링 이미지를 활용하여 기본 오브젝트 모양을 복구합니다, 알베도, 스페큘러 속성 및 조명을 복구합니다. 이를 통해 새로운 시점이나 조명 조건에서 오브젝트를 다시 렌더링할 수 있습니다.

이 논문은 2D 이미지에서 물체의 3D 속성(예: 모양, 재질)을 파악하는 과정인 '역 렌더링'을 위한 GAN2X라는 새로운 방법에 대해 설명합니다. 대부분의 역 렌더링 방법은 서로 다른 시점과 조명 조건의 이미지를 쌍으로 만들어야 하므로 많은 리소스가 필요합니다.

하지만 GAN2X는 페어링되지 않은 이미지를 학습용으로 사용하여 비지도 역 렌더링을 수행한다는 점에서 차이가 있습니다. 3D 형상을 복구하는 데 주로 초점을 맞춘 이전 방법과 달리 GAN2X는 형상뿐만 아니라 물체의 재질 특성도 복구하려고 합니다. 이는 생성적 적대 신경망(GAN)으로 알려진 일종의 인공 지능 모델에서 생성된 '의사 페어링' 데이터를 활용하여 달성할 수 있습니다.

GAN2X의 특별한 기능은 이미지에서 표면의 기하학적 구조와 재질 특성을 모델링하는 정교한 방법인 '스페큘러 인식 신경 표면 표현'입니다. 이를 통해 모델은 서로 다른 표면이 빛을 다르게 반사하는 방식, 즉 '스페큘러'를 설명할 수 있습니다. GAN2X에는 이미지의 미세한 디테일을 이해할 수 있는 '셰이딩 기반 개선' 기술도 포함되어 있습니다.

텍스트에 따르면 GAN2X는 다양한 유형의 물체에 대해 2D 이미지를 3D 모양, 색상(알베도), 광택(스페큘러 특성)으로 정확하게 분해하여 테스트에서 우수한 성능을 보였습니다. 특히 싱글뷰 2D 이미지에서 3D 얼굴을 재구성하는 데 탁월한 성능을 발휘합니다. 마지막으로, GAN2X는 실제 이미지를 편집하고 2D GAN을 3D GAN으로 변환하는 데 유용할 수 있음을 시사합니다.

1. Introduction

이 글에서는 이미지에서 물체의 물리적 속성(예: 형상, 재질, 조명)을 추정하는 컴퓨터 비전의 중요한 문제인 '역 렌더링'의 개념에 대해 설명합니다. 역 렌더링은 컴퓨터 그래픽에서 렌더링의 역방향 프로세스이며 증강 현실/가상 현실(AR/VR) 및 시각 효과에서 중요합니다.

광도 스테레오와 같은 기존의 역 렌더링 방법에는 멀티뷰 및 멀티라이팅 이미지가 필요하지만 설정이 복잡하고 자동차처럼 다양하고 실제와 같은 물체에는 적합하지 않을 수 있습니다. 페어링되지 않은 2D 이미지나 약한 주석을 사용하는 비지도 또는 약한 지도 접근 방식이 있었지만 미세한 디테일과 스페큘러 속성을 캡처하지 못하는 경우가 많았습니다.

이러한 문제를 해결하기 위해 새로운 방법인 GAN2X는 생성적 적대 신경망(GAN)을 사용하여 의사 조명 단계 데이터를 생성합니다. 이전 GAN을 사용한 작업에서는 3D 형상을 재구성하는 데 성공했지만, 스페큘러 머티리얼 속성을 간과하여 재구성된 3D 형상의 정밀도가 제한되는 경우가 많았습니다. GAN2X는 여기서 더 나아가 실제 이미지를 포함하여 사전 학습된 GAN이 생성한 각 이미지의 3D 모양, 재질 특성(알베도 및 스페큘러 구성 요소), 조명 상태를 예측합니다.

고품질 3D 모양과 비램버시안 외관을 모델링하기 위해 GAN2X는 암시적 신경 표면 표현을 사용합니다. 이 시스템은 사전 학습된 GAN을 사용하여 의사 멀티뷰 및 멀티라이팅 이미지를 생성한 다음, 의사 페어링 데이터의 재구성 손실과 추가 정규화 손실을 통해 최적화할 수 있습니다. 그러나 2D GAN에서 생성된 멀티뷰 이미지는 완전히 3D로 일치하지 않기 때문에 보다 세밀한 디테일을 복구하기 위해 셰이딩 기반 개선 프로세스가 사용됩니다.

GAN2X 방법은 다양한 물체 범주에 대해 고품질 3D 모양, 알베도 및 스페큘러 속성을 효과적으로 재구성하는 것으로 나타났으며, 이는 이미지 GAN이 실제로 비램버시안 물체 내재성을 캡처할 수 있음을 시사합니다. 알베도 및 표면 법선 추정과 단일 뷰 3D 얼굴 재구성 작업에서 GAN2X는 기존의 비지도 기준선보다 훨씬 뛰어난 성능을 발휘합니다. 또한 이미지 재조명 및 2D GAN을 3D로 변환하는 것과 같은 다운스트림 애플리케이션에서도 가능성을 보여줍니다.

요약하면, GAN2X는 공간적으로 변화하는 비램버시안 재료 특성을 학습하는 데 있어 GAN의 중요한 잠재력을 조명하고, 얼굴의 비지도 단일 뷰 3D 재구성에 대한 최첨단 성능을 보여주며, 다양한 다운스트림 애플리케이션을 가능하게 합니다.

2. Related Work

생성적 적대 신경망(GAN)은 이미지 합성, 특히 사실적인 고해상도 이미지를 생성할 수 있는 StyleGAN 제품군에서 상당한 진전을 이루었습니다. 그러나 GAN의 이미지 합성 프로세스는 일반적으로 물리적 해석 가능성이 부족하여 본질적으로 3D 모양과 재질 특성을 표현하지 못합니다.

GAN에 3D 제어 기능을 추가하려는 시도가 많이 이루어졌지만 일반적으로 외부 3D 모델이나 입력이 필요합니다. 일부 다른 방법에서는 3D 제어가 가능한 이미지 합성을 위해 3D 표현을 통합하는 3D 인식 GAN을 사용합니다. 그러나 이러한 방법은 대부분 반사율과 음영 프로세스를 명시적으로 모델링하지 않기 때문에 3D 지오메트리와 조명 제어가 최적화되지 않습니다. 이 백서에서 설명하는 방법인 GAN2X는 이러한 접근 방식에서 벗어나 광범위한 3D 표현 없이도 사전 학습된 GAN에서 비램버시안 머티리얼 속성을 복구하여 보다 효율적으로 구현하는 것을 목표로 합니다.

2D 이미지에서 오브젝트의 물리적 속성을 복구하는 프로세스인 역 렌더링은 주로 여러 시점과 조명 조건에서 오브젝트의 페어링된 이미지를 사용하여 감독된 설정에서 수행되어 왔습니다. 이 방법은 리소스를 많이 소모하고 자동차와 같은 실제 시나리오의 오브젝트에 적용하기 어려울 수 있습니다. 또한 합성 데이터로 학습된 방법을 실제 이미지에 적용하려면 도메인 갭 문제를 극복해야 합니다.

반면에 비지도 역 렌더링은 훈련에 페어링되지 않은 이미지 컬렉션만 있으면 되기 때문에 점점 더 많은 관심을 받고 있는 분야입니다. 이 방법은 입력 이미지에서 3D 지오메트리와 외형을 예측하지만, 문제가 제대로 해결되지 않아 초기에는 3D 프리어를 사용하여 사람의 얼굴과 신체에 초점을 맞춘 접근 방식이 주로 사용되었습니다. 페어링되지 않은 이미지 컬렉션에서 모양과 재질을 모두 학습하려는 시도도 있었지만, 종종 한계가 있었습니다.

이 논문에서는 GAN이 물체의 모양과 재질 특성을 암시적으로 캡처하여 형상과 재질 특성을 정밀하게 복구하는 비지도 역 렌더링에 새로운 접근 방식을 제공하는 새로운 방법인 GAN2X를 소개합니다. 이전 작업과 달리 GAN2X는 추가적인 3D 지오메트리 입력이나 거친 모양이 필요하지 않으며, 공간적으로 변화하는 비램버시안 머티리얼 속성을 성공적으로 복구합니다.

3. Method

이 접근 방식은 생성적 적대 신경망(GAN)에 의해 생성된 이미지의 고유 구성 요소(3D 모양, 알베도, 스페큘러 속성)를 검색하는 것을 목표로 합니다. 이 프로세스에는 GAN을 사용하여 데이터 분포를 학습하는 과정이 포함되며, 이를 통해 잠재 코드에서 이미지를 생성할 수 있습니다.

이미지의 3D 모양과 재질 속성은 인공 신경망의 일종인 두 개의 다층 퍼셉트론(MLP)으로 표현됩니다. 또한 카메라 뷰와 조명 상태를 각각 예측하는 뷰포인트 및 조명 인코더가 있습니다. 이를 통해 어떤 시점이나 조명 조건에서도 이미지를 렌더링할 수 있습니다.

이 모델은 볼륨 렌더링과 퐁 셰이딩을 사용하여 고유한 속성의 이미지를 차별화되고 최적화하기 쉬운 방식으로 렌더링합니다. 카메라 광선의 색상, 알베도, 스페큘러 강도, 광택 및 표면 법선은 일련의 공식을 통해 렌더링됩니다.

역 렌더링은 모양과 머티리얼 모델을 기반으로 수행됩니다. 여기에는 다양한 시점과 조명 조건으로 대략적으로 쌍을 이룬 여러 개의 이미지를 생성하는 탐색 및 활용 알고리즘이 포함됩니다. 그런 다음 이러한 이미지를 사용하여 고유한 구성 요소를 복구합니다.

![방법 개요. (a) 탐색 단계에서는 GAN 제너레이터를 안내하기 전에 볼록한 모양을 사용하여 다양한 시점과 조명 조건으로 투사된 이미지를 생성합니다. (b) 활용 단계에서는 투영된 이미지를 의사 쌍 데이터로 활용하여 이미지를 의사 페어링 데이터로 활용하여 기본 내재 구성 요소를 최적화합니다. 모양을 포함한 본질적 구성 요소 알베도 및 스페큘러 속성을 포함한 고유 구성 요소는 암시적 신경장을 통해 표현됩니다. 이 표현을 통해 이미지를 렌더링할 수 있습니다. 볼륨 렌더링 및 퐁 셰이딩을 통해 이미지를 렌더링할 수 있으며, 이는 그라데이션 기반 최적화에 자연스럽게 적용될 수 있습니다.](GAN2X%20Non-Lambertian%20Inverse%20Rendering%20of%20Image%20GA%206274c5a6e8c840f68ab3e34ef73d8cfb/Untitled%201.png)

방법 개요. (a) 탐색 단계에서는 GAN 제너레이터를 안내하기 전에 볼록한 모양을 사용하여 다양한 시점과 조명 조건으로 투사된 이미지를 생성합니다. (b) 활용 단계에서는 투영된 이미지를 의사 쌍 데이터로 활용하여 이미지를 의사 페어링 데이터로 활용하여 기본 내재 구성 요소를 최적화합니다. 모양을 포함한 본질적 구성 요소 알베도 및 스페큘러 속성을 포함한 고유 구성 요소는 암시적 신경장을 통해 표현됩니다. 이 표현을 통해 이미지를 렌더링할 수 있습니다. 볼륨 렌더링 및 퐁 셰이딩을 통해 이미지를 렌더링할 수 있으며, 이는 그라데이션 기반 최적화에 자연스럽게 적용될 수 있습니다.

이 방법은 GAN에 의해 생성된 개별 인스턴스에 적용되지만 여러 인스턴스에 대한 공동 훈련을 위해 확장할 수도 있어 일반화를 개선할 수 있습니다.

![정성적 비교. 우리의 접근 방식은 기준선보다 더 정확한 역 렌더링을 달성합니다(확대하여 자세히 보기 자세히 보기). 재조명 결과는 입술의 스페큘러 하이라이트 변화를 성공적으로 모델링하는 반면 기준선은 그렇지 못합니다.](GAN2X%20Non-Lambertian%20Inverse%20Rendering%20of%20Image%20GA%206274c5a6e8c840f68ab3e34ef73d8cfb/Untitled%202.png)

정성적 비교. 우리의 접근 방식은 기준선보다 더 정확한 역 렌더링을 달성합니다(확대하여 자세히 보기 자세히 보기). 재조명 결과는 입술의 스페큘러 하이라이트 변화를 성공적으로 모델링하는 반면 기준선은 그렇지 못합니다.

마지막으로 음영 기반 개선 단계를 채택하여 대상 이미지의 정보를 완전히 활용하고 불일치를 해결하여 유효한 3D 모양과 재질을 유지하면서 대상 이미지에서 더 많은 세부 정보를 복구합니다.

4. Experiments

연구진은 사람 얼굴, 고양이 얼굴, 자동차 등 다양한 오브젝트 카테고리에 초점을 맞춰 비지도 역 렌더링을 위한 GAN2X 방법에 대한 종합적인 테스트를 수행했습니다. 이 실험에서는 다양한 페어링되지 않은 이미지 데이터 세트를 사용했으며, 이러한 데이터 세트에 대해 사전 학습된 StyleGAN2와 배경 제거에 사용된 장면 파싱 모델을 사용했습니다.

정성적 평가의 경우, 3D 모양과 그 디테일을 재구성하는 측면에서 GAN2X 접근 방식이 Unsup3d 및 GAN2Shape와 같은 다른 방법보다 뛰어난 성능을 보였습니다. 또한 스페큘러 라이트 맵을 성공적으로 분해하고 하이라이트를 정확하게 캡처할 수 있었습니다. 그 결과 이 방법은 사실적인 재조명 효과를 생성하고 렌더링된 오브젝트의 정확도를 높였습니다. 또한 이 방법은 오브젝트에 따라 달라지는 스페큘러 속성과 공간에 따라 달라지는 스페큘러 속성을 학습하는 능력도 입증했으며, 연구진은 남은 모호성을 해결하는 것이 향후 과제가 될 것이라고 언급했습니다.

정량적 평가에는 단일 뷰 3D 재구성 및 알베도 평가가 포함되었습니다. 여기서도 GAN2X는 다른 방법에 비해 우수한 성능을 보였습니다. 더 높은 정확도와 더 자연스러운 3D 모양을 보여주었으며, 얼굴 알베도 및 모양 복구에서 기준선보다 뛰어난 성능을 보였습니다.

연구원들은 또한 방법의 다양한 구성 요소의 효과를 조사하는 절제 연구를 수행했습니다. 연구진은 특정 요소를 통합하면 알베도와 음영 사이의 엉킴이 개선되고 표면 법선 학습이 용이해지는 등 여러 가지 이점이 있음을 발견했습니다.

3D 재구성 외에도 GAN2X는 실제 이미지의 이미지 편집 효과에도 적용 가능함을 입증했습니다. 예를 들어 이미지의 스페큘러 강도와 광택을 조정하는 데 사용할 수 있습니다. 연구팀은 GAN2X가 여러 GAN 샘플에 대해 학습할 때 2D GAN의 생성 특성을 이어받아 2D GAN을 분해된 3D GAN으로 끌어올릴 수 있다는 사실을 관찰했습니다.

5. Conclusion

연구진은 비지도 역 렌더링을 위한 새로운 방법인 GAN2X를 도입했습니다. 이 기법은 생성적 적대 신경망(GAN)을 사용하여 오브젝트의 고유한 구성 요소를 나타내는 의사 페어링 데이터를 생성함으로써 페어링된 데이터가 부족하다는 문제를 해결합니다. 볼륨 렌더링과 퐁 셰이딩에 기반한 암시적 신경 표현을 활용하는 GAN2X는 다양한 물체 범주에서 고품질 3D 형상, 알베도(난반사 측정), 스페큘러 특성(거울과 같은 반사 관련)을 효과적으로 복구할 수 있습니다.

이번 성과로 이 방법의 잠재적 적용 범위가 더욱 넓어졌습니다. GAN2X는 페어링되지 않은 이미지 컬렉션만으로 공간적으로 변화하는 스페큘러 속성을 학습할 수 있는 최초의 방법입니다. 연구진은 향후 GAN2X를 최근 발전한 3D GAN과 결합하여 기하학적 정밀도와 물성 분해를 더욱 개선할 수 있을 것으로 예상하고 있습니다.

- 요약
    
    의사 페어링 데이터에 GAN 활용하기: 생성적 적대 신경망(GAN)은 서로 다른 오브젝트의 기본 내재적 구성 요소를 반영하는 인위적이지만 그럴듯한 데이터를 생성하는 데 사용됩니다. 이를 통해 학습을 위한 페어링된 데이터(해당 3D 모양과 속성을 가진 실제 이미지)가 충분하지 않거나 없는 문제를 해결할 수 있습니다.
    
    볼륨 렌더링 및 퐁 셰이딩 기반 암시적 신경 표현: GAN2X는 볼륨 렌더링과 퐁 셰이딩 기반의 신경 표현 기법을 활용합니다. 볼륨 렌더링은 이산적으로 샘플링된 3D 데이터 세트의 2D 투영을 표시하는 데 사용되는 기술입니다. 퐁 셰이딩은 컴퓨터 그래픽을 위해 표면이 빛을 반사하는 방식을 시뮬레이션하는 모델입니다.
    
    고품질 3D 셰이프, 알베도 및 스페큘러 속성 복구: 이 단계를 통해 GAN2X는 다양한 오브젝트 카테고리의 고품질 3D 모양, 알베도 및 스페큘러 속성을 복구할 수 있습니다. 알베도는 표면에 닿은 빛이 반사되는 정도를 측정하는 척도입니다. 스페큘러 속성은 물체에서 거울처럼 반사되는 빛과 관련이 있습니다.
    
    공간적으로 변화하는 스페큘러 속성의 비지도 학습: GAN2X는 페어링되지 않은 이미지 컬렉션만으로 공간적으로 변화하는 스페큘러 속성을 학습할 수 있는 최초의 방법입니다. 즉, 시스템은 페어링되지 않은 이미지 모음만 보고도 물체의 각 부분이 얼마나 반짝이는지 학습할 수 있습니다.
    
    다운스트림 애플리케이션 및 향후 작업: 고품질 3D 모양과 속성을 성공적으로 복구하면 다양한 잠재적 응용 분야가 열립니다. 연구진은 향후 GAN2X와 최근 발전한 3D GAN을 결합하여 기하학적 정밀도와 물성 분해를 더욱 개선할 것을 제안합니다
    
- 스펙큘러 검출
    
    이 논문에서 저자는 GAN2X라는 모델을 사용하여 페어링되지 않은 이미지에서 스페큘러 속성을 분리하고 감지합니다. 이들은 생성적 적대 신경망(GAN)을 사용하여 유사 페어링 이미지를 생성합니다. 이러한 유사 페어링 이미지는 페어링되지 않은 원본 이미지와 원본과 동일한 고유 속성(예: 3D 모양, 알베도, 스페큘러 구성 요소)을 공유해야 하는 해당 이미지로 구성됩니다.
    
    다음으로 저자는 볼륨 렌더링과 퐁 셰이딩에 기반한 암시적 신경 표현을 사용합니다. 퐁 셰이딩은 3D 컴퓨터 그래픽에서 빛이 표면에서 반사되는 방식을 근사화하기 위해 사용되는 모델입니다. 여기에는 스페큘러 반사를 모델링하는 용어가 포함됩니다. 이를 통해 이미지에서 스페큘러 하이라이트와 확산 알베도를 구분하여 스페큘러 속성을 모델에서 학습할 수 있습니다.
    
    학습된 스페큘러 속성은 공간에 따라 달라지므로 물체의 영역마다 광택의 수준이 다를 수 있습니다. 예를 들어 사람의 입술과 고양이 눈은 신체의 다른 부위보다 더 밝으며, 이러한 차이는 모델에 의해 포착됩니다.
    
    저자들이 지적하는 한 가지 과제는 스페큘러 강도와 광택을 구분하는 것입니다. 예를 들어 자동차의 타이어는 스페큘러 강도가 매우 낮기 때문에 예상보다 더 밝게 보일 수 있으며, 이로 인해 광택이 더 두드러지게 나타납니다. 이는 저자들이 앞으로 연구해야 할 분야 중 하나입니다.