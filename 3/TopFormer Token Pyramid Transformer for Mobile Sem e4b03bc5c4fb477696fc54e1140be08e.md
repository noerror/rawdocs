# TopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation

[https://github.com/ibaiGorordo/depthai-TopFormer-Semantic-Segmentation](https://github.com/ibaiGorordo/depthai-TopFormer-Semantic-Segmentation)

[https://arxiv.org/abs/2204.05525](https://arxiv.org/abs/2204.05525)

- Apr 2022

### 1. Introduction

이 논문에서는 시맨틱 분할과 같은 고밀도 예측 작업을 위해 특별히 설계된 새로운 모바일 친화적인 비전 트랜스포머(ViT) 아키텍처를 소개합니다. 문제는 ViT가 많은 비전 작업에서 성공을 거두었지만 많은 모바일 및 임베디드 디바이스의 성능을 초과하는 상당한 컴퓨팅 리소스가 필요하다는 점입니다.

![Untitled](TopFormer%20Token%20Pyramid%20Transformer%20for%20Mobile%20Sem%20e4b03bc5c4fb477696fc54e1140be08e/Untitled.png)

고밀도 예측 작업에 ViT를 적용하기 위해 많은 접근 방식은 컨볼루션 신경망(CNN)에서 일반적으로 사용되는 방법인 계층적 아키텍처를 채택합니다. 그러나 이러한 방법은 복잡성으로 인해 계산 비용이 많이 듭니다. 일부에서는 로컬 윈도우 영역 내에서 자체 주의도를 계산하여 효율성을 개선하려고 시도했지만, 모바일 디바이스에서는 시간이 많이 소요될 수 있습니다. 다른 사람들은 토큰 수를 줄이려고 시도했지만(토큰 슬리밍), 이는 인식 정확도에 부정적인 영향을 미칠 수 있습니다.

제안된 솔루션인 'TopFormer'는 CNN과 ViT의 장점을 모두 결합한 솔루션입니다. 토큰 피라미드 모듈이라고 하는 CNN 기반 모듈은 고해상도 이미지를 빠르게 처리하여 로컬 피처의 피라미드를 생성하는 데 사용됩니다. 의미 추출기라고 하는 ViT 기반 모듈은 이러한 토큰을 입력으로 받아 풍부한 의미와 넓은 수용 필드를 얻는 데 사용됩니다. 그런 다음 토큰을 매우 적은 수로 줄여 계산 비용을 절감합니다.

이 새로운 아키텍처는 다양한 규모의 토큰을 풀링하여 트랜스포머 블록에 공급함으로써 '규모 인식 글로벌 시맨틱'을 생성합니다. 이를 통해 토큰의 스케일과 관련된 시맨틱을 학습할 수 있습니다. 그런 다음 이러한 의미를 해당 토큰에 다시 주입하여 표현을 보강함으로써 고밀도 예측 작업을 위한 강력한 계층적 기능을 제공합니다.

이 논문은 까다로운 세분화 데이터 세트에 대한 실험을 통해 이 접근법의 효과를 입증합니다. 그 결과 탑포머 아키텍처가 더 짧은 지연 시간으로 모바일넷보다 뛰어난 성능을 발휘하는 것으로 나타났습니다. 또한, 이 모델의 작은 버전은 모바일 장치에서 실시간 세분화가 가능하면서도 경쟁력 있는 결과를 유지하는 것으로 나타났습니다.

### 2. Related Work

이 섹션에서는 제안된 연구와 관련된 세 가지 주요 영역인 경량 비전 트랜스포머, 효율적인 컨볼루션 신경망, 모바일 시맨틱 세그먼테이션을 검토합니다.

경량 비전 트랜스포머: 이미지 인식에서 트랜스포머 구조의 사용은 다양한 연구에서 탐구되고 있습니다. 최초의 비전 트랜스포머(ViT)는 이미지 분류에 순수 트랜스포머를 적용하여 뛰어난 성능을 달성했습니다. 다른 연구에서는 토큰 기반 증류를 사용하여 학습 데이터를 줄이고, 인접한 토큰을 집계하여 토큰 길이를 줄이며, 각 로컬 창 내에서 자체 주의를 계산하여 계산 복잡성을 줄이는 등 ViT를 보다 효율적으로 만드는 데 중점을 둡니다. 그러나 이러한 노력에도 불구하고 ViT는 종종 높은 계산 복잡성과 많은 수의 매개변수를 포함하기 때문에 모바일 디바이스에서 모바일넷보다 속도가 느립니다. 이 백서의 목표는 세분화 작업에서 지연 시간을 줄이면서 MobileNet보다 성능이 뛰어난 경량 ViT를 설계하는 것입니다.

효율적인 컨볼루션 신경망: 모바일 및 임베디드 디바이스에 비전 모델을 배포해야 할 필요성으로 인해 효율적인 컨볼루션 신경망(CNN) 설계에 대한 연구가 진행되었습니다. 역병목 구조, 채널 셔플 연산자, 더 많은 피처를 생성하기 위한 저렴한 연산자 사용 등 다양한 방법이 제안되었습니다. 일부 연구는 깊이, 너비, 해상도의 복합 스케일링에 초점을 맞추고 있습니다.

모바일 시맨틱 세분화: 가장 정확한 세분화 네트워크는 일반적으로 모바일 및 임베디드 디바이스의 용량을 초과하는 수십억 FLOPs의 연산이 필요합니다. 세분화 속도를 높이고 계산 비용을 줄이기 위해 멀티스케일 이미지를 입력으로 사용, 경량 백본, 측면 연결, 공간 및 시맨틱 경로, 특징 맵 정렬, 컨볼루션 분해, AutoML 기법 등 다양한 방법이 제안되었습니다. 그러나 이러한 발전에도 불구하고 효율적인 세그멘테이션 디코더인 LR-ASPP(Lite Reduced Atrous Spatial Pyramid Pooling)를 갖춘 MobileNetV3는 여전히 모바일 시맨틱 세그멘테이션의 강력한 기준이 되고 있습니다.

### 3. Architecture

이 섹션에서는 토큰 피라미드 모듈, 시맨틱 추출기, 시맨틱 주입 모듈, 세그멘테이션 헤드라는 네 가지 주요 구성 요소로 구성된 제안된 네트워크 아키텍처에 대한 개요를 설명합니다.

![Untitled](TopFormer%20Token%20Pyramid%20Transformer%20for%20Mobile%20Sem%20e4b03bc5c4fb477696fc54e1140be08e/Untitled%201.png)

토큰 피라미드 모듈: 모바일넷에서 영감을 받은 이 모듈은 스택형 모바일넷 블록을 활용하여 토큰 피라미드를 구축합니다. 모바일넷과 달리 풍부한 의미와 넓은 수신 필드를 목표로 하지 않고 더 적은 수의 블록을 사용합니다. 이미지를 입력으로 받아 일련의 토큰을 생성한 다음 목표 크기로 평균 풀링하고 연결하여 비전 트랜스포머에 공급할 새 토큰을 생성합니다.

스케일 인식 시맨틱 추출기: 이 추출기는 스택형 트랜스포머 블록으로 구성된 비전 트랜스포머를 사용하며, 각 블록은 멀티헤드 어텐션 모듈, 피드포워드 네트워크(FFN), 잔여 연결로 구성됩니다. 선형 레이어는 토큰의 공간적 모양을 유지하고 리쉐이핑 수를 줄이기 위해 1x1 컨볼루션 레이어로 대체됩니다. 모든 비선형 활성화는 ViT에서와 같이 GELU 대신 ReLU6입니다. 트랜스포머는 서로 다른 스케일의 풀링된 토큰을 입력으로 받아 공간 및 스케일 차원의 정보 교환을 통해 전체 이미지 수용 필드와 풍부한 시맨틱을 얻습니다.

시맨틱 인젝션 모듈 및 세분화 헤드: 스케일 인식 시맨틱과 다른 토큰 간의 시맨틱 갭을 완화하기 위해 시맨틱 인젝션 모듈이 도입되었습니다. 컨볼루션 레이어와 일괄 정규화를 통해 로컬 토큰과 글로벌 시맨틱을 모두 처리하여 주입할 피처와 시맨틱 가중치를 생성합니다. 그런 다음 처리된 글로벌 시맨틱을 로컬 토큰에 주입하고 그 결과를 세분화 헤드에서 사용합니다. 세그멘테이션 헤드는 고해상도 토큰의 크기와 일치하도록 저해상도 토큰을 업샘플링하고, 모든 스케일에서 토큰의 요소별 합계를 수행한 다음, 마지막으로 두 개의 컨볼루션 레이어를 통해 피처를 통과시켜 최종 세그멘테이션 맵을 생성합니다.

아키텍처 및 변형: 다양한 복잡성을 충족하기 위해 세 가지 변형 아키텍처가 제안됩니다: TopFormer-Tiny, TopFormer-Small, TopFormer-Base입니다. 각 변형은 각 멀티 헤드 셀프 어텐션 모듈의 헤드 수와 목표 채널 수 측면에서 다릅니다. 정확도-지연 시간 절충을 위해 마지막 세 가지 스케일의 토큰이 시맨틱스 주입 모듈과 세분화 헤드의 입력으로 선택됩니다.

### 4. Experiments

데이터 집합: 실험에 세 가지 공개 데이터 집합을 활용했습니다: ADE20K, PASCAL 컨텍스트 및 COCO-Stuff입니다. 평가 지표로 클래스별 교집합 평균(mIoU)이 설정되었습니다. 모델의 실제 적용을 위해 ARM 기반 컴퓨팅 코어에서 지연 시간을 측정했습니다.

![Untitled](TopFormer%20Token%20Pyramid%20Transformer%20for%20Mobile%20Sem%20e4b03bc5c4fb477696fc54e1140be08e/Untitled%202.png)

구현 세부 정보: 구현은 이미지넷에서 사전 학습된 TopFormer를 백본으로 사용하여 MMSegmentation 및 Pytorch를 기반으로 구축되었습니다. ADE20K 데이터 세트에 16개의 배치 크기와 160K 스케줄러를 사용했습니다. 초기 학습률은 0.00012로, 가중치 감쇄는 0.01로 설정했습니다. 계수 1.0의 "폴리" 학습 속도 스케줄을 사용했습니다.

ADE20K에서 실험: ADE20K 검증 세트에서 TopFormer의 성능을 이전 방법과 비교했습니다. 정확도와 계산 비용 모두에서 이전 방법보다 우수한 성능을 보였습니다.

이 실험에서 귀사의 TopFormer 모델이 이전 모델에 비해 시맨틱 세분화 작업에서 우수한 결과를 얻었으며, 계산 비용도 더 낮다는 이점이 있음을 입증했습니다. 계산과 지연 시간을 크게 줄이면서 경쟁력 있는 결과를 얻었기 때문에 TopFormer 모델이 ARM 기반 모바일 장치에서 실시간 세분화를 위한 실행 가능한 솔루션임을 보여주었습니다.

마지막으로, 탑포머의 소형 버전이 ARM 기반 모바일 디바이스에서 경쟁력 있는 결과로 실시간 세분화를 달성할 수 있었다고 언급하셨습니다. 이는 모델이 효과적일 뿐만 아니라 효율적이기 때문에 실시간 세분화가 필요한 실제 애플리케이션에 적합하다는 것을 의미합니다.

다양한 구성 요소가 모델에 미치는 영향을 이해하기 위해 일련의 제거 연구를 수행했습니다. 이러한 실험은 훈련 세트에서 수행되고 검증 세트에서 평가되었습니다. 토큰 피라미드, 규모 인식 시맨틱 추출기(SASE), 시맨틱 인젝션 모듈(SIM), 세그멘테이션 헤드의 영향을 조사했습니다.

토큰 피라미드는 수신된 입력과 출력으로 선택된 토큰 모두에서 중요한 역할을 했습니다. 토큰 피라미드를 입력으로 사용할 경우 다른 구성에 비해 더 나은 결과를 얻을 수 있었고, 1/8, 1/16, 1/32 스케일의 토큰을 사용할 경우 정확도와 계산 비용 간의 균형이 가장 잘 맞는다는 사실을 발견했습니다.

또한 SASE가 성능에 크게 기여하여 mIoU를 10% 증가시키는 것으로 나타났습니다. 또한 트랜스포머 블록의 멀티 헤드 셀프 어텐션 모듈(MHSA)이 mIoU를 약 2.4% 개선한 것으로 나타났습니다. 또한 ASPP 및 PPM과 같이 널리 사용되는 컨텍스트 모델과 비교했을 때, SASE는 훨씬 적은 계산 비용으로 훨씬 뛰어난 성능을 발휘하여 모바일 디바이스에 적합하다는 것을 입증했습니다.

SIM과 세분화 헤드도 모델 성능에 상당한 영향을 미치는 것으로 나타났습니다. SIM의 시그모이드Attn과 SemInfo 기능을 모두 사용함으로써 약간의 계산 증가만으로 더 나은 성능을 달성할 수 있었습니다. 세분화 헤드의 경우, 현재 설계가 다른 설계보다 더 나은 성능을 보였습니다.

SIM의 채널 수(M) 측면에서 256, 192, 128의 M 값이 매우 유사한 계산 비용으로 비슷한 성능을 달성한다는 것을 확인했으며, 소형, 소형, 기본 모델에서 각각 128, 192, 256으로 M을 설정하기로 했습니다. 또한, 계산과 정확도 사이의 균형을 고려하여 의미 추출기의 입력 토큰에 대한 해상도로 1/64의 출력 보폭을 선택했습니다.

파스칼 컨텍스트 테스트 세트에서 우리의 접근 방식은 정확도 측면에서 CNN이나 ViT를 기반으로 한 이전의 모든 접근 방식보다 성능이 뛰어났으며 계산 횟수도 더 적었습니다. 우리의 방법은 백본과 헤드가 가장 가벼웠으며, 이는 높은 수준의 효율성을 시사합니다.

COCO-Stuff 검증 세트에 대한 실험에서도 우리 모델의 우수한 성능을 관찰할 수 있었습니다. 탑포머의 기본 버전은 비슷한 계산을 하는 모바일넷V3 모델에 비해 8% 더 정확했습니다.

모델의 일반화 능력을 평가하기 위해 COCO 데이터 세트에서 객체 감지 작업을 수행했습니다. 객체 검출 방법으로 RetinaNet을 사용하고 특징 피라미드를 생성하기 위해 다른 백본을 사용한 결과, TopFormer를 기반으로 한 RetinaNet이 MobileNetV3와 ShuffleNet보다 더 나은 성능을 달성하면서도 계산량은 더 적다는 것을 발견했습니다. 이는 의미적 세분화를 넘어 다양한 작업에서 TopFormer의 적용 가능성을 보여줍니다.

### 5. Conclusion and Limitations

이 백서에서는 컨볼루션 신경망(CNN)과 비전 트랜스포머(ViT)의 장점을 결합한 모바일 비전 작업을 위한 새로운 아키텍처인 TopFormer를 소개했습니다. 이 아키텍처는 정확도와 계산 비용 사이에서 최적의 균형을 이룹니다. 특히 탑포머의 초소형 버전은 ARM 기반 모바일 장치에서 실시간 추론을 제공하면서도 경쟁력 있는 결과를 유지합니다. 실험 결과는 제안된 방법의 효율성을 입증합니다.

그럼에도 불구하고 TopFormer에는 한계가 있습니다. 가장 눈에 띄는 것은 물체 감지 작업의 개선이 미미하다는 점입니다. 향후 연구에서는 물체 검출에서 TopFormer의 성능을 향상시키는 것을 목표로 하고 있습니다. 또한 고밀도 예측 작업에서 TopFormer의 잠재력을 탐구할 계획입니다. 이러한 탐색을 통해 TopFormer의 적용 범위를 넓혀 다양한 비전 작업을 위한 다용도 도구로 한 걸음 더 다가갈 수 있을 것입니다.

### Appendix

공정성을 유지하기 위해 ImageNet에서 사전 학습된 매개변수를 사용하여 모델을 시작했습니다. 새로운 TopFormer 모델의 아키텍처는 클래스 점수를 생성하기 위해 평균 풀링 레이어와 글로벌 시맨틱에 추가된 선형 레이어를 사용합니다. 저해상도 이미지의 경우, 의미 추출기의 목표 해상도를 낮췄습니다. 분류 결과는 표 12에 나와 있지만, 모바일 시맨틱 세분화가 주요 목표이기 때문에 정확도를 높이기 위한 고급 기술을 아직 도입하지 않았습니다. 향후 이를 개선할 계획입니다.

네트워크 구조
표 14는 네트워크 구조에 대한 자세한 개요를 제공합니다. 토큰 피라미드 모듈이 가장 많은 레이어를 가지고 있지만, ViT를 기반으로 하는 시맨틱 추출기가 가장 많은 파라미터를 가지고 있습니다.

![Untitled](TopFormer%20Token%20Pyramid%20Transformer%20for%20Mobile%20Sem%20e4b03bc5c4fb477696fc54e1140be08e/Untitled%203.png)

도시 풍경에서의 성능
구현은 MMSegmentation과 Pytorch를 기반으로 했으며 초기 학습률 0.0003, 가중치 감쇠 0.01로 80만 번의 반복을 수행했습니다. 계수 1.0의 폴리 학습 속도 스케줄을 사용했습니다. 전체 해상도 훈련 이미지의 경우 1024 x 1024의 고정 크기로 크기를 조정하고 잘라냈습니다. 반해상도 이미지의 경우 1024 x 512로 크기를 조정한 다음 동일한 프로세스를 적용했습니다. 공정한 비교를 위해 세그포머의 데이터 증강 전략을 사용했습니다.

그 결과, Ours(f)로 표시된 당사의 모델이 MobileNetV2 기반의 L-ASPP에 비해 mIoU에서 약 2.6% 더 높은 정확도를 달성했지만 계산은 더 적게 수행했습니다. 이는 탑포머가 고해상도 입력에서도 정확도와 계산 간의 균형을 잘 맞출 수 있다는 것을 증명합니다.

그림 6에서는 제안된 TopFormer를 ADE20K 검증 세트를 사용하여 다른 CNN 및 ViT 기반 방법과 비교했습니다. 여기서는 MobileNetV2 기반의 deeplabv3+와 세그포머를 사용하여 각각 CNN과 ViT 기반 방법을 표현했습니다. 이 두 가지 방법은 모델 크기와 계산 비용이 더 크지만, TopFormer 방법이 더 나은 세분화 결과를 보여주었습니다.

![ADE20K 검증 세트에서 Ground Truth, MBV2-Deeplabv3+, SegFormer-B0 및 제안된 TopFormer의 시각화. 우리는 시각화를 수행하기 위해 TopFormer-B를 사용합니다.](TopFormer%20Token%20Pyramid%20Transformer%20for%20Mobile%20Sem%20e4b03bc5c4fb477696fc54e1140be08e/Untitled%204.png)

ADE20K 검증 세트에서 Ground Truth, MBV2-Deeplabv3+, SegFormer-B0 및 제안된 TopFormer의 시각화. 우리는 시각화를 수행하기 위해 TopFormer-B를 사용합니다.