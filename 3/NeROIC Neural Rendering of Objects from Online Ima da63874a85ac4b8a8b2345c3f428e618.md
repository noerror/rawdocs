# NeROIC: Neural Rendering of Objects from Online Image Collections

[https://arxiv.org/abs/2201.02533](https://arxiv.org/abs/2201.02533)

[https://github.com/snap-research/NeROIC](https://github.com/snap-research/NeROIC)

- Sep 2022

![온라인 이미지로부터 우리의 객체 캡처 결과. 우리의 모듈식 NeRF 기반 접근법은 객체가 광범위하게 변하는 조건에서 캡처된 대략적으로 분할된 이미지만 필요합니다(1번째 열). 우리는 먼저 신경 렌더링을 사용하여 밀도 필드로 기하학을 추론하고, 그런 다음 객체의 표면 재질 속성과 이미지 별 조명 조건을 계산합니다(2번째 열). 우리의 모델은 새로운 뷰를 합성할 뿐만 아니라, 캡처된 객체를 새로운 환경 및 조명 조건에서 재조명 및 복합화할 수도 있습니다(3-5번째 열).](NeROIC%20Neural%20Rendering%20of%20Objects%20from%20Online%20Ima%20da63874a85ac4b8a8b2345c3f428e618/Untitled.png)

온라인 이미지로부터 우리의 객체 캡처 결과. 우리의 모듈식 NeRF 기반 접근법은 객체가 광범위하게 변하는 조건에서 캡처된 대략적으로 분할된 이미지만 필요합니다(1번째 열). 우리는 먼저 신경 렌더링을 사용하여 밀도 필드로 기하학을 추론하고, 그런 다음 객체의 표면 재질 속성과 이미지 별 조명 조건을 계산합니다(2번째 열). 우리의 모델은 새로운 뷰를 합성할 뿐만 아니라, 캡처된 객체를 새로운 환경 및 조명 조건에서 재조명 및 복합화할 수도 있습니다(3-5번째 열).

### 1 INTRODUCTION

- 온라인에는 같은 물체지만 조명과 배경 등 다양한 조건에서 촬영된 이미지 컬렉션이 많이 있습니다.
- 이러한 객체를 분리하여 새로운 설정에서 사용하는 데 관심이 있지만, 촬영 조건이 다양하기 때문에 쉽지 않습니다.
- 보다 통제된 설정을 위해 설계된 현재의 기술은 이러한 "야생" 이미지에는 잘 작동하지 않습니다.
- 이전 연구에서는 특히 몇 장의 이미지에서 장면을 재현할 수 있는 '신경 방사 필드' 또는 NeRF 모델에서 좋은 진전이 있었습니다. 그러나 이러한 모델은 특히 온라인에서 찾은 임의의 이미지를 처리할 때 몇 가지 한계가 있습니다.
- 다른 연구자들도 다양한 방식으로 NeRF를 개선했지만, 실제 세계의 다양한 이미지 컬렉션을 처리할 수 있는 완벽한 솔루션을 개발한 사람은 아직 없습니다.

우리의 솔루션: NeROIC:

- 저희는 온라인 이미지 컬렉션의 객체를 신경망 렌더링하는 'NeROIC'을 소개합니다.
- 온라인에서 흔히 볼 수 있는 몇 개의 무작위 이미지에서 개체를 캡처하고 다시 만들 수 있습니다. 각 이미지에는 물체의 간단한 윤곽과 대략적인 카메라 정보만 있으면 됩니다.
- 프로세스는 단계적으로 진행됩니다: 먼저 물체의 모양을 파악하고 카메라 설정을 조정합니다. 다음으로, 물체의 표면 유형과 촬영 당시 조명이 어떻게 비춰졌는지 추측합니다.
- 이 방법의 독특한 부분은 프로세스를 세분화한 다음 물체의 표면을 더 자세히 파악할 수 있는 방법을 도입한 것입니다.
- 다양한 실제 데이터 세트를 사용해 이 방법을 테스트한 결과, 기존 기법보다 성능이 우수하면서도 효율성이 높다는 것을 확인했습니다.

핵심 포인트:

- 다양한 사진에서 물체를 이해하는 새로운 방법을 개발했습니다.
- 이 방법은 단계적으로 작동하여 먼저 물체의 모양을 파악한 다음 표면과 조명을 파악합니다.
- 또한 이러한 "신경 방사 필드"에서 더 자세한 정보를 얻을 수 있는 기법도 도입했습니다.

### 2 RELATED WORK

새로운 뷰 합성을 위한 뉴럴 렌더링:

- NeRF라는 최신 기술을 사용하면 몇 장의 이미지로 장면의 새로운 뷰를 만들 수 있습니다. 이 기술은 물체가 얼마나 투명한지, 그리고 어떻게 빛을 반사하는지 이해하는 방식으로 작동합니다. 하지만 특정 조건에서 촬영한 특정 유형의 사진이 필요합니다.
- 일부 새로운 모델은 카메라 설정을 추측하거나 설정을 몰라도 장면을 다시 만들 수 있습니다. 다른 모델은 프로세스를 더 빠르게 만들거나 이미지에서 3D 모델을 만들 수 있습니다. 하지만 다른 조명에서 물체가 어떻게 보이는지 변경하거나 세부적인 재구성을 만들 수는 없습니다.

온라인 이미지 컬렉션에서 배우기:

- 연구원들은 건물이나 사람의 얼굴을 재현하기 위해 온라인 사진 컬렉션을 사용했지만 많은 사진이 필요합니다. 이러한 방법은 유명한 장소나 인물에 대해서만 효과가 있습니다.
- 일부 새로운 기술을 사용하면 신경망과 단 한 장의 사진만으로 사물의 새로운 시각을 만들 수 있습니다. 하지만 물체의 모양, 모양 또는 설정을 제어하거나 변경할 수는 없습니다.
- 다른 기술은 카테고리에 있는 물체의 포즈, 모양 또는 질감을 추측하거나 새로운 보기를 만들거나 이미지를 분할할 수 있습니다. 하지만 물체의 구조나 다른 조명에서 어떻게 보이는지에 대한 자세한 정보는 얻을 수 없습니다.

이미지 콘텐츠 분해 및 재조명:

- 일부 연구는 조명과 물체의 고유한 속성을 이해하는 데 중점을 둡니다. 한 가지 방법은 큰 장면을 만들 수 있지만 물체의 구조나 모양에 대한 자세한 정보를 제공하지 못합니다.
- 다른 연구에서는 물체의 재질 속성을 이해하기 위해 NeRF와 물리 기반 렌더링을 혼합하기도 합니다. 하지만 특정 조명 조건이나 데이터가 필요합니다.
- 최근의 일부 방법은 입력에 더 유연하지만 여전히 한계가 있습니다. 날카로운 그림자나 반사 표면과 같은 복잡한 음영을 처리하는 데 어려움을 겪습니다.
- 유니티에서는 이러한 복잡한 음영을 이해하고 분리할 수 있는 컴포넌트를 추가하여 물체의 재질 속성을 더 잘 이해할 수 있도록 했습니다.
- 우리와 유사한 기술을 사용하는 신경 분해에 대한 연구도 있습니다. 하지만 이는 건물과 같은 큰 장면을 위해 설계되었습니다.
- 우리가 아는 한, 인터넷의 이미지를 사용해 물체의 모양과 재질을 모두 이해하는 방법은 이 방법이 최초입니다.

### 3 METHOD

3.1 개요

- 입력: 다양한 조건에서 물체(또는 동일한 물체의 인스턴스)를 보여주는 이미지 모음과 전경 마스크 세트입니다.  를 사용하여 오브젝트의 영역을 정의합니다.
- 첫 번째 단계:
    - 물리적 내용을 나타내는 밀도 필드를 통해 오브젝트의 지오메트리를 추정합니다.
    - 정적 및 과도 광도 값을 모두 학습합니다.
    - 포즈 및 카메라 고유 파라미터 최적화를 통해 대략적인 추정치를 구체화합니다.
- 2단계:
    - 지오메트리를 고정합니다.
    - 임의의 조명 조건에서 렌더링할 수 있도록 표면 재질 및 조명 파라미터를 최적화합니다.
    - 더 나은 포인트 샘플링을 위한 추정 거리 사용.
    - 밀도 필드에서 거친 추정치를 개선하기 위한 표면 노멀 최적화.

3.2 사전 준비

- Mildenhall 외(2020)의 신경 방사 필드(NeRF)의 개념을 소개합니다.
- NeRF는 네트워크를 훈련시켜 모든 3D 포인트의 복사 및 밀도를 추론하고 새로운 관점에서 이미지를 생성합니다.
- NeRF가 두 가지 함수, 밀도 함수를 사용하는 방법에 대해 자세히 설명합니다. σ(x)와 색상 함수 c(x)를 사용하여 3D 포인트를 샘플링하고 픽셀 색상을 통합하는 방법에 대해 자세히 설명합니다.

3.3 지오메트리 네트워크

- 이 섹션에서는 이미지를 사용하여 오브젝트의 지오메트리를 재구성하는 프로세스에 대해 자세히 설명합니다.
- 도전 과제:
    - 다양한 조명 환경.
    - 날카로운 그림자와 같은 일시적인 조건.
    - 다양한 카메라 파라미터.
    - 배경 컨텍스트 부족으로 인한 거친 카메라 포즈.
    - 트랜지언트 콘텐츠와 정적 콘텐츠를 별도로 처리하는 두 개의 분기 파이프라인이 사용됩니다.
    - 밀덴홀 외[2020]에서 영감을 얻은 새로운 체적 렌더링 함수 공식이 도입되었습니다.
    - 불확실성을 예측하기 위해 켄달과 갈[2017]의 베이지안 학습 프레임워크가 채택되었습니다.
        
        ![저희의 접근법 개요. 대략적으로 보정된 이미지와 해당 전경 마스크 세트가 주어지면, 우리의 기하학 네트워크는 정적 및 일시적 구성 요소를 가진 신경 방사 필드를 계산하고 카메라 매개 변수를 세밀화합니다(a). 우리의 그리드 기반의 정상 추출 계층은 그 다음 학습된 밀도 필드에서 표면 정상을 추정합니다(b). 마지막으로, 객체의 기하학을 고정하고 추정된 정상을 감독으로 사용하여 렌더링 네트워크에서 조명 조건(구형 조화 계수로 표시), 표면 재질 속성(퐁 렌더링 모델 사용) 및 고품질 표면 정상을 추론합니다(c).](NeROIC%20Neural%20Rendering%20of%20Objects%20from%20Online%20Ima%20da63874a85ac4b8a8b2345c3f428e618/Untitled%201.png)
        
        저희의 접근법 개요. 대략적으로 보정된 이미지와 해당 전경 마스크 세트가 주어지면, 우리의 기하학 네트워크는 정적 및 일시적 구성 요소를 가진 신경 방사 필드를 계산하고 카메라 매개 변수를 세밀화합니다(a). 우리의 그리드 기반의 정상 추출 계층은 그 다음 학습된 밀도 필드에서 표면 정상을 추정합니다(b). 마지막으로, 객체의 기하학을 고정하고 추정된 정상을 감독으로 사용하여 렌더링 네트워크에서 조명 조건(구형 조화 계수로 표시), 표면 재질 속성(퐁 렌더링 모델 사용) 및 고품질 표면 정상을 추론합니다(c).
        
- 몇 가지 방법론이 도입되었습니다:
    - 실루엣 손실: 입력 전경 마스크를 사용하여 네트워크가 실루엣 내부의 물체에 초점을 맞추고 모호한 지오메트리를 방지하도록 돕습니다.
    - 적응형 샘플링: 적응형 샘플링: 이러한 마스크를 사용하여 적응형 샘플링 전략을 채택하여 훈련 효율성을 높입니다.
    - 카메라 최적화: 입력 이미지는 다양한 소스에서 가져오고 배경이 제거되기 때문에 카메라 포즈가 부정확할 수 있습니다. 이 문제를 해결하기 위해 훈련 중에 카메라 포즈를 최적화합니다.
- 주어진 최종 공식인 geo 는 이 단계의 총 손실을 나타내며, 이는 특정 가중치를 가진 여러 손실 함수의 조합입니다.
- 본질적으로 이 접근 방식은 다양한 요소를 고려하고 그에 따라 최적화하여 이미지에 있는 물체의 형상을 정확하게 재구성하는 데 초점을 맞추고 있습니다.

3.4 노멀 추출 레이어

- 학습된 지오메트리에서 다음 단계를 안내하기 위해 물체의 표면 노멀을 추출합니다.
- 이 방법은 밀도 함수의 기울기로부터 노멀을 근사화하는 대신 밀도가 높은 그리드에서 3D 컨볼루션을 사용합니다. 밀도 함수는 정확한 노멀을 생성하기 위해 다시 매핑됩니다.
- 개체의 바운딩 박스를 계산하고 각 그리드 중심의 밀도를 추출하여 다시 매핑합니다.
- 그런 다음 밀도 필드의 기울기를 추정하고 그 결과를 정규화하여 노멀 감독 벡터를 생성합니다.

3.5 네트워크 렌더링

- 마지막 단계에서는 각 이미지의 조명과 오브젝트의 재질 속성을 추정하는 것을 목표로 합니다.
- 조명 모델을 표현하기 위해 저차 구형 고조파(SH)를 사용하고, 오브젝트 재질 속성을 표현하기 위해 Phong BRDF 모델을 사용합니다.
- 구형 고조파 조명 모델의 한계를 해결하기 위해 신경망과 파라메트릭 모델을 모두 사용하는 하이브리드 색상 예측 방법이 도입되었습니다.
- 학습을 가속화하기 위해 학습된 지오메트리의 깊이 정보를 사용하여 멀리 떨어진 샘플 포인트를 필터링합니다.
- 표면 법선은 이전 단계의 출력에 의해 예측 및 감독됩니다.
- 톤 매핑 프로세스가 적용되어 선형 HDR 공간에서 결과를 렌더링합니다. SH 렌더러는 최적화 과정에서 변동에 적응합니다.
- 머티리얼 속성과 조명 사이의 모호함을 줄이기 위해 규칙성 손실이 도입됩니다.

3.6 네트워크 구조

- 첫 번째 단계인 지오메트리 네트워크는 위치 인코딩 방법을 사용합니다. 입력 위치 벡터는 임베드된 다음 각각 다른 예측을 담당하는 여러 분기로 공급됩니다.
- 두 번째 단계인 렌더링 네트워크는 비슷한 구조를 공유하지만 정적 색상 예측을 위한 다른 분기가 있습니다.
- 다양한 네트워크 레이어에 대한 활성화 기능 및 특정 최적화 방법이 자세히 설명되어 있습니다.
본질적으로 이 방법은 이미지에서 물체의 기하학적 및 측광학적 속성을 추정하는 강력한 방법을 제공하며, 노이즈와 블러를 보다 효과적으로 처리하여 이전 방법보다 진일보했습니다.

![카메라 최적화에 대한 비교. 카메라 최적화 없이 훈련된 모델은 전체 모델보다 더 나쁜 객체 기하학 및 색상을 생성합니다.](NeROIC%20Neural%20Rendering%20of%20Objects%20from%20Online%20Ima%20da63874a85ac4b8a8b2345c3f428e618/Untitled%202.png)

카메라 최적화에 대한 비교. 카메라 최적화 없이 훈련된 모델은 전체 모델보다 더 나쁜 객체 기하학 및 색상을 생성합니다.

![정상 추출 계층 분석. 왼쪽에서 경사 기반의 정상 예측(파란색 화살표)은 무한한 밀도 필드에서의 잡음에 영향을 받을 수 있지만, 이 효과는 밀도 리매핑(이 경우 𝜆 = 1)으로 완화될 수 있습니다. 오른쪽에서는 원래 밀도 필드에서 추정된 정상(왼쪽 상단), 리매핑된 정상(오른쪽 상단), 저희의 정상 추출 계층 출력(왼쪽 하단) 및 저희의 결과를 신뢰도와 함께 보여줍니다(오른쪽 하단).](NeROIC%20Neural%20Rendering%20of%20Objects%20from%20Online%20Ima%20da63874a85ac4b8a8b2345c3f428e618/Untitled%203.png)

정상 추출 계층 분석. 왼쪽에서 경사 기반의 정상 예측(파란색 화살표)은 무한한 밀도 필드에서의 잡음에 영향을 받을 수 있지만, 이 효과는 밀도 리매핑(이 경우 𝜆 = 1)으로 완화될 수 있습니다. 오른쪽에서는 원래 밀도 필드에서 추정된 정상(왼쪽 상단), 리매핑된 정상(오른쪽 상단), 저희의 정상 추출 계층 출력(왼쪽 하단) 및 저희의 결과를 신뢰도와 함께 보여줍니다(오른쪽 하단).

### 4 EVALUATIONS

4.1 구현 세부 사항

- 네트워크에 수정된 MLP 구조를 사용했습니다.
- 훈련은 초기 학습률이 4 × 10^-4인 Adam 최적화기를 활용했습니다.
- 훈련과 추론 모두에 PyTorch 프레임워크를 사용했습니다.
- 훈련은 4대의 NVIDIA V100에서, 테스트는 1대의 NVIDIA V100에서 수행되었습니다.
- 모델은 첫 번째 단계에서 30개의 에포크에 대해 약 6~13시간, 두 번째 단계에서 10개의 에포크에 대해 2~4시간이 소요되었습니다.
- 평가에는 총 13개의 오브젝트로 구성된 세 가지 데이터 세트 소스가 사용되었습니다.

4.2 비교

- 오프라인에서 캡처한 7개의 물체에 대해 제안된 모델과 NeRF를 비교했습니다.
- 평가 지표는 PSNR, SSIM, LPIPS였습니다.
- 제안된 모델은 NeRD 헤드 데이터 세트의 경우를 제외하고는 일반적으로 NeRF보다 우수한 성능을 보였습니다.
- 제안한 모델은 NeRF보다 적은 수의 훈련 이미지로도 좋은 성능을 보였습니다.
- 또한 다른 최신 분해 방법인 NeRD와 NerFactor와 비교해도 좋은 성능을 보였습니다.

4.3 절제

![정상 추출 계층 분석. 왼쪽에서 경사 기반의 정상 예측(파란색 화살표)은 무한한 밀도 필드에서의 잡음에 영향을 받을 수 있지만, 이 효과는 밀도 리매핑(이 경우 𝜆 = 1)으로 완화될 수 있습니다. 오른쪽에서는 원래 밀도 필드에서 추정된 정상(왼쪽 상단), 리매핑된 정상(오른쪽 상단), 저희의 정상 추출 계층 출력(왼쪽 하단) 및 저희의 결과를 신뢰도와 함께 보여줍니다(오른쪽 하단).](NeROIC%20Neural%20Rendering%20of%20Objects%20from%20Online%20Ima%20da63874a85ac4b8a8b2345c3f428e618/Untitled%204.png)

정상 추출 계층 분석. 왼쪽에서 경사 기반의 정상 예측(파란색 화살표)은 무한한 밀도 필드에서의 잡음에 영향을 받을 수 있지만, 이 효과는 밀도 리매핑(이 경우 𝜆 = 1)으로 완화될 수 있습니다. 오른쪽에서는 원래 밀도 필드에서 추정된 정상(왼쪽 상단), 리매핑된 정상(오른쪽 상단), 저희의 정상 추출 계층 출력(왼쪽 하단) 및 저희의 결과를 신뢰도와 함께 보여줍니다(오른쪽 하단).

- 다양한 구성 요소의 중요성을 파악하기 위해 여러 가지 제거 연구를 수행했습니다:
- 새로운 뷰 합성: 제안된 모델은 실루엣 손실 또는 일반 추출 레이어와 같은 특정 특징을 제외한 변형보다 더 나은 성능을 보였습니다.
- 분해: 전체 모델은 정확한 머티리얼 속성을 생성하고 원치 않는 아티팩트를 방지하는 측면에서 더 나은 결과를 제공했습니다.
- 불완전한 마스크: 이 모델은 부정확하게 분할된 입력 이미지에 대해 견고함을 보여주었습니다.
카메라 최적화: 이 연구는 카메라 포즈의 부정확성을 처리하는 데 있어 카메라 최적화의 중요성을 강조했습니다.

4.4 재조명 및 합성 결과

- 이 모델은 새로운 조명 조건에서 머티리얼 속성을 예측하고 오브젝트를 렌더링하는 기능을 입증했습니다.
- 이 모델은 입력 이미지에서 그림자를 성공적으로 분리했습니다.
- 주요 응용 분야는 온라인 이미지 컬렉션의 오브젝트를 새로운 환경과 조명에서 렌더링하여 사실적이고 고품질의 합성 결과를 생성하는 것입니다.

![NeRF와의 질적 비교. Ours-Full의 결과는 SH 렌더링만으로 렌더링됩니다. 일부 그림자와 하이라이트는 일시적 구성 요소로 처리되므로 Ours-Full에 나타나지 않습니다.](NeROIC%20Neural%20Rendering%20of%20Objects%20from%20Online%20Ima%20da63874a85ac4b8a8b2345c3f428e618/Untitled%205.png)

NeRF와의 질적 비교. Ours-Full의 결과는 SH 렌더링만으로 렌더링됩니다. 일부 그림자와 하이라이트는 일시적 구성 요소로 처리되므로 Ours-Full에 나타나지 않습니다.

![NeRD의 데이터와의 비교. NeRD의 결과는 논문에서 복사되었습니다. 우리 모델의 새로운 설계 덕분에, 우리 모델은 NeRD에서 표시된 결과에 비해 더 매끄러운 기하학, 깨끗한 객체 경계 및 더 선명한 텍스처로 더 나은 결과를 얻습니다.](NeROIC%20Neural%20Rendering%20of%20Objects%20from%20Online%20Ima%20da63874a85ac4b8a8b2345c3f428e618/Untitled%206.png)

NeRD의 데이터와의 비교. NeRD의 결과는 논문에서 복사되었습니다. 우리 모델의 새로운 설계 덕분에, 우리 모델은 NeRD에서 표시된 결과에 비해 더 매끄러운 기하학, 깨끗한 객체 경계 및 더 선명한 텍스처로 더 나은 결과를 얻습니다.

![렌더링 네트워크에 대한 침식 연구의 질적 결과. 우리의 모델에 의해 예측된 무광 알베도 지도와 정상 지도를 보여줍니다. 우리는 Head 데이터의 알베도 지도의 노출을 늘립니다, 왜냐하면 원래 출력에서 검은색 영역이 극도로 어둡기 때문입니다.](NeROIC%20Neural%20Rendering%20of%20Objects%20from%20Online%20Ima%20da63874a85ac4b8a8b2345c3f428e618/Untitled%207.png)

렌더링 네트워크에 대한 침식 연구의 질적 결과. 우리의 모델에 의해 예측된 무광 알베도 지도와 정상 지도를 보여줍니다. 우리는 Head 데이터의 알베도 지도의 노출을 늘립니다, 왜냐하면 원래 출력에서 검은색 영역이 극도로 어둡기 때문입니다.

![불완전한 마스크에 대한 침식 연구. 불완전한 마스크가 있는 TV 데이터셋에서 전체 모델과 일시적 임베딩 없는 모델(Model w/o Transient)의 결과입니다. 모든 테스트 이미지에 대한 평균 MMSE 점수도 각 결과 이미지의 왼쪽 하단에 표시됩니다.](NeROIC%20Neural%20Rendering%20of%20Objects%20from%20Online%20Ima%20da63874a85ac4b8a8b2345c3f428e618/Untitled%208.png)

불완전한 마스크에 대한 침식 연구. 불완전한 마스크가 있는 TV 데이터셋에서 전체 모델과 일시적 임베딩 없는 모델(Model w/o Transient)의 결과입니다. 모든 테스트 이미지에 대한 평균 MMSE 점수도 각 결과 이미지의 왼쪽 하단에 표시됩니다.

![저희의 분해 결과 예시. 첫 번째 줄: 왼쪽에서 오른쪽으로: 무광 알베도 지도, 정상 지도, 반사도 지도, 및 광택도 지도. 두 번째 줄: 왼쪽에서 오른쪽으로: 일시적이지 않은 색 렌더링, 일시적 블렌딩 무게, 일시적인 색 렌더링, 및 지상 진실 이미지.](NeROIC%20Neural%20Rendering%20of%20Objects%20from%20Online%20Ima%20da63874a85ac4b8a8b2345c3f428e618/Untitled%209.png)

저희의 분해 결과 예시. 첫 번째 줄: 왼쪽에서 오른쪽으로: 무광 알베도 지도, 정상 지도, 반사도 지도, 및 광택도 지도. 두 번째 줄: 왼쪽에서 오른쪽으로: 일시적이지 않은 색 렌더링, 일시적 블렌딩 무게, 일시적인 색 렌더링, 및 지상 진실 이미지.

![재조명 결과. 왼쪽: 우리의 재조명 결과와 실제 이미지 사이의 비교; 오른쪽: 다른 포즈에서의 모델 재조명.](NeROIC%20Neural%20Rendering%20of%20Objects%20from%20Online%20Ima%20da63874a85ac4b8a8b2345c3f428e618/Untitled%2010.png)

재조명 결과. 왼쪽: 우리의 재조명 결과와 실제 이미지 사이의 비교; 오른쪽: 다른 포즈에서의 모델 재조명.

![복합 결과. 입력 온라인 이미지 및 환경 지도의 예시는 왼쪽에 표시됩니다. 저희의 합성 결과는 오른쪽에 표시됩니다.](NeROIC%20Neural%20Rendering%20of%20Objects%20from%20Online%20Ima%20da63874a85ac4b8a8b2345c3f428e618/Untitled%2011.png)

복합 결과. 입력 온라인 이미지 및 환경 지도의 예시는 왼쪽에 표시됩니다. 저희의 합성 결과는 오른쪽에 표시됩니다.

### 5 LIMITATIONS

- 이 접근 방식에는 그림 13에 표시된 것처럼 한계가 있습니다.
- 이 모델은 일부 카메라 왜곡을 처리할 수 있지만 모든 훈련 이미지에 대해 초기 카메라 포즈가 필요합니다.
- 실제 포즈와 입력 포즈 사이의 각도가 20도를 초과하면 모델이 정확한 지오메트리로 수렴하지 못할 수 있습니다.
- 향후 작업에서는 더 발전된 카메라 최적화 방법으로 이 문제를 해결할 수 있습니다.
- 렌더링 네트워크는 입력 이미지의 선명한 그림자와 같은 까다로운 셰이딩을 처리할 수 있지만 새로운 장면에서 이러한 구성 요소를 생성할 수는 없습니다.
- 조명 가시성과 같이 물리적으로 기반한 방식으로 효과를 표현하는 기법은 다양한 조명을 알 수 없는 데이터에 적용하기 어렵습니다.
- 앰비언트 오클루전과 같은 특정 음영이 훈련 이미지에 자주 나타나면 모델이 이를 오브젝트의 재질 속성으로 착각할 수 있습니다.

![우리 모델의 실패 사례: 왼쪽 부분: 우리 모델이 높은 카메라 변동성으로 수렴하지 못한 예시입니다. 지면 진실 이미지는 왼쪽에 있고 우리의 예측은 오른쪽에 있습니다; 오른쪽 부분: 주변 차단 음영이 예측된 기본 색상 지도에 나타나는 예입니다. 왼쪽에서 오른쪽까지는: 두 개의 다른 뷰에서의 참조 이미지 및 예측된 기본 색상 지도입니다. 참고로 그림자는 참조 이미지와 기본 색상 지도 모두에 나타납니다.](NeROIC%20Neural%20Rendering%20of%20Objects%20from%20Online%20Ima%20da63874a85ac4b8a8b2345c3f428e618/Untitled%2012.png)

우리 모델의 실패 사례: 왼쪽 부분: 우리 모델이 높은 카메라 변동성으로 수렴하지 못한 예시입니다. 지면 진실 이미지는 왼쪽에 있고 우리의 예측은 오른쪽에 있습니다; 오른쪽 부분: 주변 차단 음영이 예측된 기본 색상 지도에 나타나는 예입니다. 왼쪽에서 오른쪽까지는: 두 개의 다른 뷰에서의 참조 이미지 및 예측된 기본 색상 지도입니다. 참고로 그림자는 참조 이미지와 기본 색상 지도 모두에 나타납니다.

### 6 Conclusion

이 연구는 통제된 환경에서 촬영한 보정된 멀티뷰 데이터 세트 없이도 온라인 이미지 컬렉션만으로 인상적인 캡처, 합성 및 재조명 결과를 얻을 수 있다는 것을 보여줍니다.
이 연구는 미래에 희귀하거나 심지어 멸종될 수도 있지만 현재 온라인 이미지 컬렉션에서 사용할 수 있는 물체를 다시 렌더링하는 것과 같은 혁신적인 애플리케이션을 위한 길을 열어줍니다.