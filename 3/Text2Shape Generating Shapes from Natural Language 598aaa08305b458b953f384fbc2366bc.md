# Text2Shape: Generating Shapes from Natural Language by Learning Joint Embeddings (hold)

*이 논문에서는 모델이 훈련 중에 복셀화된 3D 모양 데이터를 입력으로 사용한다고 설명합니다. 복셀 데이터는 3차원 물체를 복셀이라고 하는 작은 입방체 요소의 집합으로 나타냅니다. 따라서 이 논문에서 설명한 셰이프 인코더 아키텍처에서 사용하는 3D-CNN(3D 컨볼루션 신경망)을 훈련하는 데 적합한 형식입니다.*

*또한 모델의 텍스트-도형 생성 부분은 복셀화된 3D 도형을 출력합니다. 이러한 출력 도형은 텍스트 설명과 3D 도형의 학습된 공동 임베딩을 기반으로 만들어집니다. 따라서 시스템의 입력과 출력은 모두 복셀 데이터 형식입니다.*

[https://arxiv.org/abs/1803.08495](https://arxiv.org/abs/1803.08495)

저자들은 자유형 텍스트 설명과 컬러 3D 도형의 공동 임베딩을 학습하여 자연어에서 컬러 3D 도형을 생성하는 방법을 제시합니다. 이 모델은 암시적 교차 모드 연결을 학습하기 위해 연관 학습과 메트릭 학습 접근법을 결합하고 확장하여 언어와 색상 및 모양과 같은 3D 도형의 물리적 속성 간의 다대다 관계를 포착하는 공동 표현을 생성합니다.

이 접근법을 평가하기 위해 저자들은 ShapeNet 데이터 세트에서 실제 3D 개체에 대한 자연어 설명이 포함된 대규모 데이터 세트를 수집합니다. 이 학습된 공동 임베딩을 통해 기준 접근 방식보다 뛰어난 텍스트-도형 검색을 시연합니다. 새로운 조건부 바서스타인 GAN 프레임워크와 함께 임베딩을 사용하여 텍스트에서 컬러 3D 모양을 생성합니다.

이 방법은 자연어 텍스트를 색상, 질감, 모양 디테일의 풍부한 변화를 보여주는 사실적인 3D 개체와 연결한 최초의 방법입니다.

1 Introduction

이 논문은 자연어 설명에서 3D 도형을 생성할 수 있는 Text2Shape라는 기술에 관한 것입니다. 이 기술은 텍스트-도형 검색과 텍스트-도형 생성이라는 두 가지 주요 용도로 사용할 수 있습니다.

![Untitled](Text2Shape%20Generating%20Shapes%20from%20Natural%20Language%20598aaa08305b458b953f384fbc2366bc/Untitled.png)

이 개념은 전산 설계, 증강 현실, 교육, 3D 디자인 등 여러 분야에서 유용하게 활용될 수 있습니다. 예를 들어, 이 기술은 복잡한 모델링 소프트웨어에 소요되는 시간과 비용을 절약하여 3D 모델 디자이너에게 도움이 될 수 있습니다. 경험이 없는 사용자도 자신만의 디자인을 만들 수 있습니다.

이를 위해 이 논문에서는 텍스트와 도형을 위한 공동 임베딩 공간을 통해 자연어와 3D 도형을 이해할 수 있는 시스템을 제안합니다. 텍스트 대 이미지 임베딩과 이미지 대 도형 임베딩에 대한 선행 연구는 있었지만, 텍스트 대 3D 도형 임베딩은 상대적으로 미개척 분야입니다.

자연어를 3D 도형에 연결할 때 어려운 점은 텍스트와 3D 도형 사이에 직접적인 일대일 대응이 없다는 것입니다. 예를 들어, 동일한 물체를 다른 방식으로 설명할 수 있으며, 하나의 설명이 여러 가지 가능한 모양에 대응할 수 있습니다.

이를 극복하기 위해 저자들은 3D 도형에 대한 자연어 설명에서 직접 텍스트와 도형 표현 공간을 함께 학습하는 방법을 제안합니다. 이 방법은 텍스트와 도형 인코딩 구성 요소를 종단 간 방식으로 훈련하여 두 양식 내 및 양식 간의 유사한 지점 간에 링크를 형성합니다.

또한 대부분의 도형 설명에는 색상이나 재질 속성이 포함되므로 텍스트에서 컬러 도형을 생성하는 까다로운 작업을 해결하기 위해 새로운 조건부 바서스타인 GAN을 도입했습니다.

제안된 방법은 ShapeNet 데이터 세트의 15,000개의 의자 및 테이블 모양에 대한 75,000개의 자연어 설명 모음과 합성 텍스트 캡션이 포함된 절차적으로 생성된 컬러 기본 요소의 데이터 세트 등 두 가지 데이터 세트에서 평가되었습니다. 그 결과, 검색과 생성 작업 모두에서 이 모델이 기준선을 크게 뛰어넘는 것으로 나타났습니다.

2 Related Work

저자는 멀티모달 표현 학습, 텍스트-이미지 합성, 3D 형상 생성 분야의 관련 연구를 검토하여 각 분야의 기여와 한계를 각자의 연구와 비교하여 강조합니다.

시각적 설명 표현 학습 분야에서는 수많은 텍스트-이미지 합성 연구의 토대가 된 리드(Reed) 등의 영향력 있는 연구를 인정합니다. 그러나 이러한 방법은 일반적으로 대규모 이미지 데이터 세트에 대한 사전 학습이 필요하고 세분화된 카테고리 수준의 레이블에 의존하기 때문에 비용이 많이 들고 모호할 수 있다는 점을 지적합니다. 반면, 저자들의 연구는 이러한 세분화된 레이블을 사용하지 않으며 사전 학습이 필요하지 않습니다.

멀티모달 표현 학습을 위해 스택형 멀티모달 자동 인코더, 딥 볼츠만 머신, 정식 상관관계 분석(CCA) 등 다양한 노력을 언급합니다. 하지만 이러한 방법들은 이 백서에서 제안하는 접근 방식과 달리 대용량 데이터로 잘 확장되지 않는 경우가 많습니다.

심층 신경망을 사용한 메트릭 학습, 특히 대비 손실, 삼중 손실 또는 N-쌍 손실을 사용하는 방법도 이 분야에서 영향력을 발휘해 왔습니다. 저자들은 이러한 방법을 확장하여 공동 표현 학습 접근법을 개발했습니다.

생성 모델과 생성적 적대 신경망(GAN)에 관해서는 이러한 방법이 의미론을 이해하고 사실적인 이미지를 생성하는 데 큰 잠재력을 보여줬다고 언급합니다. 저자들의 작업은 세분화된 레이블을 사용하지 않아 확장성이 뛰어나다는 점에서 차별화됩니다.

마지막으로 저자들은 일반적으로 복셀 단위 교차 엔트로피 손실과 3D GAN을 사용하는 3D 복셀 생성 방법에 대해 설명합니다. 저자는 이러한 3D GAN을 기반으로 자유 형식 텍스트에서 컬러 복셀 생성을 수행합니다. 텍스트를 컬러 복셀 생성에 적용한 것은 이들이 처음입니다.

3 Datasets

저자들은 자유형 텍스트 설명과 3D 도형에 대한 공동 표현을 학습하는 데 중점을 두며, 이를 위해 두 가지 새로운 데이터 세트를 소개합니다.

![Untitled](Text2Shape%20Generating%20Shapes%20from%20Natural%20Language%20598aaa08305b458b953f384fbc2366bc/Untitled%201.png)

첫 번째 데이터 세트에는 자연어 설명과 함께 사람이 디자인한 ShapeNet의 3D 객체가 포함되어 있습니다. 특히 기하학, 색상, 재질 등 다양한 변형이 가능한 테이블과 의자 객체 카테고리를 선택했습니다. 데이터 세트는 Amazon Mechanical Turk에서 수집한 75,000개 이상의 자연어 설명으로 확장되었습니다. 3D 메시의 컬러 복셀화를 생성하고 이러한 설명과 결합하여 사실적인 3D 모양과 어려운 자연어 설명으로 구성된 데이터 세트를 만들었습니다.

두 번째 데이터 세트는 모델을 정량적으로 평가할 수 있도록 만들어졌습니다. 여기에는 해당 텍스트 설명과 함께 3D 기하학적 기본 요소가 포함되어 있습니다. 이 데이터는 6가지 유형의 기본 요소를 다양한 색상과 크기로 복셀화하여 생성되었습니다. 가능한 각 구성에 대해 10개의 샘플을 생성하여 7,500개 이상의 복셀화된 모양을 생성했습니다. 템플릿 기반 접근 방식을 사용하여 해당 텍스트 설명을 생성하여 약 192,600개의 설명을 생성했습니다. 이 합성 텍스트는 자연어를 완벽하게 반영하지는 못하지만, 각 기본 도형의 속성과 명확하게 연결되는 간단한 벤치마크를 제공합니다.

4 Joint Text–3D Shape Representation Learning

저자들은 텍스트 설명과 3D 도형의 공동 표현을 학습하는 방법을 제안합니다. 이 접근 방식은 텍스트 설명과 3D 도형을 공유 공간에 인코딩하여 유사한 텍스트는 함께 클러스터링하고 유사한 도형은 함께 클러스터링하며 텍스트 설명은 관련 도형에 가깝게 유지하도록 하는 것입니다.

![Untitled](Text2Shape%20Generating%20Shapes%20from%20Natural%20Language%20598aaa08305b458b953f384fbc2366bc/Untitled%202.png)

접근 방식의 첫 번째 부분은 신경망을 사용하여 설명과 도형을 임베딩으로 인코딩하는 교차 모달 연관을 학습하는 것입니다. 이러한 임베딩을 기반으로 유사도 행렬을 정의하고 이를 도형과 연관된 설명 또는 그 반대의 확률로 변환합니다. 설명을 도형과 연결한 다음 다시 설명으로 연결할 수 있는 왕복 확률이 계산됩니다. 이 확률을 사용하여 왕복 손실과 엔트로피 손실을 정의하여 텍스트 설명을 가능한 모든 일치하는 도형과 연결합니다.

다음으로, 값비싼 세분화된 주석 없이도 작업할 수 있도록 이전 접근 방식을 확장하는 인스턴스 수준 연결에 대해 논의합니다. 여기서는 각 도형이 해당 설명을 포함하는 자체 클래스에 속한다고 가정합니다. 또한 라운드 트립을 추가하여 모델의 성능을 향상시킵니다.

크로스 모달 연관 학습을 더욱 용이하게 하기 위해 멀티모달 메트릭 학습 접근 방식을 도입합니다. 이 접근 방식은 삼중 손실을 사용하여 모델이 조인트 임베딩 공간에서 유사한 쌍을 더 가깝게, 서로 다른 쌍을 더 멀리 배치하도록 장려합니다.

최종 멀티모달 손실 함수는 연관 손실과 메트릭 학습 손실을 결합하여 텍스트 및 모양 인코더를 훈련합니다. 퇴화를 방지하기 위해 임베딩 벡터가 특정 임계값을 초과하면 임베딩 벡터의 L2 규범을 정규화합니다. 이 포괄적인 접근 방식은 텍스트 설명과 3D 도형에 대한 공동 표현을 효과적으로 학습할 수 있도록 하는 것을 목표로 합니다.

5 Generating Colored 3D Shapes from Text

저자들은 생성적 적대 신경망(GAN)을 사용하여 텍스트 설명에서 3D 도형을 생성하는 작업에 공동 표현 학습 접근법을 적용했습니다. 이 모델은 텍스트 인코더, 생성기, 비평기의 세 부분으로 구성됩니다.

텍스트 인코더는 텍스트를 잠재 표현으로 변환한 다음 노이즈 벡터와 결합하여 제너레이터에 공급합니다. 제너레이터는 출력 모양을 생성하고, 비평가는 이 출력물이 얼마나 사실적인지, 원본 텍스트 설명과 얼마나 일치하는지 평가합니다.

GAN은 복셀별 제약 조건과 같은 특정 제약 조건에 의존하지 않고도 설명된 속성을 유지하는 출력을 생성하도록 모델을 장려하기 때문에 이 작업에 유리합니다. 이는 단일 설명으로 설명된 속성을 모두 캡처하는 다양한 모양을 생성할 수 있어야 하므로 중요합니다.

저자들의 공식은 출력 다양성을 높이고 기존 GAN에서 흔히 볼 수 있는 모드 붕괴 문제를 완화하기 위해 고안된 바서스타인 GAN을 기반으로 합니다. 이들은 최초의 조건부 바서슈타인 GAN을 제시한다고 주장합니다.

기존의 조건부 GAN 접근 방식과 달리, 이들은 텍스트 설명과 도형이 일치하거나 일치하지 않는 배치를 샘플링합니다. 비평가가 도형의 사실성과 설명과의 일치 여부를 평가합니다. 모델의 목적 함수는 이 두 가지 평가를 모두 통합하고 모델의 안정성과 성능을 유지하기 위해 그라데이션 페널티 항을 포함합니다.

6 Experiments

저자들은 검색 및 생성 실험에서 공동 표상 학습 모델을 테스트했습니다. 검색의 경우, 문장이 주어지면 공동 임베딩 공간에서 가장 가까운 도형을 식별하는 작업을 수행했습니다. 또한 텍스트 대 텍스트, 도형 대 도형, 도형 대 텍스트 검색도 조사했습니다. 그 결과 이 모델은 의미적으로 유사한 설명과 도형을 함께 묶는 합리적인 임베딩을 생성하는 것으로 나타났습니다.

생성 작업의 경우, 저자들은 텍스트 대 도형 생성이라는 새로운 작업을 사용하여 학습된 공동 표현을 도형 합성에 사용했습니다. 저자들은 모델의 성능을 다른 방법과 비교하고 정량적 평가를 위해 교차점 간 결합, 시작 점수, 지구 이동 거리, 분류 정확도와 같은 다양한 지표를 사용했습니다.

이 모델은 검색과 생성 작업 모두에서 우수한 성능을 보였습니다. 이 모델은 의미적으로 유사한 설명과 모양을 함께 클러스터링했습니다. 생성 측면에서는 설명된 텍스트와 거의 일치하는 도형을 합성했으며, 기준 모델에 비해 텍스트의 색상 분포와 컨디셔닝이 더 우수하여 보다 사실적인 도형을 생성했습니다.

또한 저자들은 이 방법이 자연어와 3D 도형 속성을 연결하는 임베딩을 학습할 수 있음을 보여주었습니다. 이는 입력 설명의 수정에 따라 변경되는 도형을 생성함으로써 입증되었습니다.

또한 활성화 시각화를 수행하여 학습된 표현이 범주, 색상 및 물리적 모양과 같은 모양 속성을 캡처한다는 것을 보여주었습니다. 또한 텍스트와 도형 임베딩에 대한 벡터 연산을 시연하여 학습된 표현이 의미적 속성을 기반으로 설명과 도형을 연결하여 구조화된 방식으로 도형 속성을 인코딩한다는 것을 보여주었습니다.

![Untitled](Text2Shape%20Generating%20Shapes%20from%20Natural%20Language%20598aaa08305b458b953f384fbc2366bc/Untitled%203.png)

연구진은 이 모델의 성능이 우수하지만 아직 개선의 여지가 있으며, 속성을 구성하여 도형을 생성하기 위해 표현을 풀어내는 방향으로 추가 연구를 진행할 예정이라고 밝혔습니다.

7 Conclusion

저자들은 3D 도형에 대한 자연어 설명만을 사용하여 학습한 텍스트와 3D 도형의 공동 임베딩을 학습하는 방법을 개발했습니다. 이 방법은 텍스트와 도형을 검색하는 데 효과적인 것으로 밝혀졌으며, 이전 접근 방식보다 성능이 뛰어났습니다. 이들은 임베딩을 조건부 바서스타인 GAN과 결합하여 텍스트-도형 생성이라는 새로운 작업을 수행했습니다.

결과는 유망했지만, 이 작업은 복잡하고 이 접근 방식은 초기 단계에 불과했습니다. 생성된 도형의 품질을 개선하기 위해 실제 색상 분포를 더 정확하게 모델링하거나 실제 물체의 일반적인 양측 대칭을 사용하는 등의 추가 개발이 필요할 수 있습니다.

전반적으로 저자들은 이번 연구가 자연어와 색상, 질감, 모양 디테일이 풍부한 사실적인 3D 객체를 연결하기 위한 추가 연구를 촉진할 수 있기를 바랍니다.