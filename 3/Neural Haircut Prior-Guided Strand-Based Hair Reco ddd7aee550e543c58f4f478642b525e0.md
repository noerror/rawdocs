# Neural Haircut: Prior-Guided Strand-Based Hair Reconstruction

[https://samsunglabs.github.io/NeuralHaircut/](https://samsunglabs.github.io/NeuralHaircut/)

[https://arxiv.org/abs/2306.05872](https://arxiv.org/abs/2306.05872)

- Jun 2023

### 1. Introduction

이 논문에서는 이미지나 비디오 프레임을 기반으로 사람의 머리카락을 모델링하는 새로운 방법을 소개합니다. 이는 머리카락의 복잡한 구조와 특성으로 인해 특히 어려운 작업이지만 특수 효과, 텔레프레즌스, 게임 등 다양한 응용 분야에서 중요합니다. 기존 접근 방식은 일반적으로 단순한 데이터 구조를 사용하기 때문에 지나치게 매끄러운 헤어 형상과 헤어스타일의 내부 구조가 부족합니다.

![우리는 이미지 기반의 헤어 재구성을 위한 두 단계 파이프라인을 제안합니다. 첫 번째 단계에서는 부피 표현을 사용하여 대략적인 헤어, 머리, 어깨의 형태를 재구성합니다. 두 번째 단계에서는 합동 최적화 과정을 통해 대략적인 재구성에 헤어 줄기를 맞춥니다. 이 과정은 렌더링 기반 손실과 합성 데이터에서 학습된 사전을 포함합니다.](Neural%20Haircut%20Prior-Guided%20Strand-Based%20Hair%20Reco%20ddd7aee550e543c58f4f478642b525e0/Untitled.png)

우리는 이미지 기반의 헤어 재구성을 위한 두 단계 파이프라인을 제안합니다. 첫 번째 단계에서는 부피 표현을 사용하여 대략적인 헤어, 머리, 어깨의 형태를 재구성합니다. 두 번째 단계에서는 합동 최적화 과정을 통해 대략적인 재구성에 헤어 줄기를 맞춥니다. 이 과정은 렌더링 기반 손실과 합성 데이터에서 학습된 사전을 포함합니다.

복잡한 카메라 설정과 조명 조건을 사용하거나 합성 데이터의 헤어 프리어(일반화된 표현)를 사용하여 머신러닝 방법을 적용하면 정확한 헤어 재구성이 가능했습니다. 그러나 이러한 방법은 복잡하고 수동 입력이 필요하거나 다양한 사람의 헤어스타일을 표현하기에 충분한 다양성이 부족한 훈련 데이터 세트의 한계로 인해 종종 한계가 있습니다.

이에 대해 저자는 이미지 또는 비디오 데이터에만 의존하고, 수동 입력이 필요하지 않으며, 어떤 조명 조건에서도 작동하는 방법을 제안합니다. 이 방법은 체적 모발 표현의 거친 재구성과 미세한 가닥 기반 재구성의 두 단계로 구성됩니다.

첫 번째 단계에서는 머리카락과 주변 영역(머리와 어깨)에 대한 암시적 표면 표현과 머리카락 성장 방향의 3D 맵이 생성됩니다. 두 번째 단계에서는 합성 데이터로 학습된 파라메트릭 모델을 사용하여 개별 가닥을 표현하고, 이러한 가닥을 확산 기반 방법을 사용하여 결합하여 전체 헤어스타일을 만듭니다.

저자들은 머리와 모발의 3D 모양을 재구성하는 방법, 스트랜드 사전(표현) 훈련 개선, 글로벌 헤어스타일 모델링을 위한 확산 기반 방법, 보다 정확한 재구성을 위한 차별적인 소프트 헤어 래스터화 기법, 개별 스트랜드 수준에서 고품질의 모발 재구성을 생성하는 스트랜드 피팅 프로세스 등 여러 가지 기여를 했습니다.

이 방법의 효과는 3D 스캐너로 촬영한 이미지와 스마트폰 동영상으로 합성 데이터와 실제 데이터를 모두 사용하여 검증되었습니다.

### 2. Related work

이 논문에서는 관련 연구에 대한 섹션을 통해 인간의 머리와 모발 복원을 위한 이전의 노력과 그 한계에 대해 설명합니다.

사람의 머리 재구성: 최신 방법은 이미지 및 비디오 데이터를 사용하여 정적 및 동적 인간 피사체를 모델링하는 데 상당한 발전을 이루었습니다. 이러한 모델은 합성 데이터 세트 또는 3D 스캔으로 훈련된 모양 선구자를 사용합니다. 이러한 모델의 대부분은 스캔하기 어려운 것으로 알려진 머리카락을 포함하지 않습니다. 체적 표현과 이미지 또는 비디오 기반 미세 조정을 사용하거나 고급 3D 스캐너를 사용하여 머리카락을 포함하는 방법이 개발되었습니다. 이러한 방법은 얼굴 형상을 성공적으로 재구성하지만 머리카락의 충실도가 낮습니다. 또한 내부 구조가 아닌 외부 모발 표면만 모델링하기 때문에 사용 사례가 제한적입니다. 그러나 볼류메트릭 방법은 까다로운 조명 조건을 처리하고 훈련 데이터에서 보이지 않는 영역을 채울 수 있다는 장점이 있습니다. 저자는 이 방법이 제안한 방법의 첫 번째 단계에서 사용하기에 이상적이라는 사실을 발견하고, 이전 작업에서는 수행되지 않았던 머리카락과 흉상 지오메트리를 별도로 모델링하도록 확장했습니다.

스트랜드 기반 헤어 재구성: 모발 재구성에 대한 기초 작업 이후, 이미지 기반 방법은 3D 모발 가닥을 추정하기 위해 모발 방향 맵에 의존해 왔습니다. 이러한 맵은 시뮬레이션과 현실 사이의 간극을 효과적으로 메울 수 있으며, 일부 방법은 합성 데이터만을 사용하여 훈련하면서도 실제 이미지로 일반화할 수 있습니다. 하지만 고품질의 방향 맵을 얻으려면 머리카락의 조명이 균일하고 반사광 하이라이트가 없어야 하는데, 이 가정은 이러한 방법의 실용성을 제한합니다. 또한 맵은 머리카락이 자라는 방향을 포착하지 못하기 때문에 재구성 과정에서 모호함이 더해집니다. 일부 방법은 노동 집약적인 수동 주석을 사용하거나 수동 주석을 통해 훈련된 회귀자를 사용하여 모발 성장 방향을 예측함으로써 이 문제를 해결합니다. 많은 스트랜드 기반 재구성 방법은 모발 가닥을 두피에 명시적으로 부착하지 않고 모델링하기 때문에 결과물의 사실성이 제한됩니다. 저자는 물리적 사실감을 위한 새로운 헤어스타일 프리오르와 다양한 조명 조건을 처리하는 새로운 최적화 파이프라인을 도입하여 이러한 문제를 해결합니다.

### 3. Method

이 방법 섹션에서는 단일 단안 비디오 또는 멀티뷰 이미지에서 스트랜드 기반 헤어 지오메트리를 재구성하는 2단계 프로세스에 대해 설명합니다.

개요: 첫 번째 단계에서는 암시적 필드 형태로 거친 체적 헤어 재구성을 얻습니다. 그런 다음 거친 지오메트리 기반, 렌더링 기반 및 이전 기반 용어를 최적화하여 미세한 머리카락 가닥을 재구성합니다. 헤어스타일 이전은 합성 데이터 세트를 통해 훈련됩니다. 헤어와 바스트 지오메트리는 볼류메트릭 레이 마칭을 사용하여 부호화된 거리 함수(SDF)로 추정됩니다. 3D 헤어 방향의 추가 필드도 훈련됩니다. 헤어 스트랜드는 지오메트리 텍스처로 재구성되고 지오메트리, 렌더링 및 사전 기반 제약 조건이 평가됩니다.

![우리 접근법의 두 번째 단계 (세밀한 줄기 기반 재구성)에 대한 개요입니다. 우리는 헤어 줄기를 표현하기 위해 형상 텍스처를 사용하고, 이를 최적화하기 위해 여러 목표를 활용합니다. 우리는 합성 헤어스타일에 사전 훈련된 확산 네트워크를 사용하여 Lprior를 정규화 패널티로 적용합니다. 그런 다음, 우리는 Lgeom을 사용하여 재구성된 줄기를 암묵적 함수에 의해 매개변수화된 지오메트리 및 방향 필드에 맞춥니다. 마지막으로, Lrender는 렌더링된 헤어를 실제 이미지에 맞추는 데 사용됩니다.](Neural%20Haircut%20Prior-Guided%20Strand-Based%20Hair%20Reco%20ddd7aee550e543c58f4f478642b525e0/Untitled%201.png)

우리 접근법의 두 번째 단계 (세밀한 줄기 기반 재구성)에 대한 개요입니다. 우리는 헤어 줄기를 표현하기 위해 형상 텍스처를 사용하고, 이를 최적화하기 위해 여러 목표를 활용합니다. 우리는 합성 헤어스타일에 사전 훈련된 확산 네트워크를 사용하여 Lprior를 정규화 패널티로 적용합니다. 그런 다음, 우리는 Lgeom을 사용하여 재구성된 줄기를 암묵적 함수에 의해 매개변수화된 지오메트리 및 방향 필드에 맞춥니다. 마지막으로, Lrender는 렌더링된 헤어를 실제 이미지에 맞추는 데 사용됩니다.

헤어 사전 훈련: 이 단계에서는 잠재 지오메트리 텍스처를 사용하여 헤어스타일을 파라미터화합니다. 헤어 스트랜드와 잠재 임베딩 사이의 매핑은 헤어 파라메트릭 모델에 의해 제공됩니다. 또한 지오메트리 텍스처 맵에 정의된 잠복 확산 기반 프리퍼를 훈련합니다.

거친 볼류메트릭 재구성: 저자는 이 단계에서 헤어와 바스트 지오메트리를 부호화된 거리 함수(SDF)로 추정하여 접근합니다. 또한 3D 헤어 방향의 추가 필드도 훈련합니다. 시맨틱 분할 마스크는 머리카락과 흉상 영역이 겹치지 않도록 하는 데 사용됩니다.

미세 가닥 기반 재구성: 저자는 머리카락 가닥을 지오메트리 텍스처, 즉 잠재적 머리카락 벡터의 고밀도 2차원 맵으로 재구성합니다. 이러한 스트랜드는 지오메트리 및 렌더링 기반 제약 조건을 평가하는 데 사용됩니다. 렌더링된 헤어 실루엣과 RGB 이미지는 뉴럴 소프트 헤어 래스터화를 사용하여 얻습니다. 마지막으로 사전 훈련된 확산 모델을 사용하여 지오메트리 텍스처에 직접 사전 기반 정규화를 적용합니다.

헤어 사전 훈련 세부 사항: 스트랜드 파라메트릭 모델과 잠복 확산 네트워크를 사용하여 글로벌 헤어스타일 프리퍼를 훈련합니다. 저자는 가변 자동 인코더를 훈련하여 헤어 스트랜드에 대한 잠재 표현을 얻습니다. 또한 노이즈 제거기를 훈련하기 위해 설명 확산 모델(EDM)을 사용합니다.

상세한 모발 사전 훈련을 통해 정확한 모발 가닥 표현이 가능하며, 확산 모델은 입력 변형을 처리할 수 있는 노이즈 제거 기능을 제공합니다.

이 섹션에서는 거친 체적 재구성과 미세 가닥 기반 재구성이라는 두 가지 모발 재구성 방법에 대해 설명합니다.

거친 볼륨 재구성

이 프로세스에서는 머리카락과 가슴을 포함하여 피사체의 머리 형태를 분할하여 사용합니다. 이러한 형태는 신경 부호 거리 함수(SDF)로 표현됩니다[50]. 피팅은 신경 내재 표면을 위한 볼류메트릭 레이 마칭 방법인 NeuS 접근법[66]으로 수행됩니다. 헤어 지오메트리와 바스트 지오메트리를 개별적으로 재구성할 때 멀티 랩 재구성을 수용하도록 NeuS를 수정합니다. 각 픽셀의 색상은 광선을 따라 샘플링된 N개의 지점에서의 방사광으로 근사화됩니다.

![(a) [58]의 가변적인 헤어 래스터화 알고리즘은 그라디언트를 z-버퍼의 첫 번째 요소에만 전파합니다. (b) 우리가 제안하는 사각형을 기반으로 한 헤어 래스터화는 부드러운 헤어 래스터화 [36]를 활용하고 그라디언트를 z-버퍼의 여러 요소에 전달하여 더 나은 재구성을 달성합니다.](Neural%20Haircut%20Prior-Guided%20Strand-Based%20Hair%20Reco%20ddd7aee550e543c58f4f478642b525e0/Untitled%202.png)

(a) [58]의 가변적인 헤어 래스터화 알고리즘은 그라디언트를 z-버퍼의 첫 번째 요소에만 전파합니다. (b) 우리가 제안하는 사각형을 기반으로 한 헤어 래스터화는 부드러운 헤어 래스터화 [36]를 활용하고 그라디언트를 z-버퍼의 여러 요소에 전달하여 더 나은 재구성을 달성합니다.

이 방법에서는 헤어와 바스트 마스크를 렌더링하고, 헤어와 바스트 모두에 적용되는 광도계 L1 손실(Lcolor), 마스크 기반 손실(Lmask), 정규화 에이코널 항(Lreg)을 포함한 훈련 손실을 정의합니다. 또한 거친 재구성에 모발 성장 방향 필드(β)를 통합합니다.

미세 스트랜드 기반 재구성

이 프로세스는 사전 학습된 네트워크를 사용하여 헤어스타일을 디코딩할 수 있는 잠재적 헤어 지오메트리 텍스처(T)[58]를 학습하여 헤어 가닥을 재구성합니다. 딥 이미지 선행 방법[65]을 사용하여 이 맵을 UNet과 유사한 신경망으로 매개변수화합니다.

훈련은 장착된 FLAME 메시의 두피 부분에서 포인트를 샘플링하고 이를 가닥으로 디코딩하는 방식으로 진행됩니다. 그런 다음 스트랜드를 거친 지오메트리와 일치시키는 지오메트리 기반 손실(Lgeom), 차등 렌더링을 통해 계산된 광도 제약(Lrender), 확산 기반 사전 손실(Lprior)을 평가합니다.

![우리는 실제 다중 뷰 데이터 세트 [56]를 사용하여 우리의 방법을 부피 및 줄기 기반 3D 재구성 시스템과 비교합니다. 기본 부피 접근법 [46, 66]은 대략적인 헤어 지오메트리만 생성할 수 있는 반면, 우리의 방법은 줄기를 사용하여 세부 사항을 재구성할 수 있습니다. 또한 우리는 기존의 다중 뷰 헤어 재구성 방법 [30]보다 더 강건하고 정확한 결과를 달성합니다. 추가 결과에 대해서는 부록 자료를 참조하십시오. 디지털 확대가 권장됩니다.](Neural%20Haircut%20Prior-Guided%20Strand-Based%20Hair%20Reco%20ddd7aee550e543c58f4f478642b525e0/Untitled%203.png)

우리는 실제 다중 뷰 데이터 세트 [56]를 사용하여 우리의 방법을 부피 및 줄기 기반 3D 재구성 시스템과 비교합니다. 기본 부피 접근법 [46, 66]은 대략적인 헤어 지오메트리만 생성할 수 있는 반면, 우리의 방법은 줄기를 사용하여 세부 사항을 재구성할 수 있습니다. 또한 우리는 기존의 다중 뷰 헤어 재구성 방법 [30]보다 더 강건하고 정확한 결과를 달성합니다. 추가 결과에 대해서는 부록 자료를 참조하십시오. 디지털 확대가 권장됩니다.

렌더링 기반 손실의 경우, 헤어 스트랜드의 차등 렌더링을 위한 새로운 접근 방식을 개발했습니다. 이 접근 방식은 머리카락 가닥을 줄무늬 모양의 메시로 구성된 헤어 쿼드[76]로 변환합니다. 결과 쿼드 메시의 정점은 가닥에 대해 완전히 미분할 수 있습니다.

마지막으로 드림퓨전 작업[54]의 점수 증류 샘플링(SDS) 접근법을 사용하여 사전 훈련된 확산을 적용합니다. 이들은 노이즈 제거 네트워크 F를 통한 적절한 역전파가 더 나은 결과를 가져온다는 것을 발견했습니다. 스트랜드 기반 재구성 단계의 최종 목표는 Lfine = Lgeom + λrenderLrender + λpriorLprior로 정의됩니다.

이는 컴퓨터 그래픽과 머신러닝 기술을 혼합하여 고품질의 디테일한 모발 재구성을 달성하는 고도의 기술적인 방법입니다.

### 4. Experiments

3D 헤어 스트랜드 재구성 기법에 대한 과학 실험의 초록입니다. 이 실험은 다양한 유형의 데이터 세트에서 머리카락 가닥을 3D로 재구성하는 새로운 기술을 평가하며, 특히 가닥 파라메트릭 모델과 헤어스타일 확산 모듈을 사용하는 데 중점을 두고 있습니다.

이 실험에는 USC-HairSalon 데이터 세트에 대한 사전 훈련과 H3DS 데이터 세트를 포함한 합성 및 실제 데이터에 대한 평가가 포함됩니다. 실제 데이터에 대한 훈련에는 머리카락과 가슴에 대한 분할 마스크를 얻기 위해 기성 방법을 사용하고, 지오메트리 텍스처 맵을 파라미터화하기 위해 UNet 네트워크를 사용하는 것이 포함됩니다. 이 논문에서는 피사체당 총 재구성 시간이 단일 NVIDIA RTX 4090 그래픽 카드를 사용하여 3일이 걸렸다고 밝혔습니다.

![우리의 방법은 단안 비디오에서도 고해상도 헤어 재구성을 얻을 수 있습니다. 더 많은 결과에 대해서는 부록 자료를 참조하십시오. 임계값: mm / d](Neural%20Haircut%20Prior-Guided%20Strand-Based%20Hair%20Reco%20ddd7aee550e543c58f4f478642b525e0/Untitled%204.png)

우리의 방법은 단안 비디오에서도 고해상도 헤어 재구성을 얻을 수 있습니다. 더 많은 결과에 대해서는 부록 자료를 참조하십시오. 임계값: mm / d

![곡률 (상단) 및 확산 손실 (하단)에 대한 소거. 곡률 손실의 도입으로 인해 우리는 더욱 꼬인 줄기를 더 잘 모델링할 수 있게 되었고, 확산은 헤어 성장 방향과 비현실적인 각도에 대한 문제를 해결합니다 (확대해서 보기 위해 일부 헤어가 표시되어 있습니다).](Neural%20Haircut%20Prior-Guided%20Strand-Based%20Hair%20Reco%20ddd7aee550e543c58f4f478642b525e0/Untitled%205.png)

곡률 (상단) 및 확산 손실 (하단)에 대한 소거. 곡률 손실의 도입으로 인해 우리는 더욱 꼬인 줄기를 더 잘 모델링할 수 있게 되었고, 확산은 헤어 성장 방향과 비현실적인 각도에 대한 문제를 해결합니다 (확대해서 보기 위해 일부 헤어가 표시되어 있습니다).

섹션 4.2에서 저자는 멀티뷰 접근 방식과 스트랜드 기반 재구성을 위해 특별히 설계된 방법을 포함하여 널리 사용되는 다양한 3D 재구성 기법과 비교하면서 실제 평가에 대한 자세한 내용을 제공합니다. 저자들은 이 접근 방식이 기준선 방법으로는 불가능한 정확한 흉상 형상과 함께 사실적인 머리카락을 재구성할 수 있다는 점에서 탁월하다고 주장합니다.

섹션 4.3에서는 전체 방법과 일부 구성 요소가 누락된 버전을 비교한 제거 연구를 소개합니다. 여기에서는 뉴럴 스트랜드와도 비교합니다. 전체 모델이 다른 방법과 비교했을 때 정확도, 리콜, F-점수 메트릭 전반에서 개선된 성능을 보이며 가장 우수한 것으로 나타났습니다. 또한 저자는 스트랜드 파라메트릭 모델에서 확산 기반 선행과 곡률 손실의 영향에 대해 논의하면서, 확산 기반 선행은 헤어스타일 내부의 사실성에 기여하는 반면 곡률 손실은 곱슬 헤어스타일을 모델링하는 데 중요하다고 언급합니다.

요약하자면, 저자들은 3D 헤어 스트랜드 재구성을 위한 새로운 방법을 소개하고 있으며, 다양한 실제 및 합성 데이터 세트에서 기존 기법보다 성능이 뛰어나다고 주장합니다. 저자들은 이러한 주장을 뒷받침하기 위해 양적, 질적 증거를 모두 제시했습니다.

### 5. Discussion and limitations

이 토론 및 한계 섹션에서는 조명 조건이 제어되지 않은 단안 비디오에서 디테일한 사람의 머리카락을 효과적으로 재구성할 수 있는 방법을 개발했다는 점을 강조하면서 저자들이 연구를 요약합니다. 이 접근 방식은 체적 및 스트랜드 기반 헤어 표현과 차등 헤어 렌더링 및 글로벌 헤어스타일 프리퍼를 결합한 것입니다.

이 방법에는 한계가 있다는 것을 인정합니다. 예를 들어, 이 시스템은 곱슬머리를 정확하게 표현하는 데 어려움을 겪습니다. 또한 재구성을 생성하기 위해 정확한 헤어 및 신체 분할 마스크에 크게 의존합니다. 이러한 한계는 그림 5-6에 표시된 예와 보충 자료에 제공된 추가 장면에서 확인할 수 있습니다.

하지만 이러한 한계를 극복할 수 있는 잠재적인 방법을 제시합니다. 헤어스타일 사전 학습을 위한 데이터 세트를 확장하면 곱슬머리의 재구성을 개선할 수 있습니다. 또한 보다 강력한 휴먼 매트 시스템을 사용하면 매우 정확한 세분화 마스크에 대한 의존도를 완화할 수 있습니다. 이러한 문제를 향후 추가 연구와 개선의 기회로 보고 있다는 점은 분명합니다.

### Appendix

연구진은 USCHairSalon 합성 데이터세트로 헤어 프리어를 훈련하고 FLAME 헤드 메시를 템플릿과 매칭하여 두피 영역에 대한 UV 매핑을 얻었습니다. 또한 실제 H3DS 멀티뷰 데이터세트, 단안 비디오, Cem Yuksel의 합성 헤어 모델도 평가에 사용했습니다.

이 과정에서 각 모발 가닥을 로컬 탄젠트-탄젠트-노멀 기준으로 변환하고 모발 가닥의 다양성을 높이기 위해 증강했습니다. 연구팀은 멀티뷰 H3DS 데이터 세트의 공개 하위 집합을 사용하여 접근 방식을 평가하고, 휴먼 매팅 및 시맨틱 분할 네트워크를 사용하여 이미지를 처리하여 헤어 및 바스트 마스크를 얻었습니다.

추가 평가를 위해 삼성 노트20 울트라 스마트폰을 사용하여 단안 비디오로 훈련했습니다. 연구진은 모션으로부터 구조화를 수행하여 카메라 내재 및 외재 파라미터의 초기 값을 얻고 훈련 프레임에 대한 세분화 마스크와 방향 맵을 얻었습니다.

합성 데이터 세트의 각 머리카락 가닥은 L 점 집합으로 표현되며, 각 헤어스타일 샘플은 M 가닥으로 구성됩니다. 인코더를 사용하여 정렬된 3D 포인트를 평균과 시그마로 인코딩한 다음 재파라미터화 트릭을 수행했습니다.

확산 모델 학습을 위해 가닥의 기점이 무작위인 헤어스타일을 FLAME 두피 텍스처 맵의 균일한 그리드에 걸쳐 있는 헤어스타일로 매핑했습니다. 훈련 후 확산 네트워크의 가중치는 동결됩니다.

거친 체적 재구성을 위해 키포인트 기반 오브젝트를 사용하여 FLAME 헤드 메시를 맞추고 주어진 광선에 대한 불투명도를 계산했습니다. 연구진은 FLAME 메시를 사용하여 가려진 흉상 영역에 대한 추가 훈련 신호를 제공하고 방향 손실을 계산했습니다.

요약하자면, 이 연구에는 정교하고 정확한 헤어 렌더링 모델을 만들기 위한 다양하고 복잡한 프로세스가 포함되어 있습니다. 이 접근 방식에는 헤어 선행 학습, 증강, 단안 비디오 및 멀티뷰 데이터 세트를 포함한 다양한 평가 기법이 포함됩니다. 그런 다음 다양한 수학적 모델과 방법을 통해 모델을 개선하고 조정합니다.

제공된 텍스트는 머신러닝을 이용한 새로운 모발 재건 과정에 사용되는 기술과 절차에 대한 자세한 설명으로 보입니다. 다음은 몇 가지 주요 내용입니다:

미세 가닥 기반 재구성: 이 프로세스에서는 10^-3의 학습률과 멀티스텝 어닐링을 통해 최적화를 위해 아담 옵티마이저를 사용합니다. 또한 다양한 손실 함수에 특정 가중치를 할당합니다. 모델의 지오메트리와 외형 텍스처는 UNet을 사용하여 파라미터화되고 위치 인코딩으로 전처리됩니다.

보이는 표면 추출: 보이는 헤어 표면은 헤어 및 바스트 셰이프 디스턴스 함수(SDF)에서 마칭 큐브를 사용하여 추출합니다. 그런 다음 이러한 메시를 렌더링하고 손실 함수에 사용할 가시적인 헤어 페이스를 선택합니다.

소프트 렌더링: 여기에는 각 가닥에 대해 쿼드 지오메트리를 생성하고, 이러한 쿼드를 래스터화하여 z 버퍼를 얻고, 시그모이드 확률 맵을 사용하여 블렌딩하는 세 단계가 포함됩니다. 이 프로세스는 차등 소프트 래스터화를 위해 Pytorch3D 프레임워크를 사용합니다.

UNet 네트워크의 입력은 소프트 래스터화된 외형 디스크립터와 하드 래스터화된 오리엔테이션으로 구성됩니다. 또한 가닥의 각 지점에서 방향을 사용하여 뷰에 따른 헤어 컬러의 변화를 모델링합니다.

평가 프로토콜에는 50,000개의 가닥(실제 헤어스타일과 동일)을 샘플링하고 각 가닥의 포인트 수를 100으로 보간하는 작업이 포함됩니다.

실제 평가: 저자들은 이 접근 방식을 H3DS 데이터 세트의 다른 재구성 방법 및 원샷 재구성 방법인 NeuralHDHair와 비교했습니다. 저자들은 자신들의 방법이 더 높은 충실도의 재구성을 제공한다고 주장합니다.

손실에 대한 절제: 저자들은 모델 성능에 대한 다양한 손실 함수의 개별적인 영향을 조사하는 제거 연구를 수행합니다. 그들은 지오메트리 손실 함수(Lgeom)의 모든 용어가 전체 성능에 크게 기여한다고 주장합니다.

하이퍼파라미터 연구: 소프트 렌더링 부분에 사용되는 중요한 하이퍼파라미터에 대한 제거 연구를 수행하여 이러한 하이퍼파라미터의 증가나 감소가 최종 모델에 비해 결과를 개선하는 데 도움이 되지 않는다는 사실을 발견했습니다.

마지막으로, 이 방법을 뉴럴 스트랜드와 비교하여 양적 및 질적 측정 모두에서 이 방법이 뉴럴 스트랜드보다 성능이 뛰어나다고 주장합니다.