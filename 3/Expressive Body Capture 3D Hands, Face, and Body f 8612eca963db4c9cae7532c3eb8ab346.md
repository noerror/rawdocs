# Expressive Body Capture: 3D Hands, Face, and Body from a Single Image

[https://github.com/vchoutas/smplify-x](https://github.com/vchoutas/smplify-x)

[https://ps.is.mpg.de/uploads_file/attachment/attachment/497/SMPL-X.pdf](https://ps.is.mpg.de/uploads_file/attachment/attachment/497/SMPL-X.pdf)

![커뮤니케이션과 제스처는 몸의 포즈, 손의 포즈, 그리고 얼굴 표정을 모두 포함합니다. 이를 대표하기에는 몸의 주요 관절들이 충분하지 않고, 현재의 3D 모델들도 충분히 표현적이지 않습니다. 이전의 연구와는 대조적으로, 우리의 접근법은 단일 이미지에서 더 상세하고 표현적인 3D 모델을 추정합니다. 왼쪽부터 오른쪽으로: RGB 이미지, 주요 관절, 뼈대, SMPL (여성), SMPL-X (여성). SMPL-X의 손과 얼굴은 보다 전체적이고 표현적인 몸의 캡처를 가능하게 합니다.](Expressive%20Body%20Capture%203D%20Hands,%20Face,%20and%20Body%20f%208612eca963db4c9cae7532c3eb8ab346/Untitled.png)

커뮤니케이션과 제스처는 몸의 포즈, 손의 포즈, 그리고 얼굴 표정을 모두 포함합니다. 이를 대표하기에는 몸의 주요 관절들이 충분하지 않고, 현재의 3D 모델들도 충분히 표현적이지 않습니다. 이전의 연구와는 대조적으로, 우리의 접근법은 단일 이미지에서 더 상세하고 표현적인 3D 모델을 추정합니다. 왼쪽부터 오른쪽으로: RGB 이미지, 주요 관절, 뼈대, SMPL (여성), SMPL-X (여성). SMPL-X의 손과 얼굴은 보다 전체적이고 표현적인 몸의 캡처를 가능하게 합니다.

1. Introduction

이 글에서는 인체, 손, 얼굴에 대한 새롭고 포괄적인 3D 모델인 SMPL-X(SMPL eXpressive)의 개발에 대해 설명합니다. 사람의 자세와 사회적 신호를 이해하는 것은 전체적인 장면 이해의 중요한 측면입니다. 이전 방법들은 단일 이미지에서 주요 신체 관절과 대략적인 3D 포즈를 추정하는 데 진전을 이루었지만, 이러한 기술은 일반적으로 신체, 손, 얼굴의 전체 3D 표면을 캡처하지 못합니다.

![우리는 인간의 몸, 얼굴, 손을 동시에 모델링하는 새로운 3D 인체 모델인 SMPL-X를 학습합니다. 우리는 단일 RGB 이미지에 SMPLify-X로 여성 SMPL-X 모델을 적용하고, 이것이 자연스럽고 표현적인 3D 인간의 포즈, 제스처, 얼굴 표정의 다양한 풍부함을 잡아내는 것을 보여줍니다.](Expressive%20Body%20Capture%203D%20Hands,%20Face,%20and%20Body%20f%208612eca963db4c9cae7532c3eb8ab346/Untitled%201.png)

우리는 인간의 몸, 얼굴, 손을 동시에 모델링하는 새로운 3D 인체 모델인 SMPL-X를 학습합니다. 우리는 단일 RGB 이미지에 SMPLify-X로 여성 SMPL-X 모델을 적용하고, 이것이 자연스럽고 표현적인 3D 인간의 포즈, 제스처, 얼굴 표정의 다양한 풍부함을 잡아내는 것을 보여줍니다.

이 글에서는 이 문제를 해결하기 위해 1) 인체, 얼굴, 손을 정확하게 표현할 수 있는 포괄적인 3D 모델과 2) 단일 이미지에서 이 모델을 추출하는 방법이라는 두 가지 핵심 요소가 필요하다고 주장합니다.

저자는 기존 SMPL 모델과 FLAME 머리 모델 및 MANO 손 모델을 병합한 SMPL-X 모델을 해결책으로 제시합니다. SMPL-X는 대량의 3D 스캔 컬렉션을 학습하여 신체, 얼굴, 손의 모양 사이의 자연스러운 상관관계를 포착합니다.

단일 이미지에서 이 모델을 추출하기 위해 저자들은 먼저 OpenPose를 사용하여 2D 특징을 추정하고 이러한 2D 특징에 SMPL-X 모델을 맞추는 SMPLify-X라는 방법을 제안합니다. 더 나은 성능의 포즈 사전, 더 정확한 상호 침투 페널티 용어, 자동 성별 검출기, 이전 방법보다 훨씬 빠른 PyTorch에서의 구현 등 여러 가지 개선 사항이 기존 SMPLify 방법보다 개선되었습니다.

저자들은 모델을 검증하기 위해 해당 3D 지상 실체와 함께 전신 RGB 이미지가 포함된 새로운 평가 데이터 세트를 큐레이팅했습니다. 테스트 결과, SMPL-X 모델과 SMPLify-X 방법이 이전의 덜 강력한 모델보다 성능이 더 우수한 것으로 나타났습니다. 저자들은 이 작업이 단일 RGB 이미지에서 신체, 손, 얼굴을 함께 표현적으로 캡처하는 데 중요한 진전이라고 생각하며, SMPL-X 모델, SMPLify-X 코드, 학습된 네트워크, 모델 적합도, 평가 데이터세트를 연구 목적으로 사용할 수 있도록 공개합니다.

2. Related work

2.1. 신체 모델링
인체 모델은 전통적으로 얼굴, 몸통, 손과 같은 개별 부위에 초점을 맞춰 3D 스캔과 별도로 모델링되었습니다. 얼굴의 초기 3D 모델은 블랜즈와 베터에 의해 개척되었으며, 이후 많은 모델이 그들의 연구를 기반으로 만들어졌습니다. 그러나 이러한 모델 중 어느 것도 얼굴 형태와 체형 간의 상관관계를 설명하지 못했습니다. 한편, 3D 신체 모델은 신체 스캐닝 기술을 통해 구현되었으며, 손이나 얼굴은 포함하지 않고 체형과 포즈에 초점을 맞춘 다양한 모델이 등장했습니다. 손 모델도 별도로 만들어졌지만 학습된 손 모델이 문헌에 등장한 것은 최근의 일입니다.

다양한 신체 부위를 결합한 통합 모델을 만들려는 시도가 있었습니다. 몸, 손, 얼굴에 대해 서로 다른 모델을 결합한 Frank와 SMPL+H가 그 예입니다. 그러나 이러한 모델은 완전히 현실적이지 않습니다. 반면, 이 백서에서 소개하는 작업은 SMPL+H로 시작하여 FLAME 헤드 모델을 추가하고 이 결합된 모델을 3D 스캔에 맞춰 모양과 포즈에 따른 블렌드 형태를 학습하여 보다 자연스럽고 사실적인 모델을 생성합니다.

2.2. 신체 추론
이미지 또는 RGB-D 데이터에서 3D 얼굴, 손, 바디 메시를 추정하는 방법에는 여러 가지가 있습니다. 페어링된 3D 모델 파라미터가 있는 훈련 이미지가 부족하기 때문에 단일 이미지에서 SMPL 모델을 추정하는 것은 쉬운 일이 아닙니다. 이에 대한 솔루션으로는 감지된 2D 이미지 특징에 SMPL 모델을 맞추는 SMPLify와 2D 키포인트와 적대적 네트워크를 사용하여 페어링된 데이터 없이 모델을 훈련하는 HMR이 있습니다.

멀티 카메라 설정을 사용하여 3D 포즈, 메시 또는 파라메트릭 3D 모델을 캡처할 수도 있습니다. 수백 대의 카메라로 구성된 복잡한 설정을 사용하여 사람의 상호 작용을 캡처하는 Panoptic 스튜디오가 주목할 만한 예입니다. 이 백서에서는 단일 RGB 이미지에서 비슷한 수준의 표현 디테일을 구현하는 것이 목표입니다.

3. Technical approach

제시된 기술적 접근 방식은 얼굴, 손, 신체에 대한 통합 모델인 SMPL-X와 단일 RGB 이미지에 SMPL-X를 적용하는 접근 방식인 SMPLify-X를 중심으로 이루어집니다.

3.1. 통합 모델: SMPL-X

SMPL-X는 신체 관절, 손가락 관절 및 턱 관절에 대한 포즈 요소로 파라미터화된 포즈가 있는 포괄적인 모델입니다. 이 모델은 선형 블렌드 스키닝을 사용하여 구조를 생성하며 10,475개의 버텍스와 54개의 조인트를 가지고 있습니다. 셰이프 블렌드 셰이프 함수, 포즈 블렌드 셰이프 함수, 표정 블렌드 셰이프 함수로 구축되어 버텍스 변위를 조정하고 다양한 인물의 정체성, 포즈, 표정에 따른 셰이프 변화를 캡처할 수 있습니다. 서로 다른 모양의 신체에 따라 달라지는 3D 관절 위치는 체형 함수에 의해 결정됩니다. SMPL-X는 3D 아티스트가 디자인한 템플릿으로 시작하여 4개의 3D 인체 스캔 데이터 세트에 맞춰 모델을 훈련합니다.

3.2. SMPLify-X: 단일 이미지에서 SMPL-X

SMPLify-X는 단일 RGB 이미지에 SMPL-X 모델을 맞추는 접근 방식입니다. 몸, 얼굴, 손과 관련된 다양한 구성 요소로 구성된 목적 함수를 최소화하는 것을 목표로 하는 최적화 문제입니다. 데이터 용어에 재투영 손실을 사용하여 추정된 2D 관절과 SMPL-X의 해당 포즈 3D 관절의 2D 투영 사이의 거리를 최소화하는 것을 목표로 합니다. 이 접근 방식은 이미지의 각 인물에 대해 몸, 손, 얼굴, 발 키포인트를 제공하는 2D 감지를 위해 OpenPose 라이브러리를 활용합니다. 데이터 용어에서 각 관절의 기여도는 감지 신뢰도 점수에 따라 가중치가 부여되며, 강력한 Geman-McClure 오류 함수를 사용하여 잡음이 있는 감지에 가중치를 낮춥니다.

본질적으로 이 접근 방식은 더 나은 포즈 사전 설정, 더 세밀한 충돌 페널티, 성별 감지, 더 빠른 PyTorch 구현 등 다양한 측면을 개선하여 이전 방식보다 개선되었습니다.

이 텍스트는 인체 포즈 추정에 관한 연구 논문 또는 기술 보고서의 일부로 보입니다. 2D 이미지에서 3D 공간에서 인체의 위치를 정확하게 식별하고 예측하는 알고리즘을 개발하는 것으로, 특히 다양한 인체 포즈와 남성과 여성의 서로 다른 체형을 안정적으로 처리하는 데 중점을 두고 있습니다. 상당히 기술적인 글이지만 최선을 다해 자세히 설명해 보겠습니다.

다양한 인체 포즈 선행: 저자들은 특정 신체 포즈의 가능성을 추정하는 모델을 개발 중이며, 이를 신체 포즈 사전이라고 합니다. 이를 위해 가변 자동 인코더(VAE)라는 머신러닝 모델을 사용하고 있습니다. 이 모델은 '불가능한' 포즈(인간이 물리적으로 취할 수 없는 포즈)에는 불이익을 주고, '가능한' 포즈에는 관대해야 한다는 아이디어에서 출발했습니다. 이 모델은 모션 캡처 데이터로 학습되며 이를 위해 여러 손실 함수를 사용합니다.

충돌 페널라이저: 또한 저자는 일부 예상 포즈에는 신체 부위 간의 '불가능한' 충돌이 포함될 수 있다는 사실도 고려하고자 합니다. 충돌 모델을 사용하여 이러한 불가능한 포즈의 가능성을 추정하고 그에 따라 불이익을 줍니다.

심층 성별 분류기: 남성과 여성의 체형과 비율의 차이를 고려하기 위해 저자는 이미지 속 인물의 성별을 예측하는 또 다른 머신 러닝 모델인 성별 분류기도 포함시켰습니다. 예측된 성별에 따라 해당 신체 모델을 사용하여 2D 데이터에 맞춥니다.

최적화: 최적의 포즈 추정치를 찾기 위해 다단계 최적화 접근 방식을 사용하여 포즈 예측을 반복적으로 개선합니다. 최적화 프로세스는 글로벌 바디 포즈에 초점을 맞춘 다음 팔 포즈, 마지막으로 손과 얼굴 포즈를 세분화하여 표현력을 포착하는 것으로 시작됩니다. 이 프로세스는 신체의 다양한 주요 부분(예: 몸통, 손, 얼굴 키포인트)에 가중치를 사용하고, 단계별로 가중치를 조정하여 포즈 추정치를 개선하고 모델의 여러 부분 간의 잠재적인 충돌을 처리합니다.

최적화는 PyTorch 라이브러리에서 구현된 제한 메모리 BFGS(L-BFGS)라는 알고리즘을 사용하여 수행됩니다.

요약하자면, 2D 이미지에서 정확하고 믿을 수 있는 3D 포즈 추정치를 생성하기 위해 여러 단계와 다양한 머신러닝 및 최적화 모델을 포함하는 상당히 복잡한 작업입니다.

4. Experiments

이 부분에서는 SMPL-X 및 SMPLify-X 모델의 유효성을 평가하기 위해 수행한 실험에 대해 설명합니다.

이러한 모델을 평가하기 위해 연구원들은 손 포즈와 얼굴 표정을 가장 잘 표현하는 100개의 프레임을 선택하여 SMPL+H 데이터 세트에서 선별한 표현적 손 및 얼굴 데이터 세트(EHF)를 만들었습니다. 이를 통해 기존의 3D 조인트 에러 메트릭 대신 더 엄격한 버텍스 간(v2v) 에러 메트릭을 사용할 수 있었습니다.

![우리의 성별 중립 모델(위쪽, 아래쪽 행) 혹은 성별 특정 모델(가운데)이 Frank [36]의 일부 데이터에 대해 어떻게 비교되는지에 대한 질적 비교입니다. Frank를 적용하기 위해, [36]은 3D 관절과 포인트 클라우드, 즉 500개 이상의 카메라를 사용합니다. 반면에, 우리의 방법은 오직 2D 관절만을 사용하여 실제적이고 표현적인 재구성을 생성합니다. 우리는 [36]의 3D 관절을 1개의 카메라 뷰에 투영하여 결과를 보여주며(세 번째 칸), 또한 단일 이미지에서 추정된 관절을 사용하여 2D 관절 감지의 노이즈가 미치는 영향을 보여줍니다(마지막 칸). Frank에 비해 우리의 SMPL-X는 관절 주변에 피부 아티팩트가 없습니다, 예를 들어 팔꿈치 등.](Expressive%20Body%20Capture%203D%20Hands,%20Face,%20and%20Body%20f%208612eca963db4c9cae7532c3eb8ab346/Untitled%202.png)

우리의 성별 중립 모델(위쪽, 아래쪽 행) 혹은 성별 특정 모델(가운데)이 Frank [36]의 일부 데이터에 대해 어떻게 비교되는지에 대한 질적 비교입니다. Frank를 적용하기 위해, [36]은 3D 관절과 포인트 클라우드, 즉 500개 이상의 카메라를 사용합니다. 반면에, 우리의 방법은 오직 2D 관절만을 사용하여 실제적이고 표현적인 재구성을 생성합니다. 우리는 [36]의 3D 관절을 1개의 카메라 뷰에 투영하여 결과를 보여주며(세 번째 칸), 또한 단일 이미지에서 추정된 관절을 사용하여 2D 관절 감지의 노이즈가 미치는 영향을 보여줍니다(마지막 칸). Frank에 비해 우리의 SMPL-X는 관절 주변에 피부 아티팩트가 없습니다, 예를 들어 팔꿈치 등.

연구진은 이전 모델에서 사용했던 3D 포인트 클라우드와 조인트와 달리 SMPL-X를 EHF 이미지에 맞추고 하나의 이미지와 2D 조인트만 입력으로 사용하여 SMPL, SMPL+H, Frank와 같은 유사한 모델과 비교했습니다. 연구진은 손가락과 얼굴 모델링으로 신체 모델을 강화하면 오차가 줄어든다는 사실을 발견했습니다.

![LSP 데이터셋 [33]의 야외 이미지에 대한 SMPL-X의 질적 결과입니다. SMPL-X와 같은 강력한 전체적 모델은 몸, 손, 얼굴의 자연스럽고 표현적인 재구성을 가져옵니다. 회색은 성별 감지에 확신이 있는 경우에 사용되는 성별 특정 모델을 나타냅니다. 파란색은 성별 분류기가 불확실할 때 사용되는 성별 중립 모델입니다.](Expressive%20Body%20Capture%203D%20Hands,%20Face,%20and%20Body%20f%208612eca963db4c9cae7532c3eb8ab346/Untitled%203.png)

LSP 데이터셋 [33]의 야외 이미지에 대한 SMPL-X의 질적 결과입니다. SMPL-X와 같은 강력한 전체적 모델은 몸, 손, 얼굴의 자연스럽고 표현적인 재구성을 가져옵니다. 회색은 성별 감지에 확신이 있는 경우에 사용되는 성별 특정 모델을 나타냅니다. 파란색은 성별 분류기가 불확실할 때 사용되는 성별 중립 모델입니다.

모델의 다양한 구성을 테스트하고 정확도를 측정하기 위해 절제 연구를 수행했습니다. 그 결과 성별에 따른 모델이 성 중립적인 모델보다 성능이 뛰어났으며, 충돌 항을 제거하면 물리적으로 그럴듯한 포즈 추정치가 줄어든다는 사실을 발견했습니다. 그런 다음 SMPL-X 모델을 또 다른 유사한 모델인 Frank와 비교했습니다. 피팅에 훨씬 적은 데이터를 사용했음에도 불구하고 SMPL-X는 비슷한 표현력을 보였으며 Frank에서 볼 수 있는 특정 스키닝 아티팩트를 피할 수 있었습니다.

![[61]의 손만의 접근법(중간)과 우리의 남성 모델을 이용한 접근법(오른쪽)의 비교입니다. 두 접근법 모두 OpenPose에 의존합니다. 좋은 감지의 경우 둘 다 잘 작동합니다(위). 2D 감지가 노이즈가 있는 경우에는 우리의 전체 모델이 더 강력한 내성을 보여줍니다. (공간을 위해 아래쪽에서 이미지를 자름)](Expressive%20Body%20Capture%203D%20Hands,%20Face,%20and%20Body%20f%208612eca963db4c9cae7532c3eb8ab346/Untitled%204.png)

[61]의 손만의 접근법(중간)과 우리의 남성 모델을 이용한 접근법(오른쪽)의 비교입니다. 두 접근법 모두 OpenPose에 의존합니다. 좋은 감지의 경우 둘 다 잘 작동합니다(위). 2D 감지가 노이즈가 있는 경우에는 우리의 전체 모델이 더 강력한 내성을 보여줍니다. (공간을 위해 아래쪽에서 이미지를 자름)

또한 SMPL-X와 손만 사용하는 접근 방식을 비교한 결과, 신체 컨텍스트가 포함되기 때문에 노이즈가 감지되는 경우 SMPL-X가 더 강력하다는 것을 발견했습니다. 정량적 비교 결과, SMPL-X는 손 전용 모델보다 평균 3D 관절 오차가 더 낮은 것으로 나타났습니다.

마지막으로 연구진은 SMPL-X 및 SMPLify-X 모델을 LSP, LSP-확장 및 MPII 데이터 세트와 같은 일부 실제 데이터 세트에 적용했습니다. 그 결과 SMPL-X와 같은 포괄적인 모델이 일상적인 이미지에서 자연스럽고 표현력 있는 재구성을 제공할 수 있음을 입증했습니다.

5. Conclusion

이 연구의 결론에서는 신체, 얼굴, 손 표현을 통합하는 새로운 모델인 SMPL-X의 개발과 영향, 그리고 단일 RGB 이미지와 2D OpenPose 관절 감지를 사용하여 SMPL-X를 피팅하는 접근 방식인 SMPLify-X에 대해 요약합니다. 피팅 프로세스는 새롭고 강력한 신체 포즈 사전 설정과 침투를 감지하고 페널티를 주는 빠르고 정확한 방법을 통해 조절됩니다.

저자는 실제 이미지를 사용하여 다양한 정성적 결과를 시연하여 SMPL-X의 표현력과 SMPLify-X의 효과를 강조합니다. 또한 정량적 평가를 위한 의사 실측 자료가 포함된 새로운 데이터 세트를 소개하며 보다 표현력 있는 모델의 중요성을 강조합니다.

향후 연구를 위해 저자들은 자연 상태의 SMPL-X 적합 데이터 세트를 큐레이팅하고 RGB 이미지에서 SMPL-X 파라미터를 직접 계산하는 회귀분석을 개발할 계획입니다. 저자들은 이번 연구가 RGB 이미지에서 신체, 손, 얼굴의 완전한 표현력을 포착하는 데 중요한 진전을 이뤘다고 생각합니다.