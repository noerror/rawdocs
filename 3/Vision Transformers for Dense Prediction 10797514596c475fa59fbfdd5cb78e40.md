# Vision Transformers for Dense Prediction

[https://arxiv.org/abs/2103.13413](https://arxiv.org/abs/2103.13413)

[https://github.com/isl-org/DPT](https://github.com/isl-org/DPT)

- Mar 2021

### 1. Introduction

이 글은 깊이 추정 및 의미 분할과 같은 고밀도 예측 작업을 위한 새로운 유형의 아키텍처인 고밀도 예측 트랜스포머(DPT)에 대해 설명합니다.

고밀도 예측 아키텍처를 설계하는 표준 방법은 네트워크를 인코더와 디코더로 분리하는 것입니다. 인코더는 일반적으로 대규모 데이터 세트에서 사전 학습된 컨볼루션 네트워크입니다. 인코더는 입력 이미지를 다운샘플링하여 다양한 스케일로 특징을 추출하므로 네트워크가 메모리와 계산 요구 사항을 관리할 수 있습니다. 그러나 다운 샘플링은 모델이 더 깊은 단계에서 해상도와 세분성을 잃게 되어 디코더가 복구하기 어렵다는 것을 의미하기도 합니다.

세분성 손실을 해결하기 위해 사람들은 더 높은 해상도로 훈련하거나, 확장된 컨볼루션을 사용하거나, 건너뛰기 연결을 사용하거나, 네트워크 전체에 다중 해상도 표현을 연결하는 등 여러 가지 해결책을 제안해 왔습니다. 그러나 이러한 방법은 이러한 네트워크의 기본 구성 요소인 컨볼루션 연산으로 인해 여전히 한계에 직면해 있습니다.

이 논문에서 저자들은 트랜스포머, 특히 비전 트랜스포머(ViT)를 인코더의 기본 구성 요소로 사용하는 새로운 아키텍처인 고밀도 예측 트랜스포머(DPT)를 제시합니다. 이 접근 방식의 장점은 ViT가 모든 단계에서 일정한 차원 표현을 유지하고 글로벌 수용 필드를 가지므로 보다 정확하고 전 세계적으로 일관된 예측이 가능하다는 것입니다.

단안 깊이 추정 및 시맨틱 분할 작업에 대해 테스트한 결과, 현재 최고 성능의 풀 컨볼루션 네트워크보다 28% 이상 뛰어난 성능을 보였습니다. 또한, 의미론적 분할을 위해 ADE20K 및 파스칼 컨텍스트 데이터 세트에서 새로운 최첨단 결과를 기록했습니다. 이 결과는 DPT가 표준 컨볼루션 네트워크에 비해 더 정확하고 전 세계적으로 일관된 예측을 할 수 있음을 보여줍니다.

### 2. Related Work

이 섹션에서는 고밀도 예측 트랜스포머(DPT)와 관련된 이전 연구에 대해 설명합니다.

처음에는 완전 컨볼루션 네트워크가 고밀도 예측 작업에 사용되는 일반적인 아키텍처였습니다. 이 네트워크는 컨볼루션과 하위 샘플링을 기본 요소로 사용하여 다중 스케일 표현을 학습합니다. 시간이 지남에 따라 이 접근 방식에 다양한 수정이 이루어졌습니다. 일부 방법은 여러 단계에서 풀링된 표현을 점진적으로 업샘플링합니다. 다른 방법은 확장 컨볼루션 또는 병렬 멀티스케일 특징 집계를 사용하여 충분히 큰 컨텍스트를 보장하면서 세분화된 예측을 복구합니다. 최근의 아키텍처는 네트워크 전체에 걸쳐 여러 개의 저해상도 표현과 함께 고해상도 표현을 유지합니다.

최근 몇 년 동안 주의 기반 모델, 특히 트랜스포머가 자연어 처리(NLP) 작업에 가장 많이 사용되는 아키텍처가 되었습니다. 이러한 모델은 자체 주의 메커니즘을 활용하며 대규모 데이터 세트에 대해 학습된 대용량 아키텍처에서 사용할 때 매우 효과적인 것으로 입증되었습니다. 일부 연구에서는 이러한 주의 메커니즘을 이미지 분석 작업에 적용하여, 충분한 학습 데이터가 있는 경우 NLP에서 성공적인 토큰 기반 트랜스포머 아키텍처가 이미지 분류에서도 우수한 성능을 발휘할 수 있음을 입증했습니다.

이 연구의 핵심은 컨볼루션 기반 모델에서 이미지 분석에서 트랜스포머 기반 모델로 전환한 후 NLP 분야에서 성공을 거뒀다는 점입니다. 이는 네트워크 전체에서 고해상도 표현을 유지하는 트랜스포머의 능력으로 인해 충분한 학습 데이터와 함께 사용할 경우 우수한 결과를 얻을 수 있기 때문입니다.

### 3. Architecture

이 섹션에서는 고밀도 예측 작업에서 성공적인 것으로 밝혀진 전체 인코더-디코더 구조를 유지하는 고밀도 예측 트랜스포머(DPT)를 소개합니다. DPT의 아키텍처는 비전 트랜스포머(ViT)를 백본으로 활용합니다.

![왼쪽: 아키텍처 개요. 입력 이미지는 토큰(주황색)으로 변환되는데, 이는 비중복 패치를 추출한 후에 그들의 펼쳐진 표현에 선형 투영을 적용함으로써(DPT-Base 및 DPT-Large) 이루어지거나, ResNet-50 특징 추출기를 적용함으로써(DPT-Hybrid) 이루어진다. 이미지 임베딩은 위치 임베딩으로 보강되며, 패치 독립적인 읽기 토큰(빨강색)이 추가된다. 토큰은 여러 트랜스포머 단계를 통과한다. 우리는 다른 단계의 토큰을 여러 해상도에서 이미지와 유사한 표현으로 재조립한다(녹색). 융합 모듈(보라색)은 점차적으로 표현을 융합하고 업샘플링하여 세밀한 예측을 생성한다. 중앙: 재조립 작업 개요. 토큰은 입력 이미지의 공간 해상도의 1/s배로 피쳐 맵을 조립한다. 오른쪽: 융합 블록은 잔여 합성곱 단위[23]를 사용하여 특징을 결합하고 피쳐 맵을 업샘플링한다.](Vision%20Transformers%20for%20Dense%20Prediction%2010797514596c475fa59fbfdd5cb78e40/Untitled.png)

왼쪽: 아키텍처 개요. 입력 이미지는 토큰(주황색)으로 변환되는데, 이는 비중복 패치를 추출한 후에 그들의 펼쳐진 표현에 선형 투영을 적용함으로써(DPT-Base 및 DPT-Large) 이루어지거나, ResNet-50 특징 추출기를 적용함으로써(DPT-Hybrid) 이루어진다. 이미지 임베딩은 위치 임베딩으로 보강되며, 패치 독립적인 읽기 토큰(빨강색)이 추가된다. 토큰은 여러 트랜스포머 단계를 통과한다. 우리는 다른 단계의 토큰을 여러 해상도에서 이미지와 유사한 표현으로 재조립한다(녹색). 융합 모듈(보라색)은 점차적으로 표현을 융합하고 업샘플링하여 세밀한 예측을 생성한다. 중앙: 재조립 작업 개요. 토큰은 입력 이미지의 공간 해상도의 1/s배로 피쳐 맵을 조립한다. 오른쪽: 융합 블록은 잔여 합성곱 단위[23]를 사용하여 특징을 결합하고 피쳐 맵을 업샘플링한다.

트랜스포머 인코더
ViT는 이미지 패치가 논문 전체에서 토큰이라고도 하는 "단어"로 취급되는 이미지의 단어 집합 표현에서 작동합니다. 이러한 토큰은 멀티헤드 자기 주의(MHSA)를 사용하여 토큰을 서로 연관시키기 위해 변환됩니다. 결정적으로, 이 변환기는 토큰의 수를 유지하여 초기 임베딩의 공간 해상도를 보존합니다. MHSA는 모든 토큰이 다른 모든 토큰에 영향을 미칠 수 있도록 허용하여 트랜스포머에 글로벌 수용 필드를 제공합니다.

ViT는 겹치지 않는 모든 정사각형 패치를 처리하여 이미지에서 패치 임베딩을 추출합니다. 패치는 벡터로 평탄화되고 선형 투영을 사용하여 개별적으로 임베드됩니다. 표현에 공간 위치 정보를 추가하기 위해 이미지 임베딩은 학습 가능한 위치 임베딩과 연결됩니다. ViT는 분류에 사용되는 최종 글로벌 이미지 표현의 역할을 하는 판독 토큰이라는 특수 토큰을 추가합니다.

이 작업에는 세 가지 변형 ViT가 사용됩니다: ViT-Base(12개의 트랜스포머 레이어), ViT-Large(24개의 트랜스포머 레이어와 더 넓은 피처 크기), ViT-Hybrid(이미지 임베딩을 위한 ResNet50과 12개의 트랜스포머 레이어)가 그것입니다.

컨볼루션 디코더
디코더는 토큰 세트를 다양한 해상도에서 이미지와 유사한 특징 표현으로 재조합하고, 이를 점진적으로 융합하여 최종 고밀도 예측을 수행합니다. 임의의 트랜스포머 인코더 레이어의 출력 토큰에서 이미지와 유사한 표현을 복구하기 위해 "재조립"이라고 하는 3단계 작업이 제안됩니다.

세 단계는 읽기, 연결, 리샘플링입니다. 읽기는 판독 토큰을 처리합니다. Concatenate는 토큰을 이미지와 같은 표현으로 재구성합니다. 마지막으로 리샘플링은 특정 특징 차원에 따라 특정 크기로 표현의 크기를 조정합니다.

트랜스포머 백본에 관계없이 피처는 네 가지 단계와 네 가지 해상도로 재조립됩니다. 더 깊은 레이어는 더 낮은 해상도, 초기 레이어는 더 높은 해상도에 해당합니다.

그런 다음 연속된 단계의 특징 맵은 RefineNet 기반 특징 융합 블록을 사용하여 결합됩니다. 최종 표현은 입력 이미지 해상도의 절반에 도달할 때까지 각 융합 단계에서 점진적으로 업샘플링됩니다.

다양한 이미지 크기 처리
완전 컨볼루션 네트워크와 마찬가지로 DPT는 다양한 이미지 크기를 처리할 수 있습니다. 패치 크기 p로 나눌 수 있는 모든 이미지 크기를 처리할 수 있으며, 이미지 크기에 맞게 위치 임베딩을 선형적으로 보간할 수 있습니다. 재조립 모듈과 융합 모듈 모두 입력 이미지가 컨볼루션 디코더의 보폭에 맞춰 정렬되는 한 다양한 토큰 수를 처리할 수 있습니다.

### 4. Experiments

이 논문에서는 단안 깊이 추정과 시맨틱 분할이라는 두 가지 고밀도 예측 작업에 고밀도 예측 트랜스포머(DPT)를 적용한 실험 결과를 제시합니다. 특히 대규모 훈련 데이터 세트에서 DPT가 기존 컨볼루션 네트워크에 비해 정확도를 크게 향상시키는 것으로 나타났습니다.

단안 심도 추정을 위해 약 140만 개의 이미지가 포함된 대규모 메타 데이터 세트인 MIX 6이 생성되었습니다. DPT 아키텍처는 Adam 옵티마이저와 함께 다중 목표 최적화를 사용하여 훈련되었습니다. DPT 모델을 평가한 결과, 최신 아키텍처를 크게 능가하는 것으로 나타났습니다. 서로 다른 데이터 세트로의 제로 샷 전송에서 DPT-Hybrid와 DPT-Large는 가장 잘 알려진 아키텍처인 MiDAS에 비해 각각 평균 23%, 28% 이상의 상대적 개선을 달성했습니다. KITTI 및 NYUv2 데이터 세트에서 DPT-Hybrid를 미세 조정한 결과, 모든 메트릭에서 기존 최신 모델과 일치하거나 더 나은 성능을 보였습니다.

![단안 깊이 추정을 위한 샘플 결과. MiDaS에서 사용되는 완전 합성곱 네트워크에 비해, DPT는 더 나은 전역적 일관성(예: 하늘, 두 번째 행)과 더 세밀한 디테일(예: 나무 가지, 마지막 행)을 보여준다.](Vision%20Transformers%20for%20Dense%20Prediction%2010797514596c475fa59fbfdd5cb78e40/Untitled%201.png)

단안 깊이 추정을 위한 샘플 결과. MiDaS에서 사용되는 완전 합성곱 네트워크에 비해, DPT는 더 나은 전역적 일관성(예: 하늘, 두 번째 행)과 더 세밀한 디테일(예: 나무 가지, 마지막 행)을 보여준다.

의미론적 세분화 작업의 경우, DPT는 ADE20K 의미론적 세분화 데이터셋에 대해 학습하고 파스칼 컨텍스트 데이터셋에 대해 미세 조정했습니다. 실험 프로토콜은 Zhang 등이 설정한 프로토콜과 유사했습니다. 이 작업에서 DPT-Hybrid는 기존의 모든 풀 컨볼루션 아키텍처를 능가하는 것으로 나타났습니다. DPT-Large는 데이터 세트 크기가 훨씬 작기 때문에 성능이 약간 떨어졌습니다. 시각적 비교에서 DPT는 물체 경계를 더 깨끗하고 세밀하게 묘사했으며, 일부 경우 덜 복잡한 예측을 제공했습니다.

![ADE20K(첫 번째와 두 번째 열)와 Pascal Context(세 번째와 네 번째 열)에서의 의미론적 분할을 위한 샘플 결과. 예측은 대개 객체의 가장자리에 더 잘 정렬되고 덜 혼란스럽다.](Vision%20Transformers%20for%20Dense%20Prediction%2010797514596c475fa59fbfdd5cb78e40/Untitled%202.png)

ADE20K(첫 번째와 두 번째 열)와 Pascal Context(세 번째와 네 번째 열)에서의 의미론적 분할을 위한 샘플 결과. 예측은 대개 객체의 가장자리에 더 잘 정렬되고 덜 혼란스럽다.

이러한 결과는 고밀도 예측 트랜스포머(DPT) 아키텍처가 특히 많은 양의 학습 데이터를 사용할 수 있는 경우 고밀도 예측 작업에 효과적인 접근 방식임을 나타냅니다. 이 아키텍처는 기존의 컨볼루션 네트워크 모델에 비해 상당한 개선점을 제공하며, 더 작은 데이터 세트에서 미세 조정할 때도 높은 성능을 유지할 수 있습니다.

이 섹션에서는 단안 깊이 추정을 위한 DPT 모델에 대한 제거 연구에 대해 설명합니다. 주요 결과는 다음과 같습니다:

연결 건너뛰기: 이 연구에서는 낮은 수준의 특징과 높은 수준의 특징을 모두 포함하는 레이어에서 특징을 탭하면 모델의 성능이 향상된다는 사실을 발견했습니다. 이 방법은 추가 실험에서 사용됩니다.

- 판독 토큰: 이 연구에 따르면 판독 토큰을 무시하면 성능이 양호하고 토큰을 투영하면 성능이 약간 향상되는 것으로 나타났습니다. 그러나 토큰을 추가하면 성능이 저하됩니다. 따라서 추가 실험에서는 투영을 채택했습니다.
- 백본: 이 연구는 다양한 백본의 성능을 비교합니다: ViT-Large, ViT-Base, 그리고 ViT-Hybrid. ViT-Large가 다른 모든 백본보다 성능이 뛰어나지만 훨씬 더 많은 매개 변수를 가지고 있는 것으로 나타났습니다. ViT-Hybrid는 ViT-Large와 비슷한 성능을 제공하지만 ViT-Base와 비슷한 수의 매개변수를 가지고 있기 때문에 정확도와 모델 복잡성 간에 적절한 균형을 제공합니다.
- 추론 해상도: 트랜스포머 인코더는 모든 레이어에 글로벌 수신 필드를 가지고 있어 잠재적으로 DPT가 추론 해상도에 덜 의존합니다. 훈련 해상도보다 높은 해상도에서 추론을 수행할 때 DPT 변형의 성능은 완전 컨볼루션 아키텍처에 비해 더 완만하게 저하됩니다.
- 추론 속도: 이 연구에 따르면 DPT-Hybrid 및 DPT-Large는 MiDaS에서 사용하는 완전 컨볼루션 아키텍처와 비슷한 지연 시간을 보입니다. 흥미롭게도 DPT-Large는 파라미터 수가 훨씬 더 많음에도 불구하고 지연 시간이 경쟁력 있는 이유는 넓고 비교적 얕은 구조로 높은 수준의 병렬 처리가 가능하기 때문입니다.

절제 연구는 모델의 다양한 측면과 기술적 선택이 DPT 모델의 전반적인 성능과 효율성에 어떻게 기여하는지 이해하는 데 유용한 접근 방식입니다.

### 5. Conclusion

이 글에서는 단안 깊이 추정 및 시맨틱 분할과 같은 고밀도 예측 작업에 비전 트랜스포머를 성공적으로 사용하는 혁신적인 신경망 아키텍처인 고밀도 예측 트랜스포머(DPT)에 대한 연구를 마무리합니다.

연구 결과에 따르면 DPT는 기존의 완전 컨볼루션 아키텍처에 비해 더 세밀하고 전역적으로 일관된 예측을 생성할 수 있는 것으로 나타났습니다. 또한 이 연구는 트랜스포머 모델에 관한 이전 연구 결과와 일치하는 대규모 데이터 세트에 대해 훈련할 때 DPT가 최고의 성능을 발휘한다는 사실을 발견했습니다.

이와 같은 고밀도 예측 작업에서 트랜스포머를 성공적으로 구현한 것은 컴퓨터 비전 및 AI 분야의 향후 연구에 유망한 방향을 제시합니다. DPT를 사용하여 개선된 결과는 조밀하고 정확한 예측이 필요한 작업을 위한 강력한 도구로서의 잠재력을 보여주며, 대규모 데이터 세트에서의 성능은 확장성과 폭넓은 적용 가능성을 말해줍니다.

- 모델의 입력과 출력
    
    입력:
    Dense Prediction Transformer (DPT) 모델의 입력은 이미지입니다. 이미지는 토큰으로 변환됩니다. 이 토큰화 과정은 두 가지 방법 중 하나로 수행될 수 있습니다:
    
    1. 이미지에서 비중복 패치를 추출하고 이들의 펼쳐진 표현에 선형 투영을 적용하는 방법 (이 방법은 DPT-Base 및 DPT-Large에 사용됨)
    2. ResNet-50 특징 추출기를 이미지에 적용하는 방법 (이 방법은 DPT-Hybrid에 사용됨)
    
    이미지 임베딩은 위치 임베딩으로 보강되며, 패치 독립적인 읽기 토큰(추가 특성 토큰)이 추가됩니다. 이렇게 변환된 토큰들은 여러 트랜스포머 단계를 통과합니다.
    
    출력:
    DPT의 출력은 주어진 입력 이미지에 대한 dense prediction입니다. 이 모델은 monocular depth estimation (단안 깊이 추정) 및 semantic segmentation (의미론적 분할)과 같은 고밀도 예측 작업에 효과적입니다.
    
    각 트랜스포머 단계에서의 토큰은 다양한 해상도에서 이미지와 유사한 표현으로 재조립됩니다. Fusion module은 이러한 표현들을 점차적으로 결합하고 업샘플링하여 고해상도의 예측을 생성합니다.
    
    결과적으로, 출력은 각 입력 이미지의 각 픽셀에 대한 예측(예를 들어, 깊이 추정이나 클래스 레이블)을 제공하는 표현을 제공합니다. 이 결과는 이미지의 전역적 일관성과 세밀한 디테일을 모두 캡처할 수 있습니다.
    
- 의의
    
    Dense Prediction Transformer (DPT)는 이미지 분류에 성공적으로 적용되었던 Vision Transformers(ViT)를 기반으로 한 새로운 방식입니다. 이 모델은 고밀도 예측 작업, 특히 단안 깊이 추정과 의미론적 분할과 같은 작업을 위해 트랜스포머 아키텍처를 사용함으로써 이전 방식과의 차별성을 갖습니다.
    
    1. **Globally coherent and finer-grained predictions:** 전통적인 전체 컨볼루션 아키텍처와 달리 DPT는 전역적으로 일관된 예측과 더욱 세밀한 예측을 생성합니다. 이는 트랜스포머가 이미지의 모든 부분에 대한 정보를 병렬적으로 처리하고 입력 사이의 관계를 학습할 수 있기 때문입니다. 이는 깊이 예측에서 글로벌 일관성을 향상시키고 세그멘테이션에서 객체의 가장자리를 더욱 정확하게 추정하게 됩니다.
    2. **Flexible resolution handling:** DPT는 각 층에서 전역 수용 필드를 가진 트랜스포머 인코더를 사용함으로써 입력 해상도가 훈련 해상도와 크게 다른 경우에도 성능이 크게 저하되지 않습니다. 이는 전통적인 컨볼루션 아키텍처가 해상도 변화에 더욱 민감한 것과 대조적입니다.
    3. **Transformer Stages and Reassemble operation:** DPT는 여러 트랜스포머 단계를 거치며 각 단계에서 토큰을 이미지와 유사한 표현으로 재조립합니다. 이는 단계별로 추출된 특징들을 유지하면서 높은 해상도의 출력을 생성하는 데 도움이 됩니다.
    
    이 세 가지 주요 요소는 DPT가 기존 방식에 비해 향상된 성능을 보이게 하며, 이미지 분류를 위한 선행 학습 방법의 개선이 dense prediction 작업에도 도움이 될 수 있음을 보여줍니다.