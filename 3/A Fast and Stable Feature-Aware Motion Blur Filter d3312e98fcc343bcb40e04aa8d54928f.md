# A Fast and Stable Feature-Aware Motion Blur Filter

[https://www.cim.mcgill.ca/~derek/files/Guertin2014MotionBlur.pdf](https://www.cim.mcgill.ca/~derek/files/Guertin2014MotionBlur.pdf)

- 2014

![복잡한 깊이 및 모션 관계를 가진 애니메이션 시퀀스에서도 모션 아티팩트 없이 시간적으로 일관된 모션 블러를 렌더링합니다. 모든 결과는 GeForce GTX780에서 1280×720 해상도에서 2ms 이내에 계산되며, 우리의 필터는 후처리 안티앨리어싱 및 심도 효과와 매끄럽게 통합됩니다.](A%20Fast%20and%20Stable%20Feature-Aware%20Motion%20Blur%20Filter%20d3312e98fcc343bcb40e04aa8d54928f/Untitled.png)

복잡한 깊이 및 모션 관계를 가진 애니메이션 시퀀스에서도 모션 아티팩트 없이 시간적으로 일관된 모션 블러를 렌더링합니다. 모든 결과는 GeForce GTX780에서 1280×720 해상도에서 2ms 이내에 계산되며, 우리의 필터는 후처리 안티앨리어싱 및 심도 효과와 매끄럽게 통합됩니다.

## 1 Introduction

모션 블러는 현실적인 이미지 합성에서 중요한 효과로, 중요한 모션 단서를 제공하고 시청자의 주의를 끄는 데 중요한 역할을 합니다. 고품질 영화 제작 렌더링과 인터랙티브 그래픽을 구분 짓는 몇 안 되는 효과 중 하나입니다. 우리는 이 효과를 간단하고 고성능의 후처리 방법으로 높은 품질로 근사화하기 위해 모션 블러 시퀀스의 지각적 단서를 현상학적으로 모델링합니다.

이 연구는 오프라인 모션 블러 후처리 작업에서 영감을 받았으며, 특히 재구성 필터와 샘플링을 결합한 기초 작업에 기반을 두고 있습니다. 이러한 접근 방식은 현대 게임 엔진에는 너무 무겁지만, 많은 아이디어가 여전히 유용합니다. 반면에 여러 해 동안 다양한 형태로 존재해온 임시방편적인 접근 방식(예: 움직이는 물체를 블러 처리)도 있지만, 현상학적 방법론을 사용하여 모션 블러 후처리를 접근하는 방법에 대한 관심은 최근에서야 인터랙티브 렌더링 커뮤니티에서 커지고 있습니다.

이 방법론은 처음에는 후처리 안티앨리어싱과 심도 효과에 사용되어 성공을 거두었습니다. 우리는 시간적으로 일관되며, 슈퍼 샘플링과 경쟁할 만한 고품질의 모션 블러를 목표로 합니다. 우리의 기법은 최근 후처리 기법을 기반으로 하여, 몇 가지 한계를 해결하고 안정적이며 특징을 보존하는 믿을 만한 모션 블러를 생성합니다.

이 연구의 주요 기여는 다음과 같습니다:

- 이방성 속도 분포를 처리하는 개선된 분산 기반의 방향성 샘플링 기법
- 블러링되지 않은 객체의 세부 사항을 보존하고, 미세 및 대규모 블러링을 포착하는 샘플 가중치 기법
- 타일 경계 처리 및 후처리 안티앨리어싱 및 심도 효과와의 상호작용에 대한 더욱 견고한 처리 방법

우리는 단일 시간 인스턴스에서 캡처된 g-버퍼와 표준 래스터라이제이션을 사용합니다. 우리의 결과는 애니메이션에서 안정적이며 복잡한 모션 시나리오를 견고하게 처리하고, 프레임당 약 3ms의 성능을 보입니다. 우리의 기법은 이미지 후처리 필터이므로, 예술적 맥락에서 비물리적이고 과장된 모션 블러 효과를 생성하는 데 쉽게 사용할 수 있습니다.

## 2 Previous Work and Preliminaries

모션 블러에 대한 방대한 연구 중, 우리는 우리 접근 방식과 가장 관련이 있는 최근 연구를 논의하며, 관심 있는 독자들을 위해 이 주제에 대한 최근 설문 조사를 참고합니다.

### 샘플링 분석 및 재구성

Cook의 분포 효과에 대한 기초 작업은 확률적 레이 트레이싱 및 마이크로폴리곤 래스터라이제이션에서 아티팩트를 줄이기 위해 다양한 이미지 필터를 적용하는 방법을 처음으로 제시했습니다. 최근 접근 방식들은 다차원 본래 공간, 웨이블릿 또는 데이터 기반 도메인에서 중요한 시각적 디테일을 유지하면서 노이즈를 필터링합니다. Egan 등은 물체 움직임의 주파수 영역에서 샘플 배치와 필터링 효과를 분석하고, 확률적으로 분포된 시공간 샘플에서 작동하는 전단 필터를 제안했습니다. Lehtinen 등은 픽셀에서 시공간 광장을 재구성하기 위해 레이 공간의 희소 샘플을 사용하여 분포 효과를 위한 필터링된 픽셀 값을 재구성했습니다. 이러한 기술들은 확률적 렌더링 엔진에서 고정된 샘플링 예산 하에 통합 오류를 최소화하는 것을 목표로 합니다. 우리는 또한 낮은 샘플링률로 인한 가시적 아티팩트를 줄이고자 하지만, 분산된 시간 샘플링이 불가능한 인터랙티브 그래픽 파이프라인에서 밀리초 단위의 계산 예산을 가지고 있습니다.

### 확률적 래스터라이제이션

최근 연구에서는 삼각형 래스터라이제이션을 시간 및 렌즈 도메인으로 확장하여, GPU 래스터라이제이션, 확률적 레이 트레이싱, 현대 GPU 마이크로폴리곤 렌더러의 장단점을 균형 있게 맞추고자 합니다. 이러한 접근 방식은 공간-렌즈-시간에서 여러 샘플에서 카메라 가시성과 셰이딩을 평가합니다. 효율적인 GPU 파이프라인 구현에도 불구하고, 이러한 접근 방식은 여전히 현대 인터랙티브 그래픽 애플리케이션에는 너무 비쌉니다. 그러나 Shirley 등은 이러한 확률적 다중 샘플 렌더러의 시공간 출력에서 그럴듯한 모션 블러를 위한 이미지 공간 필터를 논의합니다. 우리는 모션 블러 행동에 대한 그들의 현상학적 분석에서 영감을 받아 복잡한 모션 시나리오를 보다 견고하게 처리할 수 있도록 이 분석을 확장합니다.

### 인터랙티브 휴리스틱

일부 접근 방식은 텍스처 매핑 전에 알베도 텍스처를 블러 처리하거나 셰이더를 사용하여 물체의 기하학을 압출합니다. 그러나 이러한 접근 방식은 실루엣 블러 처리를 제대로 하지 못해 비현실적인 모션 블러를 초래합니다. Max와 Lerner, Pepper는 물체를 깊이별로 정렬하고 속도를 따라 블러 처리한 후 최종 이미지에서 합성하는 전략을 사용하지만, 이는 장면이 페인터의 가시성 가정을 무효화할 때 실패합니다. 이러한 접근 방식의 픽셀 단위 변형은 이미지 속도를 샘플링 전에 확장할 때 아티팩트를 줄일 수 있지만, 배경 디테일과 중요한 모션 특징을 손상시킬 수 있습니다. 최근 타일 기반의 단일 블러 속도 접근 방식에서 영감을 받아, 우리는 큰 규모의 모션 행동을 고려하고, 적용하는 블러의 공간적으로 가변적인 부분을 설명하기 위해 원래 속도 필드에서 샘플링하지만, 높은 수준의 모션 정보를 추가로 통합하여 더욱 안정적이고 복잡한 모션에서도 견고한 결과를 생성합니다.

## 3 Tile-Based Dominant Velocity Filtering Overview

우리는 최근 단일 속도 기법을 기반으로 하는 타일 기반 필터링 방법을 채택하여 모션 블러를 생성합니다. 이 기법은 현상학적 관찰과 샘플링 인식 재구성 필터를 결합한 것입니다. 이 방법의 주요 단계는 다음과 같습니다:

!["단일 속도" 기법을 사용한 모션 블러.](A%20Fast%20and%20Stable%20Feature-Aware%20Motion%20Blur%20Filter%20d3312e98fcc343bcb40e04aa8d54928f/Untitled%201.png)

"단일 속도" 기법을 사용한 모션 블러.

1. **타일 분할**: 이미지가 최대 블러 반경 r에 따라 r × r 타일로 분할됩니다. 이를 통해 각 픽셀은 최대 (1-링) 타일 이웃에 의해 영향을 받습니다.
2. **지배적 속도 계산**: 각 타일은 지배적인 속도를 할당받습니다. 지배적 속도는 타일 내의 최대 픽셀 속도를 유지하고, 1-링 타일 이웃의 최대값을 고려하여 계산됩니다.
3. **픽셀 블렌딩**: 픽셀은 이 지배적 속도를 따라 가중치가 부여된 탭과 함께 블렌딩됩니다.

이 접근 방식의 주요 세부 사항은 다음과 같습니다:

- 타일의 지배적 속도 vmax는 두 단계로 계산됩니다. 타일당 최대 픽셀 속도는 유지되고, 1-링 타일 이웃의 최대값을 고려하여 vmax가 결정됩니다.
- 픽셀은 vmax를 따라 샘플링되며, 이는 높은 캐시 일관성을 제공하지만 복잡한 모션을 무시할 수 있습니다.
- 샘플 가중치에는 깊이 인식 메트릭이 사용되며, 샘플 지점에서 속도 크기만 고려됩니다.

"TileMax" 패스는 이미지의 각 차원당 두 번의 패스로 계산될 수 있으며, 이는 메모리 사용량을 약간 증가시키지만 성능을 크게 향상시킵니다. 샘플은 밴딩을 줄이기 위해 지터링되며, 샘플 가중치는 다음과 같은 현상학적 모션 블러 효과를 재현하기 위해 설정됩니다:

1. 먼 픽셀/객체가 셰이딩 픽셀 위로 블러링됨.
2. 셰이딩 픽셀의 모션에 의한 투명성.
3. 효과 1과 2의 깊이 인식 결합.

이 기술은 단순하고 고성능의 후처리 과정을 통해 그럴듯한 모션 블러를 생성하며, 이미 여러 게임 엔진에서 채택되었습니다. 그러나 단일 지배적 속도 가정과 샘플 가중치 기법은 여러 방향으로 움직이는 객체가 겹치거나 타일 경계 및 얇은 객체를 처리하는 데 한계가 있어 시각적 아티팩트가 발생할 수 있습니다.

우리는 이러한 한계를 해결하기 위해 새로운 솔루션을 식별, 설명 및 평가합니다. 기존의 단일 속도 접근 방식과 다른 선행 연구를 바탕으로, 우리의 기법은 높은 캐시 일관성과 병렬 처리 가능한 간단하고 고성능의 구현을 유지하면서도 더 견고한 다중 속도 확장을 제공합니다.

## 4 Stable and Robust Feature-Aware Motion Blur

우리는 기존의 단일 속도 접근 방식에서 발생하는 문제를 해결하고, 복잡한 모션 시나리오에서도 안정적이고 견고한 모션 블러를 생성하기 위해 여러 개선 사항을 제안합니다.

### 4.1 여러 유의미한 모션 벡터

단일 지배적 속도 가정은 타일 내 여러 다른 속도를 가진 픽셀이 있을 때 문제가 발생하며, 이는 타일 내부의 잘못된 블러와 타일 간의 블러 불일치를 초래합니다. 이를 해결하기 위해 두 번째 방향을 신중하게 선택하여 샘플링합니다. 우리는 타일의 속도 분산에 따라 샘플을 분할하고, 샘플링 방향으로부터의 속도 편차를 기반으로 샘플을 가중치 부여합니다. 이를 통해 복잡한 모션 디테일을 더 잘 해결할 수 있습니다.

![상단: 복잡한 깊이 및 모션 관계를 가진 애니메이션. 카메라는 위로 이동하며 회전하고, 차는 급회전하면서 위로 움직입니다. 하단: 이전 접근 방식(왼쪽)은 이러한 경우를 처리하지 못해 타일 사이에 아티팩트가 발생합니다. 우리의 필터(오른쪽)는 올바르게 블러 처리하며 시간적으로 안정적입니다(비디오 참조).](A%20Fast%20and%20Stable%20Feature-Aware%20Motion%20Blur%20Filter%20d3312e98fcc343bcb40e04aa8d54928f/Untitled%202.png)

상단: 복잡한 깊이 및 모션 관계를 가진 애니메이션. 카메라는 위로 이동하며 회전하고, 차는 급회전하면서 위로 움직입니다. 하단: 이전 접근 방식(왼쪽)은 이러한 경우를 처리하지 못해 타일 사이에 아티팩트가 발생합니다. 우리의 필터(오른쪽)는 올바르게 블러 처리하며 시간적으로 안정적입니다(비디오 참조).

![다양한 방향으로 높은 속도를 가진 복잡한 장면. 픽셀당 15개의 샘플만 사용해도 우리의 알고리즘은 이전 알고리즘보다 더 만족스러운 결과를 제공합니다.](A%20Fast%20and%20Stable%20Feature-Aware%20Motion%20Blur%20Filter%20d3312e98fcc343bcb40e04aa8d54928f/Untitled%203.png)

다양한 방향으로 높은 속도를 가진 복잡한 장면. 픽셀당 15개의 샘플만 사용해도 우리의 알고리즘은 이전 알고리즘보다 더 만족스러운 결과를 제공합니다.

![샘플링 방향 vmax(녹색), v⊥max(노란색), 및 vc(p)(파란색).](A%20Fast%20and%20Stable%20Feature-Aware%20Motion%20Blur%20Filter%20d3312e98fcc343bcb40e04aa8d54928f/Untitled%204.png)

샘플링 방향 vmax(녹색), v⊥max(노란색), 및 vc(p)(파란색).

![픽셀 p(빨간색) 주변 타일들의 분산(녹색).](A%20Fast%20and%20Stable%20Feature-Aware%20Motion%20Blur%20Filter%20d3312e98fcc343bcb40e04aa8d54928f/Untitled%205.png)

픽셀 p(빨간색) 주변 타일들의 분산(녹색).

![시청자를 향해 직접 이동하는 Sponza의 사자. 하단: 단일 속도 결과(왼쪽), 분산 기반 샘플 분배(가운데), vmax 및 vc 방향 샘플링을 사용하는 보수적인 샘플 분배(오른쪽).](A%20Fast%20and%20Stable%20Feature-Aware%20Motion%20Blur%20Filter%20d3312e98fcc343bcb40e04aa8d54928f/Untitled%206.png)

시청자를 향해 직접 이동하는 Sponza의 사자. 하단: 단일 속도 결과(왼쪽), 분산 기반 샘플 분배(가운데), vmax 및 vc 방향 샘플링을 사용하는 보수적인 샘플 분배(오른쪽).

### 4.2 타일 경계 불연속성

타일 기반 접근 방식과 단일 지배적 속도에 의존하는 특성 때문에 타일 경계에서 시각적 불연속성이 자주 발생합니다. 이를 줄이기 위해 우리는 타일 경계 근처의 픽셀에 대해 이웃 타일의 최대 속도 텍스처 조회를 확률적으로 오프셋하여, 타일 경계에서 노이즈를 트레이드오프합니다.

![세밀한 속도 정보에 따라 샘플별 가중치를 조정.](A%20Fast%20and%20Stable%20Feature-Aware%20Motion%20Blur%20Filter%20d3312e98fcc343bcb40e04aa8d54928f/Untitled%207.png)

세밀한 속도 정보에 따라 샘플별 가중치를 조정.

![타일 경계에 가까울수록 더 높은 확률로 vmax(t) 샘플을 지터링합니다.](A%20Fast%20and%20Stable%20Feature-Aware%20Motion%20Blur%20Filter%20d3312e98fcc343bcb40e04aa8d54928f/Untitled%208.png)

타일 경계에 가까울수록 더 높은 확률로 vmax(t) 샘플을 지터링합니다.

![타일 경계 아티팩트. 하단: 단일 속도 블러링(왼쪽)은 타일 경계에서 불쾌한 아티팩트를 유발하며, 다중 방향 샘플링(오른쪽; 하단)으로 일부 감소되고, 확률적 vmax 블렌딩(오른쪽; 상단)으로 완전히 해결됩니다.](A%20Fast%20and%20Stable%20Feature-Aware%20Motion%20Blur%20Filter%20d3312e98fcc343bcb40e04aa8d54928f/Untitled%209.png)

타일 경계 아티팩트. 하단: 단일 속도 블러링(왼쪽)은 타일 경계에서 불쾌한 아티팩트를 유발하며, 다중 방향 샘플링(오른쪽; 하단)으로 일부 감소되고, 확률적 vmax 블렌딩(오른쪽; 상단)으로 완전히 해결됩니다.

### 4.3 얇은 특징 보존

단일 속도 필터링은 픽셀의 중심 샘플을 무시하고 픽셀의 속도 크기에 따라 색상을 가중치 부여하여 얇은 객체가 사라지거나 '고스트' 현상이 발생할 수 있습니다. 우리는 중심 샘플을 다른 샘플과 동일하게 처리하여 상대적인 깊이와 속도 변화를 고려함으로써 얇은 특징을 보다 현실적으로 보존합니다.

![오프 축 이웃은 중앙 타일을 흐리게 할 수 있는 경우에만 vmax 계산에 사용됩니다.](A%20Fast%20and%20Stable%20Feature-Aware%20Motion%20Blur%20Filter%20d3312e98fcc343bcb40e04aa8d54928f/Untitled%2010.png)

오프 축 이웃은 중앙 타일을 흐리게 할 수 있는 경우에만 vmax 계산에 사용됩니다.

![Sponza의 깃대와 같은 얇은 객체는 단일 속도 접근 방식에서는 샘플링 속도에 따라 다양하게 유령화됩니다. 우리의 접근 방식은 이러한 디테일을 해결하고 샘플링 속도의 변화에 견고합니다.](A%20Fast%20and%20Stable%20Feature-Aware%20Motion%20Blur%20Filter%20d3312e98fcc343bcb40e04aa8d54928f/Untitled%2011.png)

Sponza의 깃대와 같은 얇은 객체는 단일 속도 접근 방식에서는 샘플링 속도에 따라 다양하게 유령화됩니다. 우리의 접근 방식은 이러한 디테일을 해결하고 샘플링 속도의 변화에 견고합니다.

### 4.4 이웃 블러링

우리는 McGuire 등 [MHBO12]의 이웃 최대 속도 계산 방식을 수정하여, 실제 최대 속도와의 편차를 줄여 불필요한 블러 아티팩트를 줄입니다. 이를 통해 중심 타일에 영향을 미치지 않는 대각선 타일의 최대 속도는 계산에서 제외합니다.

### 4.5 확률적 노이즈 및 후처리 안티앨리어싱

우리는 Halton 시퀀스를 사용하여 픽셀별 샘플 세트를 지터링하고, 최대 지터 값을 늘려 결과물의 품질을 향상시킵니다. 또한, 우리의 확률적 통합 방식은 후처리 화면 공간 안티앨리어싱(FXAA) 방법에 적합하여 잔여 노이즈를 줄이는 데 도움을 줍니다. 이 효과를 최대화하기 위해 최대 강도의 체크무늬 패턴을 사용하여 모든 모션 블러 픽셀을 감지하고 부드럽게 만듭니다.

이러한 개선 사항들을 통해 우리는 복잡한 장면에서도 견고하고 안정적인 모션 블러를 생성할 수 있으며, 이는 높은 성능과 간단한 구현을 유지하면서도 현상학적 모션 블러의 품질을 향상시킵니다.

## 5 Implementation and Results

우리의 기법은 1280 × 720 해상도에서 실시간으로 구현되었으며, Intel Core i7-3770K와 NVIDIA GTX780에서 테스트되었습니다. 주요 매개변수 설정은 다음과 같습니다: {N,r, τ,κ,η, γ,φ} = {35,40,1,40,0.95,1.5,27}. 모든 중간 텍스처는 UINT8 형식으로 저장되었으며, TileVariance 텍스처는 잔여 타일 경계 아티팩트를 제거하기 위해 선형 보간법을 사용했습니다.

![우리의 노이즈는 표준 후처리 FXAA 에지 검출에 적합하며, 픽셀 주파수 밝기 체커보드를 사용하여 FXAA를 추가로 "힌트"할 수 있습니다.](A%20Fast%20and%20Stable%20Feature-Aware%20Motion%20Blur%20Filter%20d3312e98fcc343bcb40e04aa8d54928f/Untitled%2012.png)

우리의 노이즈는 표준 후처리 FXAA 에지 검출에 적합하며, 픽셀 주파수 밝기 체커보드를 사용하여 FXAA를 추가로 "힌트"할 수 있습니다.

우리는 픽셀별 속도를 정수 버퍼에 저장할 때 올바르게 양자화하고 인코딩하는 것이 중요함을 발견했습니다. McGuire 등의 구현에서 사용된 인코딩 방식의 한계는 속도의 x 및 y 성분이 각각 ±r로 클램핑되어 큰 속도는 네 가지 가능한 값 중 하나로만 나타날 수 있다는 것입니다. 우리는 유사한 계산을 사용하되, 범위 [−r,r]에 따라 정규화하여 이 문제를 해결했습니다.

또한, 우리는 깊이 인식 전경 및 배경 블러링을 보다 잘 지원하기 위해 McGuire 등의 연속 깊이 비교 함수(zCompare)를 수정했습니다. 상대 깊이 간격을 사용하여 장면에 독립적인 방식으로 작동하며, 멀리 있는 객체들 간의 부드러운 블렌딩을 허용하여 화면상의 속도 커버리지가 줄어드는 것을 보완합니다.

우리는 Sousa의 단일 속도 구현을 최적화한 버전과 비교 실험을 진행했으며, 이 구현은 이미 여러 게임 엔진에서 사용되고 있습니다. 타일 분산 기반의 샘플 분배는 샘플을 vmax와 vc 사이에 분배하는 데 있어 약간의 개선을 제공하지만, 상호작용 애니메이션 동안에는 눈에 띄는 이점이 없음을 발견했습니다. 따라서 이 기능을 비활성화했습니다.

### 후처리 심도 효과

우리는 흔히 사용되는 후처리 효과인 FXAA와의 통합을 논의한 바 있습니다. 또 다른 후처리 효과인 심도 효과(DoF)와 모션 블러의 결합에 대해 조사했습니다. 우리는 ShaderX5의 Gilham의 후처리 DoF 접근 방식을 구현하고, 이와 우리의 모션 블러 필터의 상호작용을 테스트했습니다. 실험 결과, 모션 블러 후에 DoF를 적용하는 것이 모션이 복잡한 장면에서 더 적은 가시적 에지를 생성하고, 초점이 맞는 영역의 특징을 더 선명하게 유지하는 것으로 나타났습니다.

### 성능 결과

우리는 여러 복잡한 장면에서 우리의 기법이 제공하는 시각적 향상을 자세히 설명하고, 고해상도 결과를 통해 세밀한 디테일을 확인할 수 있도록 합니다. 우리의 접근 방식은 복잡한 상호 객체 모션과 세밀한 디테일을 처리할 수 있으며, 기존 기법 대비 명확한 품질 향상을 제공하면서도 성능 비용이 거의 없습니다.

## 6 Limitations and Future Work

### 6.1 노이즈

우리 기법에서 가장 두드러진 아티팩트는 노이즈입니다. 대부분의 경우, 우리는 밴딩 대신 노이즈를 선택했습니다. 이 문제를 해결할 수 있는 몇 가지 잠재적인 해결책을 다음과 같이 제안합니다.

![심도 효과와 모션 블러 스트레스 테스트. 상단: 모션 블러만 적용. 하단: 모션 블러와 심도 효과 순서 비교. 우리는 심도 효과를 모션 블러 후에 적용할 때 약간 더 나은 결과를 얻었습니다.](A%20Fast%20and%20Stable%20Feature-Aware%20Motion%20Blur%20Filter%20d3312e98fcc343bcb40e04aa8d54928f/Untitled%2013.png)

심도 효과와 모션 블러 스트레스 테스트. 상단: 모션 블러만 적용. 하단: 모션 블러와 심도 효과 순서 비교. 우리는 심도 효과를 모션 블러 후에 적용할 때 약간 더 나은 결과를 얻었습니다.

- **단일 속도 폴백**: 단일 일관된 속도가 지배적인 이미지에서, 우리의 접근 방식은 동일한 이미지 품질을 위해 이전 작업보다 약 두 배의 샘플을 사용합니다. 타일 분산 실험을 재활용하여 장면의 속도 분산이 낮을 때 단일 방향으로만 샘플링하는 방법을 동적으로 조정할 수 있습니다.
- **적응형 샘플링 비율**: 타일이나 픽셀의 속도 크기에 따라 축적 샘플 수를 조정하여, 작은 모션일 때는 샘플링 수를 줄이고 큰 모션일 때는 오버샘플링할 수 있습니다. 이를 통해 이미지 전반에 걸쳐 균일한 노이즈를 유지할 수 있습니다.
- **필터링**: 포스트 프로세스 FXAA 필터링을 간략히 조사했지만, 모션 블러를 위해 설계된 포스트 프로세스 AA 필터는 샘플링 비율을 줄이는 데 도움이 될 수 있습니다.

### 6.2 기타 제한 사항

![회전 스트레스 테스트: 여러 겹치는 회전 속도는 도전적인 시나리오입니다.](A%20Fast%20and%20Stable%20Feature-Aware%20Motion%20Blur%20Filter%20d3312e98fcc343bcb40e04aa8d54928f/Untitled%2014.png)

회전 스트레스 테스트: 여러 겹치는 회전 속도는 도전적인 시나리오입니다.

- **가속 및 감속**: 매우 높은 카메라 노출 시간 동안, 가속 중인 객체가 초기 위치를 넘어 블러링되는 시각적 아티팩트가 발생할 수 있습니다.
- **속도 보간**: 모션 전환 중 속도를 보간하여 전환을 부드럽게 하지만, 느린 전환의 경우 블러가 모션과 관련 없는 방향에서 시작되어 시각적으로 혼란을 줄 수 있습니다.
- **비선형 모션**: 이전 작업과 마찬가지로 우리는 선형 모션을 가정합니다. 이 가정은 극단적인 회전 모션이나 복잡한 변형에서 문제가 될 수 있습니다.

### 6.3 미래 연구 방향

- **시간 구성 요소**: 우리의 알고리즘은 프레임 간 안정적이지만, 시간 차원을 명시적으로 처리하지 않습니다. 이전 프레임 데이터를 사용하여 현재 프레임의 노이즈를 줄이는 등 여러 장점이 있을 수 있지만, 예측할 수 없는 모션 경로를 따르는 고급 애니메이션에서는 복잡한 문제가 발생할 수 있습니다.
- **그림자**: 화면 공간 후처리로서, 우리의 알고리즘은 장면의 그림자 기술과 그 상호작용에 대해 인식하지 않습니다. 모션 블러와 그림자의 상호작용을 적절히 통합하는 것은 흥미로운 연구 문제입니다.
- **동시 심도 효과**: 모션 블러와 심도 효과를 단일 알고리즘으로 결합하는 것은 새로운 아이디어가 아니며, 이를 탐구한 연구도 있습니다. 우리는 모션 블러와 심도 효과의 상호작용을 간략히 조사했지만, 두 효과를 결합하는 단일 알고리즘을 시도하지는 않았습니다.

우리의 접근 방식은 복잡한 상호 객체 모션과 세밀한 디테일을 처리할 수 있는 고성능 후처리 모션 블러 필터를 제시하며, 이는 통합이 쉽고 다른 후처리 효과와도 호환 가능합니다.

## 7 Conclusion

우리는 복잡한 상호 객체 모션과 세밀한 디테일을 처리할 수 있는 고성능 후처리 모션 블러 필터를 제안했습니다. 우리의 접근 방식은 다음과 같은 특징을 가지고 있습니다:

- **복잡한 모션 처리**: 다양한 속도로 움직이는 여러 객체가 있는 복잡한 장면에서도 안정적이고 일관된 모션 블러를 제공합니다.
- **높은 성능**: 단순한 구현과 높은 캐시 일관성을 유지하면서도 약 3ms의 성능 비용으로 고품질의 모션 블러를 생성합니다.
- **현상학적 모델링**: 모션 블러의 지각적 단서를 현상학적으로 모델링하여, 기존의 단일 속도 접근 방식에서 발생하는 여러 아티팩트를 해결합니다.
- **유연한 통합**: 우리의 기법은 표준 래스터라이제이션과 단일 시간 인스턴스에서 캡처된 g-버퍼를 사용하여 다른 후처리 효과와 쉽게 통합할 수 있습니다.

우리는 다양한 복잡한 장면에서 우리의 접근 방식이 제공하는 시각적 향상을 입증했으며, 이는 인터랙티브 애니메이션에서도 높은 품질을 유지합니다. 이러한 결과는 우리의 기법이 게임 엔진 및 다양한 실시간 그래픽 애플리케이션에서 널리 사용될 수 있음을 시사합니다.

![우리의 결과는 이전 접근 방식에서 아티팩트가 발생하는 복잡한 장면에서도 시간적으로 안정적입니다.](A%20Fast%20and%20Stable%20Feature-Aware%20Motion%20Blur%20Filter%20d3312e98fcc343bcb40e04aa8d54928f/Untitled%2015.png)

우리의 결과는 이전 접근 방식에서 아티팩트가 발생하는 복잡한 장면에서도 시간적으로 안정적입니다.

- 수도코드 유니티 셰이더로 변환해서 정리
    
    ### 타일 기반 샘플링의 원리
    
    1. **화면 분할**: 화면을 여러 개의 작은 타일로 나눕니다. 각 타일은 일정 크기의 픽셀 집합입니다.
    2. **속도 벡터 선택**: 각 타일에서 가장 중요한 속도 벡터를 선택합니다. 이 벡터는 타일 내의 가장 빠른 속도나 타일에서 가장 중요한 객체의 속도를 나타냅니다.
    3. **샘플링**: 선택된 속도 벡터를 사용하여 타일 내의 모든 픽셀에 대해 블러를 적용합니다. 이 때, 블러링은 선택된 속도 벡터를 기반으로 수행됩니다.
    
    ### 타일 기반 샘플링의 장점
    
    1. **효율성**: 타일 단위로 속도 벡터를 선택하여 계산 양을 줄입니다.
    2. **현실감**: 큰 속도 차이가 있는 장면에서도 부드럽고 자연스러운 모션 블러를 제공합니다.
    3. **세부 조정**: 각 타일에서 속도 벡터를 선택하여 블러 효과를 조정할 수 있습니다.
    
    ### 타일 기반 샘플링의 예제
    
    다음은 유니티에서 타일 기반 샘플링을 사용하는 모션 블러 셰이더의 예제입니다.
    
    ```glsl
    Shader "Custom/MotionBlurFilter"
    {
        Properties
        {
            _MainTex ("Texture", 2D) = "white" {}
            _NeighborMax ("NeighborMax", 2D) = "white" {}
            _VelocityTex ("Velocity", 2D) = "white" {}
            _DepthTex ("Depth", 2D) = "white" {}
            _HaltonOffset ("Halton Offset", Float) = 1.0
            _Samples ("Samples", Int) = 35
            _Kappa ("Kappa", Float) = 40.0
            _Gamma ("Gamma", Float) = 1.5
            _Eta ("Eta", Float) = 0.95
            _Phi ("Phi", Float) = 27.0
        }
        SubShader
        {
            Tags { "RenderType"="Opaque" }
            Pass
            {
                CGPROGRAM
                #pragma vertex vert
                #pragma fragment frag
                #include "UnityCG.cginc"
    
                sampler2D _MainTex;
                sampler2D _NeighborMax;
                sampler2D _VelocityTex;
                sampler2D _DepthTex;
                float _HaltonOffset;
                int _Samples;
                float _Kappa;
                float _Gamma;
                float _Eta;
                float _Phi;
    
                struct appdata
                {
                    float4 vertex : POSITION;
                    float2 uv : TEXCOORD0;
                };
    
                struct v2f
                {
                    float2 uv : TEXCOORD0;
                    float4 vertex : SV_POSITION;
                };
    
                float2 HaltonSeq(int index)
                {
                    float result = 0.0;
                    float f = 1.0;
                    while (index > 0)
                    {
                        f /= 2.0;
                        result = result + f * (index % 2);
                        index = index / 2;
                    }
                    return result * 2.0 - 1.0;
                }
    
                v2f vert(appdata v)
                {
                    v2f o;
                    o.vertex = UnityObjectToClipPos(v.vertex);
                    o.uv = v.uv;
                    return o;
                }
    
                float zCompare(float z1, float z2)
                {
                    return min(max(0.0, 1.0 - (z1 - z2) / min(z1, z2)), 1.0);
                }
    
                float3 norm(float3 v)
                {
                    return normalize(v);
                }
    
                float cone(float t, float k)
                {
                    return max(0.0, 1.0 - abs(t) * k);
                }
    
                float cylinder(float t, float k)
                {
                    return max(0.0, 1.0 - abs(t) / k);
                }
    
                float2 rnmix(float2 v1, float2 v2, float a)
                {
                    return lerp(v1, v2, a);
                }
    
                half4 frag(v2f i) : SV_Target
                {
                    float2 p = i.uv * _ScreenParams.xy;
                    float2 j = HaltonSeq(int(p.x + p.y)) * _HaltonOffset;
                    float2 vmax = tex2D(_NeighborMax, p / _ScreenParams.xy + j).rg;
    
                    if (length(vmax) <= 0.5)
                    {
                        return tex2D(_MainTex, i.uv);
                    }
    
                    float2 wn = norm(vmax);
                    float2 vc = tex2D(_VelocityTex, i.uv).rg;
                    float2 wp = float2(-wn.y, wn.x);
    
                    if (dot(wp, vc) < 0) wp = -wp;
    
                    float2 wc = rnmix(wp, norm(vc), (length(vc) - 0.5) / _Gamma);
    
                    float totalWeight = _Samples / (_Kappa * length(vc));
                    float4 result = tex2D(_MainTex, i.uv) * totalWeight;
    
                    float j0 = j * _Eta * _Phi / _Samples;
    
                    for (int idx = 0; idx < _Samples; idx++)
                    {
                        float t = lerp(-1.0, 1.0, (idx + j0 + 1) / (_Samples + 1));
                        float2 d = (idx % 2 == 0) ? vc : vmax;
                        float2 T = t * length(vmax);
                        float2 S = T * d + p;
    
                        float2 uvS = S / _ScreenParams.xy;
                        float2 vs = tex2D(_VelocityTex, uvS).rg;
                        float4 colorSample = tex2D(_MainTex, uvS);
                        float Zp = tex2D(_DepthTex, i.uv).r;
                        float Zs = tex2D(_DepthTex, uvS).r;
    
                        float f = zCompare(Zp, Zs);
                        float b = zCompare(Zs, Zp);
    
                        float weight = 0.0;
                        float wA = dot(wc, d);
                        float wB = dot(norm(vs), d);
    
                        weight += f * cone(T, 1 / length(vs)) * wB;
                        weight += b * cone(T, 1 / length(vc)) * wA;
                        weight += cylinder(T, min(length(vs), length(vc))) * max(wA, wB) * 2;
    
                        totalWeight += weight;
                        result += colorSample * weight;
                    }
    
                    return result / totalWeight;
                }
                ENDCG
            }
        }
        FallBack "Diffuse"
    }
    ```
    

이 코드는 모션 블러 필터를 유니티 셰이더로 구현한 것으로, 타일 경계 불연속성, 유의미한 모션 벡터, 얇은 특징 보존, 이웃 블러링을 포함한 주요 요소들을 처리합니다. 각 부분을 다음과 같이 정리할 수 있습니다.

### 1. 타일 경계의 불연속성

타일 경계에서 발생하는 불연속성을 줄이기 위해 `vmax(t)` 샘플을 타일 경계 근처에서 더 높은 확률로 지터링합니다. 이를 통해 타일 경계에서 발생하는 밴딩을 노이즈로 대체하여 불연속성을 줄입니다.

```csharp
float2 j = HaltonSeq(int(p.x + p.y)) * _HaltonOffset;
float2 vmax = tex2D(_NeighborMax, p / _ScreenParams.xy + j).rg;
```

### 2. 내부 픽셀들의 대표 벡터 외의 유의미한 모션 벡터

단일 지배적 속도(`vmax`) 외에도 각 픽셀의 속도(`vc`)와 이 속도와 수직인 벡터(`wp`)를 고려하여 샘플링합니다. 이를 통해 복잡한 모션 시나리오에서도 더 정확한 블러를 생성합니다.

```csharp
float2 wn = norm(vmax);
float2 vc = tex2D(_VelocityTex, i.uv).rg;
float2 wp = float2(-wn.y, wn.x);

if (dot(wp, vc) < 0) wp = -wp;

float2 wc = rnmix(wp, norm(vc), (length(vc) - 0.5) / _Gamma);
```

### 3. 얇은 특징 보존

얇은 객체의 경우 중심 샘플을 무시하지 않고, 다른 샘플과 동일하게 처리하여 상대적인 깊이와 속도 변화를 고려합니다. 이를 통해 얇은 객체가 사라지거나 고스트 현상이 발생하는 것을 방지합니다.

```csharp
float4 result = tex2D(_MainTex, i.uv) * totalWeight;

// 나머지 샘플링 루프
for (int idx = 0; idx < _Samples; idx++)
{
    // 코드 생략
    result += colorSample * weight;
}
```

### 4. 이웃 블러링

이웃 타일의 속도를 계산할 때, 중심 타일에 영향을 미치는 경우에만 대각선 이웃 타일의 속도를 고려합니다. 이를 통해 불필요한 블러 아티팩트를 줄입니다.

```csharp
// vmax 계산 시 이웃 타일 고려
float2 vmax = tex2D(_NeighborMax, p / _ScreenParams.xy + j).rg;
```

### 전체 코드 맥락에서 각 부분

### 타일 경계의 불연속성 및 이웃 블러링

이 부분에서는 타일 경계 근처에서 vmax를 지터링하여 불연속성을 줄이고, 중심 타일에 영향을 미치는 경우에만 대각선 이웃 타일을 고려합니다.

```csharp
float2 j = HaltonSeq(int(p.x + p.y)) * _HaltonOffset;
float2 vmax = tex2D(_NeighborMax, p / _ScreenParams.xy + j).rg;
```

### 내부 픽셀들의 대표 벡터 외의 유의미한 모션 벡터

이 부분에서는 단일 속도 외에도 픽셀의 속도와 수직 벡터를 사용하여 샘플링합니다.

```csharp
float2 wn = norm(vmax);
float2 vc = tex2D(_VelocityTex, i.uv).rg;
float2 wp = float2(-wn.y, wn.x);

if (dot(wp, vc) < 0) wp = -wp;

float2 wc = rnmix(wp, norm(vc), (length(vc) - 0.5) / _Gamma);
```

### 얇은 특징 보존

이 부분에서는 중심 샘플을 다른 샘플과 동일하게 처리하여 얇은 특징을 보존합니다.

```csharp
float4 result = tex2D(_MainTex, i.uv) * totalWeight;
```

전체적으로 이 셰이더는 주어진 수도코드를 바탕으로 복잡한 모션 시나리오에서도 안정적이고 정확한 모션 블러를 생성하기 위한 여러 기술들을 구현합니다.