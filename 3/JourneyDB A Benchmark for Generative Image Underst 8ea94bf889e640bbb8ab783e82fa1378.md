# JourneyDB: A Benchmark for Generative Image Understanding

[https://arxiv.org/abs/2307.00716](https://arxiv.org/abs/2307.00716)

### 1 Introduction

인공 지능 생성 콘텐츠(AIGC)는 특히 확산 모델에서 상당한 발전을 이루었습니다. 이러한 발전으로 인해 사용자가 콘텐츠와 스타일을 모두 설명하는 상세한 텍스트 프롬프트에서 고품질 이미지를 생성할 수 있는 DALLE, Stability AI, Runway 및 Midjourney와 같은 AIGC 플랫폼의 인기가 높아졌습니다. 이러한 프롬프트와 결과 이미지는 시각적 이해 벤치마크에 큰 도움이 될 수 있습니다.

하지만 시각적 이해 작업을 잘 수행하는 대부분의 기존 기반 모델은 실제 데이터에 대해 학습되어 생성 콘텐츠에 대한 성능이 제한될 수 있습니다. 이 문제를 해결하기 위해 연구진은 4백만 개의 이미지와 관련 텍스트 프롬프트로 구성된 데이터 세트를 수집하여 생성 콘텐츠에 대한 모델의 이해도를 평가했습니다.

평가는 네 가지 작업으로 구성됩니다:

- 프롬프트 반전: 이미지가 주어지면 그 이미지를 생성한 텍스트 프롬프트를 파악합니다.
- 스타일 검색: 문체 요소를 기반으로 유사한 이미지를 식별하고 불러옵니다.
- 이미지 캡션: 생성된 이미지의 내용을 정확하게 설명하는 캡션을 작성합니다.
- 시각적 질문 답변(VQA): 생성된 이미지에 대한 질문에 정확하게 답변합니다.

연구진은 수집된 4,692,751개의 이미지-텍스트 쌍을 훈련, 검증, 테스트 세트로 나누었습니다. 테스트 세트의 정확성을 보장하기 위해 사람의 검증을 통해 잘못 정렬된 설명을 수정했습니다. 작업 2, 3, 4의 텍스트 프롬프트는 GPT-3.5를 사용하여 작업별 주석으로 변환되었습니다.

![데이터 수집 절차. 충분한 수의 생성된 이미지를 수집하기 위해, Discord의 Midjourney 채널을 조사하여 이용 가능한 이미지를 수집합니다. 그 후, GPT-3.5를 사용하여 다음과 같은 하위 작업들을 주석 처리합니다. 1) 프롬프트를 “스타일”과 “콘텐츠”로 분리, 2) 작업 1에서 얻은 콘텐츠 단어에 따른 캡션 생성, 3) “스타일 관련 질문”과 “콘텐츠 관련 질문” 생성, 각 질문에 대해 4개의 옵션 제공 및 답변 함께 제공. 자세한 내용은 3절을 참조하십시오.](JourneyDB%20A%20Benchmark%20for%20Generative%20Image%20Underst%208ea94bf889e640bbb8ab783e82fa1378/Untitled.png)

데이터 수집 절차. 충분한 수의 생성된 이미지를 수집하기 위해, Discord의 Midjourney 채널을 조사하여 이용 가능한 이미지를 수집합니다. 그 후, GPT-3.5를 사용하여 다음과 같은 하위 작업들을 주석 처리합니다. 1) 프롬프트를 “스타일”과 “콘텐츠”로 분리, 2) 작업 1에서 얻은 콘텐츠 단어에 따른 캡션 생성, 3) “스타일 관련 질문”과 “콘텐츠 관련 질문” 생성, 각 질문에 대해 4개의 옵션 제공 및 답변 함께 제공. 자세한 내용은 3절을 참조하십시오.

연구진은 새로운 데이터 세트에서 최신 멀티모달 모델을 테스트한 결과, 이러한 모델이 실제 데이터 세트에 비해 생성 콘텐츠에 대해 덜 효과적으로 작동한다는 사실을 발견했습니다. 하지만 새로운 데이터 세트에 대한 미세 조정을 통해 성능이 향상되었습니다.

요약하면, 이 연구는 생성된 이미지의 시각적 이해에 대한 새로운 관점을 제시하고, 훈련 및 평가를 위한 대규모 벤치마크(JourneyDB)를 제안하며, 생성 콘텐츠에 대한 현재 모델의 성능 한계를 조명합니다. 이 연구는 제너레이티브 콘텐츠 이해 분야의 발전을 촉진하는 것을 목표로 합니다.

## 2 Related Works

2.1 텍스트-이미지 생성 모델 및 데이터 세트

텍스트 설명을 기반으로 이미지를 생성하는 텍스트-이미지 생성 모델은 크게 발전해 왔습니다. 만시모프(Mansimov) 등이 딥 리커런트 어텐션 라이터(DRAW)가 텍스트에 따라 이미지를 생성할 수 있다는 것을 보여주면서 발전이 시작되었습니다. 이후 자동 회귀 모델, GAN, 확산 모델과 같은 다양한 생성 아키텍처가 텍스트-이미지 생성에 사용되었습니다. 이 중 확산 모델은 계산 효율성과 생성되는 이미지의 품질이 뛰어납니다. 주목할 만한 사례로는 확산 모델을 사용하여 텍스트-이미지 생성 서비스를 제공하는 Midjourney가 있습니다. 이러한 발전은 고속으로 생성된 풍부한 인공 이미지를 제공함으로써 지각 연구에 새로운 길을 열었습니다. 연구진은 데이터 세트를 통해 이러한 발전을 정리하고 이 분야의 추가 연구를 위한 발판을 마련하는 것을 목표로 합니다.

2.2 멀티모달 파운데이션 모델 및 데이터 세트

다중 모드 기반 모델은 이미지, 텍스트, 오디오 등 여러 소스의 데이터를 이해하고 연결할 수 있습니다. CLIP 및 ALIGN과 같은 선구적인 비전 언어 모델은 웹에서 수집된 수백만 개의 이미지-텍스트 쌍에 대해 사전 학습되었으며, 유망한 시각적 제로 샷 기능을 보여주었습니다. Flamingo 및 BLIP-2와 같은 모델은 한 걸음 더 나아가 사전 학습된 비전 백본을 언어 모델과 정렬하여 비전 언어 작업에서 뛰어난 성능을 발휘했습니다. 다양한 모달리티를 위한 통합 훈련 아키텍처도 도입되어 단일 모달 방식과 경쟁할 수 있는 성능을 보여주었습니다.

최근에는 강력한 GPT-4에서 영감을 받아 LLaMA-Adapter, LLaVA, MiniGPT-4와 같은 다중 모달 인스트럭션 팔로잉 모델이 개발되었습니다. 이러한 모델은 이미지 조건이 포함된 텍스트 프롬프트를 사용하여 고정된 LLaMA를 미세 조정하고 다중 모달리티 명령에 응답합니다. 그러나 생성된 시각 언어 데이터에 대한 이러한 모델의 일반화 능력은 실제 세계의 사전 학습 데이터와 생성 콘텐츠의 차이를 고려할 때 잘 밝혀지지 않았습니다.

이 문제를 해결하기 위해 연구진은 대규모 합성 데이터 세트인 JourneyDB와 맞춤형 벤치마크를 제안하여 생성 콘텐츠 처리에서 현재 멀티 모달 모델의 효율성을 철저하게 검증합니다.

### 3 Dataset

3.1 데이터 수집

그림 2에 표시된 것처럼 데이터 수집 절차는 주로 Discord의 미드저니 채널에서 생성된 이미지를 수집하는 것입니다. 널리 사용되는 Discord 스크롤러인 DiscordDownloader는 공개적으로 사용 가능한 이미지와 해당 프롬프트를 다운로드하는 데 사용됩니다. 이 버전은 텍스트 프롬프트에서 순수하게 생성된 이미지만 유지하며, 주어진 이미지에 조건이 지정된 이미지는 제외됩니다. 프롬프트의 일반화를 개선하고 기존 대규모 언어 모델에서 프롬프트를 더 잘 이해할 수 있도록 중간 여정별 인수도 정리됩니다.

3.2 데이터 주석

다양한 시각적 이해 작업을 위해 주석이 제공됩니다. 기존 방식에 비해 이 데이터 세트는 4가지 다운스트림 작업을 지원하므로 활용도가 매우 높습니다. 이러한 작업에 주석을 달기 위해 GPT-3.5가 사용됩니다. 중간 여정 프롬프트와 구체적인 지침이 제공됩니다:

![스타일 프롬프트의 분포와 샘플](JourneyDB%20A%20Benchmark%20for%20Generative%20Image%20Underst%208ea94bf889e640bbb8ab783e82fa1378/Untitled%201.png)

스타일 프롬프트의 분포와 샘플

프롬프트를 '스타일', '콘텐츠', '분위기', '기타'로 분류합니다,
과제 1의 콘텐츠 단어를 기반으로 캡션을 생성합니다,
"스타일 관련 질문"과 "콘텐츠 관련 질문"을 만들고 각 질문에 대한 네 가지 옵션을 답변과 함께 제공합니다.
복잡한 스타일 관련 프롬프트를 관리하기 위해 스타일 클러스터링이라는 기술이 사용됩니다. 스타일은 계층 구조로 구성되어 있어 스타일을 쉽게 검색할 수 있고 사용자가 참조할 때 유용합니다. GPT-3.5는 이를 용이하게 하는 데에도 사용됩니다. 프롬프트는 각각 200개의 프롬프트를 포함하는 작은 패치로 나뉘며, GPT-3.5는 단어를 클러스터링하도록 요청받습니다. 서로 다른 패치의 카테고리는 수동으로 병합되어 최종 "스타일 트리"를 형성합니다.

테스트 세트의 품질을 보장하기 위해 텍스트-이미지 생성 모델의 제한으로 인한 프롬프트와 이미지 간의 불일치가 필터링됩니다. "표시되지 않음"으로 주석이 달린 단어는 제거하여 깨끗한 프롬프트를 얻습니다.

3.3 데이터 통계

현재 버전에는 총 4,692,751개의 이미지가 수집되었으며, 각 이미지의 해상도는 1024x1024 이상이고 해당 텍스트 프롬프트가 있습니다. 고유 프롬프트는 1,730,639개, GPT-3.5로 주석이 달린 것은 1,472,581개입니다. 또한 5,402개의 이미지가 이미지 프롬프트 일관성에 따라 필터링되었습니다.

클러스터링 기법을 사용하여 70,521개의 세분화된 스타일을 334개의 스타일 카테고리로 분류하여 롱테일 분포를 생성했습니다.

전체 데이터 세트는 20:1의 비율로 훈련 세트와 검증 세트로 나뉩니다. 훈련 세트에는 4,189,737개의 이미지와 1,385,317개의 프롬프트가 포함되어 있습니다. 검증 세트에는 234,156개의 이미지와 82,093개의 프롬프트가 있습니다. 수동 필터링을 위해 5,402개의 이미지와 5,171개의 프롬프트로 구성된 테스트 세트도 별도로 샘플링되었습니다.

### 4 Benchmarks

4.1 프롬프트 반전

생성된 이미지의 콘텐츠와 스타일에 영향을 주는 프롬프트에는 이미지에 대한 필수 정보가 들어 있습니다. 이를 통해 사용자는 이미지 생성에 사용된 가이드라인을 파악할 수 있으며, 이를 통해 콘텐츠 편집이나 유사한 스타일 생성 등의 추가 개발이 가능합니다. 그러나 기존 모델은 종종 시점, 조명 또는 아트 스타일과 같은 필수적인 세부 사항을 간과하기 때문에 이미지의 프롬프트를 예측하는 것은 어려운 작업입니다.

이미지에서 해당 프롬프트를 예측하는 프롬프트 반전은 이러한 격차를 해소하는 것을 목표로 합니다. 프롬프트 반전의 효과를 평가하기 위해 이미지 캡션에 일반적으로 사용되는 지표인 블루, 기상, 루즈, CIDEr가 확장되었습니다. 문장 변환기 기능의 코사인 유사도 계산과 같은 다른 기법도 사용됩니다. 또한 평가를 위해 질문 답변 점수(QAS)가 제안되었습니다.

제로 샷 프롬프트 반전 과제에 대한 벤치마크를 설정하기 위해 BLIP-2 OPT2.7B, BLIP-2 FlanT5XL, Flamingo9B, MiniGPT-4, Uni-Perceiver v2 등 최첨단 멀티모달 모델이 활용되었습니다. 그러나 기존 모델은 복잡한 디테일과 스타일 관련 정보를 캡처하는 데 어려움을 겪어 기존 데이터 세트에 비해 성능이 떨어지는 경우가 많았습니다.

유니티의 데이터셋을 사용하여 20회에 걸쳐 Uni-Perceiver v2를 미세 조정한 결과, 프롬프트 반전 작업에서 상당한 개선이 이루어졌음을 확인할 수 있었습니다. 그러나 강력하고 효과적인 프롬프트 반전 모델을 추가로 개발할 여지가 여전히 남아있음은 분명합니다.

4.2 이미지 캡션

이미지 캡션은 이미지의 시각적 콘텐츠에 대한 텍스트 설명을 생성하는 작업을 포함합니다. 코코 캡션과 같은 기존 벤치마크와 비교했을 때, JourneyDB는 이미지에 대한 상세한 설명과 높은 수준의 요약을 포함하므로 모델의 세분화된 인식 능력과 전체적인 이해 능력을 평가할 수 있습니다.

![JourneyDB 캡셔닝의 검증 세트 샘플. 예시는 기존 멀티모달 모델이 AI에서 생성된 이미지의 일부 핵심 개념을 인식하지 못하는 것을 보여줍니다.](JourneyDB%20A%20Benchmark%20for%20Generative%20Image%20Underst%208ea94bf889e640bbb8ab783e82fa1378/Untitled%202.png)

JourneyDB 캡셔닝의 검증 세트 샘플. 예시는 기존 멀티모달 모델이 AI에서 생성된 이미지의 일부 핵심 개념을 인식하지 못하는 것을 보여줍니다.

기존 멀티모달 모델은 JourneyDB의 이미지 캡션 하위 과제에서 평가되었습니다. 그 결과, 자연 이미지로 학습된 모델로는 AI가 생성한 콘텐츠에 대해 좋은 설명을 제공하는 것이 어렵다는 것을 알 수 있었습니다. 이러한 낮은 정량적 성능은 GPT-3.5가 생성한 실사 캡션이 길고 예측 캡션이 짧으며, AI 생성 이미지와 자연 이미지를 설명할 때 중점을 두는 개념의 차이에 기인한 것으로 볼 수 있습니다.

정성적인 측면에서 기존의 멀티모달 접근 방식은 AI 생성 콘텐츠의 일부 핵심 개념을 설명하지 못하거나 이미지에 존재하지 않는 내용을 환각으로 표현하는 경우도 있었습니다. 따라서 이러한 영역에 대한 추가적인 개발과 개선이 필요합니다.

4.3 스타일 검색

예술의 세계에서 이미지에 묘사된 스타일은 날씨, 분위기, 분위기 등 여러 요소의 영향을 받아 복잡한 '스타일 시스템'으로 이어질 수 있습니다. 이미지의 스타일 관련 특징을 설명하기 위해 150,000개 이상의 스타일 단어가 수집되었습니다. 이렇게 방대한 스타일 공간을 고려할 때 주어진 이미지의 스타일을 인식하는 것은 상당히 어려운 작업입니다.

![BLIP-2 [4]의 다중 선택 시각적 질문 응답 실패 사례. 상단 행은 스타일 관련 질문을, 하단 행은 콘텐츠 관련 질문을 보여줍니다.](JourneyDB%20A%20Benchmark%20for%20Generative%20Image%20Underst%208ea94bf889e640bbb8ab783e82fa1378/Untitled%203.png)

BLIP-2 [4]의 다중 선택 시각적 질문 응답 실패 사례. 상단 행은 스타일 관련 질문을, 하단 행은 콘텐츠 관련 질문을 보여줍니다.

이 작업을 단순화하기 위해 카메라 매개변수, 조명, 아티스트 스타일, 색 구성표와 같은 344개의 카테고리로 스타일 프롬프트를 클러스터링했습니다. 이렇게 하면 검색 공간이 크게 좁아져 스타일 검색이 덜 복잡하고 시간이 덜 소요됩니다. CLIP을 사용하면 이미지와 모든 스타일 프롬프트의 특징을 추출하고 이미지 특징과 모든 후보 스타일 프롬프트 간의 내적을 계산하여 제로 샷 스타일 검색 평가를 수행합니다. 그러나 그 결과 전체 스타일 프롬프트 공간에서 검색할 경우 회상률이 매우 낮고, 카테고리별 하위 공간에서 검색할 때 모델의 성능이 훨씬 우수한 것으로 나타났습니다.

4.4 시각적 질의응답(VQA)

JourneyDB의 이미지에는 문체 속성과 시각적 내용을 모두 설명하는 풍부하고 다양한 프롬프트가 포함되어 있습니다. 이러한 프롬프트를 사용하여 생성 데이터의 스타일과 내용에 대한 모델의 이해도를 평가하기 위해 객관식 시각적 질문 답변(MC-VQA)의 두 가지 작업을 구성합니다.

MC-VQA에서 모델은 이미지와 주어진 질문에 따라 네 가지 옵션 중에서 답을 선택합니다. 이는 언어가 다양한 방식으로 표현될 수 있기 때문에 모호성과 같은 직접 답변 평가에 내재된 많은 어려움을 우회합니다. 이 명확하고 객관적인 평가 방식은 다양한 스타일과 내용에 대한 광범위한 설명을 포함하는 벤치마크의 답변이 매우 다양하다는 점을 고려할 때 특히 유용합니다.

그러나 기존 멀티모달 모델의 성능은 콘텐츠 관련 및 스타일 관련 MC-VQA 모두에서 만족스럽지 못합니다. 생성 데이터는 현실에 존재하지 않는 장면과 구도를 묘사하는 경우가 많기 때문에 실제 이미지에 대해 사전 학습된 모델이 생성된 이미지의 시각적 구성 요소를 해석하기 어렵습니다. 또한 이러한 모델은 생성 데이터의 다양한 문체 변형에 노출되지 않기 때문에 스타일 관련 질문에 답할 때 일반적으로 성능이 떨어집니다.

요약하면, JourneyDB의 MC-VQA는 생성 데이터의 스타일과 콘텐츠를 이해하는 모델의 능력에 대한 종합적인 평가를 제공합니다. 그러나 실제 이미지에 대해 사전 학습된 기존의 멀티모달 모델은 다양한 스타일의 생성 데이터를 식별할 뿐만 아니라 가상의 장면과 새로운 객체 구성을 이해하는 데 어려움을 겪습니다.

### 5 Conclusion and Discussion

제너레이티브 모델의 급속한 발전으로 우리의 삶은 점점 더 제너레이티브 콘텐츠로 채워지고 있습니다. 이러한 콘텐츠를 이해하는 것은 앞으로의 삶에서 매우 중요합니다. 이러한 이해를 돕기 위해 크리테오는 제너레이티브 콘텐츠 이해의 개발을 촉진하기 위한 대규모 벤치마크인 JourneyDB를 제안합니다.

하지만 이 데이터 세트에도 한계가 있습니다. 한 가지 문제는 모든 이미지에 잠재적으로 불쾌하거나 폭력적인 콘텐츠가 있는지 확인되지 않았다는 것입니다. 이 문제를 해결하기 위해 데이터 세트를 공개하기 전에 NSFW 점수를 사용하여 부적절한 콘텐츠를 필터링할 계획입니다. 또한 사용자가 이러한 콘텐츠를 발견할 경우 신고해 주실 것을 권장합니다.

또 다른 한계는 생성된 이미지가 입력 프롬프트와 완벽하게 일치한다는 가정에서 발생합니다. 실제로는 이미지와 텍스트 사이에 약간의 정렬 불량이 있을 수 있으며, 이로 인해 데이터 세트에 노이즈가 발생할 수 있습니다. 이 문제는 추가적인 수동 정리 또는 다중 모달 모델을 사용한 필터링을 통해 완화할 수 있습니다.

이러한 한계에도 불구하고 JourneyDB는 제너레이티브 콘텐츠의 개발과 이해를 증진하는 데 유용한 리소스라고 생각합니다.

### Appendices

A 데이터 어노테이션의 세부 사항

이 섹션에서는 이미지 프롬프트 일관성 필터링, 다운스트림 시각적 이해 주석, 스타일 클러스터링 등 데이터 주석의 세부 사항에 대해 자세히 설명합니다.

A.1 이미지 프롬프트 일관성 필터링

깨끗한 테스트 세트를 구축하기 위해 40명의 전문 어노테이터로 구성된 팀에게 프롬프트에서 해당 이미지에 표시되지 않은 단어를 식별하도록 의뢰했습니다. '불일치'의 경우 두 가지 범주로 분류했습니다:

텍스트에 언급되어 있지만 이미지에 반영되지 않은 콘텐츠.
이미지와 텍스트가 일치하지 않는 콘텐츠.
표 7은 주석 문서에 사용된 예시를 제공합니다.

A.2 시각적 이해 주석

주어진 프롬프트에 따라 다운스트림 작업에 대한 답을 생성하기 위해 GPT-3.5를 사용했습니다. 이 접근 방식은 GPT-3.5의 출력을 "json" 패키지로 직접 로드할 수 있도록 보장합니다.

A.3 스타일 클러스터링

스타일 프롬프트를 다양한 카테고리로 클러스터링하기 위해 이 작업을 위해 설계된 특정 프롬프트와 함께 GPT-3.5를 다시 사용했습니다.

B 추가 실험

B.1 질문 답변 점수(QAS)

프롬프트와 캡션 간의 문법 구조의 차이를 감안하여 프롬프트 반전 과제를 평가하기 위한 질문 답변 점수(QAS)를 제안합니다. 이 작업에서 예측된 프롬프트는 대규모 언어 모델인 Vicuna[44]에 제공되며, 주석에 제공된 관련 질문에 대한 응답의 정확도를 계산합니다. 스타일 질문과 내용 질문에 대해 별도로 QAS를 계산하고 이 점수의 평균을 최종 QAS에 사용합니다. 표 8은 QAS 결과를 보여줍니다.

B.2 이미지 품질 분석

그림 6은 인간 선호도 점수(HPS)[45]로 정량화한 결과, JourneyDB의 이미지(출처: Midjourney 6)가 안정적 확산으로 생성된 이미지보다 시각적 품질이 더 높다는 것을 보여줍니다.