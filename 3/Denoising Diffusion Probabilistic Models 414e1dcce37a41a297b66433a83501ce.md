# Denoising Diffusion Probabilistic Models

*이 논문에서는 고품질 이미지 샘플을 생성할 수 있는 생성 모델의 일종인 확산 모델에 대한 연구를 소개합니다. 확산 모델은 마르코프 체인 학습을 위한 변형 추론, 노이즈 제거 점수 매칭, 어닐링 랑방 역학, 에너지 기반 모델, 자동 회귀 모델, 점진적 손실 압축과 같은 다른 생성 모델 기법과의 연관성을 탐구합니다.*

*연구진은 확산 모델이 이미지 데이터에 대한 귀납적 편향이 우수하여 이미지의 기본 구조와 특징을 효과적으로 포착할 수 있음을 입증했습니다. 따라서 확산 모델은 데이터 압축, 표현 학습, 예술, 사진, 음악 분야의 창의적 사용 등 다양한 애플리케이션에서 유용하게 사용될 수 있습니다.*

[https://arxiv.org/abs/2006.11239](https://arxiv.org/abs/2006.11239) (2020)

[https://arxiv.org/pdf/2006.11239.pdf](https://arxiv.org/pdf/2006.11239.pdf)

이 연구는 비평형 열역학의 원리에서 영감을 얻은 확산 확률 모델을 사용해 고품질 이미지를 합성하는 방법을 제시합니다. 노이즈 제거 점수 매칭 및 랑방 역학에 연결된 특별히 설계된 가중치 변동 바운드를 사용하여 최상의 결과를 얻을 수 있습니다. 이 모델에는 자동 회귀 디코딩을 일반화하는 고유한 손실 압축 해제 방법도 포함되어 있습니다. 이 모델은 CIFAR10 및 LSUN 데이터 세트에서 최고 성능을 달성하며 이미지 품질은 ProgressiveGAN과 비슷합니다. 코드는 GitHub에서 액세스할 수 있습니다.

1 Introduction

이 논문은 고품질 샘플을 생성할 수 있는 심층 생성 모델의 일종인 확산 확률론적 모델을 살펴봅니다. 이 모델은 변형 추론으로 훈련된 매개변수화된 마르코프 체인을 사용하여 데이터와 일치하는 샘플을 생성합니다. 이 모델은 정의가 간단하고 효율적으로 훈련할 수 있으며, 이 논문은 다른 생성 모델보다 더 우수한 샘플을 생성하는 능력을 보여줍니다.

![Untitled](Denoising%20Diffusion%20Probabilistic%20Models%20414e1dcce37a41a297b66433a83501ce/Untitled.png)

이 연구는 또한 훈련 중 확산 모델과 노이즈 제거 점수 매칭, 샘플링 중 어닐링된 랑그빈 역학 간의 동등성을 보여줍니다. 이러한 동등성은 이 논문의 핵심적인 기여로 간주됩니다. 이 모델은 다른 모델에 비해 로그 유사도가 가장 좋지는 않지만, 일부 대규모 추정치보다 더 나은 성능을 보입니다.

또한 이 논문은 확산 모델의 샘플링 절차를 자동 회귀 디코딩과 유사한 점진적 디코딩의 한 유형으로 분석합니다. 이를 통해 자동 회귀 모델에 대한 보다 일반화된 접근 방식이 가능하며 손실 압축에 대한 새로운 관점을 제공합니다.

2 Background

확산 모델은 학습된 가우시안 전이가 있는 마르코프 체인인 역방향 프로세스를 사용하여 샘플을 생성하는 잠재 변수 모델의 한 유형입니다. 포워드 프로세스 또는 확산 프로세스는 고정된 분산 일정에 따라 데이터에 가우시안 노이즈를 점진적으로 추가합니다. 훈련은 음의 로그 확률에 대한 변동 바운드를 최적화하여 수행됩니다.

포워드 프로세스 분산은 학습하거나 하이퍼파라미터로 일정하게 유지할 수 있습니다. 확률적 경사 하강으로 랜덤 조건을 최적화하고 KL 발산을 사용하여 역방향 프로세스를 포워드 프로세스 후방과 직접 비교함으로써 학습을 더욱 효율적으로 수행할 수 있습니다. 이를 통해 모든 KL 발산을 폐쇄형 식을 사용하여 계산할 수 있으므로 훈련 프로세스가 더욱 효율적이고 정확해집니다.

3 Diffusion models and denoising autoencoders

잠재 변수 모델의 일종인 확산 모델은 순방향 프로세스 분산과 역방향 프로세스 아키텍처를 선택할 수 있어 구현에 유연성을 제공합니다. 이 백서에서는 확산 모델과 노이즈 제거 점수 매칭을 연결하여 가중치가 부여된 단순화된 변동 바운드 목표를 설정합니다. 이 모델 설계는 단순성과 경험적 결과에 의해 정당화됩니다.

![Untitled](Denoising%20Diffusion%20Probabilistic%20Models%20414e1dcce37a41a297b66433a83501ce/Untitled%201.png)

포워드 프로세스 분산은 상수로 고정되어 근사 후방 q에 학습 가능한 매개변수가 없습니다. 역방향 프로세스는 포워드 프로세스 사후 평균을 예측하거나 매개변수화를 수정하여 함수 근사값을 예측하도록 학습됩니다. 선택한 매개변수화는 랑방 역학과 유사하며 노이즈 제거 점수 매칭과 유사한 목표에 대한 확산 모델의 변동 바운드를 단순화합니다.

이미지 데이터는 선형적으로 스케일링되며, 이산 디코더를 사용하여 변동 한계가 이산 데이터의 무손실 코드 길이가 되도록 합니다. 단순화된 훈련 목표가 사용되어 작은 노이즈 양에 대한 손실 조건의 가중치를 낮추고 더 어려운 노이즈 제거 작업에 집중하여 샘플 품질이 향상됩니다.

4 Experiments

이 연구에서 저자들은 이전 연구에서와 마찬가지로 샘플링 중에 필요한 신경망 평가 횟수와 일치하도록 선택한 값인 T=1000으로 실험을 설정했습니다. 그리고 역방향 프로세스를 위해 시간에 걸쳐 매개변수를 공유하는 U-Net 백본을 사용했습니다. 이 실험은 문헌에 나와 있는 대부분의 모델을 능가하는 고품질 샘플 결과를 달성했습니다.

연구 결과 확산 모델에는 유도 편향이 있어 우수한 손실 압축기라는 사실이 밝혀졌습니다. 점진적 손실 압축을 사용하여 모델의 속도 왜곡 동작을 분석한 결과, 대부분의 비트가 눈에 띄지 않는 왜곡에 할당된 것으로 나타났습니다.

![무조건 CIFAR10 프로그레시브 생성(시간이 지남에 따라 xˆ0, 왼쪽에서 오른쪽으로). 확장된 샘플 및 부록의 시간 경과에 따른 샘플 품질 지표](Denoising%20Diffusion%20Probabilistic%20Models%20414e1dcce37a41a297b66433a83501ce/Untitled%202.png)

무조건 CIFAR10 프로그레시브 생성(시간이 지남에 따라 xˆ0, 왼쪽에서 오른쪽으로). 확장된 샘플 및 부록의 시간 경과에 따른 샘플 품질 지표

![동일한 잠재력을 조건으로 하는 경우, CelebA-HQ 256 × 256 샘플은 상위 수준의 속성을 공유합니다. 오른쪽 아래 사분면은 xt이고 다른 사분면은 pθ(x0|xt)의 샘플입니다.](Denoising%20Diffusion%20Probabilistic%20Models%20414e1dcce37a41a297b66433a83501ce/Untitled%203.png)

동일한 잠재력을 조건으로 하는 경우, CelebA-HQ 256 × 256 샘플은 상위 수준의 속성을 공유합니다. 오른쪽 아래 사분면은 xt이고 다른 사분면은 pθ(x0|xt)의 샘플입니다.

또한 대규모 이미지 특징이 먼저 나타나고 디테일이 나중에 나타나는 프로그레시브 무조건 생성 프로세스도 구현되었습니다. 이 접근 방식은 개념적 압축의 가능성을 암시합니다.

마지막으로 저자는 가우시안 확산 모델을 일반화된 비트 순서를 가진 일종의 자동 회귀 모델로 볼 수 있음을 입증했습니다. 이 모델은 더 빠른 샘플링이나 더 큰 표현력을 위해 조정할 수 있습니다. 보간 또한 고품질의 재구성과 그럴듯한 보간이 관찰되어 보간도 탐구되었습니다.

5 Related Work

확산 모델은 흐름 및 VAE와 유사하지만 최상위 잠재 변수가 데이터와 상호 정보를 거의 갖지 않도록 설계되었습니다. 이 모델은 노이즈 제거 점수 매칭 및 샘플링을 위한 어닐링 랑게빈 동역학과 연결되어 있습니다. 이러한 모델을 사용하면 간단한 로그 유사도 평가가 가능하며 변형 추론을 사용하여 랑그빈 역학 샘플러를 훈련할 수 있습니다.

이 연구는 에너지 기반 모델과 속도 왜곡 곡선 계산은 물론 컨볼루션 DRAW와 같은 모델에 잠재적인 영향을 미칠 수 있습니다. 확산 모델에서의 점진적 디코딩 접근 방식은 자동 회귀 모델에서 샘플링 전략에 대한 보다 일반적인 설계로 이어질 수 있습니다.

6 Conclusion

연구진은 확산 모델을 사용하여 고품질 이미지 샘플을 제시하고 이러한 모델과 다양한 다른 생성 모델 기법 간의 연관성을 발견했습니다. 확산 모델은 이미지 데이터에 대한 귀납적 편향성이 뛰어나며 다른 데이터 양식과 머신 러닝 시스템에서 유용할 수 있습니다.

생성 모델은 정치적 목적으로 가짜 이미지와 동영상을 제작하는 등 악의적으로 사용될 수 있지만, 데이터 압축, 표현 학습, 예술, 사진, 음악 분야의 창의적인 응용 분야에도 유용할 수 있습니다. 다른 생성 모델과 마찬가지로 확산 모델의 영향은 사용 방법과 잠재적인 부정적인 결과를 완화하기 위한 노력에 따라 달라집니다.

- Markov chains
    
    마르코프 체인은 일련의 이벤트 또는 상태를 설명하는 데 사용되는 수학적 모델로, 각 이벤트의 확률은 그 바로 앞의 상태에만 의존합니다. 즉, 마르코프 체인은 특정 확률적 규칙에 따라 한 상태에서 다른 상태로 전환되는 시스템입니다. 마르코프 체인의 가장 큰 특징은 시스템이 현재 상태에 어떻게 도달했는지에 관계없이 가능한 미래 상태는 고정되어 있다는 것입니다.
    
    마르코프 체인은 노드가 상태를 나타내고 에지가 상태 간의 전환을 나타내는 방향성 그래프로 나타낼 수 있습니다. 한 상태에서 다른 상태로 이동할 확률을 전이 확률이라고 하며, 일반적으로 행렬로 표현됩니다.
    
    마르코프 체인은 물리학, 경제학, 생물학, 컴퓨터 과학 등 다양한 분야에서 널리 사용됩니다. 날씨 예측, 텍스트 및 음성 분석, 주가 모델링, 생물학적 과정 시뮬레이션 등이 대표적인 응용 분야입니다.
    
    다음은 numpy 라이브러리를 사용하는 Python의 간단한 마르코프 체인 예제입니다. 이 예는 맑음과 비의 두 가지 상태의 날씨 모델을 시뮬레이션합니다.
    
    ```
    pythonCopy code
    import numpy as np
    
    # Define the transition matrix
    transition_matrix = np.array([
        [0.8, 0.2],  # sunny to sunny, sunny to rainy
        [0.6, 0.4],  # rainy to sunny, rainy to rainy
    ])
    
    # Define the initial state probabilities
    initial_state = np.array([0.5, 0.5])
    
    # Number of steps to simulate
    num_steps = 10
    
    # Initialize the current state
    current_state = initial_state
    
    # Simulate the Markov chain
    for step in range(num_steps):
        print("Step", step + 1)
        print("Sunny probability:", current_state[0])
        print("Rainy probability:", current_state[1])
        print()
    
        # Update the current state by multiplying with the transition matrix
        current_state = current_state @ transition_matrix
    ```
    
    이 코드는 맑은 날씨와 비오는 날씨 사이의 전환 확률을 지정하는 전환 행렬이 있는 간단한 2상태 마르코프 체인을 정의합니다. 초기 상태 확률은 맑음과 비 모두에 대해 0.5로 설정되어 있으며, 이는 현재 날씨에 대한 사전 지식이 없음을 나타냅니다. 그런 다음 체인을 10단계로 시뮬레이션하고 각 단계마다 맑은 날씨와 비오는 날씨의 확률을 출력합니다.