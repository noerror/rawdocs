# StyleAvatar3D: Leveraging Image-Text Diffusion Models for High-Fidelity 3D Avatar Generation

[https://arxiv.org/abs/2305.19012](https://arxiv.org/abs/2305.19012)

[https://github.com/icoz69/StyleAvatar3D](https://github.com/icoz69/StyleAvatar3D)

![프레임워크에서 생성된 3D 스타일화된 아바타의 시각화. 아바타의 스타일은 텍스트 프롬프트 또는 예제 이미지를 사용하여 정의할 수 있습니다.](StyleAvatar3D%20Leveraging%20Image-Text%20Diffusion%20Mode%20c94b3777fbc44fa4ab10406068df3141/Untitled.png)

프레임워크에서 생성된 3D 스타일화된 아바타의 시각화. 아바타의 스타일은 텍스트 프롬프트 또는 예제 이미지를 사용하여 정의할 수 있습니다.

이 논문에서는 기존의 이미지-텍스트 확산 모델과 생성적 적대 신경망(GAN)을 사용하여 고품질의 스타일화된 3D 아바타를 만드는 새로운 방법을 소개합니다. 이 모델은 다양한 스타일과 뷰로 다양한 아바타를 만드는 데 사용됩니다.

먼저 이미지-텍스트 확산 모델의 광범위한 미적 및 기하학적 지식을 사용하여 다양한 관점에서 아바타의 이미지를 생성합니다. 기존 3D 모델에서 가져온 포즈를 사용하여 이미지 생성 프로세스를 안내합니다.

데이터의 포즈와 이미지 간의 정렬 불일치 문제를 해결하기 위해 각 시점에 대한 특정 프롬프트를 사용하고 거친 관점에서부터 세밀한 관점까지 작동하는 GAN 판별기를 개발합니다. 또한 아바타 속성과 관련된 프롬프트를 탐색하여 생성되는 아바타의 다양성을 높입니다.

또한 StyleGAN의 스타일 공간 내에 확산 모델을 생성하여 이미지 입력으로부터 아바타를 생성할 수 있도록 합니다.

이 논문은 이 새로운 접근 방식이 생성되는 아바타의 시각적 품질과 다양성 측면에서 기존 방식보다 뛰어나다고 주장합니다.

1 Introduction

최근에는 대규모 이미지-텍스트 쌍과 확산 모델과 같은 고급 모델을 사용할 수 있게 되면서 고품질 2D 이미지를 생성하는 제너레이티브 모델의 성능이 크게 향상되었습니다. 이를 통해 사용자는 텍스트 프롬프트와 함께 사실적인 이미지를 생성할 수 있습니다. 그러나 3D 생성 모델은 학습용 3D 모델의 다양성이 제한되어 있어 어려움을 겪고 있습니다.

이 문제를 해결하기 위해 저자는 사전 학습된 텍스트-이미지 확산 모델을 사용하여 3D 스타일라이즈드 아바타를 생성하는 새로운 방법을 제안합니다. 사용자는 텍스트 프롬프트를 사용하여 아바타 스타일과 얼굴 특징을 정의할 수 있습니다. 이 모델은 3D 데이터가 아닌 보정된 이미지를 훈련에 사용하는 GAN 기반 3D 생성 네트워크인 EG3D를 사용합니다. 이 접근 방식을 사용하면 향상된 이미지 데이터를 통해 3D 모델의 다양성과 충실도를 지속적으로 개선할 수 있습니다.

스테이블디퓨전을 기반으로 구축된 시스템인 컨트롤넷을 사용하여 사전 정의된 포즈에 따라 이미지를 생성합니다. 이러한 포즈는 기존 아바타 모델에서 재사용할 수 있습니다. 컨트롤넷은 종종 넓은 각도에서 뷰를 생성하는 데 어려움을 겪습니다. 이를 완화하기 위해 저자들은 이미지 생성 시 다양한 뷰에 대한 뷰별 프롬프트와 3D GAN을 훈련하기 위한 거칠고 미세한 판별자를 개발했습니다.

또한 이미지 입력으로 조건부 3D 생성이 가능하도록 StyleGAN의 잠복 스타일 공간에서 잠복 확산 모델을 개발했습니다. 이를 통해 프레임워크의 유연성을 높이고 사용자가 개인 취향에 따라 3D 모델을 생성할 수 있습니다.

저자들은 다양한 대규모 데이터 세트를 대상으로 실험을 수행했으며, 그 결과 시각적 품질과 다양성 측면에서 기존 방법을 능가하는 것으로 나타났습니다. 이 프레임워크는 사용자가 텍스트 프롬프트를 통해 스타일과 얼굴 속성을 정의할 수 있는 고충실도 3D 아바타를 생성하는 새로운 방법을 제시합니다. 이 프레임워크는 이미지 포즈 정렬 문제를 해결하고 부정확한 포즈 주석이 있는 이미지 데이터를 더 잘 활용할 수 있게 해줍니다.

2 Related Work

이 섹션에서는 2D 이미지에서 3D를 생성하는 분야와 텍스트-이미지 생성 모델의 최근 발전에 대해 설명합니다.

- 텍스트-이미지 생성 모델: 이 분야에서는 텍스트 프롬프트에 따라 이미지를 생성하는 StableDiffusion, Imagen, DALL-E 2와 같은 모델을 통해 상당한 발전이 이루어졌습니다. 특히 스테이블디퓨전은 오토인코더의 잠재 공간에서 확산 프로세스를 수행하여 추론 속도와 메모리 비용을 줄인다는 점에서 주목할 만합니다. 컨트롤넷은 추가적인 파라메트릭 모듈을 도입하여 스테이블디퓨전을 확장하여 출력 이미지 콘텐츠를 정확하게 제어할 수 있습니다. 또한 로우랭크 적응(LoRA)을 사용하여 StableDiffusion을 미세 조정할 수 있습니다.
- 사전 학습된 이미지 생성 모델에 기반한 3D 생성: 이미지 확산 모델의 성공을 3D로 옮기는 것은 상당한 양의 3D 데이터가 필요하기 때문에 어려운 작업입니다. 이를 해결하기 위해 파라메트릭 삼면 특징을 사용하여 3D 데이터를 표현하는 로댕(Rodin)과 같은 다양한 모델이 개발되었습니다. 드림퓨전, 매직3D, 드림부스3D와 같은 다른 모델도 3D 생성을 위한 이미지 생성 모델의 잠재력을 탐구했습니다.
- 3D GAN의 도메인 적응: 저자들의 작업은 StyleGAN에 기반한 지오메트리 인식 GAN인 EG3D와 밀접한 관련이 있습니다. EG3D의 제너레이터는 3개의 직교 2D 평면의 특징을 생성하고 볼륨 렌더링을 사용하여 3D 모델의 다양한 뷰를 생성합니다. 그러나 포즈 추정기는 종종 큰 각도의 얼굴을 감지하지 못해 불완전한 3D 모델이 생성됩니다. 이를 극복하기 위해 PoF3D는 포즈에 구애받지 않는 판별기를 개발했습니다. 3DAvatarGAN과 Song 등의 다른 연구에서도 훈련된 3D GAN의 도메인 적응을 탐구합니다.

전반적으로 저자들의 접근 방식은 보정된 데이터를 생성하고 이를 3D GAN을 훈련하는 데 효율적으로 사용하는 데 중점을 둡니다.

3 Method

이 섹션에서는 멀티뷰 이미지를 사용하여 양식화된 3D 아바타를 생성하는 프레임워크에 대해 자세히 설명합니다. 다음은 간단한 설명입니다:

![이미지 입력을 통한 무조건 생성 및 조건부 생성을 지원하는 네트워크의 전체 구조 생성을 지원하는 네트워크의 전체 구조입니다. 무조건 3D GAN의 훈련이 끝나면 조건부 아바타 생성을 위한 매핑 네트워크를 대체할 조건부 잠재 확산 모델을 훈련하여 조건부 아바타 생성을 위한 매핑 네트워크를 대체합니다.](StyleAvatar3D%20Leveraging%20Image-Text%20Diffusion%20Mode%20c94b3777fbc44fa4ab10406068df3141/Untitled%201.png)

이미지 입력을 통한 무조건 생성 및 조건부 생성을 지원하는 네트워크의 전체 구조 생성을 지원하는 네트워크의 전체 구조입니다. 무조건 3D GAN의 훈련이 끝나면 조건부 아바타 생성을 위한 매핑 네트워크를 대체할 조건부 잠재 확산 모델을 훈련하여 조건부 아바타 생성을 위한 매핑 네트워크를 대체합니다.

- 데이터 준비: 이 프레임워크는 컨트롤넷을 사용하여 텍스트 프롬프트의 포즈 안내와 함께 멀티뷰 이미지를 생성합니다. 또한 저자는 아바타의 정확성과 다양성을 향상시키기 위해 각각 '보기 관련' 및 '속성 관련' 프롬프트를 도입합니다.
- 거칠고 세밀한 판별자: 이는 특히 아바타의 측면 또는 후면 보기에서 데이터 세트의 이미지 포즈가 잘못 정렬되는 문제를 해결하기 위해 고안되었습니다. 정확한 포즈 주석에 해당하는 세밀한 포즈 라벨과 이미지 보기의 일반적인 표시를 제공하는 거친 포즈 라벨의 두 가지 유형의 포즈 주석과 함께 작동합니다.

![포즈 이미지의 안내에 따라 멀티뷰 이미지 데이터 세트를 생성하는 파이프라인입니다. 기존 3D 모델에서 기존 3D 모델에서 포즈를 추출하여 다양한 뷰의 이미지 합성을 안내합니다. 아바타의 스타일은 텍스트 프롬프트를 통해 텍스트 프롬프트에 의해 제어됩니다.](StyleAvatar3D%20Leveraging%20Image-Text%20Diffusion%20Mode%20c94b3777fbc44fa4ab10406068df3141/Untitled%202.png)

포즈 이미지의 안내에 따라 멀티뷰 이미지 데이터 세트를 생성하는 파이프라인입니다. 기존 3D 모델에서 기존 3D 모델에서 포즈를 추출하여 다양한 뷰의 이미지 합성을 안내합니다. 아바타의 스타일은 텍스트 프롬프트를 통해 텍스트 프롬프트에 의해 제어됩니다.

- 잠재 확산 모델: 이 모델은 양식화된 아바타의 포즈를 정확하게 추정하는 문제를 해결하기 위해 개발되었습니다. 이 모델은 StyleGAN의 잠재 스타일 공간에서 작동하며 렌더링된 전면 이미지에 따라 노이즈로부터 스타일 벡터를 확산시킵니다.

전반적으로 제안된 프레임워크는 멀티뷰 이미지와 3D 아바타의 생성을 개선하는 동시에 이미지 포즈 오정렬 및 포즈 추정과 같은 문제를 해결하는 것을 목표로 합니다.

![다양한 안내 전략과 프롬프트에 의해 생성된 데이터를 비교합니다. 보기별 프롬프트와 속성 관련 프롬프트가 보기별 프롬프트 및 속성 관련 프롬프트가 생성 정확도와 다양성을 효과적으로 향상시킬 수 있습니다.](StyleAvatar3D%20Leveraging%20Image-Text%20Diffusion%20Mode%20c94b3777fbc44fa4ab10406068df3141/Untitled%203.png)

다양한 안내 전략과 프롬프트에 의해 생성된 데이터를 비교합니다. 보기별 프롬프트와 속성 관련 프롬프트가 보기별 프롬프트 및 속성 관련 프롬프트가 생성 정확도와 다양성을 효과적으로 향상시킬 수 있습니다.

4 Experiments

저자들은 3D 아바타 생성 프레임워크에 대한 일련의 실험과 테스트를 수행했습니다. 다음은 연구 결과에 대한 간단한 설명입니다:

1. 데이터 세트 구축: 50개 스타일에서 균등하게 샘플링된 50만 개의 이미지로 데이터 세트를 만들었습니다. 실험에서는 데이터 세트 구성을 위한 다양한 유형의 안내와 프롬프트를 테스트했습니다. 실험 결과, 뷰별 프롬프트는 머리 뒷면 이미지를 생성하는 데 특히 효과적이었으며, 속성 관련 프롬프트는 아바타의 다양성을 크게 개선하는 것으로 나타났습니다. 하이브리드 안내 방식이 가장 효과적인 것으로 나타났습니다.
2. 거친 판별자에서 세밀한 판별자로: 연구팀은 프레셰 시작 거리(FID)를 평가 지표로 사용하여 제안한 거친 판별자에서 미세 판별자로의 효과를 검증했습니다. 그 결과, 이들의 판별기가 비교 대상 방법보다 훨씬 뛰어난 성능을 보여줌으로써 설계의 우수한 효능을 입증했습니다.
3. 잠재적 우주 산책: 학습된 GAN의 품질을 측정하기 위해 두 개의 입력 벡터를 선택하고 그 사이의 선형 보간을 포함하는 잠재 공간 걷기를 수행했습니다. 이 모델은 잠재 공간을 통과할 때 시각적으로 일관되고 다양한 이미지를 생성할 수 있었으며, 이는 모델의 견고함과 다양성을 나타냅니다.

![Latent 공간 워크 실험. 입력 노이즈와 렌더링된 뷰를 선형적으로 이동합니다. 다른 쪽. 모양과 지오메트리가 부드럽게 변경됩니다.](StyleAvatar3D%20Leveraging%20Image-Text%20Diffusion%20Mode%20c94b3777fbc44fa4ab10406068df3141/Untitled%204.png)

Latent 공간 워크 실험. 입력 노이즈와 렌더링된 뷰를 선형적으로 이동합니다. 다른 쪽. 모양과 지오메트리가 부드럽게 변경됩니다.

1. 이미지 컨디셔닝 3D 생성: 연구팀은 이미지 조건부 3D 생성 접근 방식의 효율성을 테스트했습니다. 그 결과 잠재 스타일 공간의 확산 모델이 입력 이미지에 따라 3D 모델을 효과적으로 생성하여 얼굴 특징을 정확하게 포착할 수 있음을 보여주었습니다.
    
    ![이미지 입력을 통한 조건부 아바타 생성 결과. 왼쪽에 입력 이미지가 주어졌을 때, 우리의 확산은 오른쪽에 표시되는 3D 아바타를 생성하는 데 사용되는 스타일 벡터를 예측합니다.](StyleAvatar3D%20Leveraging%20Image-Text%20Diffusion%20Mode%20c94b3777fbc44fa4ab10406068df3141/Untitled%205.png)
    
    이미지 입력을 통한 조건부 아바타 생성 결과. 왼쪽에 입력 이미지가 주어졌을 때, 우리의 확산은 오른쪽에 표시되는 3D 아바타를 생성하는 데 사용되는 스타일 벡터를 예측합니다.
    
2. 메시 시각화: 연구팀은 행진 큐브 알고리즘을 사용하여 트라이플레인에서 메시를 추출하고 시각화했습니다. 결과 메시와 이미지는 사실적인 지오메트리를 가진 아바타를 생성하는 모델의 정확성을 보여주었습니다.
    
    ![생성된 3D 아바타에서 내보낸 메시를 시각화합니다. 학습된 3D 생성 모델에서 메시를 추출하기 위해 행진 큐브 알고리즘을 활용합니다. 이 방법을 사용하면 원하는 스타일을 정확하게 반영하는 고유한 지오메트리를 가진 아바타를 생성할 수 있습니다.](StyleAvatar3D%20Leveraging%20Image-Text%20Diffusion%20Mode%20c94b3777fbc44fa4ab10406068df3141/Untitled%206.png)
    
    생성된 3D 아바타에서 내보낸 메시를 시각화합니다. 학습된 3D 생성 모델에서 메시를 추출하기 위해 행진 큐브 알고리즘을 활용합니다. 이 방법을 사용하면 원하는 스타일을 정확하게 반영하는 고유한 지오메트리를 가진 아바타를 생성할 수 있습니다.
    
3. 만화 캐릭터 재구성: 연구팀은 프레임워크의 다용도성을 테스트하기 위해 알려진 만화 캐릭터의 이미지로 학습된 LoRA 모델을 사용했습니다. 그 결과 모델이 캐릭터의 3D 모델을 충실하게 재구성할 수 있으며 하이브리드 안내 전략으로 캐릭터의 외형을 다양화할 수 있어 프레임워크가 다양한 스타일과 안내 전략에 적응할 수 있다는 것을 보여주었습니다.
    
    ![프레임워크를 사용한 3D 만화 캐릭터 재구성. 인터넷에서 수집한 10개의 이미지를 사용하여 인터넷에서 수집한 10개의 이미지를 사용하여 학습 이미지 생성을 위한 LoRA + StableDiffusion 모델을 세밀하게 조정했습니다.](StyleAvatar3D%20Leveraging%20Image-Text%20Diffusion%20Mode%20c94b3777fbc44fa4ab10406068df3141/Untitled%207.png)
    
    프레임워크를 사용한 3D 만화 캐릭터 재구성. 인터넷에서 수집한 10개의 이미지를 사용하여 인터넷에서 수집한 10개의 이미지를 사용하여 학습 이미지 생성을 위한 LoRA + StableDiffusion 모델을 세밀하게 조정했습니다.
    

5 Conclusion

이 연구에서 저자는 이전에 학습된 텍스트-이미지 확산 모델을 사용하여 고유한 스타일의 3D 아바타를 생성하는 새로운 시스템을 제시합니다. 이 프로세스를 통해 사용자는 텍스트 프롬프트를 사용하여 스타일과 얼굴 특징을 결정할 수 있으므로 아바타를 보다 유연하게 만들 수 있습니다. 또한 생성된 훈련 이미지와 포즈 간의 정렬 불일치 문제를 해결하는 '거친-세밀한 판별자'라는 새로운 접근 방식을 도입하여 잘못된 포즈 주석이 있는 이미지 데이터의 사용을 개선했습니다. 또한 이미지 입력에서 3D 모델을 생성할 수 있는 잠재 확산을 기반으로 하는 조건부 생성 모듈을 구축했습니다.

Appendix

이 논문에서 저자들은 실험에 사용된 데이터 세트를 어떻게 생성했는지에 대해 자세히 설명합니다. 스타일과 속성을 생성하기 위해 특정 프롬프트를 사용했으며, 그 중 일부는 수동으로 생성하고 다른 일부는 ChatGPT를 사용하여 생성했습니다.

3D 생성적 적대 신경망(GAN)을 훈련하기 위해 세밀한 포즈 주석과 거친 포즈 주석을 모두 통합하고 8개의 Tesla V100 GPU를 사용했으며, 전체 과정은 약 5일이 소요되었습니다. 또한 저자들은 유사한 조건에서 훈련된 확산 모델도 사용했습니다.

정량적 비교를 위해 모델 특징 공간에서 데이터 분포와 생성된 분포 사이의 거리를 측정하는 프레셰 시작 거리(FID)를 평가 지표로 사용했습니다.

또한 기존 3D 모델에서 Openpose 주석을 합성하는 실험도 진행했습니다. 그 결과, 눈에 보이는 모든 랜드마크를 코점과 함께 합성하는 것이 가장 좋은 결과를 가져온다는 사실을 발견했습니다.

절제 연구에서는 이들이 제안한 디자인이 미세 포즈 주석이나 거친 포즈 주석만 사용한 기준선보다 더 나은 성능을 보였습니다. 이 연구는 이 모델이 정확하고 사실적인 3D 아바타를 제작하는 데 더 효과적이라는 사실을 밝혀냈습니다.

마지막으로, 연구팀은 조건부 아바타 생성의 두 가지 특수한 경우, 즉 얼굴 각도가 앞쪽 얼굴에서 멀리 떨어져 있는 입력 이미지와 도메인 외부 이미지에서 아바타를 생성하는 경우를 살펴보았습니다. 이 두 가지 경우 모두 모델이 포즈 각도가 큰 입력 이미지와 배포 범위를 벗어난 이미지를 처리할 수 있었습니다.

- 요약
    
    데이터 세트 생성: 저자들은 실험을 위한 데이터 세트를 생성하는 것으로 시작했습니다. 50가지 아바타 스타일을 수집하고 512x512픽셀 해상도의 이미지를 생성했습니다. 또한 50개의 스타일에서 균등하게 샘플링한 50만 개의 이미지로 구성된 혼합 스타일 데이터세트를 생성하여 다양한 스타일에 대한 모델의 일반화 능력을 테스트했습니다. 또한 뎁스 맵과 사람 포즈 가이드를 위해 각각 Midas와 Openpose와 같은 기존 모델을 사용했습니다.
    
    프롬프트 디자인: 개발자들은 아바타 생성 과정을 안내하기 위해 프롬프트를 사용했습니다. 프롬프트는 아바타의 스타일 및 속성과 관련된 것이었습니다. 처음 10개의 스타일 관련 프롬프트는 수작업으로 디자인했고, 나머지 속성 관련 프롬프트와 함께 ChatGPT를 사용하여 생성했습니다.
    
    3D GAN 훈련: 다음으로 저자들은 생성된 데이터 세트를 사용하여 3D 생성적 적대 신경망(GAN)을 훈련했습니다. 훈련에는 세밀한 포즈 주석과 거친 포즈 주석을 모두 통합했습니다. 이 모델은 배치 크기가 32인 8개의 Tesla V100 GPU에서 훈련되었습니다.
    
    거친-세밀한 판별자 설계: 저자들은 생성된 훈련 이미지와 포즈 간의 정렬 불일치를 처리하기 위해 거친 판별자에서 미세한 판별자를 개발했습니다. 프레셰 시작 거리(FID) 평가 지표를 사용하여 그 효과를 검증한 결과, 이전 방법보다 성능이 뛰어나다는 것을 확인했습니다.
    
    확산 모델 통합: 잠재 확산을 기반으로 조건부 생성 모듈을 추가로 개발하여 이미지 입력에 기반한 3D 모델을 생성할 수 있게 되었습니다.
    
    실험 및 결과 분석: 저자들은 접근 방식을 검증하기 위해 다양한 실험과 분석을 수행했습니다. Openpose 주석을 합성하기 위한 다양한 전략을 탐색하고, 모델을 기준 모델과 비교하기 위한 제거 연구를 수행했습니다. 또한 조건부 아바타 생성의 두 가지 특수 사례도 분석했습니다.
    
    결론: 마지막으로 저자들은 연구 결과와 제안한 접근 방식의 효과를 요약하여 논문을 마무리했습니다. 또한 다양하고 역동적인 아바타 또는 캐릭터를 생성하는 데 있어 모델의 유연성을 강조했습니다.