# Boximator: Generating Rich and Controllable Motions for Video Synthesis

[https://arxiv.org/abs/2402.01566](https://arxiv.org/abs/2402.01566)

[https://boximator.github.io/](https://boximator.github.io/)

- Feb 2024

## 1. Introduction

이 논문은 최근 비디오 합성 분야에서 이루어진 주목할 만한 발전에 기여하는 새로운 접근 방법을 제시합니다. 기존의 모델들은 주로 텍스트 프롬프트나 주요 프레임을 사용하여 비디오를 생성하는데 집중해왔으며, 최신 연구는 스케치, 깊이 맵, 인간의 포즈, 궤적 및 조건부 이미지와 같은 프레임 레벨의 제약 조건을 도입함으로써 제어 가능성을 향상시키고 있습니다.

이러한 맥락에서 본 연구는 박스 형태의 제약 조건을 이용하여 미세한 움직임 제어를 가능하게 하는 새로운 방법을 소개합니다. '박스'는 물체의 경계를 정확하게 또는 넓은 범위 내에서 규정하는 역할을 하며, 하드 박스와 소프트 박스 두 가지 유형으로 나뉩니다. 하드 박스는 물체의 경계를 정확히 지정하는 반면, 소프트 박스는 물체가 존재해야 하는 더 넓은 영역을 정의합니다. 이러한 박스를 통해 사용자는 여러 프레임에 걸쳐 다수의 객체를 유니크한 객체 ID와 연결하여 제어할 수 있습니다.

본 연구에서 제안하는 'Boximator'는 이러한 박스 제약 조건을 이용하여, 전경 및 배경 객체의 움직임을 관리하고, 큰 물체의 포즈를 미세 조정하는 등 다양한 장점을 제공합니다. 예를 들어, 이미지 기반 생성에서는 사용자가 원하는 객체 주변에 하드 박스를 그려 쉽게 선택할 수 있으며, 소프트 박스를 통해 사용자 정의 박스가 없는 프레임에 대해 대략적인 움직임 경로를 제어할 수 있습니다. Boximator는 기존 비디오 확산 모델에 플러그인처럼 작동하며, 박스 제약 조건을 새로운 유형의 자기 주의 층을 통해 모델에 통합하여, 텍스트에 의존하지 않고 시각적 입력만으로 객체의 움직임을 제어하는 것을 목표로 합니다.

![ Boximator를 이용한 움직임 제어: (a) 점프하는 고양이의 최종 형태와 위치를 제어하기 위해 하드 박스 사용; (b) 카메라를 왼쪽으로 회전시키기 위해 침대와 창문을 오른쪽으로 밀어내기; (c) 사람이 커피잔을 들어 올리는 방식 제어; (d) 개와 공의 움직임 경로 제어; (e) 두 개의 풍선의 궤적과 근접성을 제어하기 위해 움직임 경로와 하드 박스 사용. 모든 그림에서 점선 박스는 첫 번째 프레임 제약을 나타내며, 실선 박스는 마지막 프레임 제약을 나타냅니다; 화살표가 있는 선은 움직임을 나타냅니다.](Boximator%20Generating%20Rich%20and%20Controllable%20Motions%2089c3b4c210114238acbeebb4586c0403/Untitled.png)

 Boximator를 이용한 움직임 제어: (a) 점프하는 고양이의 최종 형태와 위치를 제어하기 위해 하드 박스 사용; (b) 카메라를 왼쪽으로 회전시키기 위해 침대와 창문을 오른쪽으로 밀어내기; (c) 사람이 커피잔을 들어 올리는 방식 제어; (d) 개와 공의 움직임 경로 제어; (e) 두 개의 풍선의 궤적과 근접성을 제어하기 위해 움직임 경로와 하드 박스 사용. 모든 그림에서 점선 박스는 첫 번째 프레임 제약을 나타내며, 실선 박스는 마지막 프레임 제약을 나타냅니다; 화살표가 있는 선은 움직임을 나타냅니다.

실험을 통해 이 방법이 동영상 합성의 질을 유지하면서도 다양한 실제 시나리오에서의 움직임 제어에 있어 견고함을 제공함을 입증합니다. 또한, 사용자 연구를 통해 Boximator가 비디오 품질과 움직임 제어 측면에서 기존 모델에 비해 우수함을 확인하였습니다. 이러한 결과는 Boximator가 동영상 합성 분야에서 유용한 도구로 사용될 수 있음을 시사합니다.

## 2. Related Work

관련 연구 장에서는 동영상 합성 분야의 발전과 현재까지의 주요 연구 동향에 대해 설명합니다. 이 분야는 이미지 확산 모델에서 비롯되어, 시간적 레이어를 추가하여 U-Net 아키텍처를 확장하는 방식으로 발전했습니다. 특히, 계산 효율성을 향상시키기 위해 잠재 공간에서 노이즈를 제거하는 방법이 널리 채택되고 있습니다. 텍스트-투-비디오(T2V) 확산 모델은 조건부 생성의 기반으로 자주 사용되며, 초기에 텍스트를 기반으로 이미지를 생성한 뒤 이 이미지를 참조하여 동영상을 생성하는 두 단계 접근법을 제안합니다. 이 접근법은 비디오 모델이 동적인 측면에 집중하게 함으로써 비디오 품질을 향상시킵니다.

또한, 연구는 T2V 및 이미지-투-비디오(I2V) 모델의 제어 가능성을 높이기 위한 다양한 방법에 초점을 맞춥니다. 예를 들어, VideoComposer와 같은 연구에서는 스케치, 깊이 맵, 모션 벡터와 같은 조건을 사용합니다. 댄스 비디오 제작에는 참조 비디오에서 추출한 인간의 포즈가 일반적으로 사용되며, 사용자는 더 정밀한 움직임 제어를 위해 객체나 카메라의 궤적을 플롯팅할 수 있습니다. 그러나 이러한 방법들은 대상 객체를 정확히 정의하는 명확한 방법을 제공하지 않아, 이미지로부터 크거나 복합 객체를 선택하고 제어하는 것이 어렵습니다. 또한, 궤적은 객체의 형태와 크기를 포착하지 못해, 팔을 벌리거나 접근하는 동작과 같은 포즈나 근접성 변화를 묘사하는 데 한계가 있습니다.

![제어 모듈 개요: 공간적 자기 주의와 공간적 교차 주의 사이의 모든 공간적 주의 블록에 새로운 자기 주의 층을 추가합니다. 훈련 중에는 모든 원본 모델 매개변수가 고정됩니다.](Boximator%20Generating%20Rich%20and%20Controllable%20Motions%2089c3b4c210114238acbeebb4586c0403/Untitled%201.png)

제어 모듈 개요: 공간적 자기 주의와 공간적 교차 주의 사이의 모든 공간적 주의 블록에 새로운 자기 주의 층을 추가합니다. 훈련 중에는 모든 원본 모델 매개변수가 고정됩니다.

동시에 진행된 두 연구에서는 움직임 제어를 위해 경계 상자를 사용했지만, 본 연구와는 몇 가지 주요한 차이점이 있습니다. TrailBlazer는 주의 맵 수정을 사용하여 모델이 지정된 영역 내 특정 객체를 생성하도록 유도하는 훈련 없는 방법입니다. FACTOR는 변환기 기반 생성 모델인 Phenaki를 수정하여 박스 제어 모듈을 추가했으며, 각 박스에 대한 텍스트 설명이 필요합니다. 이 두 방법 모두 소프트 박스 제약 조건을 지원하지 않으며, 훈련과 관련된 도전 과제를 다루지 않습니다.

이 장은 동영상 합성 기술의 발전과 그 제어 가능성을 향상시키기 위한 다양한 연구 노력을 소개하면서, 본 논문에서 제안하는 Boximator의 차별화된 접근 방식과 그 중요성을 강조합니다. Boximator는 텍스트 설명 없이 시각적 입력만을 사용하여 객체의 움직임을 제어하려는 새로운 시도로, 이 분야에서의 기존 연구와 차별화됩니다.

## 3. Background: Video Diffusion Model

"Background: Video Diffusion Model" 장에서는 Boximator의 기반이 되는 비디오 확산 모델에 대한 배경 지식을 설명합니다. 비디오 확산 모델은 이미지 확산 모델을 확장한 것으로, 순차적으로 노이즈 벡터를 예측하여 순수 가우시안 노이즈로부터 고품질의 비디오 프레임으로 점진적으로 변환하는 과정을 수행합니다. 이러한 변환 과정은 3D U-Net 아키텍처를 기반으로 하는데, 여기서 U-Net은 노이즈가 섞인 입력과 타임스탬프, 다양한 조건을 고려하여 입력된 노이즈를 예측합니다.

3D U-Net은 교대로 배치된 컨볼루션 블록과 주의(attention) 블록으로 구성됩니다. 각 블록은 공간적 구성 요소와 시간적 구성 요소를 포함하여, 비디오 프레임을 개별 이미지로 처리하면서 동시에 프레임 간의 정보 교환을 가능하게 합니다. 주의 블록 내에서, 공간적 구성 요소는 일반적으로 자기 주의 층을 거친 후, 텍스트 프롬프트에 조건을 부과하는 교차 주의 층이 따릅니다.

이 모델의 최적화는 잡음 예측 손실을 통해 이루어지며, 이는 잡음 벡터가 순차적으로 변환되는 과정을 학습하는 데 사용됩니다. 여기서 중요한 개념은 비디오 확산 모델이 비디오의 각 프레임을 독립적인 이미지로 처리하면서도, 시간에 따라 프레임 간 정보를 교환할 수 있는 구조를 갖추고 있다는 점입니다. 이를 통해 모델은 비디오 내의 동적인 움직임과 시간에 따른 변화를 효과적으로 모델링할 수 있습니다.

본 장은 비디오 합성을 위한 기술적 배경을 제공하며, Boximator가 이러한 기존의 비디오 확산 모델 위에 구축되어, 특정한 제약 조건을 통해 움직임을 제어하는 새로운 기능을 추가한다는 점을 설명합니다. Boximator의 혁신적인 접근 방식은 이러한 기반 기술을 활용하여 비디오 생성 과정에서 사용자가 더 세밀하게 제어할 수 있는 새로운 가능성을 탐색합니다.

## 4. Boximator: Box-guided Motion Control

"Boximator: Box-guided Motion Control" 장은 Boximator 모델의 핵심 아이디어와 구조에 대해 상세히 설명합니다. Boximator의 목표는 기존 비디오 확산 모델에 움직임 제어 기능을 추가하는 것이며, 이를 통해 사용자가 더욱 세밀하고 유연하게 비디오 내 객체의 움직임을 조절할 수 있도록 합니다. 이 장은 모델 아키텍처, 데이터 파이프라인, 자기 추적 기법, 다단계 훈련 절차, 그리고 추론 방식에 대해 설명합니다.

### **모델 아키텍처**

Boximator는 비디오 확산 모델의 공간적 주의 블록에 새로운 자기 주의 층을 추가하여 박스 제약 조건을 모델에 통합합니다. 이 층은 비디오 프레임의 시각적 토큰과 함께 박스 제약 조건의 임베딩을 처리하여, 비디오 생성 과정에서 객체의 움직임을 제어합니다. 박스 임베딩은 박스의 위치, 객체 ID, 박스 유형(하드 또는 소프트)을 나타내는 벡터로 구성됩니다. 이러한 정보는 박스의 움직임과 관련된 시각적 정보와 결합되어, 비디오 내에서 객체를 정확히 추적하고 조절하는 데 사용됩니다.

### **데이터 파이프라인**

Boximator는 WebVid-10M 데이터셋에서 추출한 동적인 비디오 클립을 사용하여 훈련됩니다. 데이터 파이프라인은 비디오 클립의 첫 프레임을 분석하여 객체 프롬프트를 생성하고, 이를 기반으로 하여 객체 추적 및 경계 상자 생성을 수행합니다. 이 과정은 2.4M 개의 객체에 대한 경계 상자를 생성하는 데 성공했습니다.

![훈련 데이터: 모든 경계 상자는 잘린 영역(흰색 점선 상자)으로 투영됩니다.](Boximator%20Generating%20Rich%20and%20Controllable%20Motions%2089c3b4c210114238acbeebb4586c0403/Untitled%202.png)

훈련 데이터: 모든 경계 상자는 잘린 영역(흰색 점선 상자)으로 투영됩니다.

### **자기 추적(Self-Tracking)**

Boximator는 자기 추적 기법을 사용하여 비디오 내 객체의 움직임을 효과적으로 제어합니다. 모델은 각 객체에 대한 색깔이 지정된 경계 상자를 생성하도록 훈련되며, 이를 통해 모델이 객체를 추적하고 박스 제약 조건에 따라 정확히 정렬하는 능력을 향상시킵니다. 이 기법은 박스 제약 조건에 따라 객체의 움직임을 조절하는 중간 표현을 생성하는 데 핵심적인 역할을 합니다.

![자기 추적: 모델이 모든 제한된 객체를 추적하도록 훈련합니다. 이 그림은 검은 말과 그 주변의 노란 상자가 함께 생성되는 3개의 프레임을 보여줍니다.](Boximator%20Generating%20Rich%20and%20Controllable%20Motions%2089c3b4c210114238acbeebb4586c0403/Untitled%203.png)

자기 추적: 모델이 모든 제한된 객체를 추적하도록 훈련합니다. 이 그림은 검은 말과 그 주변의 노란 상자가 함께 생성되는 3개의 프레임을 보여줍니다.

### **다단계 훈련 절차**

Boximator의 훈련은 세 단계로 구성됩니다. 첫 번째 단계에서는 모델이 하드 박스 제약 조건에 따라 초기 학습을 수행하고, 두 번째 단계에서는 일부 하드 박스를 소프트 박스로 대체하여 모델의 유연성을 높입니다. 마지막 단계에서는 자기 추적을 제외하고 계속하여 훈련을 진행합니다.

### **추론**

추론 단계에서는 사용자가 정의한 몇몇 프레임에 대해 박스를 적용하고, 이 박스 정보를 사용하여 비디오 내 객체의 움직임을 조절합니다. Boximator는 사용자 정의 박스와 모션 경로를 기반으로 하여 나머지 프레임에 대해 소프트 박스를 생성하고 적용함으로써, 객체가 사용자가 의도한 대로 움직이도록 합니다. 이 과정은 선형 보간과 박스 영역의 확장을 통해 이루어지며, 모델에게 객체의 대략적인 움직임 경로를 제공하면서도 생성 과정에 필요한 유연성을 부여합니다. 사용자가 하드 박스를 정의하고 해당 박스의 움직임 경로를 지정한 경우, Boximator는 이 정보를 활용하여 추론 과정에서 객체가 경로를 따라 움직이도록 만듭니다. 이러한 방식으로, Boximator는 비디오 생성 시 객체의 움직임을 정밀하게 제어할 수 있는 강력한 수단을 제공합니다.

![추론에서의 소프트 박스. 우리는 사용자가 지정한 두 박스(상단 행) 또는 사용자가 지정한 박스와 움직임 경로(하단 행)를 기반으로 소프트 박스를 보간하고 이를 완화합니다.](Boximator%20Generating%20Rich%20and%20Controllable%20Motions%2089c3b4c210114238acbeebb4586c0403/Untitled%204.png)

추론에서의 소프트 박스. 우리는 사용자가 지정한 두 박스(상단 행) 또는 사용자가 지정한 박스와 움직임 경로(하단 행)를 기반으로 소프트 박스를 보간하고 이를 완화합니다.

Boximator의 이러한 접근 방식은 기존의 비디오 생성 모델에 비해 사용자에게 더욱 직관적이고 유연한 움직임 제어 기능을 제공합니다. 이를 통해 사용자는 복잡한 움직임 패턴이나 다수의 객체가 포함된 시나리오에서도 비디오 내의 움직임을 자연스럽고 정밀하게 조절할 수 있게 됩니다. 또한, Boximator는 객체의 식별과 추적, 움직임 제어를 위한 복잡한 프로세스를 간소화함으로써, 비디오 생성 과정을 효율적으로 만들고, 다양한 사용 사례와 응용 분야에서의 활용 가능성을 크게 확장합니다.

결론적으로, "Boximator: Box-guided Motion Control" 장은 Boximator 모델의 구조와 작동 원리, 그리고 비디오 내 객체의 움직임을 제어하는 데 있어서의 혁신적인 접근 방식을 상세히 설명합니다. 이 모델은 비디오 합성 분야에서의 새로운 패러다임을 제시하며, 더욱 진보된 비디오 생성 및 편집 도구로서의 가능성을 열어줍니다. Boximator의 개발을 통해, 사용자가 비디오 내에서 객체의 움직임을 더욱 자유롭고 정밀하게 조절할 수 있는 새로운 방법을 제공함으로써, 비디오 합성과 관련된 연구 및 응용 분야에 중요한 기여를 하고 있음을 확인할 수 있습니다.

## 5. Experiments

"Experiments" 장은 Boximator 모델의 성능을 평가하기 위해 수행된 실험들과 그 결과를 상세히 설명합니다. 이 장에서는 기본 모델들에 대한 Boximator의 훈련 과정, 사용된 데이터셋, 평가 메트릭스, 그리고 양적 및 질적 평가 결과에 대해 다룹니다.

### **실험 설정**

Boximator는 PixelDance와 ModelScope라는 두 가지 기반 모델 위에 구축되어 훈련되었습니다. 실험은 MSR-VTT, ActivityNet, UCF-101 데이터셋을 사용하여 진행되었으며, 비디오 품질, 텍스트 정렬, 그리고 움직임 제어의 정밀도를 평가하는 데 사용된 주요 메트릭스로는 Frechet Video Distance(FVD), CLIP 유사성 점수(CLIPSIM), 평균 정밀도(AP) 등이 있습니다.

### **실험 결과**

양적 평가에서 Boximator는 기본 모델들의 원래 비디오 품질을 유지하면서도 다양한 실제 상황에서 견고한 움직임 제어를 제공하는 것으로 나타났습니다. 특히, 박스 제약 조건을 추가함으로써 비디오 품질이 크게 향상되었으며, 객체 탐지기의 평균 정밀도(AP) 점수도 상당히 증가했습니다. 이는 Boximator가 효과적으로 움직임을 제어하고 있음을 시사합니다.

또한, 사용자 연구 결과에서도 Boximator 모델이 비디오 품질과 움직임 제어 측면에서 기반 모델보다 우수한 성능을 보임을 확인할 수 있었습니다. 사용자들은 Boximator로 생성된 비디오의 품질과 움직임 제어 능력을 기반 모델과 비교해 크게 선호했습니다.

### **이탈 분석**

이탈 분석을 통해 Boximator의 다양한 설계 결정이 모델 성능에 미치는 영향을 평가했습니다. 특히, 자기 추적 기법과 소프트 박스 사용의 중요성이 강조되었습니다. 자기 추적을 사용하지 않았을 때 모델이 박스 제약 조건에 따른 객체의 정확한 추적과 정렬을 수행하는 데 어려움을 겪었으며, 소프트 박스를 제거하면 움직임 제어의 정밀도가 크게 떨어지는 것으로 나타났습니다.

### **사례 연구**

사례 연구를 통해 Boximator가 복잡한 시나리오에서 객체의 움직임을 어떻게 정밀하게 제어할 수 있는지 보여주었습니다. 예를 들어, 여러 객체가 포함된 비디오에서 Boximator는 각 객체에 대한 박스 제약 조건을 정확히 따르면서도, 동적인 움직임과 상호 작용을 자연스럽게 생성할 수 있었습니다.

![사례 연구: (a) 네 개의 박스를 기반으로 한 생성 및 움직임 제어; (b) 프레임의 상당 부분에 영향을 미치는 움직임; (c) 객체의 조합(예: "말 위의 사람")에 정의된 박스; (d) 장면에 새로운 객체 추가.](Boximator%20Generating%20Rich%20and%20Controllable%20Motions%2089c3b4c210114238acbeebb4586c0403/Untitled%205.png)

사례 연구: (a) 네 개의 박스를 기반으로 한 생성 및 움직임 제어; (b) 프레임의 상당 부분에 영향을 미치는 움직임; (c) 객체의 조합(예: "말 위의 사람")에 정의된 박스; (d) 장면에 새로운 객체 추가.

### **결론**

"Experiments" 장은 Boximator가 기존 비디오 생성 모델을 훨씬 뛰어넘는 움직임 제어 능력을 제공함을 명확히 보여줍니다. 실험 결과는 Boximator의 유용성과 효과를 입증하며, 비디오 합성 분야에서의 새로운 가능성을 제시합니다. Boximator의 도입으로, 사용자는 복잡한 동적 콘텐츠를 포함하는 비디오를 더욱 직관적이고 세밀하게 생성 및 수정할 수 있게 되었습니다. 이는 특히 광고, 영화 제작, 비디오 게임 개발 등 다양한 산업 분야에서 매우 유용할 것으로 기대됩니다.

양적 및 질적 평가를 통해 박스 제약 조건이 비디오 생성 과정에 긍정적인 영향을 미치며, 특히 움직임 제어의 정밀도와 비디오 품질의 개선이 두드러졌습니다. 사용자 연구 결과는 Boximator가 제공하는 개선된 비디오 품질과 움직임 제어 기능이 실제 사용자에게도 인식될 수 있음을 보여줍니다.

이탈 분석은 Boximator 모델의 핵심 기능인 자기 추적과 소프트 박스 사용이 모델 성능에 중요하게 기여함을 확인했습니다. 이를 통해 Boximator의 설계 결정이 합리적이며, 향후 비디오 합성 모델 개발에 있어 중요한 지침을 제공할 수 있음을 시사합니다.

사례 연구를 통해서는 Boximator가 다양한 시나리오에서 유연하고 정밀한 움직임 제어를 가능하게 함으로써, 비디오 내에서 자연스러운 동작과 상호작용을 생성할 수 있음을 보여주었습니다. 이는 Boximator가 단순한 움직임 추적을 넘어, 비디오 내 객체들 사이의 복잡한 상호작용과 동적인 씬 변화를 성공적으로 핸들링할 수 있음을 의미합니다.

종합적으로, "Experiments" 장은 Boximator의 효과성과 실용성을 잘 입증하며, 이 모델이 비디오 합성 분야에서 혁신적인 도구로서의 잠재력을 가지고 있음을 보여줍니다. Boximator의 성공적인 개발과 평가는 향후 이 분야의 연구 및 개발에 중요한 영향을 미칠 것으로 기대되며, 비디오 콘텐츠 생성의 새로운 방향을 제시합니다.

## 6. Conclusion

Boximator는 비디오 내 객체의 움직임을 제어하기 위해 박스 형태의 제약 조건을 활용하는 새로운 접근 방법을 제시합니다. 이 모델은 사용자가 비디오 생성 과정에서 객체의 위치와 움직임을 직관적이고 세밀하게 조절할 수 있게 해주며, 이는 비디오 합성 분야에서 중요한 진보를 대표합니다. Boximator의 개발을 통해, 기존 비디오 확산 모델에 대한 움직임 제어 기능이 크게 향상되었으며, 다양한 실제 시나리오에서 높은 유연성과 정밀도를 제공함을 실험적으로 입증했습니다.

이 연구는 Boximator가 기본 모델의 비디오 품질을 유지하면서도, 박스 제약 조건을 추가함으로써 비디오 품질과 객체 감지의 정밀도를 상당히 향상시킬 수 있음을 보여주었습니다. 사용자 연구에서도 Boximator로 생성된 비디오의 품질과 움직임 제어가 기반 모델에 비해 우수함을 확인할 수 있었습니다.

Boximator의 성공은 비디오 생성 및 편집 도구에 새로운 가능성을 열어주며, 광고, 영화 제작, 비디오 게임 개발 등 다양한 분야에서의 응용을 기대할 수 있습니다. 특히, 사용자가 복잡한 동적 콘텐츠를 보다 쉽고 효과적으로 생성하고 조작할 수 있게 함으로써, 창의적인 콘텐츠 제작의 새로운 지평을 열어줍니다.

또한, 이 연구는 Boximator의 핵심 기술인 박스 제약 조건과 자기 추적 기법이 비디오 합성 분야에서의 다른 형태의 제어, 예를 들어 인간의 포즈나 키포인트 조건과 같은 새로운 연구 방향을 가능하게 할 수 있음을 시사합니다. 향후 연구에서는 Boximator의 접근 방식을 더욱 확장하고 다양화하여, 비디오 합성 기술의 범위와 가능성을 넓힐 수 있을 것으로 기대됩니다.

결론적으로, Boximator는 비디오 합성 분야에 중요한 기여를 하며, 비디오 내 객체의 움직임을 정밀하게 제어할 수 있는 강력하고 유연한 도구를 제공합니다. 이 연구는 향후 비디오 합성 및 편집 기술의 발전에 중요한 영향을 미칠 것으로 기대되며, 창의적인 비디오 콘텐츠 생성의 새로운 방향을 제시합니다.