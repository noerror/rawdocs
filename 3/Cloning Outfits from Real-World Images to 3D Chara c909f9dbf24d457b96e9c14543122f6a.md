# Cloning Outfits from Real-World Images to 3D Characters for Generalizable Person Re-Identification

[https://arxiv.org/abs/2204.02611](https://arxiv.org/abs/2204.02611)

- Apr 2022

### 1. Introduction

이 요약은 다양한 카메라 뷰에서 사람을 식별하는 프로세스인 사람 재식별에 관한 연구 프로젝트에 초점을 맞추고 있습니다. 이 기술의 개선은 중요하지만 개인정보 보호 문제와 값비싼 데이터 주석으로 인해 대규모의 다양한 학습 데이터가 부족하다는 한계가 있습니다. 이에 대한 한 가지 해결책은 사람의 합성 데이터 세트를 생성하여 개인 정보 보호 문제를 피하고 주석 처리 비용을 절감하는 것입니다.

![사람 이미지로부터 비슷한 옷차림의 3D 캐릭터를 자동으로 생성하는 제안된 ClonedPerson 파이프라인.](Cloning%20Outfits%20from%20Real-World%20Images%20to%203D%20Chara%20c909f9dbf24d457b96e9c14543122f6a/Untitled.png)

사람 이미지로부터 비슷한 옷차림의 3D 캐릭터를 자동으로 생성하는 제안된 ClonedPerson 파이프라인.

이 논문에서는 랜드퍼슨(RandPerson), 언리얼퍼슨(UnrealPerson) 등의 합성 데이터세트에 대해 설명하지만, 합성된 사람이 충분히 현실적이지 않아 합성 데이터와 실제 데이터 사이에 격차가 발생한다는 한계가 있다고 언급합니다.

이를 개선하기 위해 연구진은 실제 이미지에서 가상 3D 캐릭터로 의상을 자동으로 복제하는 방법을 제안합니다. 이 방법은 등록된 옷 매핑과 균질 옷감 확장이라는 두 가지 기술을 사용하여 구현됩니다. 등록된 의상 매핑은 일반적인 의상 구조에 사용되며, 원근 동형 기법을 사용하여 현실 세계의 의상을 UV 맵에 일치시킵니다. 반면에 균질 확장은 보이지 않는 옷 부분과 불규칙한 UV 맵을 위한 것으로, 옷에서 넓은 균질 영역을 찾아 UV 맵을 채우는 데 사용합니다.

또한 연구진은 합성 캐릭터 모집단의 다양성을 높이고 외형이 비슷한 캐릭터를 더 많이 생성하기 위해 '유사성-다양성' 확장 전략을 도입했습니다. 이는 실제 이미지를 클러스터링하고 이 클러스터에서 샘플링하여 3D 캐릭터를 생성함으로써 달성됩니다.

이 방법론을 사용하여 5,621개의 캐릭터로 구성된 887,766개의 이미지가 포함된 ClonedPerson이라는 데이터 세트가 생성되었습니다. 연구 결과, 이 데이터세트로 학습된 모델은 다른 실제 및 합성 데이터세트로 학습된 모델보다 일반화 성능이 더 우수한 것으로 나타났습니다. 이 논문은 전반적으로 보다 사실적인 합성 데이터 세트를 생성하여 사람 재식별 기술의 효율성을 개선하는 혁신적인 방법을 소개합니다.

### 2. RELATED WORK

이 섹션에서는 개인 재식별 및 합성 데이터 사용과 관련된 이전 연구에 대해 설명합니다. 개인 재식별을 위해 실제 데이터를 수집하고 라벨을 붙이는 작업은 비용이 많이 들고 개인정보 보호 문제가 발생할 수 있습니다. 합성 데이터는 수동 라벨링이나 개인정보 보호 문제를 수반하지 않기 때문에 이러한 문제를 완화하는 데 도움이 됩니다.

SyRI 및 PersonX와 같은 이전의 합성 데이터 세트는 제한된 수의 수작업 문자에 의존했습니다. 또 다른 데이터세트인 RandPerson은 기존 3D 의류 모델의 UV 맵을 중성 이미지나 임의의 색상 및 질감 패턴으로 대체하여 새로운 의류 모델을 생성하는 혁신적인 방법을 제안했습니다. 또한 자동 파이프라인을 사용하여 캐릭터 생성 속도를 높였으며, 합성 데이터로 훈련된 모델이 실제 데이터세트에서도 잘 일반화된다는 사실을 입증했습니다. 그 후 언리얼퍼슨은 실제 인물 이미지를 사용하여 가상 캐릭터를 생성함으로써 정확도를 개선했습니다. 하지만 언리얼퍼슨은 여전히 스케일링 문제로 인해 캐릭터가 비현실적으로 보이기도 했습니다.

가상 트라이온 방법도 연구되었습니다. 이 방법은 대상 의상을 참조 인물에게 입혀보는 것을 목표로 합니다. 현재의 방식은 대부분 2D이므로 가상 환경에서 포괄적인 렌더링을 위한 3D 모델을 생성할 수 없습니다. PIFu와 같은 일부 최신 방법은 2D 이미지에서 3D 인물을 재구성하려고 시도하지만 비용이 많이 들고 규모가 제한적입니다. HPBTT 및 Pix2Surf와 같은 방법은 2D 이미지에서 3D 재구성을 시도하지만 텍스처가 흐릿하고 아티팩트가 발생하는 경우가 많습니다. 또한 이러한 방법은 긴 치마와 같은 일부 의류 유형을 처리할 수 없습니다.

이러한 한계를 고려하여 이 백서의 저자는 새로운 접근 방식을 제안합니다. 랜드퍼슨과 언리얼퍼슨처럼 기존 UV 맵을 다른 이미지로 직접 대체하는 대신, 두 가지 복제 방법을 설계하여 UV 맵을 보다 정밀하고 구조를 인식하여 리페인팅합니다. 이를 통해 가상 캐릭터와 실제 인물 간의 차이를 줄이는 것이 목표입니다.

### 3. 3D Virtual Character Generation

이 섹션에서는 연구원들이 3D 가상 캐릭터를 생성하는 접근 방식, 즉 복제된 사람 접근 방식에 대해 설명합니다. 이 프로세스는 보행자 감지, 포즈 감지, 옷 감지, 옷 키포인트 감지 등의 사전 처리 단계로 시작하여 적격 정면도 인물 이미지와 옷의 위치, 카테고리, 키포인트에 대한 데이터를 확보합니다. 그런 다음 등록 매핑과 동질 확장이라는 두 가지 복제 방법을 사용하여 사람 이미지에서 UV 텍스처 맵으로 옷을 복제하고 3D 캐릭터를 생성합니다. 마지막으로 이러한 캐릭터를 Unity3D로 임포트하여 합성된 인물 이미지를 렌더링합니다.

![다른 카테고리의 옷과 해당 3D 옷 모델의 UV 텍스처 맵.](Cloning%20Outfits%20from%20Real-World%20Images%20to%203D%20Chara%20c909f9dbf24d457b96e9c14543122f6a/Untitled%201.png)

다른 카테고리의 옷과 해당 3D 옷 모델의 UV 텍스처 맵.

등록된 매핑 프로세스에서는 MakeHuman 커뮤니티에서 제공되는 3D 의상 모델을 활용하며, 옷은 UV 맵에서 규칙적인 모양과 구조로 나타납니다. 팀은 이러한 일반 UV 맵을 사용하여 원근 동형 기하법을 적용하여 실제 옷 텍스처를 3D 캐릭터의 UV 맵에 매핑합니다. 이 방법을 사용하면 옷의 원본 텍스처 구조를 잘 보존하고 선명하게 표현할 수 있습니다.

![등록된 옷 매핑(위쪽)과 균일한 옷 확장(아래쪽)의 과정 파이프라인.](Cloning%20Outfits%20from%20Real-World%20Images%20to%203D%20Chara%20c909f9dbf24d457b96e9c14543122f6a/Untitled%202.png)

등록된 옷 매핑(위쪽)과 균일한 옷 확장(아래쪽)의 과정 파이프라인.

![유사성-다양성 확장의 개념도.](Cloning%20Outfits%20from%20Real-World%20Images%20to%203D%20Chara%20c909f9dbf24d457b96e9c14543122f6a/Untitled%203.png)

유사성-다양성 확장의 개념도.

![다른 ϵ 값에 대한 클러스터링. (a) ϵ=0.4일 때 두 클러스터(위쪽과 아래쪽)의 예시. (b) ϵ=0.5일 때 두 클러스터(왼쪽과 오른쪽)의 예시로, 사람 이미지(첫 번째 행)와 생성된 캐릭터(두 번째 행).](Cloning%20Outfits%20from%20Real-World%20Images%20to%203D%20Chara%20c909f9dbf24d457b96e9c14543122f6a/Untitled%204.png)

다른 ϵ 값에 대한 클러스터링. (a) ϵ=0.4일 때 두 클러스터(위쪽과 아래쪽)의 예시. (b) ϵ=0.5일 때 두 클러스터(왼쪽과 오른쪽)의 예시로, 사람 이미지(첫 번째 행)와 생성된 캐릭터(두 번째 행).

원근 변환이라고도 하는 원근 호모그래피는 2D 점 집합 {pi}의 각 점을 호모그래피 행렬 H ∈ R3×3에 의해 해당 점 집합 {p′i}에 매핑합니다. 호모그래피 행렬 H는 최소제곱 문제를 해결하여 계산되며, 레벤버그-마쿼트 방법을 사용하여 재투영 오류를 줄이기 위해 개선할 수 있습니다.

다음으로 원근 워핑을 구현합니다. 이 작업에서는 일반 UV 텍스처 맵에 레이블이 지정된 옷 키포인트와 실제 인물 이미지에서 감지된 해당 옷 키포인트가 주어지면 호모그래피 행렬 H를 얻습니다. 그런 다음 옷 이미지에 대한 이중 선형 보간을 통해 원근 워핑 프로세스를 수행하여 결과 픽셀 값으로 UV 맵을 채웁니다. 배경의 영향을 줄이기 위해 옷의 바깥 부분은 검은색으로 설정됩니다.

대부분의 일반 UV 맵의 경우 모든 옷 키포인트를 통해 원근 동형 도형이 직접 계산됩니다. 그러나 UV 맵에서 긴팔 옷과 바지의 모양이 실제 이미지에서 보이는 것과 상당히 다른 경우 각 부분에 대해 원근 동위 원근을 개별적으로 계산합니다. 그런 다음 이러한 부분을 UV 텍스처 맵에 워프하고 결과를 결합합니다. 예를 들어 바지를 왼쪽과 오른쪽으로 분할할 수 있습니다.

이 섹션에서는 3D 가상 캐릭터 생성 접근 방식에서 균질 클로스 확장의 적용에 대해 설명합니다. 등록된 옷 매핑은 앞면의 옷 텍스처를 효과적으로 처리하지만, 뒷면은 앞면과 다른 경우가 많으며 일반적으로 보이지 않습니다. 이 문제를 해결하기 위해 연구팀은 균질 클로스 확장 방법을 고안했습니다. 이 방법은 옷에서 균질한 영역, 즉 리얼리스틱 클로스 셀을 식별하고 이 셀을 확장하여 UV 맵을 채웁니다.

균질 클로스 확장은 클로스 세분화와 클로스 확장의 두 단계로 구성됩니다.

클로스 세분화 단계에서는 최적화 알고리즘이 옷에서 넓은 균질 영역을 찾아서 이를 사실적인 클로스 셀로 사용합니다. 이 프로세스는 먼저 옷 영역을 잘라내고 QAConv 2.0으로 MSMT17에서 학습된 모델을 사용하여 이 옷 이미지의 특징 맵을 추출하는 것으로 시작됩니다. 그런 다음 다양한 스케일의 정사각형 블록을 특징 맵에 정의합니다. 각 블록에 대해 특징값의 평균과 표준편차를 계산합니다. 그런 다음 팀은 최적화 문제의 목적 함수로 비율 R을 정의하여 가능한 한 크고 균일한 블록을 선택하는 것을 목표로 합니다. 이 블록은 입력된 옷 이미지에 위치하며 잘려서 패치인 옷감 셀을 생성합니다.

클로스 확장 단계에서는 균일한 클로스 확장이 일반 및 불규칙 UV 맵 모두에 적용됩니다. 일반 UV 맵의 경우 옷 영역의 뒷면과 배경을 채우는 데 사용됩니다. 불규칙한 UV 맵의 경우 균질 천 셀의 원래 모양을 사용하여 전체 UV 맵을 완전히 채울 때까지 뒤집고 타일링합니다. 랜드퍼슨과 언리얼퍼슨에서와 같이 단순히 클로스 셀의 크기를 조정하면 텍스처가 흐릿해지고 패턴이 비현실적일 수 있습니다. 이 단계에서는 균일한 클로스 셀의 스케일을 조정하여 옷 텍스처의 일관성을 유지하는 것이 목표입니다.

이러한 방법을 결합하여 팀은 3D 캐릭터에 더 다양한 의상 모델과 스타일을 생성할 수 있습니다.

### 4. Similarity-Diversity Expansion

이 섹션에서는 광범위한 이미지 풀에서 가상 캐릭터를 생성하는 프로세스를 최적화하기 위해 개발한 유사성-다양성 확장 전략에 대해 설명합니다. 이 전략은 샘플의 다양성이 높을수록 일반화 성능이 향상되고, 유사한 이미지를 사용하면 모델 학습이 미묘한 차이에 집중하는 데 도움이 된다는 두 가지 기본 원칙을 활용합니다.

이 전략은 유사하면서도 다양한 캐릭터를 생성하기 위해 2단계 클러스터링 프로세스를 사용합니다. 먼저, 각 클러스터가 유사한 캐릭터를 나타내는 그룹 인물 이미지에 DBSCAN 클러스터링을 적용합니다. 그런 다음 각 클러스터에서 이미지를 샘플링하고 이 이미지에서 의상을 복제하여 3D 캐릭터를 생성합니다. 이 프로세스는 동일한 클러스터 내에서 유사한 캐릭터를 생성하는 동시에 다른 클러스터를 포함하면 캐릭터의 다양성을 증가시킵니다.

클러스터링 프로세스는 피처 맵을 추출하고 인물 이미지 간의 유사도 점수를 계산하는 QAConv 2.0으로 MSMT17 데이터세트에 대해 학습된 모델을 사용하여 수행됩니다. 그런 다음 유사도 정도를 제어하기 위해 다양한 엡실론(ϵ) 파라미터와 함께 DBSCAN 알고리즘을 적용합니다. 첫 번째 클러스터링은 ϵ=0.4로 수행하여 동일한 의상을 입은 동일한 사람을 그룹화합니다.

다음 단계에서는 각 클러스터에서 하나의 이미지(클러스터 중심에 가장 가까운 이미지)를 선택하고 다른 중복 이미지를 제거합니다. 나머지 이미지(첫 번째 라운드에서 클러스터링에 실패한 이미지 포함)로 두 번째 클러스터링 라운드가 수행되며, 이번에는 ϵ=0.5를 사용합니다. 이 라운드에서는 동일한 클러스터 내의 이미지가 시각적으로 유사하지만 일반적으로 다른 사람의 이미지입니다.

마지막으로 클러스터당 7개의 이미지(훈련용 5개, 테스트용 2개)를 선택하여 문자를 생성합니다. 그런 다음 이 캐릭터를 Unity3D로 임포트하여 합성된 인물 이미지를 렌더링합니다. 이 전략을 통해 5,621개의 캐릭터와 887,766개의 이미지가 포함된 ClonedPerson 데이터 세트가 생성되었으며, 이 중 4,826개의 캐릭터에서 763,953개의 이미지가 훈련에, 795개의 캐릭터에서 123,813개의 이미지가 테스트에 사용되었습니다.

### 5. EXPERIMENTS

실험 섹션에서는 세 가지 실제 인물 재식별 데이터 세트(CUHK03, Market-1501, MSMT17)를 활용하여 일반화 성능을 평가합니다. 이 데이터 세트는 다양한 카메라 시점으로 촬영된 다양한 신원을 특징으로 하며, 다양한 이미지를 제공합니다.

![다양한 합성 데이터셋에서의 예시.](Cloning%20Outfits%20from%20Real-World%20Images%20to%203D%20Chara%20c909f9dbf24d457b96e9c14543122f6a/Untitled%205.png)

다양한 합성 데이터셋에서의 예시.

![다른 합성 방법에 대한 질적 비교.](Cloning%20Outfits%20from%20Real-World%20Images%20to%203D%20Chara%20c909f9dbf24d457b96e9c14543122f6a/Untitled%206.png)

다른 합성 방법에 대한 질적 비교.

일반화 가능한 사람 재식별 작업에서 우수한 성능을 보여준 두 개의 합성 데이터세트(RandPerson 및 UnrealPerson)도 비교에 사용되었습니다. 또한 공정한 비교를 위해 랜드퍼슨의 렌더링 설정 일부를 수정하여 조정된 세트를 랜드퍼슨*으로 표시했습니다.

ClonedPerson 데이터 세트의 유효성 검사는 사람 재식별 실험을 통해 이루어집니다. 이 실험에서는 일반화 가능한 사람 재식별과 비지도 도메인 적응(UDA)이라는 두 가지 주요 작업을 수행하며, 모두 MIT 라이선스에 따라 작동하는 QAConv 2.0, TransMatcher, SpCL 방법을 사용합니다.

평가는 단일 쿼리 평가 프로토콜을 따르며, 성능 지표로 누적 매칭 특성(CMC)과 평균 평균 정밀도(mAP)를 사용합니다.

실험 결과, ClonedPerson 데이터 세트는 개인 재식별 작업에서 합성 데이터 세트와 실제 데이터 세트 모두보다 우수한 성능을 보였습니다. ClonedPerson 데이터 세트는 CUHK03 및 Market-1501 데이터 세트에서 UnrealPerson에 비해 특히 우수한 성능을 보였지만, MSMT17 데이터 세트에서도 비슷한 성능을 보였습니다.

저자들은 ClonedPerson 데이터 세트의 성능이 더 좋은 이유로 단순히 데이터 용량이 더 큰 것이 아니라 사람 이미지에서 전체 의상을 복제할 수 있기 때문이라고 설명합니다. 랜드퍼슨과 랜드퍼슨*을 비교한 결과 새로운 렌더링 설정이 더 효과적인 것으로 나타났습니다. 또한 동일한 렌더링 설정의 RandPerson*에 비해 ClonedPerson 데이터 세트는 평균 약 2%의 mAP 개선을 보였습니다.

ClonedPerson 테스트 세트의 모델을 평가한 결과, 데이터 세트 내에서는 만족스러운 결과를 보였지만 데이터 세트 간 평가에서는 만족스럽지 않은 성능을 보였으며, 이는 ClonedPerson 데이터 세트의 독특하고 까다로운 특성을 나타냅니다. 그럼에도 불구하고, MSMT17과 Market-1501은 CUHK03보다 일반화하기에 더 다양하다는 것을 알 수 있습니다.

5.4절에서 저자들은 원본 훈련 데이터와 타겟 테스트 데이터로 ClonedPerson을 사용한 실험에서 비지도 도메인 적응(UDA) 방법인 SpCL을 사용한 방법을 설명합니다. ClonedPerson 훈련 집합의 크기로 인해 SpCL에 사용할 하위 집합을 선택했습니다. 그 결과, ClonedPerson은 UDA 작업에서 랜드퍼슨과 언리얼퍼슨을 모두 능가하는 성능을 보였으며, 특히 CUHK03 데이터세트에서 눈에 띄는 차이를 보였습니다. 그러나 ClonedPerson 자체에 대한 UDA 결과는 좋지 않았으며, 클러스터링 기반 아이덴티티 라벨 추론에 대한 ClonedPerson의 고유한 과제를 강조했습니다.

5.5장에서는 제안된 유사성-다양성 확장 전략과 간단한 무작위 확장 전략을 포함한 다양한 문자 확장 방법의 효과를 분석합니다. 그 결과 선택된 이미지의 수(유사도 증가)와 클러스터의 수(다양성 증가)가 증가함에 따라 성능이 향상되는 것을 발견했습니다. 연구팀은 신원 변화의 영향을 제어하기 위해 유사도와 다양성의 변화를 균형 있게 조정하여 작은 범위 내에서 성능 변동이 발생하도록 하여 가상 데이터 생성에서 유사도와 다양성이 모두 중요하다는 점을 강조했습니다. 텍스처 복제와 캐릭터 생성을 위해 사람 이미지를 무작위로 선택하는 무작위 생성 방식은 제안된 유사도-다양성 확장 전략보다 효율성이 떨어지며, 특히 신원 수가 많을 경우 더욱 그렇습니다.

섹션 5.6에서는 세 가지 방법으로 생성된 캐릭터의 질적 비교를 제시합니다: 랜드퍼슨, 언리얼퍼슨, 그리고 제안된 클론퍼슨입니다. 클론화된 사람 캐릭터가 가장 사실적이었는데, 그 이유는 클론화 파이프라인을 설계했기 때문입니다. HPBTT와 비교한 결과, 제안한 방식이 옷 텍스처가 더 선명하고 또렷하며 뒷모습이 더 좋아 보입니다. 또한, 긴 스커트의 예에서 볼 수 있듯이 HPBTT가 어려움을 겪는 옷 카테고리를 ClonedPerson은 보존합니다.

### 6. CONCLUSION

결론에서 저자는 실제 인물 이미지에서 가상의 3D 캐릭터로 전체 의상을 복제하는 자동 접근 방식을 개발하는 과정을 요약합니다. 핵심 기술은 등록된 의상 매핑과 균질한 옷감 확장을 통해 합성된 인물과 실제 인물 간의 격차를 해소하는 것입니다. 그 결과 이렇게 합성된 인물로 훈련된 모델은 사람 재식별 작업을 위한 향상된 일반화 기능을 제공합니다.

또한 저자는 가상 캐릭터의 수를 확장하기 위한 유사성-다양성 확장 전략을 강조합니다. 저자는 유사성(모델 변별력 향상)과 다양성(모델 일반화 능력 향상)의 증가가 가져다주는 이점에 주목합니다.

저자들은 다양한 유형의 의류 모델 개발과 추가 데이터 소스 활용을 포함한 향후 작업을 제안합니다. 또한 부록에서 이번 연구의 몇 가지 한계점에 대해서도 언급하고 있습니다.