# DiffusionGPT : LLM-Driven Text-to-Image Generation System

[https://arxiv.org/abs/2401.10061](https://arxiv.org/abs/2401.10061)

[https://diffusiongpt.github.io/](https://diffusiongpt.github.io/)

- Jan 2024

![우리는 대규모 언어 모델(LLM)을 활용하여 다양한 유형의 프롬프트 입력을 원활하게 수용하고 출력을 위한 도메인 전문가 모델을 통합하는 통합 생성 시스템인 DiffusionGPT를 제안합니다. 이 시스템은 프롬프트 기반, 명령어 기반, 영감 기반, 가설 기반 입력 유형 등 다양한 형태의 입력을 파싱할 수 있습니다. 우수한 품질의 결과물을 생성할 수 있는 능력을 보여줍니다.](DiffusionGPT%20LLM-Driven%20Text-to-Image%20Generation%20S%208dbc9a8f19bb4c72a0798ec81397f3ab/Untitled.png)

우리는 대규모 언어 모델(LLM)을 활용하여 다양한 유형의 프롬프트 입력을 원활하게 수용하고 출력을 위한 도메인 전문가 모델을 통합하는 통합 생성 시스템인 DiffusionGPT를 제안합니다. 이 시스템은 프롬프트 기반, 명령어 기반, 영감 기반, 가설 기반 입력 유형 등 다양한 형태의 입력을 파싱할 수 있습니다. 우수한 품질의 결과물을 생성할 수 있는 능력을 보여줍니다.

### 1. Introduction

- 최근 이미지 생성 작업에서 확산 모델의 인기가 높아졌으며, DALLE-2, Imagen, Stable Diffusion (SD) 등의 모델이 등장했습니다.
- SDXL은 사실적이고 세부적인 이미지 생성에 탁월합니다.
- SD의 발전과 함께 커뮤니티 플랫폼이 활성화되고 있습니다.
- 그러나 현재의 안정적인 확산 모델들은 모델 한계와 프롬프트 제약으로 인해 실제 시나리오에서 어려움을 겪고 있습니다.
- 이러한 문제를 해결하기 위해 여러 연구가 진행되고 있지만, 아직 완벽한 해결책은 아닙니다.

### 2. Related Work

2.1. 텍스트 기반 이미지 생성

- Generative Adversarial Networks (GANs): 초기에는 GANs를 통한 텍스트 기반 이미지 생성이 주를 이루었습니다.
- 확산 모델의 부상: 그러나 최근에는 텍스트 인코더, 예를 들어 CLIP과 T5와 결합된 확산 모델이 우세해졌습니다.

![DiffusionGPT 개요. DiffusionGPT의 워크플로는 4단계로 구성됩니다: 프롬프트 구문 분석, 모델 구축 및 검색, 모델 선택, 실행 생성의 네 단계로 구성됩니다. 이 네 단계는 왼쪽에서 오른쪽으로 표시되며 LLM과 지속적으로 상호 작용합니다. 위쪽은 각 단계의 세부 프로세스를 보여줍니다. 아래쪽은 전체 워크플로우의 예시를 보여줍니다.](DiffusionGPT%20LLM-Driven%20Text-to-Image%20Generation%20S%208dbc9a8f19bb4c72a0798ec81397f3ab/Untitled%201.png)

DiffusionGPT 개요. DiffusionGPT의 워크플로는 4단계로 구성됩니다: 프롬프트 구문 분석, 모델 구축 및 검색, 모델 선택, 실행 생성의 네 단계로 구성됩니다. 이 네 단계는 왼쪽에서 오른쪽으로 표시되며 LLM과 지속적으로 상호 작용합니다. 위쪽은 각 단계의 세부 프로세스를 보여줍니다. 아래쪽은 전체 워크플로우의 예시를 보여줍니다.

- 특정 모델 사례:
    - DAELL2: CLIP의 이미지 임베딩을 활용하여 고품질 이미지 생성.
    - Stable Diffusion: CLIP의 텍스트 임베딩을 직접 사용하여 이미지 생성.
    - Imagen: 강력한 언어 모델인 T5를 활용하여 텍스트 프롬프트 인코딩, 정확한 이미지 생성.
- 트랜스포머 기반 아키텍처: CogView2와 Muse와 같은 모델이 텍스트 입력에서 이미지 생성에 효과적임을 보여줍니다.
- 인간의 선호도 반영: 최근 방법론들은 보상 신호를 사용하여 훈련된 확산 모델을 제안하고 있으며, 이는 생성된 이미지가 품질 기준을 충족시키는 동시에 인간의 의도와 선호도에 더 밀접하게 맞추려는 노력의 일환이다.

2.2. 비전-언어 작업을 위한 대규모 언어 모델 (LLMs)

- LLMs의 변화: LLMs는 대화형 인터페이스를 통한 인간과의 상호작용에서 뛰어난 능력을 보여주고 있습니다.
- Chain-of-Thought (CoT) 프레임워크: LLMs가 단계별로 답변을 생성하도록 유도하여 최종 답변의 질을 향상시키는 프레임워크입니다.
- LLMs의 확장: 최근 연구들은 LLMs와 외부 도구나 모델을 통합하는 새로운 접근 방식을 탐구하고 있습니다.
    - 예를 들어, Toolformer는 LLMs에 API 태그를 통한 외부 도구 접근 기능을 부여합니다.
    - Visual ChatGPT와 HuggingGPT는 LLMs가 언어의 경계를 넘어서 복잡한 작업을 처리할 수 있도록 다른 모델을 활용합니다.
    - Visual Programming과 ViperGPT는 프로그래밍 언어를 사용하여 시각적 쿼리를 파싱함으로써 LLMs의 시각적 객체 처리 능력을 강화합니다.
- 이러한 노력들에서 영감을 받아, 연구진들은 LLMs를 다재다능한 도구로 활용하고, 이를 통해 T2I(텍스트-이미지) 모델이 고품질 이미지를 생성하도록 유도합니다.

### 3. Methodology

3.1. 프롬프트 파싱

- 주요 역할: 입력된 프롬프트에서 중요한 텍스트 정보를 추출하는 것.
- 프롬프트 유형:
    - 프롬프트 기반: 전체 입력을 프롬프트로 사용합니다.
    - 지시 기반: 지시의 핵심 부분을 프롬프트로 추출합니다.
    - 영감 기반: 영감의 대상을 프롬프트로 사용합니다.
    - 가설 기반: 가설 조건과 행동 대상을 프롬프트로 사용합니다.
- 목적: 사용자가 원하는 핵심 내용을 정확하게 인식하고, 불필요한 텍스트의 영향을 최소화합니다.

![ChatGPT[9]와 상호작용하는 동안의 세부 프롬프트[9]. 그림의 '{}' 슬롯은 ChatGPT에 입력되기 전에 해당 텍스트 값으로 균일하게 대체됩니다.](DiffusionGPT%20LLM-Driven%20Text-to-Image%20Generation%20S%208dbc9a8f19bb4c72a0798ec81397f3ab/Untitled%202.png)

ChatGPT[9]와 상호작용하는 동안의 세부 프롬프트[9]. 그림의 '{}' 슬롯은 ChatGPT에 입력되기 전에 해당 텍스트 값으로 균일하게 대체됩니다.

3.2. 모델의 트리-오브-사우트 (Tree-of-Thought)

- 모델 트리 구축: 모든 모델의 태그 속성을 바탕으로 모델 트리를 자동 구축합니다.
- 주제 및 스타일 도메인: 주제와 스타일 카테고리를 기반으로 두 계층의 계층적 트리 구조를 만듭니다.
- 모델 트리 검색: 주어진 프롬프트에 가장 적합한 모델을 식별하기 위해 트리-오브-사우트 검색 방법을 사용합니다.

3.3. 모델 선택

- 목적: 입력된 프롬프트에 가장 적합한 모델을 선정합니다.
- 과정: 휴먼 피드백과 이점 데이터베이스 기술을 활용하여 모델 선택을 인간의 선호도와 일치시킵니다.
- 이점 데이터베이스: 이전에 생성된 모델 결과에 대한 점수를 기반으로 최적의 모델을 선정합니다.

3.4. 생성 실행

- 프롬프트 확장: 입력된 프롬프트를 풍부하게 만들어 더 높은 품질의 결과를 얻습니다.
- 프롬프트 확장 에이전트: 선택된 모델의 예시 프롬프트를 활용하여 입력된 프롬프트를 보강합니다.

### 4. Experiments

4.1. 설정

- LLM 컨트롤러: ChatGPT의 text-davinci-003 버전을 사용.
- LangChain 프레임워크: LLM의 응답을 지시하고 제어하는 데 사용됨.
- 생성 모델: Civitai와 Hugging Face 커뮤니티에서 다양한 스타일의 인기 있는 모델을 선정함.

![SD1.5 기반 DiffusionGPT와 SD15[16]를 비교했을 때, 사람이나 장면과 같은 범주에 대해 세분화된 수준에서 더 사실적인 결과를 생성하는 데 있어 DiffusionGPT가 더 뛰어나다는 것을 알 수 있습니다. 생성된 이미지는 SD15에 비해 시각적 충실도가 향상되어 더 세밀한 디테일을 포착하고 더 높은 수준의 사실감을 보여줍니다.](DiffusionGPT%20LLM-Driven%20Text-to-Image%20Generation%20S%208dbc9a8f19bb4c72a0798ec81397f3ab/Untitled%203.png)

SD1.5 기반 DiffusionGPT와 SD15[16]를 비교했을 때, 사람이나 장면과 같은 범주에 대해 세분화된 수준에서 더 사실적인 결과를 생성하는 데 있어 DiffusionGPT가 더 뛰어나다는 것을 알 수 있습니다. 생성된 이미지는 SD15에 비해 시각적 충실도가 향상되어 더 세밀한 디테일을 포착하고 더 높은 수준의 사실감을 보여줍니다.

4.2. 질적 결과

1. SD1.5 버전 비교:
    - 기본 모델 SD1.5와 비교하여 DiffusionGPT의 성능 평가.
    - 의미적 정렬과 이미지 미학의 두 가지 측면에서 분석.
    - DiffusionGPT는 기본 모델보다 더 완전한 대상 영역 표현 및 인간 관련 객체에 대한 더 상세하고 정확한 이미지를 생성함.
2. SDXL 버전 비교:
    - SD XL과 비교하여 DiffusionGPT의 성능 평가.
    - DiffusionGPT는 SD XL보다 더 정확하고 시각적으로 매력적인 이미지를 생성함.

![DiffusionGPT의 SDXL 버전과 베이스라인 SDXL[10]의 비교. 생성된 모든 이미지의 크기는 1024×1024픽셀입니다.](DiffusionGPT%20LLM-Driven%20Text-to-Image%20Generation%20S%208dbc9a8f19bb4c72a0798ec81397f3ab/Untitled%204.png)

DiffusionGPT의 SDXL 버전과 베이스라인 SDXL[10]의 비교. 생성된 모든 이미지의 크기는 1024×1024픽셀입니다.

4.3. 양적 결과

- 이미지 보상 및 미학 점수:
    - 기본 버전인 SD1.5와 비교하여 DiffusionGPT의 프레임워크가 이미지 보상 및 미학 점수에서 더 높은 성능을 보임.

![DiffusionGPT의 제거 연구. 무작위 선택은 이미지 생성을 위한 기본 방법입니다. TOT 또는 TOT+HF는 서로 다른 에이전트의 성능을 나타냅니다.](DiffusionGPT%20LLM-Driven%20Text-to-Image%20Generation%20S%208dbc9a8f19bb4c72a0798ec81397f3ab/Untitled%205.png)

DiffusionGPT의 제거 연구. 무작위 선택은 이미지 생성을 위한 기본 방법입니다. TOT 또는 TOT+HF는 서로 다른 에이전트의 성능을 나타냅니다.

4.4. Ablation Study

1. Tree-of-Thought와 인간 피드백:
    - TOT와 HF 모듈을 통합함으로써 생성된 이미지의 품질 개선을 시각적으로 분석.
    - TOT와 HF 모듈을 사용함으로써 현실성, 의미적 일치, 미학적 매력이 향상됨.
2. 프롬프트 확장:
    - 원래 프롬프트와 확장된 프롬프트를 사용한 생성 결과 비교.
    - 확장된 프롬프트는 더 상세하고 미학적으로 향상된 이미지 생성에 기여함.
    
    ![프롬프트 확장에 대한 제거 연구. 이 확장 기능은 더 높은 품질의 이미지를 생성하는 풍부한 프롬프트를 제공하는 것을 목표로 합니다.](DiffusionGPT%20LLM-Driven%20Text-to-Image%20Generation%20S%208dbc9a8f19bb4c72a0798ec81397f3ab/Untitled%206.png)
    
    프롬프트 확장에 대한 제거 연구. 이 확장 기능은 더 높은 품질의 이미지를 생성하는 풍부한 프롬프트를 제공하는 것을 목표로 합니다.
    

4.5. 사용자 연구

- 모델 비교:
    - 기본 모델과 비교하여 DiffusionGPT의 선호도 평가.
    - 100개의 프롬프트에 대해 이미지 생성 후, 20명의 사용자로부터 피드백 수집.
    - 사용자들은 DiffusionGPT가 생성한 이미지를 기본 모델보다 더 높은 품질로 인식함.

4.6. 한계 및 향후 작업

- 피드백 기반 최적화: LLM의 최적화 과정에 피드백을 직접 통합할 계획.
- 모델 후보 확장: 더 인상적인 결과를 얻기 위해 사용 가능한 모델의 범위 확장.
- 텍스트-이미지 작업 넘어서: 컨트롤러 생성, 스타일 마이그레이션, 속성 편집 등 더 넓은 작업 범위에 적용할 계획.

### 5. Conclusion

- Diffusion-GPT는 다양한 프롬프트와 도메인에 걸쳐 우수한 성능을 제공하는 통합 프레임워크입니다.
- 이는 커뮤니티 개발에 효율적이고 효과적인 방법을 제공합니다.