# DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs

[https://arxiv.org/pdf/1606.00915.pdf](https://arxiv.org/pdf/1606.00915.pdf)

[https://arxiv.org/abs/1606.00915](https://arxiv.org/abs/1606.00915)

- 2 Jun 2016

### 1 INTRODUCTION

이 논문에서는 이미지의 각 픽셀을 특정 카테고리로 분류하는 시맨틱 세그먼테이션 작업을 위해 DeepLab이라는 고급 모델을 소개합니다. DeepLab은 이미지 분류 및 객체 감지와 같은 고수준 작업에 탁월한 심층 컨볼루션 신경망(DCNN)을 사용하지만, 의미론적 세분화에 적용하면 특징 해상도 감소, 여러 축척으로 존재하는 객체, 로컬라이제이션 정확도 감소라는 세 가지 문제에 직면하게 됩니다.

![모델 설명. VGG-16이나 ResNet-101과 같은 깊은 합성곱 신경망이 완전히 합성곱 방식으로 사용되어, atrous 합성곱을 이용하여 신호 다운샘플링의 정도를 줄입니다(32x에서 8x로). 양선형 보간 단계는 특징 맵을 원래 이미지 해상도로 확대합니다. 완전 연결된 CRF가 적용되어 세분화된 결과를 세밀하게 수정하고 객체 경계를 더 잘 포착합니다.](DeepLab%20Semantic%20Image%20Segmentation%20with%20Deep%20Conv%206116c05431df4d43ad1c060eda176a65/Untitled.png)

모델 설명. VGG-16이나 ResNet-101과 같은 깊은 합성곱 신경망이 완전히 합성곱 방식으로 사용되어, atrous 합성곱을 이용하여 신호 다운샘플링의 정도를 줄입니다(32x에서 8x로). 양선형 보간 단계는 특징 맵을 원래 이미지 해상도로 확대합니다. 완전 연결된 CRF가 적용되어 세분화된 결과를 세밀하게 수정하고 객체 경계를 더 잘 포착합니다.

특징 해상도 감소는 DCNN의 마지막 몇 개의 최대 풀링 레이어에서 다운샘플링을 제거하고 "아트리스 컨볼루션"이라는 기술을 사용하여 해결할 수 있습니다. 후속 컨볼루션 레이어의 필터는 업샘플링되어 더 높은 해상도의 피처 맵을 제공합니다. 이는 계산 부하나 매개변수 수를 늘리지 않고도 달성할 수 있습니다.

서로 다른 스케일의 오브젝트를 처리해야 하는 문제는 '무감각 공간 피라미드 풀링(ASPP)'이라는 기술을 도입하여 해결합니다. 이 기술은 피처를 리샘플링하는 대신 샘플링 속도가 서로 다른 여러 병렬 아트리스 컨볼루션 레이어를 사용하여 여러 스케일에서 객체와 컨텍스트를 효과적으로 캡처합니다.

세 번째 문제인 로컬라이제이션 정확도 감소는 시맨틱 세분화에 널리 사용되는 완전 연결 조건부 랜덤 필드(CRF)를 사용하여 해결할 수 있습니다. 이를 통해 모델은 클래스 점수를 저수준 픽셀 및 에지 정보와 결합하여 공간 정확도를 개선할 수 있습니다.

딥랩 시스템은 엔비디아 타이탄 X GPU에서 초당 8프레임으로 작동하며, 잘 정립된 두 가지 모듈인 DCNN과 CRF로 구성됩니다. 이 시스템은 여러 가지 까다로운 데이터 세트에서 최첨단 결과를 달성합니다. 또한 새로운 버전의 DeepLab에는 여러 스케일에서 객체를 분할하는 기능이 향상되었으며, 잔여 넷 변형은 성능을 더욱 향상시킵니다.

### 2 RELATED WORK

초기의 시맨틱 분할 시스템은 수작업으로 만든 특징과 부스팅, 랜덤 포레스트, 서포트 벡터 머신과 같은 기본 분류기에 의존했습니다. 하지만 피처의 표현력이 제한적이어서 성능에 한계가 있었습니다.

딥 러닝의 등장으로 의미론적 세분화에 상당한 진전이 이루어졌습니다. 본문에서는 세 가지 주요 유형의 시스템을 소개합니다:

- 캐스케이드 시스템: 이러한 시스템은 먼저 상향식 이미지 세분화 접근 방식을 사용한 다음 심층 컨볼루션 신경망(DCNN)을 사용하여 영역을 분류합니다. 그러나 이러한 시스템의 정확도는 초기 세분화의 정확도에 의해 제약을 받습니다.
- 특징 결합 시스템: 이 시스템은 조밀한 이미지 라벨링을 위해 DCNN 특징을 사용하여 독립적으로 얻은 세그먼테이션과 결합합니다. 그러나 세분화 알고리즘과 DCNN 분류기의 분리로 인해 성급한 결정을 내릴 위험이 있습니다.
- 직접 라벨링 시스템: 이러한 시스템은 DCNN을 직접 적용하여 조밀한 픽셀 레이블을 제공하므로 세분화를 완전히 폐기할 수 있습니다. 이는 전체 이미지에 완전 컨볼루션 DCNN을 적용함으로써 가능해졌지만, 공간적 로컬라이제이션과 관련된 과제를 안고 있습니다.

현재 논의 중인 연구는 이 세 번째 유형의 시스템을 기반으로 하며, 특징 해상도 제어, 다중 스케일 풀링 기법, 조밀하게 연결된 조건부 랜덤 필드(CRF)의 통합과 같은 혁신을 DCNN 위에 도입한 것으로 보입니다. 이 연구는 기존의 DCNN+CRF 조합을 기반으로 하지만, 장거리 종속성을 포착하고 빠른 평균 필드 추론을 가능하게 함으로써 이를 개선한다고 주장합니다.

첫 번째 버전의 작업 이후, 여러 그룹이 시스템의 주요 기능(아트러스 컨볼루션 및 완전 연결 CRF)을 채택하여 PASCAL VOC 2012 시맨틱 세그멘테이션 벤치마크의 결과를 크게 개선했습니다.

주목할 만한 발전으로는 구조화된 예측을 위한 엔드투엔드 훈련, DCNN을 통한 CRF의 쌍별 용어 학습, 평균 필드 추론에 사용되는 양방향 필터링 모듈을 더 빠른 모듈로 대체, 시맨틱 세그멘테이션과 에지 감지의 결합, 약한 감독 탐색 등이 있습니다.

아트리스 컨볼루션은 원래 데시메이션되지 않은 웨이블릿 변환의 계산을 위해 개발된 기법으로, 저자들이 이 분야에 처음 도입했습니다. 이 기법은 해상도를 높이고 더 큰 컨텍스트를 통합하는 데 사용되었으며, 의미적 세분화 외에도 다른 작업에도 적용되고 있습니다.

잔여 네트워크와 같은 고급 DCNN을 시스템에 통합하면 더 나은 결과를 얻을 수 있습니다.

### 3 METHODS

심층 컨볼루션 신경망(DCNN)을 사용한 의미적 분할 작업의 맥락에서 고밀도 특징 추출 및 시야 확대에 대한 아트러스 컨볼루션의 적용에 대해 설명합니다. 주요 요점은 다음과 같습니다:

![1-D에서의 atrous 합성곱 설명. (a) 낮은 해상도의 입력 피처 맵에서의 표준 합성곱으로 희소 피처 추출. (b) 고해상도의 입력 피처 맵에 적용된 atrous 합성곱을 통한 밀집 피처 추출(r = 2).](DeepLab%20Semantic%20Image%20Segmentation%20with%20Deep%20Conv%206116c05431df4d43ad1c060eda176a65/Untitled%201.png)

1-D에서의 atrous 합성곱 설명. (a) 낮은 해상도의 입력 피처 맵에서의 표준 합성곱으로 희소 피처 추출. (b) 고해상도의 입력 피처 맵에 적용된 atrous 합성곱을 통한 밀집 피처 추출(r = 2).

아트리스 컨볼루션 사용: 이 기술은 최대 풀링과 보폭으로 인해 일반적으로 32배까지 감소하는 DCNN에서 특징 맵의 공간 해상도를 유지하는 데 도움이 됩니다. 비선형 컨볼루션 레이어와 달리 비선형 컨볼루션은 추가 메모리와 시간이 필요하지 않습니다. 이 알고리즘의 작동을 통해 원하는 해상도로 모든 레이어의 응답을 계산할 수 있으며 사후에 적용하거나 훈련과 원활하게 통합할 수 있습니다.

![2-D에서의 atrous 합성곱 설명. 위쪽 행: 낮은 해상도의 입력 피처 맵에서의 표준 합성곱으로 희소 피처 추출. 아래쪽 행: 고해상도의 입력 피처 맵에 적용된 atrous 합성곱을 통한 밀집 피처 추출(r = 2).](DeepLab%20Semantic%20Image%20Segmentation%20with%20Deep%20Conv%206116c05431df4d43ad1c060eda176a65/Untitled%202.png)

2-D에서의 atrous 합성곱 설명. 위쪽 행: 낮은 해상도의 입력 피처 맵에서의 표준 합성곱으로 희소 피처 추출. 아래쪽 행: 고해상도의 입력 피처 맵에 적용된 atrous 합성곱을 통한 밀집 피처 추출(r = 2).

아트리스 컨볼루션 계산: 아트리스 컨볼루션은 원래 필터를 한 계수씩 업샘플링하고 필터 값 사이에 0을 도입하여 계산합니다. 이렇게 하면 유효 필터 크기는 증가하지만 위치당 필터 매개변수 및 연산 수는 일정하게 유지됩니다.

![Atrous 공간 피라미드 풀링(ASPP). 중심 픽셀(오렌지색)을 분류하기 위해, ASPP는 다른 비율을 가진 여러 개의 병렬 필터를 사용하여 다중 스케일 피처를 활용합니다. 다른 색으로 표시된 효과적인 시야 필드(Field-Of-Views)가 표시됩니다.](DeepLab%20Semantic%20Image%20Segmentation%20with%20Deep%20Conv%206116c05431df4d43ad1c060eda176a65/Untitled%203.png)

Atrous 공간 피라미드 풀링(ASPP). 중심 픽셀(오렌지색)을 분류하기 위해, ASPP는 다른 비율을 가진 여러 개의 병렬 필터를 사용하여 다중 스케일 피처를 활용합니다. 다른 색으로 표시된 효과적인 시야 필드(Field-Of-Views)가 표시됩니다.

![Untitled](DeepLab%20Semantic%20Image%20Segmentation%20with%20Deep%20Conv%206116c05431df4d43ad1c060eda176a65/Untitled%204.png)

DCNN에서의 적용: 아트리스 컨볼루션은 DCNN의 레이어 체인에서 사용할 수 있으며, 이를 통해 임의의 높은 해상도로 최종 DCNN 네트워크 응답을 계산할 수 있습니다. 아트리스 컨볼루션을 사용하여 계산된 특징 맵의 밀도를 높이고 이중 선형 보간을 사용하여 원래 이미지 해상도로 특징 맵을 복구하는 하이브리드 접근 방식이 채택됩니다. 이 접근 방식은 비선형 컨볼루션 접근 방식과 달리 추가 매개변수를 학습할 필요가 없습니다.

시야 확대: 아트리스 컨볼루션을 사용하면 모든 DCNN 레이어에서 필터의 시야를 확대할 수 있습니다. 파라미터의 수나 계산량을 늘리지 않고도 필터의 커널 크기를 효과적으로 확대할 수 있습니다.

효율적인 구현: 홀을 삽입하여 필터를 암시적으로 업샘플링하거나 입력 특징 맵을 드물게 샘플링하는 두 가지 효율적인 컨볼루션 수행 방법에 대해 설명합니다. 두 번째 방법은 입력 피처 맵을 아트리스 컨볼루션 속도와 동일한 비율로 하위 샘플링하여 디인터레이싱하여 해상도가 감소된 맵을 생성한 다음 이러한 중간 피처 맵에 표준 컨볼루션을 적용하고 원본 이미지 해상도로 다시 인터레이스하는 것입니다.

아트리스 컨볼루션을 사용하면 다양한 해상도에서 신경망 특징 응답을 계산할 수 있으므로 DCNN의 공간 해상도와 시야를 효율적으로 제어할 수 있어 시맨틱 분할과 같은 작업에 유용하게 사용할 수 있습니다.

심층 컨볼루션 신경망(DCNN)은 다양한 크기의 객체가 포함된 데이터 세트를 학습하기 때문에 다양한 스케일을 암시적으로 처리할 수 있습니다. 그러나 객체 규모를 명시적으로 고려하면 성능을 더욱 향상시킬 수 있습니다. 여기에는 두 가지 접근 방식이 사용됩니다:

멀티스케일 처리: 원본 이미지의 스케일이 조정된 여러 버전에서 DCNN 점수 맵을 추출하는 방식입니다. 그런 다음 결과 맵을 보간하고 융합하여 최종 결과를 얻습니다. 이렇게 하면 성능이 크게 향상되지만 계산 비용이 증가합니다.

![Aeroplane에 대한 점수 맵(소프트맥스 함수 전 입력)과 신뢰 맵(소프트맥스 함수의 출력). 각 평균 필드 반복 후의 점수(1행)와 신뢰(2행) 맵을 보여줍니다. 마지막 DCNN 레이어의 출력은 평균 필드 추론의 입력으로 사용됩니다.](DeepLab%20Semantic%20Image%20Segmentation%20with%20Deep%20Conv%206116c05431df4d43ad1c060eda176a65/Untitled%205.png)

Aeroplane에 대한 점수 맵(소프트맥스 함수 전 입력)과 신뢰 맵(소프트맥스 함수의 출력). 각 평균 필드 반복 후의 점수(1행)와 신뢰(2행) 맵을 보여줍니다. 마지막 DCNN 레이어의 출력은 평균 필드 추론의 입력으로 사용됩니다.

R-CNN의 공간 피라미드 풀링 방법에서 영감을 얻은 아트리스 공간 피라미드 풀링. 이 방법은 샘플링 속도가 서로 다른 병렬 아트리스 컨볼루션 레이어를 사용하며, 이 레이어의 특징들을 처리하고 융합하여 최종 결과를 생성합니다.

최대 풀링 레이어가 여러 개 있는 딥 모델이 세부적인 경계를 생성하지 못할 수 있다고 제안합니다. 다른 접근 방식은 DCNN의 인식 기능과 완전히 연결된 조건부 랜덤 필드(CRF)의 로컬라이제이션 정확도를 결합하는 것입니다. 목표는 더 평활화하는 것이 아니라 상세한 로컬 구조를 복구하는 것입니다.

CRF는 전통적으로 노이즈가 많은 세분화 맵을 평활화하는 데 사용되어 왔습니다. 그러나 기존 분류기와 비교했을 때 최신 DCNN은 더 부드럽고 균일한 분류 결과를 생성합니다. 단거리 CRF를 사용하는 것은 지역 구조를 평활화하는 것이 아니라 세부적인 구조를 복구하는 것이 목표이기 때문에 해로울 수 있습니다. 따라서 이 논문에서는 모든 이미지 픽셀 쌍을 연결하고 효율적인 추론을 가능하게 하는 에너지 함수를 사용하는 완전 연결 CRF 모델을 소개합니다.

이 에너지 함수는 DCNN이 계산한 라벨 할당 확률에서 파생된 단항 전위와 두 개의 가우시안 커널을 포함하는 형태를 갖는 쌍 전위를 결합합니다. 첫 번째 커널은 색상과 위치가 비슷한 픽셀에 비슷한 레이블을 적용하고, 두 번째 커널은 평활화를 적용할 때 공간적 근접성만 고려합니다. 이 모델은 효율적인 근사 확률 추론을 가능하게 하며 실제로도 빠릅니다.

### 4 EXPERIMENTAL RESULTS

이 연구에서는 이미지넷에서 사전 학습된 두 가지 널리 사용되는 컨볼루션 신경망 아키텍처인 VGG-16과 ResNet-101을 시맨틱 이미지 분할 작업에 적용합니다. 각 픽셀을 고려 중인 데이터 세트에 존재하는 클래스 중 하나로 분류하도록 미세 조정되었습니다.

연구원들은 4개의 데이터 세트에서 모델을 테스트했습니다: PASCAL VOC 2012, PASCAL-컨텍스트, PASCAL-인물-파트, 도시 풍경. 연구진은 이 모든 데이터 세트에서 경쟁력 있는 결과를 얻었습니다. 성능은 모든 클래스에 걸쳐 평균화된 픽셀 단위 교집합(IOU)으로 측정되었습니다.

PASCAL VOC 2012를 사용한 첫 번째 실험 세트에서는 VGG-16 모델로 시작했습니다. 연구진은 무신경 컨볼루션을 통해 모델의 시야를 조정하고 속도와 성능을 최적화했습니다. 그리고 세분화 정확도를 3~5% 향상시키는 CRF 단계를 도입했습니다.

![PASCAL VOC 2012 val 결과. 입력 이미지와 우리의 DeepLab 결과 (CRF 전/후)](DeepLab%20Semantic%20Image%20Segmentation%20with%20Deep%20Conv%206116c05431df4d43ad1c060eda176a65/Untitled%206.png)

PASCAL VOC 2012 val 결과. 입력 이미지와 우리의 DeepLab 결과 (CRF 전/후)

그런 다음 연구진은 다른 학습 속도 정책, 무감각 공간 피라미드 풀링(ASPP), 심층 네트워크 및 다중 규모 처리 사용과 같은 개선 사항을 도입했습니다. 연구진은 다항식 학습률 감쇠 전략을 사용하면 단계 감쇠 전략보다 모델의 성능이 더 향상된다는 사실을 발견했습니다. ASPP는 다양한 크기의 물체를 캡처하여 세분화 정확도를 향상시켰으며, ResNet-101과 같은 심층 네트워크를 사용하면 특히 물체 경계를 따라 정확도가 향상되었습니다. 또한 MS-COCO 데이터 세트에 대한 모델 사전 학습, 학습 중 데이터 증강, 멀티스케일 융합을 통해 성능이 더욱 향상되었음을 발견했습니다.

![DeepLab-ASPP는 다른 비율을 가진 여러 필터를 사용하여 여러 스케일에서 객체와 컨텍스트를 포착합니다.](DeepLab%20Semantic%20Image%20Segmentation%20with%20Deep%20Conv%206116c05431df4d43ad1c060eda176a65/Untitled%207.png)

DeepLab-ASPP는 다른 비율을 가진 여러 필터를 사용하여 여러 스케일에서 객체와 컨텍스트를 포착합니다.

최종적으로 가장 우수한 모델은 PASCAL VOC 2012 테스트 세트에서 79.7%의 평균 IOU를 달성하여 이전 모델을 능가하는 성능을 보였으며 이 벤치마크에서 현재 최첨단임을 입증했습니다.

이 연구는 사전 학습된 모델 미세 조정, ResNet-101과 같은 최신 아키텍처 사용, ASPP 적용, 학습 속도 조정과 같은 기술을 통해 시맨틱 이미지 분할 작업의 성능을 효과적으로 개선할 수 있음을 보여줍니다.

이 글에서는 다양한 설정과 아키텍처를 가진 DeepLab 프레임워크를 사용해 여러 의미론적 세분화 데이터 세트에 대한 포괄적인 실험 분석을 설명합니다. 여기에는 PASCAL-Context, PASCAL-Person-Part, Cityscapes 데이터 세트가 포함됩니다.

PASCAL-Context: 제안된 모델은 자주 등장하는 59개의 클래스와 배경 클래스를 포함한 60개의 클래스에 대해 평가되었습니다. 저자들은 VGG-16 기반의 LargeFOV 변형을 사용했으며, 나중에 DeepLab용 ResNet-101로 용도를 변경하여 성능을 개선했습니다. 멀티스케일 입력, 결과 병합을 위한 최대 풀링, MS-COCO에 대한 사전 학습을 활용하면 성능이 더욱 향상되었습니다. 최종 모델은 45.7%의 성능을 달성하여 당시의 최첨단 방법을 능가했습니다.

![ASPP에 비해 기본 LargeFOV 모델과 비교한 정성적인 세분화 결과. 다중 큰 FOV를 사용하는 ASPP-L 모델은 여러 스케일에서 객체와 이미지 컨텍스트를 성공적으로 포착할 수 있습니다.](DeepLab%20Semantic%20Image%20Segmentation%20with%20Deep%20Conv%206116c05431df4d43ad1c060eda176a65/Untitled%208.png)

ASPP에 비해 기본 LargeFOV 모델과 비교한 정성적인 세분화 결과. 다중 큰 FOV를 사용하는 ASPP-L 모델은 여러 스케일에서 객체와 이미지 컨텍스트를 성공적으로 포착할 수 있습니다.

![VGG-16 네트워크 또는 ResNet-101 기반 DeepLab 결과 (CRF 전/후). VGG-16에서는 객체 경계에서 정확한 예측을 위해 CRF가 필수적인 반면, ResNet-101은 CRF 전에도 수용 가능한 성능을 보여줍니다.](DeepLab%20Semantic%20Image%20Segmentation%20with%20Deep%20Conv%206116c05431df4d43ad1c060eda176a65/Untitled%209.png)

VGG-16 네트워크 또는 ResNet-101 기반 DeepLab 결과 (CRF 전/후). VGG-16에서는 객체 경계에서 정확한 예측을 위해 CRF가 필수적인 반면, ResNet-101은 CRF 전에도 수용 가능한 성능을 보여줍니다.

![(a) Trimap 예시 (왼쪽 위: 이미지. 오른쪽 위: 지상 사실. 왼쪽 아래: 2 픽셀의 trimap. 오른쪽 아래: 10 픽셀의 trimap). (b) VGG-16 또는 ResNet-101을 사용하고 CRF 전/후에 객체 경계 주변의 밴드 폭에 대한 픽셀 평균 IOU 함수.](DeepLab%20Semantic%20Image%20Segmentation%20with%20Deep%20Conv%206116c05431df4d43ad1c060eda176a65/Untitled%2010.png)

(a) Trimap 예시 (왼쪽 위: 이미지. 오른쪽 위: 지상 사실. 왼쪽 아래: 2 픽셀의 trimap. 오른쪽 아래: 10 픽셀의 trimap). (b) VGG-16 또는 ResNet-101을 사용하고 CRF 전/후에 객체 경계 주변의 밴드 폭에 대한 픽셀 평균 IOU 함수.

![PASCAL-Context 결과. 입력 이미지, 지상 사실, 그리고 우리의 DeepLab 결과 (CRF 전/후).](DeepLab%20Semantic%20Image%20Segmentation%20with%20Deep%20Conv%206116c05431df4d43ad1c060eda176a65/Untitled%2011.png)

PASCAL-Context 결과. 입력 이미지, 지상 사실, 그리고 우리의 DeepLab 결과 (CRF 전/후).

PASCAL-인체-부품: 이 데이터 세트에는 사람에 대한 상세한 부위 주석이 포함되어 있으며, 6개의 클래스와 하나의 배경 클래스로 병합되었습니다. 이 실험은 ResNet-101을 DeepLab과 함께 사용했을 때의 효과에 중점을 두었으며, 그 결과 이전 구성에 비해 상당한 개선이 이루어졌습니다. 멀티스케일 입력과 최대 풀링을 사용하고 MS-COCO에 대한 사전 학습을 통해 성능이 더욱 향상되었습니다. 포스트 프로세싱에 고밀도 CRF를 사용한 것도 상당한 개선을 가져왔습니다.

![PASCAL-Person-Part 결과. 입력 이미지, 지상 사실, 그리고 우리의 DeepLab 결과 (CRF 전/후).](DeepLab%20Semantic%20Image%20Segmentation%20with%20Deep%20Conv%206116c05431df4d43ad1c060eda176a65/Untitled%2012.png)

PASCAL-Person-Part 결과. 입력 이미지, 지상 사실, 그리고 우리의 DeepLab 결과 (CRF 전/후).

도시 풍경: 이 대규모 데이터 세트에는 50개 도시의 거리 장면에 대한 고품질 픽셀 수준 주석이 포함되어 있습니다. 작성자는 테스트 세트와 검증 세트 결과를 모두 보고했습니다. 검증 세트의 경우, 저자는 더 높은 메모리 요구량에도 불구하고 원본 이미지 해상도를 사용하는 것이 이점이 있음을 관찰했습니다. VGG-16에서 ResNet-101로 전환하고, LargeFOV와 비정형 공간 피라미드 풀링(ASPP)을 사용하고, 후처리에 CRF를 사용한 결과 모두 성능이 향상되었습니다. 평가 서버에서 테스트했을 때 가장 우수한 모델은 70.4%의 성능을 달성했습니다.

![Cityscapes 결과. 입력 이미지, 지상 사실, 그리고 우리의 DeepLab 결과 (CRF 전/후).](DeepLab%20Semantic%20Image%20Segmentation%20with%20Deep%20Conv%206116c05431df4d43ad1c060eda176a65/Untitled%2013.png)

Cityscapes 결과. 입력 이미지, 지상 사실, 그리고 우리의 DeepLab 결과 (CRF 전/후).

저자들은 또한 몇 가지 실패 모드를 관찰했는데, 특히 CRF 후처리를 사용해도 모델이 캡처하지 못하는 물체의 섬세한 경계가 있었습니다. 저자는 이 문제를 잠재적으로 완화하기 위해 인코더-디코더 구조의 사용을 조사하기 위한 향후 작업을 제안합니다.

![실패 모드. 입력 이미지, 지상 사실, 그리고 우리의 DeepLab 결과 (CRF 전/후).](DeepLab%20Semantic%20Image%20Segmentation%20with%20Deep%20Conv%206116c05431df4d43ad1c060eda176a65/Untitled%2014.png)

실패 모드. 입력 이미지, 지상 사실, 그리고 우리의 DeepLab 결과 (CRF 전/후).

### 5 CONCLUSION

결론적으로, 저자들의 DeepLab 시스템은 조밀한 특징 추출을 위해 업샘플링된 필터와 함께 아트리스 컨볼루션을 적용하여 의미적 분할을 위한 이미지 분류 네트워크의 용도를 성공적으로 변경했습니다. 또한 다양한 스케일에서 객체와 이미지 컨텍스트를 인코딩할 수 있는 아트리스 공간 피라미드 풀링을 구현하여 이를 더욱 확장합니다. 이 시스템은 의미적으로 정확한 예측과 물체 경계를 따라 상세한 세분화 맵을 생성하기 위해 심층 컨볼루션 신경망과 완전히 연결된 조건부 랜덤 필드의 기술을 결합합니다.

이 시스템은 광범위한 테스트를 거쳤으며, 그 결과 제안된 방법이 여러 가지 까다로운 데이터 세트에서 최첨단 기술을 크게 발전시킨 것으로 나타났습니다. 여기에는 PASCAL VOC 2012 시맨틱 이미지 세분화 벤치마크, PASCAL-Context, PASCAL-Person-Part, Cityscapes 데이터 세트가 포함됩니다.

저자들은 딥랩이 시맨틱 분할 작업을 위한 다목적 고성능 솔루션을 제공하여 이미지 분석 및 이해의 현재 역량을 향상시킨다는 것을 보여줍니다. 하지만 섬세한 물체 경계를 더 정확하게 캡처하는 등 몇 가지 확인된 과제를 해결하기 위한 향후 작업이 필요하다는 점도 인정합니다.

- 모델의 입력과 출력
    
    DeepLab 모델은 원본 이미지를 입력으로 받고, 각 픽셀에 대한 클래스 레이블을 예측하는 세그멘테이션 맵을 출력합니다.
    
    1. **입력**: DeepLab 모델의 입력은 일반적으로 RGB 이미지입니다. 모델은 이 이미지를 받아서 먼저 합성곱 연산을 통해 피처를 추출합니다. 특히, atrous 합성곱은 이미지에서 더 높은 해상도의 피처를 추출할 수 있도록 해주며, 이는 세그멘테이션 작업에서 중요한 역할을 합니다.
    2. **출력**: 이렇게 추출된 피처들은 다음으로 Atrous Spatial Pyramid Pooling (ASPP)을 거치게 됩니다. ASPP는 다른 비율의 atrous 합성곱을 병렬적으로 적용하여, 다양한 스케일에서의 정보를 추출합니다. 이 정보는 이미지의 픽셀마다 레이블을 할당하기 위해 사용됩니다.
        
        마지막으로, 모델의 출력은 세그멘테이션 맵으로, 이는 각 픽셀에 대한 클래스 레이블을 예측한 것입니다. 이 세그멘테이션 맵은 이미지의 객체들을 인식하고, 그 경계를 식별하는 데 도움이 됩니다.
        
    
    추가적으로, CRF(Conditional Random Field)를 통해 출력 세그멘테이션 맵이 더욱 개선될 수 있습니다. CRF는 객체의 경계를 더욱 정확하게 만들고, 예측의 세부 사항을 개선하는 역할을 합니다. 이렇게 해서 최종 출력 세그멘테이션 맵은 각 픽셀에 대한 클래스 레이블을 예측하여, 이미지에 있는 각 객체의 위치와 형태를 표현합니다.
    
- 의의
    
    DeepLab은 기존의 semantic segmentation 방법론과 몇 가지 중요한 점에서 차별화됩니다.
    
    1. **Atrous Convolution**: DeepLab은 이미지의 다운샘플링 정도를 줄이기 위해 atrous (또는 dilated) convolution을 채택했습니다. 이를 통해, DeepLab은 더 높은 해상도의 feature map을 유지하면서, 동시에 receptive field를 확장하여 이미지의 더 넓은 context를 포착할 수 있습니다. 이것은 세그멘테이션 작업에서 중요한 역할을 하는데, 그 이유는 객체의 모양과 크기를 정확하게 인식하고 예측해야 하기 때문입니다.
    2. **Atrous Spatial Pyramid Pooling (ASPP)**: ASPP는 병렬로 구성된 다양한 atrous convolution rate을 사용하여 여러 스케일에서 feature를 추출하는 방법입니다. 이로 인해, 모델은 객체와 이미지 컨텍스트를 다양한 스케일에서 포착할 수 있습니다. 이러한 기능은 다양한 크기와 모양의 객체를 처리하는 데 매우 유용합니다.
    3. **Fully Connected CRF**: DeepLab은 세그멘테이션 결과를 refine하기 위해 fully connected Conditional Random Field (CRF)를 사용합니다. CRF는 높은 해상도의 세부 정보를 복원하고, 객체 경계를 보다 정확하게 만드는 데 도움이 됩니다. 따라서, 세그멘테이션의 정확도가 향상됩니다.
    
    이러한 기술들 덕분에 DeepLab은 다양한 크기와 모양의 객체를 처리하며, 경계를 보다 정확하게 잡아내는 능력을 가지고 있습니다. 따라서 이는 기존의 semantic segmentation 방법론보다 향상된 결과를 가져올 수 있습니다.
    
- 학습 입력과 입력 이미지의 해상도 이슈 (일반론)
    
    이미지 세그멘테이션을 수행할 때, 이미지의 비율이 상하 또는 좌우로 크게 차이가 나는 경우에는 다음과 같은 전략들을 고려할 수 있습니다:
    
    1. **Resizing**: 이미지를 세그멘테이션 모델이 요구하는 입력 크기에 맞게 조정합니다. 이는 가장 간단하고 직관적인 방법이지만, 원본 이미지의 비율이 크게 차이나는 경우에는 이미지의 왜곡이 발생할 수 있습니다.
    2. **Padding**: 이미지의 짧은 측면을 패딩하여 모델의 입력 크기에 맞게 만듭니다. 이 방법은 이미지의 왜곡을 최소화하지만, 패딩된 영역은 세그멘테이션에서 배경으로 처리되어야 하므로 모델의 성능에 영향을 줄 수 있습니다.
    3. **Cropping**: 큰 이미지를 여러 개의 작은 패치로 분할하고, 각 패치에 대해 세그멘테이션을 수행한 후 결과를 다시 합칩니다. 이 방법은 원본 이미지의 왜곡을 방지하고, 더 큰 이미지에 대해 세그멘테이션을 수행할 수 있게 해주지만, 패치 간의 경계에서 세그멘테이션 결과가 일관성을 유지하는 것이 어려울 수 있습니다.
    4. **Multi-scale Segmentation**: 여러 가지 스케일에서 세그멘테이션을 수행하고, 이들 결과를 결합하는 방법입니다. 이 방법은 다양한 크기와 비율의 객체를 처리하는 데 효과적일 수 있습니다.
    5. **Use Models Designed for Arbitrary Aspect Ratios**: 일부 세그멘테이션 모델은 임의의 종횡비를 가진 이미지를 처리할 수 있도록 설계되어 있습니다. 예를 들어, Fully Convolutional Networks (FCN)는 임의의 크기의 이미지를 입력으로 받을 수 있습니다.
    
    이러한 방법 중 어떤 것을 선택할지는 문제의 특성, 사용 가능한 컴퓨팅 리소스, 그리고 특정 애플리케이션에 대한 요구 사항에 따라 달라집니다.