# OneFormer: One Transformer to Rule Universal Image Segmentation

*이 논문에서는 머신러닝 모델의 일종인 트랜스포머와 작업 안내 쿼리를 사용하는 혁신적인 이미지 세분화 프레임워크인 원포머(OneFormer)를 소개합니다. 다양한 세분화 작업(시맨틱, 인스턴스, 파놉틱)을 위해 별도의 모델이 필요했던 기존 방식과 달리, OneFormer는 이러한 작업을 단일 데이터 세트에서 학습된 단일 모델로 통합합니다. 원포머는 각 작업에 대해 개별적으로 학습된 전문 모델보다 성능이 뛰어나 학습 시간, 모델 저장 공간, 컴퓨팅 리소스 측면에서 효율성을 개선합니다. 따라서 이미지 세분화 작업에 더 쉽게 접근할 수 있는 솔루션입니다. 저자들은 이미지 분할 분야의 추가 연구와 발전을 위해 코드와 모델을 공개할 계획입니다.*

[https://arxiv.org/pdf/2211.06220.pdf](https://arxiv.org/pdf/2211.06220.pdf)

[https://arxiv.org/abs/2211.06220](https://arxiv.org/abs/2211.06220)

[https://huggingface.co/spaces/shi-labs/OneFormer](https://huggingface.co/spaces/shi-labs/OneFormer)

- Nov 2022

![Untitled](OneFormer%20One%20Transformer%20to%20Rule%20Universal%20Image%20%20a22270a435124586a6eb7cf22345e284/Untitled.png)

범용 이미지 분할은 시맨틱, 인스턴스, 파놉틱 분할 등 여러 유형의 이미지 분할 작업을 단일 모델로 결합하는 것을 목표로 합니다. 과거에도 파놉틱 아키텍처와 같은 시도가 있었지만 최적의 성능을 달성하기 위해 각 작업에 대해 별도의 학습이 필요했기 때문에 진정한 통합이 이루어지지 못했습니다.

저자들은 단 한 번의 훈련으로 세 가지 유형의 이미지 분할 작업 모두에서 최첨단(SOTA) 성능을 제공하는 범용 이미지 분할 모델인 '원포머'를 제안합니다.

원포머에는 세 가지 핵심 전략이 사용됩니다:

- 작업 조건부 공동 훈련 전략은 단일 멀티태스크 프로세스 내에서 각 세분화 도메인(시맨틱, 인스턴스, 파놉틱)의 기준값에 대한 훈련을 가능하게 합니다.
- '작업 토큰'을 사용하면 모델을 당면한 작업에 맞게 조정할 수 있어 멀티태스크 훈련과 추론을 지원합니다.
- 훈련 중에 쿼리 텍스트 대비 손실이 사용되어 작업과 클래스를 더 잘 구분할 수 있습니다.

원포머는 리소스의 3분의 1을 사용하면서도 여러 데이터 세트의 모든 세분화 작업에서 마스크2포머와 같은 전문 모델보다 뛰어난 성능을 발휘하는 것으로 입증되었습니다. 새로운 ConvNeXt 및 DiNAT 백본을 사용하여 모델의 성능은 더욱 향상되었습니다. 연구원들은 더 많은 연구와 개발을 장려하기 위해 원포머를 오픈 소스로 공개했습니다.

1. Introduction

이미지 분할은 이미지의 픽셀을 세그먼트로 그룹화하는 프로세스입니다. 이러한 세그먼트는 시맨틱 기반(예: 도로, 하늘, 건물) 또는 인스턴스 기반(경계가 명확한 개별 개체)일 수 있습니다. 과거의 접근 방식은 일반적으로 각 작업마다 다른 모델과 아키텍처를 사용하여 이러한 작업을 개별적으로 처리했습니다.

시맨틱 세그멘테이션과 인스턴스 세그멘테이션을 결합하려는 노력은 비정형 배경 영역과 잘 정의된 모양을 가진 오브젝트를 서로 다르게 세그멘테이션하는 파놉틱 세그멘테이션으로 이어졌습니다. 그러나 이로 인해 특수한 파놉틱 아키텍처가 필요하게 되었고, 최적의 성능을 달성하기 위해서는 여전히 각 작업에 대해 개별적인 학습이 필요했습니다.

이미지 분할을 진정으로 통합하기 위해 "OneFormer"라는 새로운 프레임워크가 제안되었습니다. 이 프레임워크는 하나의 파놉틱 데이터 세트에 대해 단 한 번의 훈련만으로 세 가지 세분화 작업(시맨틱, 인스턴스, 파놉틱) 모두에서 다른 모델보다 뛰어난 성능을 발휘합니다.

원포머의 주요 특징:

- 작업 입력 토큰을 사용해 당면한 작업에 따라 모델을 조건화함으로써, 단일 모델을 통해 학습을 위한 가이드 아키텍처와 추론을 위한 동적 아키텍처를 제공합니다.
- 파놉틱 주석에서 의미 및 인스턴스 레이블을 도출하기 때문에 훈련 중에는 파놉틱 데이터만 필요합니다. 따라서 훈련 시간과 스토리지 요구 사항이 최대 3배까지 줄어들어 이미지 세분화의 리소스 집약도가 낮아지고 접근성이 향상됩니다.
- 이 모델은 쿼리에 대한 대비 손실을 포함하는 트랜스포머 접근 방식을 기반으로 하여 모델을 작업에 더 민감하게 만들고 카테고리 오예측을 줄입니다.

원포머는 세 가지 주요 세분화 데이터 세트에서 테스트되었으며, 공동으로 학습된 단일 모델로 세 가지 작업 모두에서 최첨단 성능을 달성했습니다. 이미지 분할 작업의 새로운 기준을 세웠으며 이전의 개별 훈련 방법보다 더 효율적이고 효과적인 것으로 입증되었습니다. 또한 새로운 ConvNeXt 및 DiNAT 백본을 사용하면 성능이 더욱 향상되는 것으로 나타났습니다.

2. Related Work

이미지 처리 및 컴퓨터 비전의 핵심 작업인 이미지 분할은 전통적으로 시맨틱 분할, 인스턴스 분할, 파놉틱 분할의 세 가지 개별 작업으로 이루어집니다.

- 시맨틱 세분화: 이 작업은 처음에는 컨볼루션 신경망(CNN)을 사용하여 픽셀 분류 문제로 처리되었습니다. 최근에는 트랜스포머 기반 방법을 활용하고 있으며, 대표적인 예로 MaskFormer가 있습니다. 이러한 방법은 시맨틱 세그먼테이션을 마스크 분류 문제로 취급합니다.
- 인스턴스 세분화: 인스턴스 세분화를 위한 기존의 방법도 마스크 분류기로 공식화되어 이진 마스크와 각 마스크에 대한 클래스 레이블을 예측합니다.
- 파놉틱 세분화: 인스턴스 및 의미론적 세분화를 통합하기 위해 제안되었습니다. 이러한 모델은 발전에도 불구하고 독립형 인스턴스 및 의미론적 세분화 모델에 비해 성능이 뒤떨어집니다. 따라서 제안된 원포머 모델은 파놉틱 주석으로만 학습하도록 설계되었습니다.

범용 이미지 분할은 오랫동안 사용되어 온 개념으로, 최근에는 시맨틱 및 인스턴스 분할 작업에서도 우수한 성능을 보이는 파놉틱 분할을 위한 유망한 아키텍처가 등장하고 있습니다. 그러나 이러한 아키텍처는 여전히 각 작업에 대해 별도의 학습이 필요하기 때문에 진정한 통합을 이루기에는 부족한 점이 있습니다.

원포머는 단일 범용 모델로 세 가지 이미지 세분화 작업 모두에서 탁월한 성능을 발휘하는 최초의 프레임워크로 제안되었습니다. 이 프레임워크는 물체 감지 및 이미지 분할에 효과적인 트랜스포머 인코더-디코더 구조를 기반으로 합니다. 작업 안내 쿼리에 쿼리-텍스트 대비 손실을 포함하면 모델이 작업 간 차이를 학습하고 카테고리 오예측을 줄이는 데 도움이 됩니다. 다른 작업과 달리 OneFormer는 여러 작업에 초점을 맞추고 훈련 샘플의 기준값 레이블에 있는 클래스를 사용하여 쿼리-텍스트 대비 손실을 계산합니다.

3. Method

"원포머"는 시맨틱, 인스턴스, 파놉틱의 세 가지 유형의 세분화 작업을 수행하도록 설계된 범용 이미지 세분화 모델입니다. 세 가지 작업을 모두 함께 훈련할 경우 성능이 저하되는 경우가 많았던 이전 모델과 달리, 원포머는 작업 조건부 공동 훈련 전략을 사용하여 이 문제를 극복합니다. 이 모델은 이미지와 작업 설명이라는 두 가지 입력을 사용합니다. 작업은 각 이미지에 대해 무작위로 선택되며 해당 레이블은 파놉틱 주석에서 파생됩니다.

![Untitled](OneFormer%20One%20Transformer%20to%20Rule%20Universal%20Image%20%20a22270a435124586a6eb7cf22345e284/Untitled%201.png)

훈련에서 OneFormer는 이미지의 세그먼트에 대한 텍스트 기반 표현과 이미지 기반 표현이라는 텍스트 및 객체 쿼리를 사용합니다. 모델에 세 가지 작업 간의 차이점을 학습시키기 위해 객체 쿼리와 텍스트 쿼리 간에 대비 손실이 계산됩니다. 이 손실은 모델이 작업 간의 구분을 학습하는 데 도움이 되며 카테고리 오분류가 줄어듭니다.

원포머의 아키텍처에는 특징 추출을 위한 백본 및 픽셀 디코더와 다양한 해상도의 특징으로 객체 쿼리를 업데이트하는 멀티스케일 트랜스포머 디코더가 포함되어 있습니다. 최종 클래스 및 마스크 예측은 업데이트된 쿼리를 기반으로 이루어집니다. 최종 손실 함수는 쿼리에 대한 대비 손실, 분류 교차 엔트로피 손실, 마스크 예측에 대한 이진 교차 엔트로피와 주사위 손실의 조합으로 이루어집니다. 이러한 접근 방식을 통해 원포머는 세 가지 세분화 작업 각각에 대해 개별적으로 학습된 모델보다 더 나은 성능을 발휘할 수 있습니다.

4. Experiments

이 연구에서는 세 가지 데이터 세트를 사용하여 이미지 세분화 작업에서 원포머 모델의 성능에 대해 설명합니다: 도시 풍경, ADE20K, COCO. 작업 조건부 공동 훈련 전략으로 한 번만 훈련된 OneFormer는 시맨틱, 인스턴스, 파놉틱 세분화 작업에 잘 일반화됩니다. 성능은 PQ, AP, mIoU 점수를 사용하여 측정됩니다.

연구 결과, 원포머는 세 가지 데이터 세트 모두에서 기존의 최신 아키텍처보다 성능이 뛰어난 것으로 나타났습니다. 원포머는 ADE20K 및 시티스케이프 데이터세트에서 새로운 성능 표준을 수립했습니다. COCO 데이터 세트에서는 개별적으로 훈련된 모델과 비슷한 성능을 보였으며, PQ 점수는 약간 개선되었습니다.

원포머의 구성 요소의 중요성을 분석하기 위해 일련의 제거 연구를 수행했습니다. 작업 토큰, 학습 가능한 텍스트 컨텍스트, 작업 안내 쿼리 초기화가 높은 성능에 중요한 것으로 밝혀졌습니다. 이 연구는 또한 대조 쿼리 손실과 텍스트 목록의 항목에 대한 텍스트 템플릿 선택의 중요성도 강조했습니다.

공동 훈련 전략과 원포머 모델의 설계는 마스크2포머-조인트 기준선에 비해 성능이 크게 개선된 것으로 나타났습니다. 이 모델은 작업 토큰 입력에 민감하게 반응하여 작업 간 구분을 동적으로 학습하는 것으로 나타났는데, 이는 한 번 훈련으로 여러 작업을 수행하는 아키텍처에 매우 중요한 요소입니다.

![텍스트 매퍼. 6계층 트랜스포머 텍스트 인코더[49, 57]를 사용하여 입력 텍스트 목록(T패드)을 토큰화한 다음 인코딩하여 Ntext 임베딩 집합을 얻습니다. 인코딩된 표현에 Nctx 학습 가능한 임베딩 세트를 연결하여 다음을 얻습니다. 최종 N개의 텍스트 쿼리(Qtext)를 얻습니다. N개의 텍스트 쿼리는 이미지에 존재하는 객체의 텍스트 기반 표현을 나타냅니다.](OneFormer%20One%20Transformer%20to%20Rule%20Universal%20Image%20%20a22270a435124586a6eb7cf22345e284/Untitled%202.png)

텍스트 매퍼. 6계층 트랜스포머 텍스트 인코더[49, 57]를 사용하여 입력 텍스트 목록(T패드)을 토큰화한 다음 인코딩하여 Ntext 임베딩 집합을 얻습니다. 인코딩된 표현에 Nctx 학습 가능한 임베딩 세트를 연결하여 다음을 얻습니다. 최종 N개의 텍스트 쿼리(Qtext)를 얻습니다. N개의 텍스트 쿼리는 이미지에 존재하는 객체의 텍스트 기반 표현을 나타냅니다.

마지막으로 원포머의 쿼리-텍스트 대비 손실은 작업 간 구분을 학습하는 데 도움이 되었으며, 카테고리 오분류의 수를 줄여 유사한 클래스가 있는 영역에서 더 정확한 예측을 이끌어냈습니다.

5. Conclusion

이 연구에서는 새로운 멀티태스크 범용 이미지 세분화 프레임워크인 OneFormer를 소개합니다. 원포머는 트랜스포머와 작업 안내 쿼리를 사용해 시맨틱, 인스턴스, 파놉틱 세분화를 단일 데이터 세트에서 한 번만 학습되는 단일 아키텍처로 결합합니다.

원포머는 개별적으로 훈련된 전문 모델보다 성능이 뛰어나 주요 데이터 세트에서 이미지 세분화 작업을 위한 최첨단 단일 아키텍처 모델입니다. 따라서 훈련 시간, 가중치 저장 및 추론 호스팅 요구 사항을 3분의 2로 줄여 이미지 세분화에 더 쉽게 접근할 수 있습니다.

이 연구를 주도한 팀은 원포머가 보편적이고 접근하기 쉬운 이미지 세분화를 향한 중요한 단계로 보고 있습니다. 이 분야의 추가 연구를 지원하기 위해 코드와 모델을 오픈소스화할 계획입니다.

- 시멘틱분할
    
    시맨틱 분할은 이미지의 모든 픽셀에 레이블을 할당하는 것이 목표인 컴퓨터 비전의 작업입니다. 이 레이블은 '사람', '자동차', '나무' 등과 같이 픽셀이 속한 카테고리 또는 클래스를 나타냅니다.
    
    예를 들어 거리 풍경 이미지가 있는 경우, 해당 이미지의 의미론적 세분화는 어떤 픽셀이 도로에 속하는지, 어떤 픽셀이 자동차에 속하는지, 어떤 픽셀이 보행자에 속하는지 등을 식별할 수 있습니다.
    
    의미적 세분화에서 주목해야 할 점은 같은 클래스의 다른 인스턴스를 구분하지 않는다는 것입니다. 예를 들어 이미지에 두 대의 자동차가 있는 경우 시맨틱 세그멘테이션은 두 대의 자동차를 구분하지 않고 두 대의 자동차에 속한 모든 픽셀을 "자동차"로 레이블을 지정합니다.
    
    이러한 유형의 세분화는 자율 주행, 의료 영상, 이미지 편집 등 많은 애플리케이션에서 널리 사용됩니다. 픽셀 수준에서 이미지를 이해하는 데 도움이 되며 장면에 대한 포괄적인 이해를 제공합니다.
    
- 인스턴스 분할
    
    인스턴스 분할은 이미지에 나타나는 각각의 개별적인 관심 대상을 식별하고 묘사하는 컴퓨터 비전 작업입니다. 이미지에서 객체를 식별하는 것이 목표인 객체 감지와 이미지의 각 픽셀을 분류하는 것이 목표인 시맨틱 세그먼테이션의 조합으로 볼 수 있습니다.
    
    즉, 인스턴스 분할은 시맨틱 분할과 마찬가지로 이미지의 각 픽셀을 분류할 뿐만 아니라 동일한 유형의 객체에 대한 개별 인스턴스도 구분합니다. 예를 들어 이미지에 여러 대의 자동차가 있는 경우 인스턴스 세분화 모델은 각 자동차를 개별적으로 식별하여 각 자동차의 픽셀에 고유한 레이블을 할당합니다.
    
    따라서 두 대의 자동차가 있는 거리 장면 이미지가 있는 경우 인스턴스 세분화는 시맨틱 세분화와 같이 두 자동차에 속한 모든 픽셀에 "자동차"라는 레이블을 지정할 뿐만 아니라 "자동차 1"과 "자동차 2"도 구분합니다.
    
    이 수준의 세부 세분화는 여러 개체가 겹치거나 상호 작용하는 이미지에서 특히 유용합니다. 인스턴스 세분화는 각 객체를 독립적으로 식별하는 것이 중요한 자율 주행, 로봇 공학, 비디오 감시 등 다양한 분야에서 활용되고 있습니다.
    
- 파놉틱 분할
    
    파놉틱 분할은 시맨틱 분할과 인스턴스 분할의 개념을 결합한 컴퓨터 비전 작업입니다. 이미지의 각 픽셀에 클래스 레이블을 지정하고(시맨틱 세분화), 같은 클래스의 여러 인스턴스를 구분하는(인스턴스 세분화) 작업이 포함됩니다.
    
    ![Untitled](OneFormer%20One%20Transformer%20to%20Rule%20Universal%20Image%20%20a22270a435124586a6eb7cf22345e284/Untitled%203.png)
    
    자세한 내용은 다음과 같습니다:
    
    - 시맨틱 세분화: 여기에는 이미지의 모든 픽셀에 클래스 레이블을 지정하는 작업이 포함됩니다. 예를 들어 자동차에 속한 픽셀은 '자동차', 건물에 속한 픽셀은 '건물'로 레이블을 지정하는 식입니다.
    - 인스턴스 세분화: 여기에는 이미지에서 관심 있는 각각의 개체를 식별하고 묘사하여 각 개별 개체에 고유한 레이블을 할당하는 작업이 포함됩니다. 예를 들어 이미지에 세 대의 자동차가 있는 경우 "자동차 1", "자동차 2", "자동차 3"으로 레이블이 지정됩니다.
    
    파놉틱 세분화의 목표는 이 두 가지 접근 방식을 결합하여 이미지의 모든 픽셀에 클래스 레이블과 고유 인스턴스 레이블을 지정하는 것입니다.
    
    따라서 같은 예를 들어 파놉틱 세분화에서는 자동차에 속한 모든 픽셀이 "자동차"로 레이블이 지정될 뿐만 아니라 각 개별 자동차도 "자동차 1", "자동차 2", "자동차 3"으로 명확하게 레이블이 지정됩니다. 동시에 뚜렷한 물체가 없을 수 있는 배경에 속한 모든 픽셀에도 시맨틱 세그멘테이션과 유사하게 "도로", "하늘" 등의 레이블이 지정됩니다.
    
    따라서 파놉틱 세그멘테이션은 전체 장면을 이해하는 보다 포괄적인 이미지 세그멘테이션 방법입니다. 특히 자율 주행과 같이 같은 유형의 여러 물체(예: 자동차, 보행자)를 식별하고 구분해야 하며 장면의 다른 모든 픽셀도 분류해야 하는 분야에서 유용합니다.