# ImageDream: Image-Prompt Multi-view Diffusion for 3D Generation

[https://arxiv.org/abs/2312.02201](https://arxiv.org/abs/2312.02201)

[https://image-dream.github.io/](https://image-dream.github.io/)

- Dec 2023

![ImageDream은 단일 이미지가 주어지면 모든 관점에서 고품질 3D 모델을 생성하는 새로운 프레임워크입니다. 이 프레임워크는 이전의 SoTA(예: Magic123[31])에 비해 3D 지오메트리 품질을 크게 향상시키며, 무엇보다도 생성된 이미지 프롬프트에서 텍스트 이미지 정렬이 우수하여 MVDream[37]과 비교할 때 훨씬 더 우수합니다. 여기에서는 다양한 방법으로 생성된 객체의 8가지 보기를 제공하며, 마지막 행에는 ImageDream으로 생성된 모델로 렌더링된 해당 노멀 맵을 표시합니다.](ImageDream%20Image-Prompt%20Multi-view%20Diffusion%20for%203%205c85d3d57f1c46148f4f4df95961596e/Untitled.png)

ImageDream은 단일 이미지가 주어지면 모든 관점에서 고품질 3D 모델을 생성하는 새로운 프레임워크입니다. 이 프레임워크는 이전의 SoTA(예: Magic123[31])에 비해 3D 지오메트리 품질을 크게 향상시키며, 무엇보다도 생성된 이미지 프롬프트에서 텍스트 이미지 정렬이 우수하여 MVDream[37]과 비교할 때 훨씬 더 우수합니다. 여기에서는 다양한 방법으로 생성된 객체의 8가지 보기를 제공하며, 마지막 행에는 ImageDream으로 생성된 모델로 렌더링된 해당 노멀 맵을 표시합니다.

### 1. Introduction

이 논문에서는 텍스트만 사용하는 방법과 비교하여 3D 생성에 이미지를 사용할 때의 이점을 살펴봅니다. 이미지는 텍스처, 색상, 공간 관계 등 텍스트만으로는 정확하게 설명하기 어려운 풍부한 시각적 디테일을 제공합니다. 따라서 이미지가 명확한 시각적 참조를 제공하기 때문에 더욱 정확하고 세밀한 3D 모델을 만들 수 있습니다. 또한 이미지를 사용하면 특히 말로 설명하기 어려운 아이디어를 더 쉽게 전달할 수 있습니다.

하지만 3D 생성에 이미지를 통합하는 데는 여러 가지 어려움이 따릅니다. 이미지에는 색상과 질감 등 다양한 특징이 포함되어 있기 때문에 이미지를 분석하는 것은 복잡합니다. 조명, 모양, 오클루전의 불일치로 인해 3D 모델이 흐릿하거나 불완전할 수 있습니다. 이러한 시각적 단서를 정확하게 처리하고 여러 뷰에서 일관성을 유지하려면 고급 알고리즘이 필요합니다.

연구에 따르면 이미지 기반 솔루션은 시각적으로 인상적인 모델을 만들 수 있지만, 특히 원본 이미지에서 보이지 않는 물체 부분의 경우 기하학적 정확도와 디테일한 텍스처가 부족한 경우가 많다고 합니다. 이는 합성된 뷰의 기하학적 불일치로 인해 최종 모델에서 평균적으로 일치하지 않는 픽셀이 발생하기 때문입니다.

이미지 조건부 3D 생성은 이러한 제약으로 인해 텍스트 조건부 생성보다 더 복잡합니다. 예를 들어, 텍스트 설명으로 말을 생성할 때 훈련 데이터 세트에 다양한 스타일이 있는 경우 상세한 모델을 생성할 수 있습니다. 그러나 이미지가 특정 텍스처와 모양을 지정하는 경우 생성된 모델에서 이러한 세부 사항을 유지하기가 어렵습니다.

이 논문에서는 이러한 문제를 해결할 수 있는 솔루션인 ImageDream을 소개합니다. 이 솔루션은 서로 다른 객체 인스턴스에 걸쳐 표준 카메라 조정과 기존 아키텍처에 통합된 다단계 이미지 프롬프트 컨트롤러를 사용합니다. 이 접근 방식은 입력 이미지의 변화를 3D로 매핑하는 작업을 간소화하고 이미지 입력에서 각 아키텍처 블록에 이르는 확산 모델을 계층적으로 제어할 수 있습니다. 이미지드림은 정성적, 정량적 분석을 통해 기존 방식에 비해 정확한 지오메트리와 텍스처 품질을 가진 오브젝트를 생성하는 데 있어 우수한 성능을 보였습니다.

### 2. Related Works

이 논문에서는 3D 생성 분야의 중요한 발전에 대한 개요를 제공하며, 특히 본 연구의 연구와 밀접한 관련이 있는 분야에 중점을 두고 있습니다.

확산을 이용한 텍스트-3D 생성

이 분야는 생성적 적대 신경망(GAN)을 사용하는 것에서 3D 생성을 위한 확산 기반 프레임워크로 발전해 왔습니다. 초기의 방법은 멀티뷰 렌더링 이미지를 사용하여 단순한 물체를 재구성하는 것이었습니다. 그러나 최근의 3D 확산 모델은 특정 오브젝트에 초점을 맞추는 경향이 있어 이러한 모델을 광범위한 오브젝트에 일반화하는 데 한계를 보이고 있습니다. 이러한 한계는 3D 데이터 크기, 표현 및 아키텍처 설계의 문제에서 기인합니다.

3D 생성을 위한 2D 확산 해제

3D 생성을 위해 2D 확산 모델을 사용하는 방법에 대한 연구가 진행되어 왔으며, 종종 NeRF와 같은 3D 표현과 통합되기도 합니다. 주목할 만한 기술로는 확산 전제를 사용하여 3D 표현 최적화를 유도하는 점수 증류 샘플링(SDS)이 있습니다. 이러한 방법은 직접적인 3D 데이터 학습 없이도 사실적인 오브젝트를 생성할 수 있지만 멀티뷰 일관성 문제가 있으며 각 모델에 대한 개별적인 최적화가 필요합니다. 예를 들어 MVDream은 2D 및 3D 데이터 세트와의 공동 학습을 통해 개선된 결과를 보여주었습니다.

이미지 기반의 새로운 뷰 합성

또 다른 관심 분야는 기존의 재구성 프로세스를 거치지 않고 단일 이미지에서 새로운 3D 뷰를 직접 합성하는 것입니다. 상당한 발전이 있었지만, 특정 훈련 데이터에 의존하고 다양한 이미지 입력에 적응하지 못한다는 공통적인 한계가 있습니다. 제로123과 같은 노력과 후속 개발은 멀티뷰 일관성을 향상시키는 것을 목표로 했지만, 기하학적으로 일관된 3D 모델을 재구성하는 데는 여전히 어려움이 있습니다.

단일 이미지 컨디셔닝 재구성

이 분야의 최근 발전은 단일 또는 소수의 이미지에서 3D 모델을 도출하기 위해 NeRF 표현을 활용합니다. RegNeRF, SinNeRF, RealFusion, NeuralLift와 같은 기술은 가능성을 보이지만, 생성된 모델의 품질은 실제 애플리케이션에 사용하기에는 아직 최적이 아닙니다. 단일 뷰와 새로운 뷰 확산 네트워크를 결합한 Magic123은 인상적인 텍스처 품질을 구현하지만 정확한 물체 형상을 구현하는 데 어려움을 겪습니다.

요약하자면, 3D 생성 분야는 확산 기반 프레임워크의 도입과 2D 및 3D 데이터의 통합으로 상당한 발전을 이루었습니다. 그러나 생성된 모델의 일반화 가능성, 멀티뷰 일관성, 기하학적 일관성을 달성하는 데는 여전히 과제가 남아 있습니다. 이 연구의 접근 방식은 이러한 개념을 기반으로 하며, 특히 이미지 프롬프트 생성에 중점을 둡니다.

### 3. Methodology

방법론 섹션에서는 3D 모델 생성을 위해 이미지 프롬프트를 MVDream[37] 파이프라인에 통합하기 위해 취한 접근 방식에 대해 설명합니다.

예비 단계

MVDream은 3D 모델 제작을 위해 2단계 프로세스를 사용합니다. 첫 번째 단계는 다양한 카메라 시점을 고려하여 텍스트 프롬프트에서 일관된 멀티뷰 이미지를 생성하는 멀티뷰 확산 네트워크를 훈련하는 것입니다. 두 번째 단계에서는 멀티뷰 점수 증류 샘플링(MV-SDS)을 사용하여 상세한 3D NeRF 모델을 생성합니다. 네트워크는 렌더링된 데이터 세트와 대규모 텍스트-이미지 데이터 세트를 결합한 공동 데이터 세트로 훈련됩니다. 이러한 훈련을 통해 네트워크는 서로 다른 뷰 간의 관계를 학습하고 모델의 일반화 가능성을 유지할 수 있습니다.

![ImageDream의 훈련 파이프라인. 파란색 화살표는 확산 네트워크의 훈련을, 녹색 화살표는 NeRF 모델의 훈련을 나타냅니다. 확산 훈련에서는 3D 오브젝트가 주어지면 먼저 표준 카메라 조정을 기반으로 다중 뷰를 렌더링하고(아래쪽), 무작위 설정으로 또 다른 이미지 프롬프트 전면 뷰 이미지를 렌더링합니다(위쪽). 멀티뷰 이미지는 멀티뷰 확산 네트워크의 훈련 대상으로 제공되며, 이미지 프롬프트는 멀티레벨 컨트롤러를 통해 확산에 대한 입력으로 인코딩됩니다. NeRF 훈련에서는 훈련된 확산을 이미지 프롬프트 점수 증류에 사용합니다.](ImageDream%20Image-Prompt%20Multi-view%20Diffusion%20for%203%205c85d3d57f1c46148f4f4df95961596e/Untitled%201.png)

ImageDream의 훈련 파이프라인. 파란색 화살표는 확산 네트워크의 훈련을, 녹색 화살표는 NeRF 모델의 훈련을 나타냅니다. 확산 훈련에서는 3D 오브젝트가 주어지면 먼저 표준 카메라 조정을 기반으로 다중 뷰를 렌더링하고(아래쪽), 무작위 설정으로 또 다른 이미지 프롬프트 전면 뷰 이미지를 렌더링합니다(위쪽). 멀티뷰 이미지는 멀티뷰 확산 네트워크의 훈련 대상으로 제공되며, 이미지 프롬프트는 멀티레벨 컨트롤러를 통해 확산에 대한 입력으로 인코딩됩니다. NeRF 훈련에서는 훈련된 확산을 이미지 프롬프트 점수 증류에 사용합니다.

표준 카메라

MVDream의 주요 관찰 사항은 전역적으로 정렬된 카메라 조정을 사용하는 것으로, 기본 카메라 뷰는 항상 물체의 전면 뷰입니다. 이 정렬은 확산된 이미지의 융합을 단순화하고 물체 형상을 정확하게 재구성하는 데 도움이 됩니다. MVDream의 확장 버전인 ImageDream은 이 표준 카메라 정렬을 채택하여 상대 카메라 정렬을 사용하는 시스템에 비해 우수한 기하학적 정확도를 달성할 수 있을 것으로 기대합니다.

멀티 레벨 컨트롤러

이 방법론은 글로벌, 로컬, 픽셀 컨트롤러로 구성된 이미지 프롬프트를 통합하기 위한 멀티 레벨 전략을 도입합니다. 글로벌 컨트롤러는 글로벌 클립 이미지 기능을 MVDream 프레임워크에 통합하여 이미지 기능을 텍스트 기능에 맞게 조정합니다. 로컬 컨트롤러는 클립 인코더의 숨겨진 피처를 사용하여 보다 자세한 구조 정보를 제공합니다. 특징의 균형을 맞추기 위해 리샘플링 모듈이 구현됩니다. 픽셀 컨트롤러는 ImageDream의 모든 관심 레이어에 잠재된 이미지 프롬프트 픽셀을 임베드하여 멀티뷰 일관성을 유지하면서 입력 이미지의 통합을 향상시킵니다. 이 접근 방식은 생성된 멀티뷰 이미지가 입력 이미지의 모양을 유지하고 MVDream의 특성과 일관성을 유지하도록 보장합니다.

![ImageDream의 다단계 컨트롤러. 이미지 프롬프트가 주어지면 글로벌 컨트롤러와 로컬 컨트롤러는 CLIP 인코딩 후 이미지 특징을 입력받은 다음 적응된 특징을 교차 주의 레이어에 출력합니다. 이는 이미지 시맨틱 정보를 나타냅니다. 픽셀 컨트롤러는 VAE 인코딩된 특징을 디퓨전으로 보내고, 4뷰 MVDiffusion의 각 레이어에서 해당 숨겨진 특징을 사용하여 픽셀 수준의 고밀도 셀프 어텐션을 수행합니다.](ImageDream%20Image-Prompt%20Multi-view%20Diffusion%20for%203%205c85d3d57f1c46148f4f4df95961596e/Untitled%202.png)

ImageDream의 다단계 컨트롤러. 이미지 프롬프트가 주어지면 글로벌 컨트롤러와 로컬 컨트롤러는 CLIP 인코딩 후 이미지 특징을 입력받은 다음 적응된 특징을 교차 주의 레이어에 출력합니다. 이는 이미지 시맨틱 정보를 나타냅니다. 픽셀 컨트롤러는 VAE 인코딩된 특징을 디퓨전으로 보내고, 4뷰 MVDiffusion의 각 레이어에서 해당 숨겨진 특징을 사용하여 픽셀 수준의 고밀도 셀프 어텐션을 수행합니다.

![ImageDream의 다양한 멀티레벨 컨트롤러 설정에 따른 확산 결과의 예시(3.3절 참조).](ImageDream%20Image-Prompt%20Multi-view%20Diffusion%20for%203%205c85d3d57f1c46148f4f4df95961596e/Untitled%203.png)

ImageDream의 다양한 멀티레벨 컨트롤러 설정에 따른 확산 결과의 예시(3.3절 참조).

이미지 프롬프트 점수 증류
ImageDream은 배경 및 카메라 정렬을 조정하여 MVDream의 멀티뷰 점수 증류 프레임워크에 따라 이미지 프롬프트 멀티뷰 확산 네트워크를 구현합니다. NeRF 렌더링 이미지에는 아티팩트를 방지하기 위해 이미지 프롬프트와 일치하는 배경색이 포함됩니다. 카메라 매개변수도 일반적인 사용자 사진 설정과 일치하도록 조정되어 기하학적 정확도가 향상됩니다. 그러나 이미지 프롬프트의 카메라 매개변수가 선택한 범위와 크게 다를 경우에는 한계가 있습니다.

![이미지 프롬프트 점수 증류로 수정한 아티팩트 예시(3.4절 참조).](ImageDream%20Image-Prompt%20Multi-view%20Diffusion%20for%203%205c85d3d57f1c46148f4f4df95961596e/Untitled%204.png)

이미지 프롬프트 점수 증류로 수정한 아티팩트 예시(3.4절 참조).

요약하면, 이 방법론은 다단계 컨트롤러와 점수 증류 조정을 사용하여 이미지 프롬프트를 MVDream 파이프라인에 통합하여 기하학적으로 정확하고 입력 이미지와 일관된 3D 모델을 생성하는 것을 목표로 합니다.

### 4. Experiments

실험 섹션에서는 구현 세부 사항, 테스트 데이터 세트, 비교 및 제한 사항을 포함하여 ImageDream에 사용된 설정 및 평가 방법에 대해 간략하게 설명합니다.

구현 세부 사항

ImageDream 모델은 3D 멀티뷰 렌더링을 위한 Objaverse의 데이터 세트와 2D 이미지 데이터 세트를 결합하여 훈련했습니다. 훈련에는 이미지 프롬프트의 무작위 선택 및 탈락이 포함되었으며, AdamW 옵티마이저를 사용하여 수행되었습니다. 학습 속도는 사용된 컨트롤러에 따라 조정되었으며, 훈련에는 8개의 A100 GPU에서 약 이틀이 소요되었습니다. NeRF 최적화를 위해 3단계 최적화 프로세스가 사용되었으며, 훈련에는 약 1시간이 소요되었습니다.

테스트 데이터 세트

테스트 데이터 세트는 복잡한 지오메트리와 외관을 가진 다양한 오브젝트를 포함하는 MVDream에서 잘 선별된 39개의 프롬프트로 구성되었습니다. 이미지는 배경을 제거하고 오브젝트의 중심을 다시 맞춘 SDXL을 사용하여 생성되었습니다.

비교

이미지드림은 제로123-XL, Magic123, 싱크드리머 등 여러 최신 기준선과 비교되었습니다. 지오메트리 품질과 이미지 프롬프트와의 유사성 측면에서 비교가 이루어졌습니다. 정성적 평가를 위해 사용자 연구를 실시했는데, 참가자들은 특히 픽셀 컨트롤러가 있는 ImageDream 모델을 선호했습니다. 수치적 평가에는 이미지 품질과 텍스트-이미지 정렬을 평가하는 시작 점수(IS)와 CLIP 점수가 포함되었습니다. ImageDream 모델은 확산 단계와 3D 융합 후 단계 모두에서 높은 이미지 품질을 유지했으며 이미지 CLIP 점수에서 우수한 결과를 보였습니다.

![서로 다른 기준선에서 합성된 이미지의 그림. 확산: 확산 모델에서. 재구성: 해당 융합 NeRF 모델에서 다시 렌더링한 이미지. 더 많은 결과는 웹페이지에서 확인하세요.](ImageDream%20Image-Prompt%20Multi-view%20Diffusion%20for%203%205c85d3d57f1c46148f4f4df95961596e/Untitled%205.png)

서로 다른 기준선에서 합성된 이미지의 그림. 확산: 확산 모델에서. 재구성: 해당 융합 NeRF 모델에서 다시 렌더링한 이미지. 더 많은 결과는 웹페이지에서 확인하세요.

한계점

뛰어난 성능에도 불구하고 ImageDream은 전신 아바타의 작은 얼굴 디테일을 캡처하는 것과 같이 이미지 제약이 지나치게 엄격한 경우 한계를 보였습니다. 픽셀 컨트롤러 모델은 이미지 내재적 및 외재적 속성을 더 잘 추정해야 하며, 이는 다단계 컨트롤러 내에서 밸런스 조정의 필요성을 시사합니다. 향후 작업에는 이러한 문제를 해결하기 위해 SDXL과 같은 더 큰 모델을 사용하는 것이 포함될 수 있습니다.

![실패 사례의 예시. 3D 융합 재구성 후 트럼프의 얼굴이 흐릿하게 변한 경우(첫 번째 줄). 그러나 시맨틱 글로벌 표현 덕분에 글로벌 전용 컨트롤러를 사용하는 모델로 얼굴 텍스처를 생성할 수 있습니다.](ImageDream%20Image-Prompt%20Multi-view%20Diffusion%20for%203%205c85d3d57f1c46148f4f4df95961596e/Untitled%206.png)

실패 사례의 예시. 3D 융합 재구성 후 트럼프의 얼굴이 흐릿하게 변한 경우(첫 번째 줄). 그러나 시맨틱 글로벌 표현 덕분에 글로벌 전용 컨트롤러를 사용하는 모델로 얼굴 텍스처를 생성할 수 있습니다.

요약하면, 이미지드림은 이미지 프롬프트에서 3D 모델을 생성하는 데 상당한 진전을 보이며 이미지 품질과 정렬에서 높은 점수를 획득했습니다. 그러나 세부적인 뉘앙스를 처리하는 데 있어서는 어려움을 겪고 있어 향후 개선이 필요한 부분도 있습니다.

### 5 Conclusion

이 논문은 멀티뷰 확산을 활용하고 이미지 프롬프트를 위해 특별히 설계된 혁신적인 3D 생성 모델인 ImageDream의 소개를 강조하면서 마무리합니다. ImageDream은 표준 카메라 조정과 다단계 이미지 프롬프트 컨트롤러를 사용한다는 점에서 두드러집니다. 이러한 기능은 생성 프로세스에 대한 제어를 향상시키고 이전 방법에서 문제가 되었던 기하학적 부정확성을 성공적으로 해결합니다.

이 백서에서는 앞으로 이미지드림의 잠재적인 개선 사항을 제안합니다. 주요 개선 사항 중 하나는 훈련 단계에서 이미지 프롬프트의 무작위성을 높이는 것입니다. 이러한 개선은 생성된 3D 모델의 텍스처 흐릿함을 줄여 전반적인 품질과 사실감을 향상시키는 것을 목표로 합니다. 이러한 향후 개발은 3D 모델 생성 분야에서 ImageDream의 기능과 실제 적용 범위를 확장하여 다양한 창의적, 기술적 용도로 더욱 강력하고 다재다능한 도구가 될 것으로 기대됩니다.