# Garment3DGen: 3D Garment Stylization and Texture Generation

[https://arxiv.org/abs/2403.18816](https://arxiv.org/abs/2403.18816)

[https://nsarafianos.github.io/garment3dgen](https://nsarafianos.github.io/garment3dgen)

- Mar 2024

## 1 Introduction

1장 서론에서는 3D 자산 생성이란 과정을 소개하고 이것이 게임, 영화, 패션 및 가상 현실(VR) 응용 프로그램과 같은 여러 산업에서 어떻게 직접적인 적용을 찾는지 설명합니다. 특히, 시뮬레이션에 준비된 옷감을 얻는 것은 전문 소프트웨어와 경험이 많은 아티스트가 필요한 복잡하고 시간이 많이 소요되는 과정임을 지적합니다. 현재, 가상 옷을 만드는 것은 도전적인 작업으로, 옷감은 수동으로 설계되어야 하며, 시뮬레이션을 위해 고려된 토폴로지를 가져야 한다고 언급합니다. 이러한 배경에서, 저자들은 누구나 쉽게 맞춤형 아바타를 생성하고 개인화된 가상 경험을 구축할 수 있게 하는 핵심 기술로 생성적 AI를 제시합니다. 또한, 이 기술이 설계 과정을 돕고 새로운 디자인의 빠른 탐색과 생성을 가능하게 할 것이라고 합니다.

![Garment3DGen, 이미지나 텍스트 프롬프트에서 직접 시뮬레이션 준비가 가능한 기본 옷감 메시로 변환하는 완전 자동화된 방법을 소개합니다. 우리의 방법은 전문 소프트웨어와 전문 지식이 필요한 콘텐츠 생성을 자동화하여, 빠른 자산 생성을 가능하게 합니다. 물리 기반 시뮬레이션과 VR에서의 손-옷감 상호작용과 같은 응용 프로그램을 시연합니다.](Garment3DGen%203D%20Garment%20Stylization%20and%20Texture%20Ge%20df71a5f08201485a8f5b96b2528282f0/Untitled.png)

Garment3DGen, 이미지나 텍스트 프롬프트에서 직접 시뮬레이션 준비가 가능한 기본 옷감 메시로 변환하는 완전 자동화된 방법을 소개합니다. 우리의 방법은 전문 소프트웨어와 전문 지식이 필요한 콘텐츠 생성을 자동화하여, 빠른 자산 생성을 가능하게 합니다. 물리 기반 시뮬레이션과 VR에서의 손-옷감 상호작용과 같은 응용 프로그램을 시연합니다.

이러한 문제를 해결하기 위해 저자들은 이미지 입력으로부터 직접 3D 옷감을 생성하는 Garment3DGen 방법을 개발했습니다. 이 방법은 기본 기하학 메시와 단일 이미지를 입력으로 받아, 이미지 가이드에 따른 토폴로지 보존 메시 기반 변형을 수행하고, 새로운 3D 자산을 즉석에서 합성합니다. 생성된 옷감은 입력 이미지와 스타일적으로 일치하며, 고해상도 텍스처 맵을 포함합니다. 제시된 이미지 가이드는 실제 세계 또는 합성적으로 생성될 수 있으며, 이를 통해 저자들은 실제와 환상적인 3D 옷감 모두를 생성할 수 있습니다.

이러한 배경과 해결책 제시를 통해, 1장은 3D 옷감 생성이 직면한 도전과 이를 극복하기 위한 Garment3DGen 방법론의 도입으로, 3D 옷감 생성 분야에서의 진보를 이끄는 새로운 접근법을 소개합니다.

## 2 Related work

2장에서는 3D 옷감 모델링과 관련된 기존 연구들을 검토하며, 이 분야에서의 중요한 연구 라인들을 다룹니다. 이 장은 크게 두 부분으로 나뉘어, 옷감 모델링과 옷감 변형 및 스타일링에 초점을 맞춥니다.

### **옷감 모델링 관련 연구**

옷감 모델링에 관한 연구는 옷감의 디자인, 캡처, 등록, 복원, 표현 방법들을 포함합니다. 이 분야의 연구들은 이미지나 비디오 입력에서 옷감과 그 텍스처를 디자인하고 복원하는 방법에 중점을 둡니다. 옷감 등록은 특히 중요한 작업으로, 외부 스캔이나 통제된 환경에서 매개 변수화된 옷감 템플릿을 맞추고, 등록된 옷감을 하류 작업에 사용할 수 있게 합니다. 여러 연구들이 캡처된 4D 데이터에서 모양 기반의 확산 우선순위를 학습하여 텍스처가 없는 옷감의 등록을 가능하게 하거나, 실세계 캡처에 옷감 기하학을 정렬하는 방법을 제안합니다. 이와 같은 방법들은 물리 기반의 손실과 함께 3D 감독 학습을 활용하여 동적인 옷감 모델을 복원하려는 시도를 포함합니다.

![ 개요: 입력 3D 기본 메시와 목표 옷감 이미지가 주어지면, 확산 기반 방법을 사용하여 3D 가상의 정답을 생성하고, 변형 과정 동안 이 출력 기하학을 부드러운 감독 신호로 활용합니다. 우리의 3D 생성 기하학은 입력 이미지의 기하학을 정확히 포착하면서도, 소매/칼라의 색상으로 나타나는 바와 같이 기본 메시의 토폴로지와 구조를 보존합니다. 그 다음 텍스처 추정 모듈이 해당 UV 텍스처를 출력하여, 기하학과 함께 우리의 최종 생성된 3D 옷감을 구성합니다.](Garment3DGen%203D%20Garment%20Stylization%20and%20Texture%20Ge%20df71a5f08201485a8f5b96b2528282f0/Untitled%201.png)

 개요: 입력 3D 기본 메시와 목표 옷감 이미지가 주어지면, 확산 기반 방법을 사용하여 3D 가상의 정답을 생성하고, 변형 과정 동안 이 출력 기하학을 부드러운 감독 신호로 활용합니다. 우리의 3D 생성 기하학은 입력 이미지의 기하학을 정확히 포착하면서도, 소매/칼라의 색상으로 나타나는 바와 같이 기본 메시의 토폴로지와 구조를 보존합니다. 그 다음 텍스처 추정 모듈이 해당 UV 텍스처를 출력하여, 기하학과 함께 우리의 최종 생성된 3D 옷감을 구성합니다.

### **옷감 변형 및 스타일링 관련 연구**

옷감 변형과 스타일링에 관한 최근의 진전은 단일 텍스트나 이미지 프롬프트에서 복장된 아바타를 재현하고 재구성하는 새로운 방법들을 개방했습니다. 이러한 방법들은 주어진 이미지나 텍스트 입력에서 일관된 다중 뷰를 생성하는데, 이는 3D 장면을 직접 최적화하거나, Neural Radiance Fields와 유사한 3D 장면 매개 변수화를 사용합니다. 그러나 이러한 방법들은 옷감이 인간에게 드레이핑되고 시뮬레이션될 수 있는 필요한 토폴로지와 구조를 가지지 않는 거친, 밀폐된 메시를 생성한다는 문제가 있습니다. 최근 연구들은 텍스트-이미지 생성 모델을 적용하여 메시와 주어진 텍스트/이미지에 기반한 텍스처를 생성하는 방법을 탐색하고 있습니다.

### **종합**

2장에서는 3D 옷감 생성에 관련된 다양한 연구들과 이들이 직면한 문제점들을 검토합니다. 이러한 배경 지식을 바탕으로, Garment3DGen은 기존의 한계를 극복하고 더 고도화된 3D 옷감 모델링 방법을 제시하려는 시도로 위치지어집니다. 연구자들은 특히 이미지나 텍스트 입력에서 3D 옷감을 생성하는 새로운 방법론의 필요성을 강조하며, 이를 해결하기 위한 방법론으로 Garment3DGen을 도입합니다.

## 3 Method

3장에서는 Garment3DGen의 방법론이 상세하게 설명됩니다. 이 접근법은 단일 이미지와 기본 옷감 템플릿 메시를 입력으로 받아, 이미지 가이드에 따른 토폴로지를 보존하는 변형을 통해 목표 변형 메시를 생성합니다. 이 과정은 다음과 같은 주요 단계로 구성됩니다.

![3D 옷감 생성(왼쪽): 가이드로서 이미지나 텍스트 프롬프트와 함께 기본 기하학 메시(왼쪽 하단 삽화)를 주어졌을 때, 목표와는 거리가 먼 경우에도 실제와 환상적인 옷감 모두에 대해 고품질의 텍스처가 적용된 3D 기하학을 생성합니다. 맞춤(오른쪽): 생성된 텍스처가 적용된 3D 옷감(이 경우 중세 갑옷)과 표준 자세의 매개변수화된 몸체(왼쪽)로 시작하여, 생성된 옷감이 몸체에 정확히 맞도록 몸체 자세와 모양 매개변수를 최적화하는 몸체-옷감 최적화 과정을 수행합니다.](Garment3DGen%203D%20Garment%20Stylization%20and%20Texture%20Ge%20df71a5f08201485a8f5b96b2528282f0/Untitled%202.png)

3D 옷감 생성(왼쪽): 가이드로서 이미지나 텍스트 프롬프트와 함께 기본 기하학 메시(왼쪽 하단 삽화)를 주어졌을 때, 목표와는 거리가 먼 경우에도 실제와 환상적인 옷감 모두에 대해 고품질의 텍스처가 적용된 3D 기하학을 생성합니다. 맞춤(오른쪽): 생성된 텍스처가 적용된 3D 옷감(이 경우 중세 갑옷)과 표준 자세의 매개변수화된 몸체(왼쪽)로 시작하여, 생성된 옷감이 몸체에 정확히 맞도록 몸체 자세와 모양 매개변수를 최적화하는 몸체-옷감 최적화 과정을 수행합니다.

### **목표 기하학 생성**

이 단계에서는 단일 이미지에서 3D 메소드를 활용하여 초기 거친 기하학을 얻는 것을 목표로 합니다. 이미지로부터 RGB와 정규 이미지를 생성하는 교차 도메인 확산 모델을 사용하여 여섯 개의 뷰를 합성하고, 이를 기반으로 다중 뷰 3D 복원 알고리즘을 통해 거친, 밀폐된 기하학적 구조를 생성합니다. 이 구조는 최종적인 시뮬레이션 준비 결과물로는 사용될 수 없으나, 기본 메시를 변형시키기 위한 유용한 가이드로 사용됩니다.

### **메시 변형: 토폴로지 보존 변형**

변형 과정은 입력 기본 메시의 구조와 토폴로지를 보존하면서 이미지 기반 스타일화를 가능하게 하는 방법론을 제안합니다. Neural Jacobian Fields에 영감을 받아, 각 삼각형에 대한 변형을 정의하는 한 세트의 삼각형별 Jacobian을 사용하여 이 변형을 매개변수화합니다. 이러한 방식으로, 메시는 이미지 가이드에 따라 효과적으로 변형될 수 있으며, 동시에 원본 메시의 구조적 세부사항을 유지할 수 있습니다.

### **3D, 2D 및 임베딩 감독 (Supervisions)**

변형 메시의 품질을 보장하기 위해 여러 감독 신호를 사용합니다. 3D 감독은 Chamfer Distance 손실을 사용하여 변형된 메시와 가이드 메시 간의 유사성을 평가합니다. 2D 감독은 다양한 카메라 뷰에서 렌더링된 이미지들 사이의 L1 손실을 사용하여, 메시가 다양한 관점에서 타겟과 유사하게 보이도록 합니다. 임베딩 감독은 FashionCLIP과 같은 패션 데이터에 미세 조정된 모델을 사용하여, 입력 이미지와 변형된 메시의 렌더링 사이의 임베딩 유사성을 강화합니다.

### **텍스처 추정**

변형된 3D 기하학에 고해상도 텍스처를 매핑하기 위해, 텍스트-이미지 생성 모델을 사용하여 여러 뷰에서의 고품질 텍스처를 생성합니다. 이 과정은 모델이 생성한 텍스처가 기하학적 구조를 정확하게 반영하도록 하며, 다양한 관점에서의 일관성을 보장합니다.

### **생성된 옷감을 매개변수화된 몸체에 맞추기**

마지막 단계에서는 생성된 옷감을 매개변수화된 인체 모델에 맞추는 작업을 수행합니다. 이는 Chamfer distance 손실을 사용하는 최적화 과정을 통해 이루어지며, 몸체와 옷감 간의 충돌을 최소화하면서 옷감이 인체 모델에 정확하게 드레이핑될 수 있도록 합니다.

이 방법론은 고해상도의 시뮬레이션 준비된 3D 옷감을 생성하는 데 있어 핵심적인 기술적 진보를 대표하며, 이러한 접근법을 통해 다양한 형태와 스타일의 옷감을 효과적으로 모델링할 수 있음을 보여줍니다.

## 4 Experiments

4장에서는 Garment3DGen 방법론을 검증하기 위한 실험들과 그 결과를 설명합니다. 이 장은 방법론의 효과와 정확성을 증명하기 위해 설계된 다양한 실험 설정과 평가 지표, 그리고 비교 대상이 되는 기존 방법론들에 대해 논의합니다.

### **데이터와 평가 지표**

실험을 위해, 연구팀은 여러 옷감 카테고리를 커버하는 아티스트가 생성한 기본 옷감 템플릿을 사용합니다. 이 템플릿들은 정형화된 자세를 가지고 있으며, 향후 3D 옷감 연구를 촉진하기 위해 공개될 예정입니다. 가이드로 사용되는 이미지들은 다양한 자세, 텍스처를 가진 실제 옷감과 메시 라이브러리에 존재하지 않는 옷감, 심지어 텍스트 프롬프트에서 생성된 환상적인 AI 생성 옷감을 포함합니다. 실험의 평가 지표로는 입력 이미지와의 일관성을 측정하기 위해 다양한 뷰에서 렌더링된 비텍스처 출력의 지각적 점수와 CLIP 유사도 점수를 사용합니다.

![소거 실험: 기본 입력 메시에서 시작하여, 우리의 주요 기여가 입력 이미지 가이드를 포착하고, 미세 수준의 옷감 세부 정보를 포함하며, 하류 작업에 적합한 변형된 기하학을 생성함을 보여줍니다.](Garment3DGen%203D%20Garment%20Stylization%20and%20Texture%20Ge%20df71a5f08201485a8f5b96b2528282f0/Untitled%203.png)

소거 실험: 기본 입력 메시에서 시작하여, 우리의 주요 기여가 입력 이미지 가이드를 포착하고, 미세 수준의 옷감 세부 정보를 포함하며, 하류 작업에 적합한 변형된 기하학을 생성함을 보여줍니다.

### **기준 모델과 비교**

Garment3DGen은 여러 기준 모델과 비교됩니다. 이러한 모델에는 텍스트 프롬프트를 기반으로 입력 메시를 변형하는 TextDeformer, 이미지를 입력으로 사용하는 ImageDeformer 변형, 단일 이미지에서 3D 기하학을 생성하는 Wonder3D와 Zero123++, 그리고 제로샷 복원을 수행하는 ZeroShape 등이 있습니다. 이 비교를 통해 Garment3DGen의 우수성을 입증합니다.

![메시 품질(상단) 및 기하학 비교(하단): 모든 접근 방식의 와이어프레임을 보여줍니다. 우리의 방법은 입력 이미지를 준수하면서 좋은 메시 품질을 유지하고 물리 기반 시뮬레이션 작업에 필요한 구멍을 포함하는 유일한 방법으로 두각을 나타냅니다. 아래에서는 우리의 접근법이 기하학적 오류 없이 미세한 기하학적 세부 사항을 포착함을 강조하기 위해 다양한 기술의 출력 기하학을 보여줍니다(Wonder3D).](Garment3DGen%203D%20Garment%20Stylization%20and%20Texture%20Ge%20df71a5f08201485a8f5b96b2528282f0/Untitled%204.png)

메시 품질(상단) 및 기하학 비교(하단): 모든 접근 방식의 와이어프레임을 보여줍니다. 우리의 방법은 입력 이미지를 준수하면서 좋은 메시 품질을 유지하고 물리 기반 시뮬레이션 작업에 필요한 구멍을 포함하는 유일한 방법으로 두각을 나타냅니다. 아래에서는 우리의 접근법이 기하학적 오류 없이 미세한 기하학적 세부 사항을 포착함을 강조하기 위해 다양한 기술의 출력 기하학을 보여줍니다(Wonder3D).

### **실험 결과**

Garment3DGen은 이미지로부터 직접 3D 옷감 자산을 생성하는 능력을 시연하며, 사용자가 참조 이미지를 제공하면 수동 개입 없이도 고품질의 3D 자산을 신속하게 얻을 수 있음을 보여줍니다. 또한, 실제 및 환상적인 옷감을 묘사하는 텍스트 입력과 간단한 옷감 스케치로부터도 3D 옷감을 생성할 수 있음을 입증합니다. 본 연구는 또한 몸체-옷감 공동 최적화 프레임워크를 통해 매개변수화된 몸체 모델에 옷감을 적합시키고, 물리 기반의 옷감 시뮬레이션을 수행하여 다양한 새로운 시나리오에서 옷감의 행동을 더 정확하게 나타낼 수 있음을 보여줍니다.

![정성적 비교: 왼쪽에 보이는 입력 이미지에서 시작하는 여러 메시 생성 방법을 시연합니다. 각 재구성의 전면 및 후면 뷰를 보여줍니다. 3D 가우시안 스플래팅 [84] 방법은 변형된 전면 색상과 어두운 또는 흐릿한 후면 색상을 생성하지만, 시뮬레이션과 같은 하류 작업에는 적합하지 않은 기하학을 생성합니다. 두 번째 재구성 접근 방식 [40,83]은 매우 거친 기하학적 세부 사항과 흐려진 색상을 가진 밀폐된 메시를 생성합니다. 우리의 제안된 접근 방식은 이전 작업이 생성하지 못한 미세 수준의 텍스처 세부 사항을 가진 기하학적으로 정확한 3D 기하학을 출력합니다.](Garment3DGen%203D%20Garment%20Stylization%20and%20Texture%20Ge%20df71a5f08201485a8f5b96b2528282f0/Untitled%205.png)

정성적 비교: 왼쪽에 보이는 입력 이미지에서 시작하는 여러 메시 생성 방법을 시연합니다. 각 재구성의 전면 및 후면 뷰를 보여줍니다. 3D 가우시안 스플래팅 [84] 방법은 변형된 전면 색상과 어두운 또는 흐릿한 후면 색상을 생성하지만, 시뮬레이션과 같은 하류 작업에는 적합하지 않은 기하학을 생성합니다. 두 번째 재구성 접근 방식 [40,83]은 매우 거친 기하학적 세부 사항과 흐려진 색상을 가진 밀폐된 메시를 생성합니다. 우리의 제안된 접근 방식은 이전 작업이 생성하지 못한 미세 수준의 텍스처 세부 사항을 가진 기하학적으로 정확한 3D 기하학을 출력합니다.

### **응용 및 논의**

실험은 Garment3DGen이 물리 기반의 옷감 시뮬레이션, VR 환경에서의 손-옷감 상호작용, 간단한 스케치로부터 3D 옷감으로의 직접 변환 등 다양한 응용 분야에서 사용될 수 있는 시뮬레이션 준비가 완료된 3D 옷감을 생성할 수 있음을 입증합니다. 실험 결과는 Garment3DGen이 기존의 방법들을 능가하며, 입력 이미지 가이드에 대한 지각적 유사성과 CLIP 임베딩 유사성 모두에서 더 나은 성능을 보임을 확인시켜줍니다.

이 장에서의 실험과 결과는 Garment3DGen이 3D 옷감 생성 분야에서 중요한 진보를 이루었음을 보여주며, 향후 가상 옷감 모델링과 관련된 응용 프로그램 개발에 큰 영향을 미칠 것으로 기대됩니다.

![응용: Garment3DGen은 이미지, 텍스트 프롬프트, 간단한 스케치에서 시작하여 인간 몸에 맞추고 물리 기반 옷감 시뮬레이션을 수행하거나 심지어 VR 환경에서 손과 옷감 사이의 상호작용을 가능하게 하는 텍스처가 적용된 3D 옷감을 생성할 수 있습니다.](Garment3DGen%203D%20Garment%20Stylization%20and%20Texture%20Ge%20df71a5f08201485a8f5b96b2528282f0/Untitled%206.png)

응용: Garment3DGen은 이미지, 텍스트 프롬프트, 간단한 스케치에서 시작하여 인간 몸에 맞추고 물리 기반 옷감 시뮬레이션을 수행하거나 심지어 VR 환경에서 손과 옷감 사이의 상호작용을 가능하게 하는 텍스처가 적용된 3D 옷감을 생성할 수 있습니다.

## 5 Conclusion

5장 결론에서는 Garment3DGen이 제안한 방법론이 3D 옷감 생성 분야에서 어떠한 기여를 했는지를 정리하고, 연구의 주요 성과를 강조합니다. 이 연구는 기존 방법론의 한계를 극복하고, 고화질의 물리적으로 타당한 옷감 자산을 직접적으로 생성할 수 있는 새로운 접근 방식을 제시했습니다.

### **연구의 주요 기여**

- **새로운 3D 기하학 및 텍스처 생성 접근법:** Garment3DGen은 기본 메시와 단일 이미지 가이드를 입력으로 사용하여, 텍스처화된 옷감 자산을 생성하는 새로운 방법을 제안합니다. 이는 하류 시뮬레이션 작업에 유용하며, 연구는 이러한 자산이 최초로 생성될 수 있음을 보여줍니다.
- **직접적인 3D 공간에서의 기하학 감독:** 연구는 이미지 입력으로부터 거친 가이드 메시를 생성하고, 이를 메시 변형 과정에서 부드러운 제약으로 사용함으로써, 더 높은 품질의 메시를 생성할 수 있는 방법을 소개합니다. 이는 더 정확한 옷감 시뮬레이션과 손-옷감 상호작용을 가능하게 합니다.
- **텍스처 강화 모듈:** 고품질 UV 텍스처를 생성할 수 있는 텍스처 추정 방법을 제안합니다. 이는 출력 기하학에 더욱 사실적인 렌더링을 가능하게 합니다.
- **체형-옷감 최적화 프레임워크:** 생성된 3D 옷감을 매개변수화된 몸체 모델에 적합하게 조정하는 방법을 도입합니다. 이는 실제와 같은 드레이핑과 옷감 시뮬레이션을 위한 기초를 마련합니다.

### **응용 및 미래 연구 방향**

Garment3DGen의 출력은 물리 기반 옷감 시뮬레이션, VR 환경에서의 실시간 손-옷감 상호작용, 간단한 스케치로부터 직접 3D 옷감으로의 변환 등, 다양한 응용 분야에서 활용될 수 있습니다. 연구는 또한 Garment3DGen의 실행 시간과 제한 사항을 언급하며, 향후 성능 개선과 다양한 템플릿 라이브러리를 제공하여, 더 넓은 범위의 옷감을 지원할 수 있는 방법에 대해 논의합니다.

### **결론**

Garment3DGen은 3D 옷감 생성 분야에서 중요한 진보를 나타내며, 향후 연구와 응용 프로그램 개발에 큰 영향을 미칠 것으로 기대됩니다. 연구는 3D 옷감 모델링의 가능성을 확장하고, 가상 및 증강 현실, 영화 제작, 패션 디자인 등 다양한 분야에서의 새로운 창조적 가능성을 열어줍니다.