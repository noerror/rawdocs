# HairNet: Single-View Hair Reconstruction using Convolutional Neural Networks

[https://arxiv.org/abs/1806.07467](https://arxiv.org/abs/1806.07467)

[https://github.com/papagina/HairNet_DataSetGeneration](https://github.com/papagina/HairNet_DataSetGeneration)

- Jun 2018

![Untitled](HairNet%20Single-View%20Hair%20Reconstruction%20using%20Conv%20c2a15432fdec4bc4af106a68a211b7da/Untitled.png)

이 논문에서는 딥러닝을 사용하여 단일 이미지에서 3D 헤어 지오메트리를 생성하는 새로운 방법을 소개합니다. 이 새로운 접근 방식은 참조 및 후속 수정 작업을 위해 대량의 헤어스타일 컬렉션에 의존하는 기존 방식과 달리 저장 및 속도 측면에서 더 효율적입니다. 30,000가닥의 머리카락을 최대 1,000배 빠르게 생성할 수 있습니다.

이 방법은 컨볼루션 신경망(CNN)을 사용하여 모발 이미지의 2D 방향 필드를 처리하고 매개변수화된 2D 두피에 고르게 분포된 스트랜드 특징을 생성합니다. 또한 연구진은 보다 사실적인 헤어스타일을 생성하기 위해 충돌 손실 기능을 도입했습니다. 각 가닥의 가시성은 재구성의 정확도를 높이기 위해 가중치로 사용됩니다.

네트워크의 인코더-디코더 아키텍처는 헤어스타일을 간결하고 연속적으로 표현하여 서로 다른 헤어스타일 간에 자연스럽게 보간할 수 있도록 합니다. 네트워크는 렌더링된 합성 헤어 모델의 대규모 세트에 대해 학습됩니다.

이 방법은 이미지에서 중간 2D 방향 필드를 계산하여 실제 이미지에 적용할 수 있으며, 이는 합성 모발과 실제 모발 사이의 간극을 메우는 데 도움이 됩니다. 연구진은 인터넷의 다양한 실제 이미지와 동영상에서 재구성한 헤어 시퀀스에 대해 이 방법의 효과와 견고성을 입증했습니다.

### 1 Introduction

이 논문에서는 가상 인간을 제작할 때 사실적인 헤어 모델링의 과제에 대해 설명합니다. 고품질 3D 헤어 모델을 제작하기 위한 기존 방법에는 배포 및 관리가 어려운 특수 하드웨어 설정이 필요한 경우가 많습니다. 단일 이미지에서 헤어를 모델링하는 기존 기법은 수동 입력이 필요하고 보이지 않는 헤어 부분을 정확하게 생성하는 데 어려움을 겪었습니다.

모델링 프로세스를 자동화하기 위해 데이터 기반 기법이 개발되었지만 이러한 방법은 대규모 헤어 모델 데이터 세트를 저장 및 쿼리하고 계산 집약적인 정제 단계를 수행해야 합니다. 이러한 방법은 실시간 성능이 필요하거나 스토리지 및 메모리 공간이 제한된 애플리케이션에는 실용적이지 않습니다. 또한 이러한 방법은 모발의 미세한 디테일을 포착하지 못하는 경우가 많으며 때때로 성장 방향이나 가르마가 잘못된 모발을 생성할 수 있습니다.

이러한 문제를 해결하기 위해 저자는 단일 뷰 이미지에서 전체 헤어 지오메트리를 생성하는 딥러닝 기반 접근 방식을 제안합니다. 헤어넷(HairNet)이라고 부르는 이 방법은 컨볼루션 인코더를 사용하여 모발 이미지의 2D 방향 필드에서 높은 수준의 모발 특징을 추출하고, 컨볼루션 디코더를 사용하여 매개변수화된 2D 두피에 고르게 분포된 스트랜드 특징을 생성합니다. 모발 가닥 특징을 두피 공간에 보간하여 해상도를 높인 다음 최종 가닥으로 디코딩하여 3D 포인트 시퀀스로 표현할 수 있습니다.

또한 충돌 손실 함수를 도입하여 보다 사실적인 헤어스타일을 생성하고 각 가닥의 가시성을 가중치로 사용하여 재구성의 정확도를 높였습니다. 네트워크는 합성 헤어 모델과 실제 이미지로 구성된 대규모 데이터 세트를 통해 훈련됩니다.

이전의 데이터 기반 방식에 비해 저자들의 방식은 훨씬 더 빠르고 저장 공간도 적게 차지합니다. 저자는 합성 모발 이미지와 인터넷의 실제 이미지 모두에서 이 방법의 효과를 입증하고 모발 보간 및 비디오 추적에 적용하는 방법을 보여줍니다.

저자들의 공헌은 다음과 같습니다:

- 단일 뷰 이미지에서 조밀한 모발 형상을 생성하는 최초의 심층 신경망으로, 3D 형상을 처리하기 위해 심층 신경망에 충돌과 가시성을 모두 통합했습니다.
- 최첨단 해상도와 품질을 달성하고 속도와 저장 공간에서 기존 데이터 기반 방식보다 월등히 뛰어난 성능을 발휘하는 방식입니다.
- 다양한 헤어스타일을 부드럽게 샘플링하고 보간할 수 있는 헤어 지오메트리를 최초로 컴팩트하고 연속적으로 표현할 수 있습니다.
- 약 40,000개의 3D 헤어 모델과 160,000개의 해당 렌더링 이미지로 구성된 대규모 데이터베이스를 구축합니다.

### 2 Related Work

이 섹션에서는 기존 헤어 모델링 기법과 이와 관련된 과제에 대한 개요를 제공합니다.

XGen이나 헤어팜과 같은 상용 소프트웨어를 사용하여 수동으로 편집하면 고품질의 유연하고 제어 가능한 헤어 모델을 제작할 수 있지만, 이 과정은 시간이 많이 걸리고 사실적인 헤어스타일을 만드는 데 몇 주가 걸릴 수 있습니다. 개별 모발 섬유를 조작하는 지루한 작업을 피하기 위해 효율적인 디자인 도구가 제안되었습니다.

실제 세계에서 헤어스타일 데이터를 수집하기 위한 헤어 캡처 방법도 개발되었습니다. 이러한 방법은 일반적으로 고충실도 캡처 시스템, 제어된 녹화 세션 및 수동 지원에 의존합니다. 이러한 방법에는 멀티뷰 스테레오 카메라, 단일 RGB-D 카메라, 열화상 카메라 등의 도구가 사용됩니다.

단일 뷰 모발 디지털화 방법도 제안되었지만, 이는 모발의 정면 형상을 대략적으로만 생성할 수 있습니다. 단일 입력 이미지에서 최소한의 사용자 인터랙션으로 데이터베이스 기반 재구성 기술을 사용하여 전체 헤어스타일을 가닥 수준에서 모델링할 수 있는 보다 포괄적인 시스템도 개발되었습니다. 그러나 이러한 방법은 매칭을 위해 대규모 데이터 세트에 의존하기 때문에 속도가 느릴 수 있으며 최종 결과는 데이터베이스의 품질과 다양성에 따라 크게 달라집니다.

심층 신경망에 의한 3D 데이터 생성은 점점 더 많은 주목을 받고 있습니다. 볼류메트릭 CNN은 3D 컨볼루션 신경망을 사용하여 복셀화된 모양을 생성하지만 3D 컨볼루션의 볼륨 해상도와 계산 비용으로 인해 많은 제약을 받습니다. 계층적 재구성 및 옥트리와 같은 기술을 사용하여 해상도를 개선할 수 있지만, 머리카락 가닥과 같은 디테일을 생성하는 것은 여전히 매우 어렵습니다.

포인트 클라우드는 구조화되지 않은 표현으로 인해 고해상도로 잘 확장되며 3D 오브젝트 분류 및 세분화와 같은 작업에는 사용되었지만 생성에는 사용되지 않았습니다. 포인트 클라우드는 여전히 거친 구조를 나타내며 머리카락 가닥의 위상 구조를 포착할 수 없습니다.

### 3 Method

이 논문에서는 단일 이미지에서 3D 헤어 모델을 생성하는 3단계 프로세스를 간략하게 설명합니다.

전처리: 첫 번째 단계는 자동으로 추정된 헤어 마스크를 기반으로 헤어 영역의 2D 방향 필드를 계산하는 것입니다. 이 작업은 PSPNet을 사용하여 입력 인물 이미지의 픽셀 단위 헤어 마스크를 생성한 다음 가버 필터를 사용하여 헤어 영역의 각 픽셀에 대해 방향이 지정되지 않은 2D 방향을 계산하는 방식으로 수행됩니다. 최종 출력은 3 × 256 × 256 이미지로, 처음 두 채널은 색상으로 구분된 머리카락 방향을 저장하고 세 번째 채널은 머리카락, 몸, 배경의 세분화를 나타냅니다.

![네트워크 아키텍처. 입력 방향 이미지는 먼저 높은 수준의 헤어 특징 벡터로 인코딩된 다음 32 × 32개의 개별 가닥 특징으로 디코딩됩니다. 각 스트랜드 피처는 두 개의 다중 레이어를 통해 샘플 위치와 곡률을 모두 포함하는 샘플 위치와 곡률을 모두 포함하는 최종 가닥 지오메트리로 디코딩됩니다.](HairNet%20Single-View%20Hair%20Reconstruction%20using%20Conv%20c2a15432fdec4bc4af106a68a211b7da/Untitled%201.png)

네트워크 아키텍처. 입력 방향 이미지는 먼저 높은 수준의 헤어 특징 벡터로 인코딩된 다음 32 × 32개의 개별 가닥 특징으로 디코딩됩니다. 각 스트랜드 피처는 두 개의 다중 레이어를 통해 샘플 위치와 곡률을 모두 포함하는 샘플 위치와 곡률을 모두 포함하는 최종 가닥 지오메트리로 디코딩됩니다.

데이터 생성: 제작자는 공개 온라인 리포지토리에서 340개의 3D 헤어 모델이 포함된 원본 헤어 데이터 세트를 수집하여 동일한 레퍼런스 헤드에 정렬하고 메시를 헤어 스트랜드로 변환한 후 헤어와 바디 사이의 충돌을 해결합니다. 그런 다음 원본 헤어 세트는 미러링과 페어별 블렌딩을 통해 채워집니다. 저자는 각 헤어의 가닥을 5개의 중앙 가닥으로 클러스터링하고, 각 헤어스타일 쌍은 중앙 가닥의 추가 조합을 생성할 수 있습니다. 새로운 중심 가닥은 세부적인 머리카락을 블렌딩하기 위한 지침 역할을 합니다. 저자는 합성 모발 데이터 세트에 4만 개가 넘는 머리카락을 사용했습니다.

![오리엔테이션 이미지(b)는 실제 이미지( (a) 또는 9K 가닥으로 합성된 헤어 모델에서 자동으로 생성될 수 있습니다. 오리엔테이션 맵과 1K 가닥의 다운 샘플링된 헤어 모델(c)을 사용하여 신경망을 훈련합니다.](HairNet%20Single-View%20Hair%20Reconstruction%20using%20Conv%20c2a15432fdec4bc4af106a68a211b7da/Untitled%202.png)

오리엔테이션 이미지(b)는 실제 이미지( (a) 또는 9K 가닥으로 합성된 헤어 모델에서 자동으로 생성될 수 있습니다. 오리엔테이션 맵과 1K 가닥의 다운 샘플링된 헤어 모델(c)을 사용하여 신경망을 훈련합니다.

헤어 예측 네트워크: 저자의 네트워크인 HairNet은 먼저 입력 이미지를 잠재 벡터로 인코딩한 다음 벡터에서 대상 머리카락 가닥을 디코딩합니다. 이 네트워크는 컨볼루션 레이어를 사용하여 이미지의 높은 수준의 특징을 추출하고 2D 최대 풀링을 사용하여 부분 특징을 글로벌 특징 벡터로 공간적으로 집계합니다. 그런 다음 모발 특징 벡터는 컨볼루션 레이어를 통해 여러 가닥 특징 벡터로 디코딩되고, 각 가닥 특징 벡터는 최종 가닥 지오메트리로 추가 디코딩될 수 있습니다. 저자들은 네트워크에 3D 위치와 각 샘플의 곡률에 대한 L2 재구성 손실, 출력된 모발 가닥과 인체 사이의 충돌 손실 등 세 가지 손실을 적용합니다.

![(b) 스트랜드 특징과 (c) 최종 스트랜드 기하학 공간에서 헤어 스트랜드 업샘플링 스트랜드 지오메트리입니다. (d)는 (c)를 확대한 모습입니다.](HairNet%20Single-View%20Hair%20Reconstruction%20using%20Conv%20c2a15432fdec4bc4af106a68a211b7da/Untitled%203.png)

(b) 스트랜드 특징과 (c) 최종 스트랜드 기하학 공간에서 헤어 스트랜드 업샘플링 스트랜드 지오메트리입니다. (d)는 (c)를 확대한 모습입니다.

또한 저자는 재구성 단계에서 머리카락의 부드러움과 컬을 개선합니다. 가우시안 필터를 사용하여 노이즈를 제거하여 머리카락을 매끄럽게 만듭니다. 그런 다음 예측된 곡률과 출력 가닥의 곡률의 차이를 비교합니다. 차이가 임계값보다 크면 스트랜드 샘플에 오프셋을 추가합니다. 또한 저자들은 네트워크에서 생성된 중간 가닥 특징을 보간하고 퍼셉트론 네트워크를 사용하여 가닥으로 디코딩하여 임의의 해상도로 헤어 모델을 생성할 수 있습니다.

![컬을 사용하거나 사용하지 않고 재구성하기](HairNet%20Single-View%20Hair%20Reconstruction%20using%20Conv%20c2a15432fdec4bc4af106a68a211b7da/Untitled%204.png)

컬을 사용하거나 사용하지 않고 재구성하기

저자들은 네트워크에 컬을 추가하는 것이 얼마나 효과적인지 보여줍니다. 곱슬성을 추가 제약 조건으로 사용하지 않으면 네트워크는 고주파 디테일을 잃으면서도 지배적인 주요 성장 방향만 학습합니다. 저자는 9K에서 30K 스트랜드의 해상도에서 모든 결과를 시연합니다.

### 4 Evaluation

저자들은 이 방법의 정확도를 추정하기 위해 정량적 분석을 실시했습니다. 100개의 무작위 헤어 모델과 각 헤어 모델에 대해 무작위 뷰에서 렌더링된 4개의 이미지로 구성된 합성 테스트 세트를 준비했습니다. 그리고 점 사이의 평균 제곱 거리와 충돌 오차를 사용하여 머리카락의 보이는 부분과 보이지 않는 부분의 재구성 오류를 별도로 계산했습니다. 그리고 그 결과를 Chai와 Hu의 방법과 비교했습니다.

그 결과, 이들의 방법이 모든 절제 방법과 Chai 등의 방법을 능가하는 것으로 나타났습니다. 가시성 적응 가중치를 적용하지 않은 경우, 보이는 부분과 보이지 않는 부분의 재구성 오류는 거의 같았지만, 가시성 적응 가중치를 적용한 모든 네트워크에서 보이는 모발의 재구성 오류는 약 30% 감소했습니다. 곡률 손실은 또한 재구성의 평균 제곱 거리 오차를 줄이는 데 도움이 되었습니다. 또한 실험 결과 충돌 손실을 사용하면 충돌 오류가 훨씬 줄어드는 것으로 나타났습니다.

또한 저자들은 9K 스트랜드의 해상도에서 이 방법과 데이터 기반 방법의 계산 시간과 하드 디스크 사용량을 비교했습니다. 저자들의 방법이 훨씬 더 빠르고 저장 공간도 적게 사용했습니다.

질적 결과 측면에서 저자들은 다양한 실제 인물 사진을 입력으로 사용하여 방법을 테스트했습니다. 이 방법은 다양한 헤어스타일의 전체적인 모양과 다양한 수준의 컬을 효율적으로 처리할 수 있었습니다. 연구진은 이 방법과 자동 헤어 모두 길이와 모양 측면에서 전체적인 모발의 형상을 합리적으로 추론할 수 있지만, 특히 곱슬머리의 경우 자동 헤어의 모발이 국소적인 디테일을 더 잘 보존하고 더 자연스러워 보인다는 것을 발견했습니다.

저자들은 또한 비디오 추적 결과를 보여줬는데, 이는 그들의 결과물이 충분한 시간적 일관성을 얻지 못할 수 있음을 나타냅니다.

### 5 Conclusion

저자들은 연구의 주요 성과를 요약하며 글을 마무리합니다. 이들은 단일 뷰 이미지에서 실시간으로 머리카락을 생성할 수 있는 최초의 심층 컨볼루션 신경망을 개발했습니다. 최종 머리카락 가닥을 직접 생성하는 이 방법은 현재의 최첨단 방법보다 더 많은 머리카락 디테일을 포착하고 더 높은 정확도를 달성할 수 있습니다.

중간 2D 방향 필드를 네트워크 입력으로 사용하면 유연성이 높아져 적절한 전처리를 거치면 이미지, 스케치, 스캔 등 다양한 유형의 헤어 표현에 네트워크를 사용할 수 있습니다.

네트워크의 다중 스케일 디코딩 메커니즘을 통해 자연스러운 외관을 유지하면서 임의의 해상도의 헤어스타일을 생성할 수 있습니다. 또한 인코더-디코더 아키텍처 덕분에 네트워크는 연속적인 헤어 표현을 제공하여 그럴듯한 헤어스타일을 원활하게 샘플링하고 보간할 수 있습니다.

![보간 비교.](HairNet%20Single-View%20Hair%20Reconstruction%20using%20Conv%20c2a15432fdec4bc4af106a68a211b7da/Untitled%205.png)

보간 비교.

### 6 Limitations and Future Work

저자들은 이 접근 방식에 몇 가지 한계가 있음을 인정합니다. 예를 들어, 변태, 아프로 또는 버즈 컷과 같은 특정 유형의 헤어스타일을 생성하지 못합니다. 이는 주로 훈련 데이터베이스에 이러한 헤어스타일이 없기 때문이며, 더 많은 변형을 포괄하는 더 큰 헤어 데이터 세트를 구축하면 이 문제를 해결하는 데 도움이 될 수 있다고 제안합니다.

또한 이 방법은 머리카락이 부분적으로 가려져 있을 때 어려움을 겪기 때문에 무작위 가려짐을 추가하여 학습을 개선할 계획입니다. 현재는 얼굴 인식 기능을 사용하여 몸통의 자세를 추정하지만, 딥러닝을 사용하여 머리와 몸을 세분화하는 것으로 대체할 수 있다고 합니다.

또 다른 한계는 생성된 헤어 모델이 비디오 프레임에 대해 시간적 일관성이 충분하지 않다는 것입니다. 저자들은 시간적 평활성을 훈련 제약 조건으로 통합하는 것이 잠재적인 해결책이 될 수 있다고 제안합니다.

마지막으로, 저자들의 네트워크는 머리카락에 대해 보다 간결한 표현을 제공하지만, 이 잠재적 표현은 의미론적 의미가 부족합니다. 저자들은 제어 학습을 위해 명시적 레이블(예: 색상)을 잠재 변수에 연결하는 것이 흥미로울 것이라고 제안합니다.

- 요약
    
    전처리: 첫 번째 단계는 입력 이미지를 전처리하는 것입니다. 저자는 PSPNet을 사용하여 입력 인물 이미지의 정확하고 견고한 픽셀 단위의 헤어 마스크를 생성합니다. 그런 다음 가버 필터를 사용하여 머리카락 영역의 각 픽셀에 대한 방향이 없는 2D 방향을 계산합니다. 또한 입력 이미지에 사람의 머리와 몸의 분할 마스크를 추가합니다. 최종 출력은 3 × 256 × 256 이미지로, 처음 두 채널은 색상으로 구분된 머리카락 방향을 저장하고 세 번째 채널은 머리카락, 몸, 배경의 세분화를 나타냅니다.
    
    데이터 생성: 저자는 340개의 3D 헤어 모델이 포함된 원본 헤어 데이터 세트를 수집하고, 이를 동일한 레퍼런스 헤드에 정렬하고, 메시를 헤어 스트랜드로 변환하고, 헤어와 바디 사이의 충돌을 해결합니다. 그런 다음 미러링과 페어별 블렌딩을 통해 원본 헤어 세트를 채웁니다. 스타일에 따라 헤어를 12개의 클래스로 구분하고 같은 클래스 내에서 각 헤어 스타일 쌍을 블렌딩하여 보다 자연스러운 예시를 생성합니다. 또한 각 헤어 모델에 대해 서로 다른 뷰에서 4개의 방향 이미지를 렌더링합니다.
    
    헤어 예측 네트워크: 저자들은 헤어넷이라는 네트워크를 제안합니다. 이 네트워크는 먼저 입력 이미지를 잠재 벡터로 인코딩한 다음 벡터에서 대상 머리카락 가닥을 디코딩합니다. 이 네트워크는 두 단계로 머리카락 가닥을 생성합니다. 머리카락 특징 벡터는 먼저 디컨볼루션 레이어를 통해 여러 가닥 특징 벡터로 디코딩되고, 각 가닥 특징 벡터는 다중 레이어 완전 연결 네트워크를 통해 최종 가닥 형상으로 추가 디코딩될 수 있습니다. 저자는 네트워크에 3D 위치와 각 샘플의 곡률에 대한 L2 재구성 손실, 출력된 모발 가닥과 인체 사이의 충돌 손실이라는 세 가지 손실을 적용했습니다.
    
    재구성: 네트워크의 출력 가닥에는 노이즈가 포함될 수 있으며, 대상 모발이 곱슬일 경우 고주파 디테일이 손실되는 경우가 있습니다. 따라서 저자는 머리카락의 부드러움과 컬을 더욱 세밀하게 다듬습니다. 먼저 가우시안 필터를 사용하여 노이즈를 제거하여 머리카락을 매끄럽게 만듭니다. 그런 다음 예측된 곡률과 출력 가닥의 곡률의 차이를 비교합니다. 차이가 임계값보다 크면 스트랜드 샘플에 오프셋을 추가합니다. 또한 네트워크에서 생성된 중간 스트랜드 특징을 보간하고 퍼셉트론 네트워크를 사용하여 스트랜드로 디코딩하여 임의의 해상도로 헤어 모델을 생성할 수 있습니다.
    
    평가: 저자들은 방법의 성능을 평가하기 위해 정량적 평가와 정성적 평가를 모두 수행합니다. 100개의 무작위 헤어 모델과 각 헤어 모델에 대해 무작위 뷰에서 렌더링된 4개의 이미지로 구성된 합성 테스트 세트를 준비합니다. 그리고 점 사이의 평균 제곱 거리와 충돌 오차를 사용하여 머리카락의 보이는 부분과 보이지 않는 부분의 재구성 오류를 개별적으로 계산합니다. 또한 다양한 실제 인물 사진을 입력으로 사용하여 방법을 테스트합니다.
    
    한계와 향후 작업: 저자들은 자신들의 접근 방식에 몇 가지 한계가 있음을 인정합니다. 예를 들어, 이 방법은 변태, 아프로, 버즈 컷과 같은 특정 유형의 헤어스타일을 생성하지 못합니다. 또한 이 방법은 머리카락이 부분적으로 가려진 경우에도 어려움을 겪습니다. 연구진은 더 많은 변형을 포함하는 더 큰 헤어 데이터 세트를 구축하고, 훈련에 무작위 폐색을 추가하고, 딥러닝을 사용하여 머리와 몸을 세분화하고, 시간적 평활성을 훈련 제약 조건으로 통합하고, 제어 훈련을 위해 명시적 레이블을 잠재 변수에 연결하는 등 향후 몇 가지 개선 방향을 제안합니다.
    
- HairNet
    
    헤어넷은 단일 뷰 이미지에서 3D 헤어 형상을 생성하기 위해 저자들이 제안한 딥러닝 모델입니다. 헤어넷의 작동 방식에 대한 단계별 설명은 다음과 같습니다:
    
    - 인코더: 네트워크는 먼저 입력 이미지를 잠재 벡터로 인코딩합니다. 입력 이미지는 3 × 256 × 256 이미지로, 처음 두 채널은 색상으로 구분된 머리카락 방향을 저장하고 세 번째 채널은 머리카락, 몸, 배경의 세분화를 나타냅니다. 인코더는 컨볼루션 레이어를 사용하여 이 이미지에서 높은 수준의 특징을 추출합니다. 완전히 연결된 레이어를 마지막 레이어로 사용하는 대신 2D 최대 풀링을 사용하여 부분적인 특징을 글로벌 특징 벡터로 공간적으로 집계합니다. 이렇게 하면 네트워크 매개변수의 수가 줄어듭니다.
    - 디코더: 디코더는 두 단계로 머리카락 가닥을 생성합니다. 먼저 헤어 특징 벡터는 컨볼루션 레이어를 통해 여러 가닥 특징 벡터로 디코딩됩니다. 각 스트랜드 특징 벡터는 완전히 연결된 다중 레이어 네트워크를 통해 최종 스트랜드 지오메트리로 추가 디코딩될 수 있습니다. 이러한 다중 스케일 디코딩 메커니즘을 통해 네트워크는 스트랜드 피처를 보간하여 보다 밀도가 높은 헤어 모델을 효율적으로 생성할 수 있습니다.
    - 손실 함수: 저자들은 네트워크에 3D 위치와 각 샘플의 곡률에 대한 L2 재구성 손실, 출력 모발 가닥과 인체 사이의 충돌 손실 등 세 가지 손실을 적용합니다. 충돌 손실은 타원체 표면까지의 각 충돌 지점 거리를 기준으로 계산되며, 타원체 내부에 있는 가닥의 길이에 따라 가중치가 부여됩니다. 또한 가시성에 따라 샘플에 적응형 가중치를 할당하여 눈에 보이는 샘플이 보이지 않는 샘플보다 더 높은 가중치를 갖습니다.
    - 재구성: 네트워크의 출력 가닥에는 노이즈가 포함될 수 있으며 대상 모발이 곱슬일 경우 고주파 디테일이 손실되는 경우가 있습니다. 따라서 저자는 머리카락의 부드러움과 컬을 더욱 세밀하게 다듬습니다. 먼저 가우시안 필터를 사용하여 노이즈를 제거하여 머리카락 가닥을 부드럽게 만듭니다. 그런 다음 예측된 곡률과 출력 가닥의 곡률의 차이를 비교합니다. 차이가 임계값보다 크면 스트랜드 샘플에 오프셋을 추가합니다.
    
    요약하자면, 헤어넷은 헤어 이미지의 2D 방향 필드를 입력으로 받아 3D 헤어 지오메트리를 생성하는 딥러닝 모델입니다. 인코더-디코더 아키텍처를 사용하고 다중 손실 함수를 적용하여 생성된 모발 가닥의 정확도를 향상시킵니다.
    
- 3D 생성
    
    이 논문에서 2D 이미지를 공간적으로 변환하는 과정에는 이미지의 2D 정보를 3D 표현으로 변환하는 과정이 포함됩니다. 이 작업은 일련의 단계를 거쳐 수행됩니다:
    
    전처리: 전처리: 2D 표현인 입력 이미지를 먼저 전처리하여 모발 영역의 2D 방향 필드를 계산합니다. 이 방향 필드는 이미지에서 머리카락 가닥의 방향을 캡처합니다. 사람의 머리와 몸의 분할 마스크도 생성됩니다.
    
    인코딩: 그런 다음 사전 처리된 이미지가 헤어넷 모델에 공급됩니다. 모델의 인코더 부분은 컨볼루션 레이어를 사용하여 이미지에서 높은 수준의 특징을 추출합니다. 그런 다음 이러한 특징은 2D 최대 풀링을 사용하여 글로벌 특징 벡터로 공간적으로 집계됩니다. 이 벡터는 입력 이미지의 잠재적 표현으로, 3D 헤어 지오메트리를 생성하는 데 필요한 필수 정보를 캡처합니다.
    
    디코딩: 모델의 디코더 부분은 글로벌 특징 벡터를 가져와 헤어 스트랜드를 생성합니다. 이러한 가닥은 처음에 여러 가닥 특징 벡터로 표현된 다음 최종 3D 가닥 지오메트리로 추가 디코딩됩니다. 이 프로세스는 이미지의 2D 정보를 3D 표현으로 효과적으로 변환합니다.
    
    재구성: 네트워크의 출력 가닥을 더욱 세분화하여 부드러움과 컬을 개선하여 보다 정확한 3D 헤어 모델을 생성합니다.
    
    따라서 여기서 2D 이미지의 공간 변환은 딥러닝 모델을 사용하여 이미지의 2D 정보를 3D 표현으로 변환하는 과정을 의미합니다.
    
- 머리와 몸의 분할 마스크
    
    세분화 마스크는 이미지에서 서로 다른 물체 또는 물체의 일부에 해당하는 서로 다른 영역을 식별하는 이미지 유형입니다. 여기서 사람의 머리와 몸의 세분화 마스크는 각 픽셀이 머리의 일부, 몸의 일부 또는 배경의 일부로 레이블이 지정된 이미지입니다.
    
    이 논문의 경우, 저자는 세분화 마스크를 사용하여 모델이 신체의 나머지 부분과 관련하여 머리카락의 위치를 이해하는 데 도움을 줍니다. 이는 3D 공간에서 머리카락의 위치와 방향이 머리와 몸의 위치와 방향에 크게 영향을 받기 때문에 중요합니다.
    
    세분화 마스크는 3D 모핑 가능한 머리 모델을 입력 이미지의 얼굴에 맞춰 생성됩니다. 그런 다음 리지드 변환을 통해 몸통을 적절히 배치할 수 있습니다. 이 프로세스는 자동화하여 실시간으로 실행할 수 있습니다. 최종 출력은 3 × 256 × 256 이미지로, 처음 두 채널은 색상으로 구분된 모발 방향을 저장하고 세 번째 채널은 모발, 신체, 배경의 세분화를 나타냅니다. 이 이미지는 헤어넷 모델의 입력으로 사용됩니다.
    
- 입력이미지
    
    이 논문에서는 세분화 프로세스를 사용하여 이미지를 머리카락, 사람의 머리, 신체에 해당하는 여러 영역으로 분리합니다. 세분화는 256x256 크기의 3채널 이미지로 표현됩니다. 다음은 세분화가 어떻게 구성되는지에 대한 간단한 예시입니다:
    
    채널 1(머리 방향 - X): 이 채널은 색상으로 구분된 헤어 방향의 X 컴포넌트를 저장합니다. 이 채널의 값은 가로(왼쪽에서 오른쪽) 방향의 헤어 스트랜드 방향을 나타냅니다.
    
    채널 2(헤어 방향-Y): 이 채널은 색상으로 구분된 헤어 방향의 Y 컴포넌트를 저장합니다. 이 채널의 값은 수직(상하) 방향의 헤어 스트랜드 방향을 나타냅니다.
    
    채널 3(세분화 마스크): 이 채널은 헤어, 바디, 배경의 세분화를 나타냅니다. 이 채널의 각 픽셀에는 해당 픽셀이 속한 영역에 해당하는 값이 할당됩니다. 예를 들어 머리카락 영역에 속한 픽셀은 1, 몸통에 속한 픽셀은 2, 배경에 속한 픽셀은 0의 값이 할당될 수 있습니다.
    
    이는 단순화된 예시이며 실제 프로세스에는 특히 머리카락 방향을 계산하는 등 더 복잡한 계산이 포함될 수 있습니다. 그러나 일반적인 개념은 세분화 프로세스가 이미지를 여러 영역으로 나누고 이 정보를 헤어넷 모델에 입력으로 사용할 수 있는 형식으로 인코딩한다는 것입니다.