# Instant3D: Fast Text-to-3D with Sparse-View Generation and Large Reconstruction Model

[https://arxiv.org/abs/2311.06214](https://arxiv.org/abs/2311.06214)

[https://jiahao.ai/instant3d/](https://jiahao.ai/instant3d/)

- Nov 2023
    
    ![우리의 방법은 주어진 텍스트 프롬프트에서 20초 이내에 고품질 3D NeRF 에셋을 생성합니다. 여기에서는 생성된 NeRF의 새로운 뷰 렌더링과 밀도 필드에서 추출된 메시의 렌더링을 보여줍니다.](Instant3D%20Fast%20Text-to-3D%20with%20Sparse-View%20Generat%20a5461f4df9ab45ccb47fbbc342a342e6/Untitled.png)
    
    우리의 방법은 주어진 텍스트 프롬프트에서 20초 이내에 고품질 3D NeRF 에셋을 생성합니다. 여기에서는 생성된 NeRF의 새로운 뷰 렌더링과 밀도 필드에서 추출된 메시의 렌더링을 보여줍니다.
    

### 1 INTRODUCTION

2D 이미지 생성의 발전은 확산 모델과 같은 새로운 생성 모델의 개발과 Laion5B와 같은 대규모 데이터 세트의 가용성에 기인합니다. 그러나 3D 훈련 데이터의 가용성과 품질이 제한되어 있기 때문에 이러한 성공을 3D 이미지 생성으로 옮기는 것은 어려운 일입니다.

기존의 3D 이미지 생성 방법은 시각적 품질, 다양성, 복잡성 측면에서 한계에 직면해 있었습니다. 이는 주로 사용 가능한 가장 큰 3D 데이터 세트인 Objaverse-XL이 Laion5B와 같은 2D 데이터 세트보다 훨씬 작고 다양하지 않기 때문입니다. 일부 방법은 사전 학습된 2D 확산 모델의 기능을 활용하여 이러한 한계를 극복하려고 시도했습니다. 이러한 접근 방식은 2D 제너레이터를 사용하여 3D 표현에 최적화하며, 일반적으로 NeRF(신경 방사 필드)를 사용합니다. 이러한 방식은 시각적 품질과 텍스트와의 정렬이 더 우수하지만, 시간이 오래 걸리며 각 프롬프트에 맞게 3D 이미지를 최적화하는 데 몇 시간이 걸리는 경우가 많습니다. 또한 색상이 지나치게 채도가 높고 결과물의 다양성이 제한되는 등의 문제가 있습니다.

이러한 문제를 해결하기 위해 텍스트 프롬프트를 기반으로 고품질의 다양한 3D 에셋을 빠르게 생성할 수 있는 새로운 방법인 Instant3D를 소개합니다. Instant3D는 사전 학습된 2D 확산 모델을 기반으로 하며 두 단계로 작동합니다: 2D 생성 및 3D 재구성. 첫 번째 단계에서는 기존 텍스트-이미지 확산 모델을 미세 조정하여 단일 노이즈 제거 프로세스에서 희박한 4뷰 이미지 세트를 생성하므로 보다 일관된 결과를 얻을 수 있습니다. 두 번째 단계에서는 생성된 멀티뷰 이미지에서 삼면 기반 NeRF를 회귀하는 트랜스포머 기반 아키텍처의 새로운 스파스 뷰 대규모 재구성 모델을 사용합니다. 이 모델은 약 75만 개의 3D 오브젝트에 대한 멀티뷰 렌더링 이미지로 훈련됩니다.

이전 방법과 달리 Instant3D는 각 텍스트 프롬프트에 약 20초만 걸리는 빠른 속도로 이전의 최적화 기반 방법보다 훨씬 빠릅니다. 다른 방식에 비해 훈련에 더 적은 데이터 세트를 사용하지만, Instant3D의 2단계 접근 방식은 사전 훈련된 2D 확산 모델의 성능과 결합하여 복잡한 프롬프트에도 고품질의 다양한 3D 에셋을 생성할 수 있습니다. 그 결과 이전 기법보다 더 빠를 뿐만 아니라 비슷하거나 더 나은 품질을 얻을 수 있는 방법이 탄생했습니다.

### 2 RELATED WORKS

백서의 두 번째 섹션인 '관련 연구'에서는 3D 제너레이션 기술의 배경과 진화에 대해 자세히 살펴보고 이 분야의 발전과 한계를 강조합니다.

3D 생성:

이 백서는 생성적 적대 신경망(GAN)과 확산 모델을 사용한 2D 이미지 생성의 성공에 따른 3D 생성의 진전에 대해 논의하는 것으로 시작합니다. 이전의 GAN 기반 방법에서는 포인트 클라우드, 트라이앵글 메시, 볼륨과 같은 다양한 형태의 3D 모델을 생성하는 방법을 모색했습니다. 그러나 이러한 방법은 일반적으로 카테고리별 학습이 필요하고 새로운 카테고리로 일반화하는 데 어려움이 있습니다.

확산 모델은 3D 생성에 새로운 가능성을 가져왔습니다. 일부 방법은 3D 표현에 대해 3D 확산 모델을 직접 훈련하거나 확산 프로세스에 잠재 표현을 사용합니다. 이러한 접근 방식은 수백만 개의 3D 에셋에 대한 학습에도 불구하고 종종 시각적 품질이 떨어지고 입력 프롬프트에 맞지 않는 콘텐츠가 생성됩니다.

이러한 한계를 극복하기 위해 최근에는 2D 확산 모델을 활용하여 3D 생성을 지원하고 있습니다. 렌더링된 이미지와 입력 프롬프트 사이의 클립 점수를 사용하여 3D 모델을 최적화하는 방법도 있고, 사전 학습된 2D 확산 모델을 기반으로 점수 증류 손실을 사용하는 방법도 있습니다. 그러나 이러한 방법은 느린 최적화, 시각적 사실감 문제, 동일한 물체의 다른 시점이 일관되지 않게 보이는 야누스 문제와 같은 문제가 종종 발생합니다.

스파스 뷰 재구성:
기존의 3D 재구성 방법에는 일반적으로 밀도가 높은 입력 이미지 세트가 필요합니다. NeRF(신경 방사 필드)와 그 변형으로 3D 모델을 더 쉽게 재구성할 수 있게 되었지만 여전히 많은 입력 이미지가 필요합니다. 이전의 일부 방법은 드문드문한 이미지 세트에서 NeRF를 추론하려고 시도했지만, 카테고리별로 다르거나 작은 데이터 세트에 대해 학습되어 일반화 가능성이 제한적이었습니다.

최근의 방법은 사전 학습된 2D 확산 모델의 데이터를 사용하여 2D 이미지를 3D로 변환하지만, 이 접근 방식은 여러 입력 보기 간에 불일치를 초래할 수 있습니다. 반면, 이 논문에서 제안한 방법인 Instant3D는 대규모 3D 데이터로 학습된 확장 가능한 트랜스포머 기반 아키텍처를 사용하여 단 4개의 이미지로 3D 모델을 정확하게 재구성할 수 있습니다. 이 접근 방식은 스파스 뷰에서 3D를 재구성하는 초기 기술을 최신 학습 기법으로 재검토하며, 단순한 장면 재구성이 아닌 생성의 맥락에서 적용됩니다.

이 백서에서는 기존 3D 생성 및 재구성 방법의 맥락에서 인스턴트3D의 속도, 효율성, 희소 이미지 세트에서 고품질의 다양한 3D 에셋을 생성하는 능력의 장점을 강조합니다.

![방법 개요. 텍스트 프롬프트('초밥으로 만든 자동차')가 주어지면, 미세 조정된 2D 확산 모델을 사용하여 가우시안 블롭을 초기화로 사용하여 멀티뷰 생성을 수행하여 2×2 그리드 형태의 4뷰 이미지를 생성합니다. 그런 다음 4뷰 이미지에 트랜스포머 기반 스파스뷰 3D 재구성기를 적용하여 최종 NeRF를 생성합니다.](Instant3D%20Fast%20Text-to-3D%20with%20Sparse-View%20Generat%20a5461f4df9ab45ccb47fbbc342a342e6/Untitled%201.png)

방법 개요. 텍스트 프롬프트('초밥으로 만든 자동차')가 주어지면, 미세 조정된 2D 확산 모델을 사용하여 가우시안 블롭을 초기화로 사용하여 멀티뷰 생성을 수행하여 2×2 그리드 형태의 4뷰 이미지를 생성합니다. 그런 다음 4뷰 이미지에 트랜스포머 기반 스파스뷰 3D 재구성기를 적용하여 최종 NeRF를 생성합니다.

### 3 METHOD

이 백서의 '방법' 섹션에서는 스파스 뷰 생성 및 피드 포워드 NeRF 재구성으로 구성된 Instant3D의 2단계 프로세스에 대해 설명합니다.

3.1 텍스트 조건부 스파스 뷰 생성:
첫 번째 단계는 주어진 텍스트 프롬프트와 일치하고 서로 일관된 멀티뷰 이미지 세트를 생성하는 것입니다. 이는 사전 학습된 텍스트-이미지 확산 모델을 미세 조정하여 2x2 그리드에서 이미지를 생성함으로써 이루어집니다. 사용된 모델은 보기 일관성 있는 이미지를 생성할 수 있는 SDXL입니다.

이 프로세스에는 몇 가지 핵심 기술이 사용됩니다:

이미지 그리드를 사용한 다중 뷰 생성: 이 모델은 서로 다른 보기의 이미지를 단일 이미지 그리드로 컴파일합니다. 이 그리드 형식은 2D 확산 모델의 원본 데이터 형식과 호환되며 효과적으로 미세 조정할 수 있습니다.

멀티뷰 데이터 생성 및 큐레이션: 이 팀은 Blender를 사용하여 약 75만 개의 오브젝트에 대한 멀티뷰 렌더링을 생성하고 Cap3D의 텍스트 프롬프트를 채택했습니다. 하지만 모든 데이터가 똑같이 유용한 것은 아니었기 때문에 에셋 품질을 예측하기 위해 간단한 스코어를 훈련하고 상위 10K 데이터만 훈련에 사용했습니다.

가우시안 블롭 초기화를 통한 추론: 추론 과정에서 깨끗한 배경 생성을 보장하기 위해 팀은 가우시안 블롭 초기화에서 시작하는 기법을 활용했습니다. 이 접근 방식은 배경이 더 깨끗한 고품질 이미지를 생성하여 재구성 프로세스를 용이하게 합니다.

이 가벼운 미세 조정 접근 방식은 선별된 멀티뷰 데이터에 대해 10,000회만 반복하면 되므로 학습 시간과 리소스를 크게 줄일 수 있습니다.

3.2 피드 포워드 스파스 뷰 대규모 재구성 모델:
두 번째 단계는 첫 번째 단계에서 생성된 4뷰 이미지에서 NeRF를 재구성하는 것을 목표로 합니다. 이 프로세스에는 스파스 입력의 고유한 모호성을 처리할 수 있는 강력한 모델이 필요합니다.

![스파스뷰 재구성기의 아키텍처. 이 모델은 사전 학습된 ViT를 적용하여 멀티뷰 이미지를 포즈 인식 이미지 토큰으로 인코딩한 다음, 트랜스포머 기반 디코더를 사용하여 장면의 삼면 표현을 디코딩합니다. 마지막으로 포인트별 삼면 특징을 밀도와 색상으로 디코딩하고 볼륨 렌더링을 수행하여 새로운 뷰를 렌더링합니다. 여기서는 2개의 뷰로 설명하지만 실제 구현에서는 4개의 뷰를 사용합니다.](Instant3D%20Fast%20Text-to-3D%20with%20Sparse-View%20Generat%20a5461f4df9ab45ccb47fbbc342a342e6/Untitled%202.png)

스파스뷰 재구성기의 아키텍처. 이 모델은 사전 학습된 ViT를 적용하여 멀티뷰 이미지를 포즈 인식 이미지 토큰으로 인코딩한 다음, 트랜스포머 기반 디코더를 사용하여 장면의 삼면 표현을 디코딩합니다. 마지막으로 포인트별 삼면 특징을 밀도와 색상으로 디코딩하고 볼륨 렌더링을 수행하여 새로운 뷰를 렌더링합니다. 여기서는 2개의 뷰로 설명하지만 실제 구현에서는 4개의 뷰를 사용합니다.

모델 아키텍처에는 다음이 포함됩니다:

이미지 인코더: 사전 학습된 비전 트랜스포머(ViT)가 멀티뷰 이미지를 토큰으로 인코딩합니다. 카메라 정보를 주입하여 출력 포즈를 인식할 수 있도록 합니다.

이미지-트라이플레인 디코더: 이 컴포넌트는 크로스 어텐션과 자체 어텐션, MLP 레이어를 사용하여 포즈 인식 이미지 토큰을 트라이플레인 토큰과 연결합니다. 삼면체는 장면을 나타내는 학습 가능한 토큰의 평평한 시퀀스입니다.

NeRF 디코더: 트라이플레인 피처는 공유 MLP를 통해 포인트별 밀도와 색상으로 디코딩되고 최종 픽셀 색상은 볼륨 렌더링을 통해 얻습니다.

모델은 MSE 손실과 LPIPS 손실의 조합을 사용하여 Objaverse 데이터 세트의 멀티뷰 렌더링에 대해 엔드투엔드로 학습됩니다. 데이터 증강은 각 오브젝트 주변의 뷰를 무작위로 샘플링하는 등 견고성을 개선하기 위해 훈련 중에 사용됩니다.

요약하면, Instant3D의 방식은 일관된 멀티뷰 이미지를 생성하고 이를 3D 모델로 변환하는 혁신적인 기술을 결합하여 효율적이고 고품질의 3D 에셋을 생성할 수 있습니다.
이 가벼운 미세 조정 접근 방식은 선별된 멀티뷰 데이터에 대해 10,000회만 반복하면 되므로 학습 시간과 리소스를 크게 줄일 수 있습니다.

3.2 피드 포워드 스파스 뷰 대규모 재구성 모델:
두 번째 단계는 첫 번째 단계에서 생성된 4뷰 이미지에서 NeRF를 재구성하는 것을 목표로 합니다. 이 프로세스에는 스파스 입력의 고유한 모호성을 처리할 수 있는 강력한 모델이 필요합니다.

모델 아키텍처에는 다음이 포함됩니다:

이미지 인코더: 사전 학습된 비전 트랜스포머(ViT)가 멀티뷰 이미지를 토큰으로 인코딩합니다. 카메라 정보를 주입하여 출력 포즈를 인식할 수 있도록 합니다.

이미지-트라이플레인 디코더: 이 컴포넌트는 크로스 어텐션과 자체 어텐션, MLP 레이어를 사용하여 포즈 인식 이미지 토큰을 트라이플레인 토큰과 연결합니다. 삼면체는 장면을 나타내는 학습 가능한 토큰의 평평한 시퀀스입니다.

NeRF 디코더: 트라이플레인 피처는 공유 MLP를 통해 포인트별 밀도와 색상으로 디코딩되고 최종 픽셀 색상은 볼륨 렌더링을 통해 얻습니다.

모델은 MSE 손실과 LPIPS 손실의 조합을 사용하여 Objaverse 데이터 세트의 멀티뷰 렌더링에 대해 엔드투엔드로 학습됩니다. 데이터 증강은 각 오브젝트 주변의 뷰를 무작위로 샘플링하는 등 견고성을 개선하기 위해 훈련 중에 사용됩니다.

요약하면, Instant3D의 방식은 일관된 멀티뷰 이미지를 생성하고 이후 3D 모델로 변환하는 데 혁신적인 기술을 결합하여 효율적이고 고품질의 3D 에셋을 생성할 수 있습니다.
이미지 인코더: 사전 학습된 비전 트랜스포머(ViT)가 멀티뷰 이미지를 토큰으로 인코딩합니다. 카메라 정보를 주입하여 출력 포즈를 인식합니다.

이미지-트라이플레인 디코더: 이 컴포넌트는 크로스 어텐션과 자체 어텐션 및 MLP 레이어를 사용하여 포즈 인식 이미지 토큰을 트라이플레인 토큰과 연결합니다. 삼면체는 장면을 나타내는 학습 가능한 토큰의 평평한 시퀀스입니다.

NeRF 디코더: 트라이플레인 피처는 공유 MLP를 통해 포인트별 밀도와 색상으로 디코딩되고 최종 픽셀 색상은 볼륨 렌더링을 통해 얻습니다.

모델은 MSE 손실과 LPIPS 손실의 조합을 사용하여 Objaverse 데이터 세트의 멀티뷰 렌더링에 대해 엔드투엔드로 학습됩니다. 데이터 증강은 각 오브젝트 주변의 뷰를 무작위로 샘플링하는 등 견고성을 개선하기 위해 훈련 중에 사용됩니다.

요약하면, Instant3D의 방식은 일관된 멀티뷰 이미지를 생성하고 이를 3D 모델로 변환하는 혁신적인 기술을 결합하여 효율적이고 고품질의 3D 에셋을 생성할 수 있습니다.
이 가벼운 미세 조정 접근 방식은 선별된 멀티뷰 데이터에 대해 10K 반복만 수행하면 되므로 훈련 시간과 리소스를 크게 절감할 수 있습니다.

3.2 피드 포워드 스파스 뷰 대규모 재구성 모델:
두 번째 단계는 첫 번째 단계에서 생성된 4뷰 이미지에서 NeRF를 재구성하는 것을 목표로 합니다. 이 프로세스에는 스파스 입력의 고유한 모호성을 처리할 수 있는 강력한 모델이 필요합니다.

모델 아키텍처에는 다음이 포함됩니다:

이미지 인코더: 사전 학습된 비전 트랜스포머(ViT)가 멀티뷰 이미지를 토큰으로 인코딩합니다. 카메라 정보를 주입하여 출력 포즈를 인식할 수 있도록 합니다.

이미지-트라이플레인 디코더: 이 컴포넌트는 크로스 어텐션과 자체 어텐션, MLP 레이어를 사용하여 포즈 인식 이미지 토큰을 트라이플레인 토큰과 연결합니다. 삼면체는 장면을 나타내는 학습 가능한 토큰의 평평한 시퀀스입니다.

NeRF 디코더: 트라이플레인 피처는 공유 MLP를 통해 포인트별 밀도와 색상으로 디코딩되고 최종 픽셀 색상은 볼륨 렌더링을 통해 얻습니다.

모델은 MSE 손실과 LPIPS 손실의 조합을 사용하여 Objaverse 데이터 세트의 멀티뷰 렌더링에 대해 엔드투엔드로 학습됩니다. 데이터 증강은 각 오브젝트 주변의 뷰를 무작위로 샘플링하는 등 견고성을 개선하기 위해 훈련 중에 사용됩니다.

요약하면, Instant3D의 방식은 일관된 멀티뷰 이미지를 생성하고 이후 3D 모델로 변환하는 데 혁신적인 기술을 결합하여 효율적이고 고품질의 3D 에셋을 생성할 수 있습니다.

![이전 방법과 비교한 텍스트 대 3D의 정성적 비교. 보충 자료에 선별되지 않은 더 많은 비교 결과가 포함되어 있습니다.](Instant3D%20Fast%20Text-to-3D%20with%20Sparse-View%20Generat%20a5461f4df9ab45ccb47fbbc342a342e6/Untitled%203.png)

이전 방법과 비교한 텍스트 대 3D의 정성적 비교. 보충 자료에 선별되지 않은 더 많은 비교 결과가 포함되어 있습니다.

### 4 EXPERIMENTS

이 백서의 "실험" 섹션에서는 Instant3D의 성능을 평가하고, 텍스트에서 3D로 생성하는 기존 방법과 비교하고, 모델의 다양한 측면에 대한 제거 연구를 수행하고, 스파스 뷰 재구성의 유효성을 조사합니다.

4.1 텍스트-3D 비교:

Instant3D는 텍스트에서 3D로 생성하는 최신 방법과 비교됩니다: Shap-E, 드림퓨전, 프로리컬드리머. 질적으로 Instant3D는 이러한 방식에 비해 더 선명한 텍스처, 더 나은 지오메트리, 향상된 텍스트-3D 정렬을 생성합니다. 또한 입력 텍스트와 더 잘 정렬됨을 나타내는 CLIP 점수도 더 높습니다. 특히 Instant3D의 추론 시간은 훨씬 빨라 3D 에셋을 생성하는 데 20초밖에 걸리지 않아 DreamFusion(1.5시간) 및 ProlificDreamer(10시간)보다 훨씬 빠릅니다.

4.2 스파스 뷰 재구성 비교:

이 부분에서는 인스턴트3D와 스파스 뷰 NeRF 재구성을 위한 스파스네우스를 비교합니다. 테스트는 구글 스캔 오브젝트 데이터세트에서 수행됩니다. 입력 이미지 수가 더 적음에도 불구하고 Instant3D는 SparseNeus보다 성능이 뛰어나 스파스 뷰 재구성기의 효율성을 보여줍니다.

4.3 절제 연구:

Instant3D의 몇 가지 주요 측면을 자세히 연구합니다:

![Untitled](Instant3D%20Fast%20Text-to-3D%20with%20Sparse-View%20Generat%20a5461f4df9ab45ccb47fbbc342a342e6/Untitled%204.png)

2D 베이스 모델 선택: 모델의 효율성은 기본 2D 텍스트-이미지 모델의 효능에 따라 확장됩니다. 더 큰 SDXL은 SD1.5에 비해 텍스트 이해도와 시각적 품질이 우수합니다.

가우시안 블롭 초기화: 이 기술은 깨끗한 흰색 배경의 이미지를 생성하여 2단계 재구성기를 지원합니다.

미세 조정 데이터 세트의 품질 및 크기: 데이터 세트의 품질은 결과에 큰 영향을 미칩니다. 선별된 데이터는 더 나은 클립 정렬 점수와 질적 개선으로 이어집니다. 데이터 세트 크기는 '이중 하강' 효과를 나타내며, 데이터가 너무 적거나 많으면 결과에 부정적인 영향을 미칠 수 있습니다.

미세 조정 단계 수: 이 연구에서는 미세 조정 단계 수가 너무 적거나 많으면 결과가 저하되는 최적의 미세 조정 단계 수가 있다는 것을 발견했습니다. 최적의 지점은 모델 크기에 따라 다릅니다.

이 실험은 Instant3D가 고품질의 텍스트 정렬 3D 에셋을 빠르게 생성하는 데 탁월할 뿐만 아니라 모델 아키텍처 및 훈련 프로세스에서 신중한 디자인 선택의 이점을 제공한다는 것을 보여줍니다.

### 5 CONCLUSIONS

이 백서의 결론에는 Instant3D에 제시된 연구의 주요 기여와 시사점이 요약되어 있습니다. 이 새로운 접근 방식은 텍스트 프롬프트에서 단 20초 만에 고품질의 다양한 3D 에셋을 생성할 수 있는 피드포워드 2단계 방식입니다. 이 방법은 미세 조정된 2D 텍스트-이미지 모델을 활용하여 일관된 4뷰 이미지를 생성한 다음, 강력한 트랜스포머 기반의 대규모 재구성 모델을 사용하여 3D 모델로 변환함으로써 이를 달성합니다.

성능 측면에서 Instant3D는 비슷한 속도를 유지하면서 품질 면에서 이전 피드포워드 방식을 능가합니다. 또한 이전 최적화 기반 방법과 비슷하거나 더 나은 결과를 얻으면서도 속도가 200배 이상 빨라졌습니다. 이러한 효율성 덕분에 Instant3D는 초보 사용자와 전문가 모두에게 특히 유용하며, 3D 에셋을 쉽게 생성하고 3D 디자인 및 모델링과 같은 분야에서 신속한 프로토타이핑을 가능하게 합니다.

또한 이 백서에는 인스턴트3D의 생성 기능이 공개 2D 안정 확산 모델(SDXL)에서 계승되었음을 인정하는 윤리 선언문도 포함되어 있습니다. 미세 조정 프로세스는 SDXL에 추가적인 지식을 추가하지 않으며, 윤리적 및 법적 고려 사항도 유사합니다. 그러나 학습에 사용되는 선별된 데이터는 작성자의 선호도를 반영하기 때문에 잠재적인 편견이 있을 수 있습니다. 또한 이 모델은 텍스트 입력을 필터링하지 않으므로 주어진 프롬프트에 대한 출력을 생성하려고 시도합니다.

재현성을 위해 이 백서에서는 모델 개발의 두 단계에 사용된 주요 기술과 데이터 생성 및 큐레이션 프로세스를 자세히 설명합니다. 전체 모델 구성, 학습 세부 사항, 최적화 하이퍼파라미터, 모델 차원은 데이터 큐레이션 프로세스와 함께 부록에 제공됩니다. 재현성을 더욱 지원하기 위해 연구에 사용된 큐레이션된 데이터 주석이 부록에 포함되어 있습니다.

### Appendix

A.1 생성의 다양성:
Instant3D는 피드포워드 패스에서 랜덤 시드를 변경하여 동일한 텍스트 프롬프트에서 다양한 3D 에셋을 생성할 수 있습니다. 그 결과 텍스처와 지오메트리가 뚜렷한 에셋이 생성되어 모델의 다재다능함을 보여줍니다.

A.2 멀티뷰 확산 훈련 세부 사항:
이 모델은 32개의 A100 GPU에서 효율적인 트레이닝을 위해 AdamW 옵티마이저와 특정 하이퍼파라미터를 사용하여 미세 조정을 위한 기반으로 SDXL을 사용합니다. 약 3시간 동안 진행되는 훈련 과정에는 표준 노이즈 제거 확산 손실이 포함됩니다. 훈련에 사용되는 데이터는 1024x1024 그리드로 조립된 렌더링 이미지로 구성되며, SDXL의 해상도 및 화면비 컨디셔닝에 맞춰 조정됩니다.

A.3 데이터 큐레이션 세부 사항:
개발팀은 품질 점수기를 사용하여 Objaverse 데이터 세트에서 고품질 데이터를 큐레이션했습니다. 수동으로 레이블이 지정된 3D 에셋과 CLIP에서 추출한 피처에 대해 바이너리 SVM 분류기를 학습시켜 데이터를 필터링했습니다. 사실적인 텍스처와 복잡한 지오메트리를 보여주는 상위 10K 오브젝트가 미세 조정을 위해 선택되었습니다.

A.4 스파스 뷰 재구성 디테일:
재구성 모델에는 멀티뷰 입력을 수용하고 카메라 정보를 통합하기 위한 조정과 함께 DINO-ViT-B/16 이미지 인코더가 사용되었습니다. 이 모델에는 이미지-투-트라이플레인 트랜스포머 디코더와 체적 렌더링을 위한 NeRF MLP가 포함되어 있습니다. 훈련에는 특정 옵티마이저 설정, 손실 함수, 렌더링 기법이 포함되었습니다.

A.5 안정적 확산 1.5(SD1.5) 트레이닝 세부 사항:
SD1.5는 배치 크기와 그라데이션 누적을 조정하는 등 SDXL과 유사하게 미세 조정되었습니다. 훈련에는 약 33시간이 소요되었습니다.

A.6 이미지 컨디셔닝 생성으로 확장:
이미지 컨디셔닝을 포함하도록 모델을 확장하여 생성된 3D 모델을 더 세밀하게 제어할 수 있게 되었습니다. 여기에는 추가 입력 이미지를 수용하도록 훈련 프로세스를 수정하여 텍스트 프롬프트와 입력 이미지 모두에 일관된 생성 결과를 도출하는 작업이 포함되었습니다.

A.7 가우시안 블롭 초기화:
이 기법은 미세 조정 데이터 분포와 일치하는 샘플을 생성하도록 모델을 안내하기 위해 도입되었습니다. 여기에는 가우시안 노이즈와 물체 사분면 및 흰색 배경을 특징으로 하는 특수하게 구성된 이미지를 혼합하여 노이즈 제거 프로세스의 초기 반복을 수정하는 작업이 포함됩니다.

A.8 스파스 뷰 재구성 제거 결과:
제거 연구에서는 다양한 구성과 훈련 레시피를 테스트하여 트랜스포머 하이퍼파라미터에 대한 모델의 견고성, 훈련에서 LPIPS 손실과 새로운 감독 뷰의 중요성 등을 밝혀냈습니다.

B 한계 및 논의:
이 백서에서는 모델의 효율성, 3D 일관된 뷰를 생성하기 위한 2D 모델에 대한 의존성, 재구성 모델이 텍스처를 흐리게 처리하여 원본 뷰에 비해 3D 모델의 품질이 약간 저하되는 경향에 대한 한계를 인정합니다.