# Meta 3D Gen

[https://ai.meta.com/research/publications/meta-3d-gen](https://ai.meta.com/research/publications/meta-3d-gen/?utm_source=threads&utm_medium=organic_social&utm_content=carousel&utm_campaign=research)

- 2024

## **1. Introduction**

![ Meta 3D Gen은 Meta의 텍스트 기반 3D 생성 모델(Meta 3D AssetGen (Siddiqui et al., 2024))과 텍스트 기반 텍스처 생성 모델(Meta 3D TextureGen (Bensadoun et al., 2024))을 통합하여 다양한 고품질 텍스처 3D 자산을 PBR 재료 맵으로 효율적이고 최첨단으로 생성 및 편집할 수 있게 합니다.](Meta%203D%20Gen%20cd988f3e9c48460fb88eb5006834c118/Untitled.png)

 Meta 3D Gen은 Meta의 텍스트 기반 3D 생성 모델(Meta 3D AssetGen (Siddiqui et al., 2024))과 텍스트 기반 텍스처 생성 모델(Meta 3D TextureGen (Bensadoun et al., 2024))을 통합하여 다양한 고품질 텍스처 3D 자산을 PBR 재료 맵으로 효율적이고 최첨단으로 생성 및 편집할 수 있게 합니다.

텍스트 기반 3D 생성은 텍스트 설명을 바탕으로 캐릭터, 소품, 장면 등의 3D 콘텐츠를 생성하는 과정을 의미합니다. 3D 콘텐츠 제작은 비디오 게임, 증강 현실 및 가상 현실 애플리케이션, 영화 산업의 특수 효과 디자인 및 개발에서 가장 시간 소모적이고 어려운 측면 중 하나입니다. 3D 아티스트 역할을 하는 AI 어시스턴트를 통해 개인 맞춤형 3D 콘텐츠 제작에 중점을 둔 새로운 경험을 제공할 수 있습니다. 생성형 3D 어시스턴트는 사용자 생성 비디오의 가상 제품 배치와 같은 다양한 애플리케이션을 지원할 수 있으며, 메타버스의 무한히 큰 가상 세계를 구축하는 데도 중요합니다.

3D 생성에는 이미지나 비디오 생성과는 다른 고유하고 어려운 도전 과제가 있습니다. 생산 준비가 된 3D 콘텐츠는 예술적 품질, 생성 속도, 3D 메시의 구조적 및 토폴로지적 품질, UV 맵의 구조, 텍스처의 선명도 및 해상도 측면에서 엄격한 기준을 충족해야 합니다. 다른 미디어와 비교할 때 고유한 도전 과제는 학습할 수 있는 이미지 및 비디오가 수십억 개 존재하는 반면, 훈련에 적합한 3D 콘텐츠의 양은 세 자릿수에서 네 자릿수 정도로 훨씬 적다는 것입니다. 따라서 3D 생성은 3D가 아닌 이미지 및 비디오에서도 학습해야 하며, 2D 관찰에서 부분적으로 3D 정보를 추론해야 합니다.

Meta 3D Gen은 1분 이내에 고품질의 3D 자산 생성을 달성합니다. 이는 애플리케이션에서 생성된 자산의 재조명을 가능하게 하는 물리 기반 렌더링(PBR)을 지원합니다. 전문 3D 아티스트들이 평가한 결과, Meta 3D Gen은 복잡한 텍스트 프롬프트에 대해 특히 중요한 지표를 크게 개선하였습니다. 텍스트 프롬프트에 대한 충실도는 다른 상업적 또는 비상업적 텍스트 기반 3D 접근 방식보다 우수하며, 생성에 3분에서 1시간이 걸리는 기술들을 능가합니다. 생성된 3D 형태와 텍스처의 품질은 이러한 경쟁 기술들과 동등하거나 더 나은 수준이며, 더 빠르고 충실한 확장 가능한 시스템을 사용합니다. 객체가 생성된 후에는 텍스처를 20초 내에 더 높은 품질로 편집 및 맞춤화할 수 있으며, 대안과 비교했을 때 비용도 훨씬 적게 듭니다. 동일한 접근 방식은 수정 없이 아티스트가 만든 3D 메시의 텍스처링에도 적용할 수 있습니다.

이 기술 보고서의 나머지 부분에서는 Meta 3D Gen 파이프라인 전체를 설명하고, Meta 3D AssetGen과 Meta 3D TextureGen이 어떻게 통합되는지 논의하며, 텍스트 기반 3D 생성에 대한 가장 저명한 산업 표준과의 광범위한 평가 연구를 수행합니다. Meta 3D Gen은 텍스트 기반 3D 생성과 텍스트 기반 텍스처 생성을 결합한 두 단계의 방법으로, 몰입형 콘텐츠 제작을 위한 더 높은 품질의 3D 생성을 실현합니다.

- **1단계: 3D 자산 생성** - 사용자가 제공한 텍스트 프롬프트를 바탕으로 Meta 3D AssetGen 모델을 사용하여 초기 3D 자산을 생성합니다. 이 단계는 텍스처와 PBR 재료 맵이 포함된 3D 메시를 생성하며, 추론 시간은 약 30초입니다.
- **2단계, 사용 사례 1: 생성적 3D 텍스처 개선** - 1단계에서 생성된 3D 자산과 초기 텍스트 프롬프트를 바탕으로 더 높은 품질의 텍스처와 PBR 맵을 생성합니다. 이 과정은 Meta 3D TextureGen 모델을 사용하며, 추론 시간은 약 20초입니다.
- **2단계, 사용 사례 2: 생성적 3D (재)텍스처링** - 텍스처가 없는 3D 메시와 원하는 외형을 설명하는 프롬프트를 제공하면, 이 단계에서 3D 자산의 텍스처를 처음부터 생성할 수 있습니다. 추론 시간은 약 20초입니다.

기술적 접근 방식으로는 AssetGen과 TextureGen을 기반으로 3D 객체의 세 가지 상호 보완적인 표현(view 공간, 볼륨 공간, UV 공간)을 효과적으로 결합하여 최종 텍스처 품질과 해상도를 높이면서 초기 프롬프트에 대한 충실도를 유지합니다. 3DGen의 각 단계는 Meta의 강력한 텍스트 기반 이미지 모델 Emu를 활용하여 다중 뷰 생성 및 UV 공간 생성을 수행합니다.

성능 측면에서는 두 단계의 통합과 다양한 표현 방식의 결합으로 인해 평가에서 68%의 승률을 기록하며, 각각의 구성 요소가 해당 기능에서 최첨단 성능을 보입니다. AssetGen과 TextureGen은 모두 피드포워드 생성기로, 배포 후 빠르고 효율적입니다.

![Meta 3D Gen의 개요. 이 파이프라인은 텍스트 프롬프트를 입력으로 받아 텍스트 기반 3D 생성(1단계, Siddiqui et al. (2024))을 수행하고, 이어서 텍스처 개선(2단계, Bensadoun et al. (2024))을 진행합니다. 2단계는 사용자가 제공한 새로운 텍스트 프롬프트를 사용하여 생성된 메시나 아티스트가 만든 메시를 다시 텍스처링하는 데에도 사용할 수 있습니다.](Meta%203D%20Gen%20cd988f3e9c48460fb88eb5006834c118/Untitled%201.png)

Meta 3D Gen의 개요. 이 파이프라인은 텍스트 프롬프트를 입력으로 받아 텍스트 기반 3D 생성(1단계, Siddiqui et al. (2024))을 수행하고, 이어서 텍스처 개선(2단계, Bensadoun et al. (2024))을 진행합니다. 2단계는 사용자가 제공한 새로운 텍스트 프롬프트를 사용하여 생성된 메시나 아티스트가 만든 메시를 다시 텍스처링하는 데에도 사용할 수 있습니다.

## **2. Method**

**TextureGen (단계 II)**
TextureGen은 주어진 3D 형태에 텍스트 기반으로 텍스처를 생성하는 모델입니다. 텍스처 생성 과정은 여러 단계로 이루어집니다. 먼저, 텍스트 프롬프트와 3D 객체를 입력으로 받아 여러 뷰를 생성합니다. 생성된 뷰는 텍스처 이미지로 재투영되며, 이를 이용해 최종 텍스처를 생성합니다. 이 과정에서 뷰 기반 텍스처의 불일치를 조정하고, 보이지 않는 부분의 텍스처를 보완합니다. 마지막으로, 선택적으로 텍스처의 해상도를 높이는 슈퍼 해상도 네트워크를 적용합니다. 각 단계는 Emu 이미지 생성기를 기반으로 훈련된 디퓨전 기반 생성기를 사용합니다.

**AssetGen (단계 I)**
AssetGen은 텍스트 프롬프트를 기반으로 3D 객체와 텍스처를 생성하는 모델입니다. 이 모델은 단계별로 작동합니다. 먼저, 텍스트 프롬프트를 입력으로 받아 객체의 여러 뷰를 생성합니다. 그런 다음, 생성된 뷰를 바탕으로 3D 메시와 초기 텍스처를 생성합니다. AssetGen은 디퓨전 모델을 사용하여 뷰를 생성하며, 재구성 네트워크를 통해 3D 객체를 결정론적으로 생성합니다. 이 과정에서 PBR 재료를 재구성하여 재조명 가능한 객체를 생성하고, 뷰 정보를 하나의 텍스처로 결합합니다. 마지막으로, 재투영된 텍스처를 결합하여 최종 텍스처를 생성합니다.

**3DGen: 통합 접근법**
3DGen은 AssetGen과 TextureGen을 통합하여 고품질의 텍스트 기반 3D 객체를 생성합니다. 이 통합 과정은 AssetGen에서 생성된 초기 3D 객체와 텍스처를 TextureGen을 통해 개선하여 최종 텍스처의 품질을 높이는 방식으로 이루어집니다. 먼저, AssetGen을 사용해 초기 3D 메시와 UV 맵을 생성한 후, TextureGen을 사용해 더 나은 뷰 기반 텍스처를 생성하고, 이를 UV 공간으로 재투영하여 부분적인 텍스처를 만듭니다. 그런 다음, TextureGen의 네트워크를 사용해 통합된 UV 텍스처를 생성하고, AssetGen의 네트워크를 통해 최종 텍스처를 완성합니다.

## **3. Experiments**

**3.1 Industry baselines**
Meta 3D Gen의 성능을 평가하기 위해, 주요 업계 모델들과 비교 실험을 수행했습니다. 비교 대상 모델은 Common Sense Machines (CSM) Cube 2.0, Tripo3D, Rodin Gen-1 (0525) V0.5, Meshy v3, 그리고 또 다른 익명의 텍스트 기반 3D 생성기(T23D)입니다. 각 모델의 기능과 실행 시간을 요약한 표를 통해 성능을 비교합니다. 각 모델은 공식 API와 웹 인터페이스를 사용하여 텍스트에서 이미지, 이미지에서 3D 생성, 텍스처 생성 및 재료 생성 단계를 거쳐 결과를 도출했습니다.

**3.2 User studies**
사용자 연구는 텍스트 프롬프트 충실도와 시각적 품질을 평가하기 위해 수행되었습니다. 사용자 연구는 두 그룹으로 나누어졌습니다: 3D에 대한 사전 지식이 없는 일반 사용자 그룹과 전문 3D 아티스트, 디자이너, 게임 개발자로 구성된 전문가 그룹입니다. 평가 벤치마크는 DreamFusion에서 처음 도입된 404개의 텍스트 프롬프트 세트를 사용하였으며, 객체, 캐릭터, 그리고 캐릭터와 객체의 조합으로 구성된 카테고리로 나누어 각 모델의 성능을 평가했습니다. 각 평가 항목은 360도 회전 비디오로 렌더링된 메쉬를 사용하여 수행되었습니다. 텍스트 프롬프트 충실도, 시각적 품질, 기하학적 품질, 텍스처 디테일 및 아티팩트가 평가 항목으로 포함되었습니다.

![사용자 연구: 텍스트 프롬프트로 설명된 장면 복잡성에 따른 프롬프트 충실도, 시각적 품질, 기하학 및 텍스처 매개변수의 분석 결과(모든 평가자를 종합한 결과). 3DGen의 베이스라인 대비 승률을 보고하며, 우리 방법이 베이스라인과 동일한 성능을 보이는 50% 임계값(점선)을 강조합니다.](Meta%203D%20Gen%20cd988f3e9c48460fb88eb5006834c118/Untitled%202.png)

사용자 연구: 텍스트 프롬프트로 설명된 장면 복잡성에 따른 프롬프트 충실도, 시각적 품질, 기하학 및 텍스처 매개변수의 분석 결과(모든 평가자를 종합한 결과). 3DGen의 베이스라인 대비 승률을 보고하며, 우리 방법이 베이스라인과 동일한 성능을 보이는 50% 임계값(점선)을 강조합니다.

**3.3 Qualitative results**
질적 결과는 텍스트 기반 3D 생성의 시각적 비교를 통해 제시됩니다. 1단계와 2단계 생성물의 시각적 비교 결과, 2단계 생성물이 더 높은 시각적 미학을 가지고 있으며, 현실적이고 높은 주파수의 디테일을 포함하고 있음을 확인했습니다. 사용자는 68%의 경우 2단계 생성물을 선호했습니다. 다양한 클래스의 텍스트 기반 3D 생성물의 예시는 Figure 5와 Figure 11에 제시되었습니다.

![Meta 3D Gen의 1단계(왼쪽)와 2단계(오른쪽) 후에 얻어진 텍스트 기반 3D 생성물의 시각적 비교. A/B 사용자 연구에서, 2단계 생성물은 텍스처 품질에서 1단계 생성물 대비 68%의 승률을 기록했습니다.](Meta%203D%20Gen%20cd988f3e9c48460fb88eb5006834c118/Untitled%203.png)

Meta 3D Gen의 1단계(왼쪽)와 2단계(오른쪽) 후에 얻어진 텍스트 기반 3D 생성물의 시각적 비교. A/B 사용자 연구에서, 2단계 생성물은 텍스처 품질에서 1단계 생성물 대비 68%의 승률을 기록했습니다.

![텍스트 기반 3D 생성에 대한 정성적 결과. 3DGen이 생성한 텍스트 기반 3D 생성물의 품질과 다양성을 단일 객체 및 구성된 장면 카테고리별로 보여줍니다.](Meta%203D%20Gen%20cd988f3e9c48460fb88eb5006834c118/Untitled%204.png)

텍스트 기반 3D 생성에 대한 정성적 결과. 3DGen이 생성한 텍스트 기반 3D 생성물의 품질과 다양성을 단일 객체 및 구성된 장면 카테고리별로 보여줍니다.

![3DGen이 생성한 단일 객체 클래스("llama")의 품질과 다양성.](Meta%203D%20Gen%20cd988f3e9c48460fb88eb5006834c118/Untitled%205.png)

3DGen이 생성한 단일 객체 클래스("llama")의 품질과 다양성.

또한, 업계 표준 모델과 동일한 장면에서의 성능을 시각적으로 비교하고, 더 복잡한 프롬프트에 대한 결과를 추가적으로 제시했습니다. 이를 통해 대체 모델들이 단순한 객체 생성에서는 우수하지만, 더 복잡한 구성 및 장면 생성에서는 어려움을 겪는다는 것을 확인했습니다. 고주파 디테일 생성과 시각적 아티팩트 노출 간의 명확한 상충 관계가 존재함을 발견했습니다. Meshy v3는 시각적으로 매력적인 스타일을 가지고 있으나, 텍스처 맵의 이음새 문제와 같은 아티팩트가 발생하기 쉽습니다. Rodin Gen-1은 올바른 토폴로지를 가진 쿼드 메쉬를 생성하지만, 복잡한 프롬프트에서 결과를 생성하지 못하는 경우가 있습니다.

![모든 산업 표준과의 텍스트 프롬프트 충실도에 대한 정성적 비교(도전적인 프롬프트에서).](Meta%203D%20Gen%20cd988f3e9c48460fb88eb5006834c118/Untitled%206.png)

모든 산업 표준과의 텍스트 프롬프트 충실도에 대한 정성적 비교(도전적인 프롬프트에서).

![동일한 프롬프트 세트에서 PBR 재료로 텍스처를 생성하는 산업 표준과의 정성적 비교.](Meta%203D%20Gen%20cd988f3e9c48460fb88eb5006834c118/Untitled%207.png)

동일한 프롬프트 세트에서 PBR 재료로 텍스처를 생성하는 산업 표준과의 정성적 비교.

![다양한 방법의 일반적인 실패 모드의 예.](Meta%203D%20Gen%20cd988f3e9c48460fb88eb5006834c118/Untitled%208.png)

다양한 방법의 일반적인 실패 모드의 예.

3D 자산 재텍스처링 실험에서는, 1단계에서 생성된 3D 메쉬를 2단계에서 다른 텍스트 프롬프트를 사용하여 재텍스처링하여 새로운 외형을 가진 자산을 생성할 수 있음을 보여줍니다. 이는 새로운 재료와 예술적 스타일을 성공적으로 모방할 수 있음을 시각적으로 증명합니다. 전체 장면을 일관되게 재텍스처링하는 방법도 제시되었습니다.

![생성된 형태에 대한 (재)텍스처링 결과. 파이프라인의 1단계에서 생성된 메시와 원래 프롬프트와 다른 다양한 텍스트 프롬프트로 2단계에서 텍스처링된 예.](Meta%203D%20Gen%20cd988f3e9c48460fb88eb5006834c118/Untitled%209.png)

생성된 형태에 대한 (재)텍스처링 결과. 파이프라인의 1단계에서 생성된 메시와 원래 프롬프트와 다른 다양한 텍스트 프롬프트로 2단계에서 텍스처링된 예.

![생성된 형태에 대한 (재)텍스처링 결과. Meta 3D Gen의 2단계에서 새로운 스타일 정보를 추가하여 객체별 텍스처링 프롬프트를 일관되게 강화하여 생성된 테마 장면 예.](Meta%203D%20Gen%20cd988f3e9c48460fb88eb5006834c118/Untitled%2010.png)

생성된 형태에 대한 (재)텍스처링 결과. Meta 3D Gen의 2단계에서 새로운 스타일 정보를 추가하여 객체별 텍스처링 프롬프트를 일관되게 강화하여 생성된 테마 장면 예.

## **4. Related Work**

**Text-to-3D**
텍스트 기반 3D 생성 분야에서는 3D 데이터를 학습하는 여러 방법이 제안되었습니다. 일부 연구들은 3D 데이터셋을 활용하여 3D 생성기를 훈련합니다. 그러나 이러한 접근 방식은 제한된 3D 데이터로 인해 일반화에 어려움을 겪습니다. 따라서 최근에는 이미지나 비디오 기반 생성기를 사용하여 수십억 개의 데이터를 학습하는 접근법이 주목받고 있습니다.

많은 방법들은 디스틸레이션(distillation) 기법을 사용합니다. 그러나 디스틸레이션은 느리며 Janus 효과와 같은 아티팩트를 유발할 수 있습니다. 따라서 최근 연구들은 다중 뷰 인식 이미지 생성기를 기반으로 구축되고 있습니다.

다수의 최신 연구들은 일관된 여러 뷰를 생성하여 직접 3D 재구성이 가능하도록 하는 데 초점을 맞추고 있습니다. 그러나 이러한 방법들은 생성된 이미지의 다중 뷰 일관성에 제한이 있을 수 있습니다. 따라서 일부 접근법은 소수의 뷰를 사용한 3D 재구성을 학습합니다.

**Multi-view to 3D**
다수의 생성기들은 소수의 뷰를 사용한 3D 재구성을 기반으로 합니다. NeRF와 같은 방법은 분석-합성 접근법으로 차별화 가능한 렌더링 손실을 최적화합니다. 이러한 접근법은 메쉬에서 3D 가우시안까지 다양한 3D 표현을 사용할 수 있습니다.

소수의 뷰만 사용할 수 있는 경우, 연구자들은 필요한 사전 지식을 습득하기 위해 재구성 모델을 훈련합니다.

**PBR Modelling**
여러 연구자들은 PBR(Physically-Based Rendering) 지원 재구성 방법을 고려해 왔습니다. 이는 3D 생성기에서도 마찬가지입니다.

**Texture Generation**
3D 객체에 텍스처를 생성하는 작업도 여러 연구에서 다루어졌습니다. 예를 들어 일부 연구들은 CLIP과 차별화 가능한 렌더링을 사용하여 텍스트 프롬프트와 일치하는 텍스처를 생성합니다. 다른 연구들은 SDS 손실 최적화를 사용하고, GAN과 유사한 접근 방식을 사용합니다. 다른 방법들은 UV 공간에서 디퓨전을 사용하지만, 이는 주로 인간 캐릭터 텍스처링에 초점을 맞춥니다. 또 다른 연구는 포인트 클라우드 디퓨전을 사용하여 텍스처를 생성합니다.

일부 연구는 텍스처 인페인팅과 깊이 조건 이미지 디퓨전을 결합하지만, 한 번에 하나의 이미지를 생성하여 속도가 느리고 아티팩트에 취약할 수 있습니다. 다른 연구들은 디퓨전 반복과 재투영을 번갈아 사용하여 일관성을 향상시킵니다. 또 다른 연구는 네 개의 텍스처링된 뷰를 공동으로 생성하지만, 텍스처를 추출하기 위해 느린 SDS 최적화를 사용합니다. 또 다른 연구도 텍스처 생성 모듈을 제공하지만, 그 세부 사항은 비공개로 유지됩니다.

**Image Generators**
3DGen의 생성기는 이미지 생성기를 기반으로 합니다. 이미지 생성기는 GAN부터 시작하여 광범위하게 연구되었습니다. 최근 연구들은 트랜스포머 아키텍처를 사용합니다. 더 많은 연구들은 픽셀 공간 또는 잠재 공간에서 디퓨전을 사용합니다. Meta 3D Gen은 Emu 클래스의 이미지 생성기를 기반으로 구축되었습니다.

## **5. Conclusions**

Meta 3D Gen은 텍스트 기반 3D 객체 생성을 위한 통합된 파이프라인으로, 텍스처 편집 및 재료 생성 기능을 포함하고 있습니다. 이 시스템은 각각의 강점을 결합하여 텍스트 프롬프트로부터 매우 높은 품질의 3D 객체를 1분 이내에 생성할 수 있습니다.

Meta 3D Gen의 핵심 구성 요소는 AssetGen과 TextureGen입니다. AssetGen은 텍스트를 기반으로 3D 객체와 초기 텍스처를 생성하는 반면, TextureGen은 이 초기 텍스처를 개선하여 최종 텍스처의 품질을 높입니다. 이러한 접근 방식은 기존 솔루션보다 빠르고 효율적으로 작동하며, 텍스트 프롬프트의 복잡성에 상관없이 일관된 고품질 결과를 제공합니다.

Meta 3D Gen은 특히 전문 3D 아티스트들이 평가한 결과, 업계의 다른 솔루션들과 비교했을 때 복잡한 프롬프트에서도 더 나은 성능을 보였으며, 속도 면에서도 3배에서 60배 더 빠릅니다. 이는 텍스트 기반 3D 생성의 새로운 가능성을 열어주며, 미래 연구의 방향성을 제시합니다.

또한, Meta 3D Gen은 뷰 공간과 UV 공간에서의 생성 및 텍스처와 형태 생성을 위한 종단 간 반복을 포함한 두 가지 주요 연구 방향을 통합합니다. 이러한 접근 방식은 고품질 3D 객체 생성을 위한 강력한 솔루션을 제공하며, 다양한 응용 분야에서 활용될 수 있는 잠재력을 가지고 있습니다.

이로써, Meta 3D Gen은 텍스트 기반 3D 생성의 새로운 표준을 세우고, 개인 맞춤형 3D 콘텐츠 생성 및 다양한 산업 응용에 기여할 수 있는 가능성을 보여줍니다.