# Humans in 4D:Reconstructing and Tracking Humans with Transformers

[https://shubham-goel.github.io/4dhumans/](https://shubham-goel.github.io/4dhumans/)

[https://arxiv.org/abs/2305.20091](https://arxiv.org/abs/2305.20091)

[https://huggingface.co/spaces/brjathu/HMR2.0](https://huggingface.co/spaces/brjathu/HMR2.0)

![인간 메시 복구에 대한 "트랜스포머화된" 시각. 우리는 HMR 2.0을 소개합니다. 이는 단일 이미지로부터 3D 인간 자세와 형상 재구성을 위한 완전한 트랜스포머 기반 접근 방식입니다. 다양한 자세와 시점에 걸쳐 인상적인 성능을 제공하는 것 뿐만 아니라, HMR 2.0은 4차원에서 인간을 공동으로 재구성하고 추적하는 개선된 시스템인 4DHumans의 중추 역할을 합니다. 여기서 왼쪽 이미지의 각 2D 탐지에 대한 HMR 2.0의 출력 재구성을 볼 수 있습니다.](Humans%20in%204D%20Reconstructing%20and%20Tracking%20Humans%20wi%2000cb19ea5d0148c29dd637b3d9b04e48/Untitled.png)

인간 메시 복구에 대한 "트랜스포머화된" 시각. 우리는 HMR 2.0을 소개합니다. 이는 단일 이미지로부터 3D 인간 자세와 형상 재구성을 위한 완전한 트랜스포머 기반 접근 방식입니다. 다양한 자세와 시점에 걸쳐 인상적인 성능을 제공하는 것 뿐만 아니라, HMR 2.0은 4차원에서 인간을 공동으로 재구성하고 추적하는 개선된 시스템인 4DHumans의 중추 역할을 합니다. 여기서 왼쪽 이미지의 각 2D 탐지에 대한 HMR 2.0의 출력 재구성을 볼 수 있습니다.

### 1. Introduction

이 연구 논문에서는 단일 이미지에서 인체를 3D 메시로 복구하고 동영상에서 시간 경과에 따라 추적하는 새로운 트랜스포머 기반 방법인 HMR 2.0을 소개합니다. 이 접근 방식은 사람의 특이한 포즈에 사용해도 전례 없는 수준의 정확도를 제공합니다.

'트랜스포머라이제이션'이라고 하는 이 개념은 컨볼루션 신경망(CNN) 또는 장단기 메모리 네트워크(LSTM)에서 트랜스포머 백본으로 모델을 변경하는 프로세스입니다. HMR 2.0은 휴먼 메시 복구 및 추적에 대한 이전 작업의 "트랜스포머화" 버전입니다.

HMR 2.0 시스템은 오클루전 또는 감지 실패 사례를 처리하는 것을 포함하여 비디오에서 사람을 동시에 재구성하고 추적할 수 있습니다. 이를 통해 모든 비디오에 배포하여 사람을 추적하고 재구성할 수 있는 도구인 4DHumans가 탄생했습니다.

이 작업은 포즈트랙 데이터 세트에서 추적에 대한 최첨단 결과를 달성했으며, AVA v2.2 데이터 세트에서 동작 인식이 크게 개선되었음을 입증했습니다. HMR 2.0은 컴퓨터 비전뿐만 아니라 로봇 공학, 컴퓨터 그래픽, 생체 역학 및 이미지나 비디오에서 사람의 형태와 움직임을 분석해야 하는 모든 분야에 응용될 수 있을 것으로 기대됩니다.

이 논문의 주요 내용은 휴먼 메시 복구를 위한 엔드투엔드 트랜스포머 기반 아키텍처인 HMR 2.0의 생성, 비디오에서 사람을 공동으로 재구성하고 추적할 수 있는 4DHumans의 개발, 행동 인식이라는 다운스트림 작업의 성능 향상을 위해 HMR 2.0을 적용하여 AVA 벤치마크에서 최첨단 결과를 달성한 것입니다.

### 2. Related Work

단일 이미지에서 휴먼 메시 복구: 여기서는 단일 이미지에서 체형을 추론하는 모델에 중점을 둡니다. 대표적인 예로 컨볼루션 신경망(CNN)을 사용하여 표준 다인 선형(SMPL) 모델의 매개변수를 추론하는 HMR이 있습니다. 이 기존 방법에는 시간 정보, 다중 뷰 또는 반복 최적화를 활용하는 의사 실측 자료 생성 전략 등 많은 개선이 이루어졌습니다. 또한 더 나은 오클루전 처리를 위해 메시 정렬 모듈 또는 신체 부위 안내 주의 메커니즘을 통합하는 새로운 HMR 아키텍처 설계도 등장했습니다. 이와 달리 이 백서에서 소개하는 새로운 HMR 2.0은 도메인별 고려 사항 없이 설계되어 이전의 모든 접근 방식보다 성능이 뛰어납니다.

비디오에서 휴먼 메시 및 모션 복구: 이 카테고리에 속하는 대부분의 방법은 프레임별 기능을 결합하는 템포럴 인코더를 위한 설계를 추가하여 HMR을 기본으로 사용합니다. 하지만 일반적으로 한 사람 또는 최소한의 오클루전이 있는 시나리오에서 작동합니다. 이와는 대조적으로 4D휴먼 접근 방식은 추적 문제도 해결합니다.

비디오 속 사람 추적: 최근의 기술은 HMR 모델에서 3D 인간 재구성을 사용하여 최첨단 성능을 달성했습니다. 이 시스템은 이러한 추적 기법, 특히 PHALP를 사용하여 휴먼 메시 복구 방법을 평가합니다.

동작 인식: 일반적인 동작 인식은 원시 비디오 입력의 외관 특징을 사용하여 수행됩니다. 그러나 일부 접근 방식은 신체 포즈 정보에서 추출한 특징을 활용합니다. 연구진은 비디오 기반 특징과 3D 인체 포즈 추정 특징을 융합하여 동작 인식을 위한 최첨단 성능을 입증한 최신 접근법의 파이프라인을 사용합니다. 저자들은 휴먼 메시 복구 방법을 평가하기 위한 다운스트림 작업으로 동작 인식을 사용합니다.

### 3. Reconstructing People

예선: SMPL 모델은 포즈 및 모양에 대한 입력 파라미터로부터 인체의 3D 메시를 출력하는 데 사용됩니다. 포즈 파라미터에는 신체 포즈 파라미터와 전역 방향이 모두 포함됩니다. 초점 거리와 내재값이 고정된 원근 카메라 모델은 SMPL 공간의 포인트를 이미지에 투영하는 데 사용됩니다. 휴먼 메시 재구성(HMR) 작업의 목표는 단일 이미지가 주어졌을 때 이러한 파라미터를 예측하는 것입니다.

![우리의 접근 방식 개요. 왼쪽: HMR 2.0은 인간 메시 복구를 위한 완전한 "트랜스포머화된" 네트워크입니다. 오른쪽: 우리는 HMR 2.0을 PHALP [62]를 기반으로 한 우리의 4DHumans 시스템의 중추로 사용하여, 4차원에서 인간을 공동으로 재구성하고 추적합니다.](Humans%20in%204D%20Reconstructing%20and%20Tracking%20Humans%20wi%2000cb19ea5d0148c29dd637b3d9b04e48/Untitled%201.png)

우리의 접근 방식 개요. 왼쪽: HMR 2.0은 인간 메시 복구를 위한 완전한 "트랜스포머화된" 네트워크입니다. 오른쪽: 우리는 HMR 2.0을 PHALP [62]를 기반으로 한 우리의 4DHumans 시스템의 중추로 사용하여, 4차원에서 인간을 공동으로 재구성하고 추적합니다.

아키텍처: HMR 모델은 도메인별 설계 선택을 사용하지 않는 엔드투엔드 트랜스포머 아키텍처로 재구상되었습니다. 비전 트랜스포머(ViT)는 이미지 토큰을 추출하는 데 사용되며, 표준 트랜스포머 디코더는 SMPL 및 카메라 파라미터를 출력합니다.

손실: 모델은 2D 손실, 3D 손실 및 판별자의 조합을 사용하여 학습되며, 각 이미지에 사용할 수 있는 주석에 따라 특정 손실이 사용됩니다. 실측 SMPL 포즈 및 모양 매개변수를 사용할 수 있는 경우 평균제곱오차(MSE) 손실이 사용되며, 실측 3D 및 2D 키포인트 주석에는 L1 손실이 사용됩니다. 모델이 유효한 3D 포즈를 예측할 수 있도록 적대적 사전 예측도 사용됩니다.

![자세 예측: 우리는 BERT 스타일의 [12] 트랜스포머 모델을 [60]에서 얻은 100만 개 이상의 트랙에 대해 훈련시킵니다. 이를 통해 우리는 같은 모델을 사용하여 미래의 예측과 누락된 탐지의 아모달 완성을 할 수 있습니다. 미래의 자세(t+1, t+2, ...)를 예측하기 위해, 우리는 해당 위치 임베딩을 사용하여 모델에 마스크 토큰을 쿼리합니다. 마찬가지로 아모달 완성을 위해, 우리는 누락된 탐지를 마스크된 토큰으로 대체합니다.](Humans%20in%204D%20Reconstructing%20and%20Tracking%20Humans%20wi%2000cb19ea5d0148c29dd637b3d9b04e48/Untitled%202.png)

자세 예측: 우리는 BERT 스타일의 [12] 트랜스포머 모델을 [60]에서 얻은 100만 개 이상의 트랙에 대해 훈련시킵니다. 이를 통해 우리는 같은 모델을 사용하여 미래의 예측과 누락된 탐지의 아모달 완성을 할 수 있습니다. 미래의 자세(t+1, t+2, ...)를 예측하기 위해, 우리는 해당 위치 임베딩을 사용하여 모델에 마스크 토큰을 쿼리합니다. 마찬가지로 아모달 완성을 위해, 우리는 누락된 탐지를 마스크된 토큰으로 대체합니다.

의사 기준 진실 피팅: 레이블이 지정되지 않은 데이터 세트에 맞게 모델을 조정하기 위해 의사 기준 진실 주석이 계산됩니다. 여기에는 상용 검출기와 바디 키포인트 추정기를 사용하여 바운딩 박스와 해당 2D 키포인트를 구한 다음, 이 2D 키포인트에 SMPL 메시를 피팅하여 의사 기준 진실 SMPL 파라미터를 구하는 과정이 포함됩니다.

### 4. Tracking People

앞서 언급한 3D 재구성에서 얻은 특징을 기반으로 하는 최첨단 트래커인 PHALP라는 기존 모델을 사용합니다. 관련된 단계는 다음과 같습니다:

프로세스는 개별 프레임에서 사람을 감지하는 것으로 시작됩니다. 이를 3D로 '리프팅'하여 3D 공간에서 포즈, 위치, 외형을 추출합니다.

시간이 지남에 따라 각 사람에 대한 트랙렛 표현이 생성됩니다. 재귀 단계에서는 다음 프레임에서 각 개인의 포즈, 위치, 외모를 모두 3D로 예측합니다.

그런 다음 예측을 프레임에서 감지된 사람과 비교하여(3D로 들어올린 후) 가장 잘 일치하는 사람을 찾습니다. 각 트래클릿 상태는 들어오는 관찰에 따라 업데이트되며, 과거 기록을 기반으로 3D 표현을 계속 업데이트하기 때문에 폐색을 통한 추적이 가능합니다.

이 논문에서는 강력한 포즈 예측기가 이러한 다운스트림 추적 작업에서 우수한 성능을 발휘해야 한다고 주장합니다. 결과적으로 추적 메트릭은 3D 재구성의 품질을 평가하는 데 사용됩니다.

저자들은 PHALP 프레임워크 내에서 서로 다른 포즈 예측 모델을 공정하게 비교할 수 있도록 몇 가지 수정을 가했습니다. 원래 PHALP는 HMR 네트워크의 마지막 레이어에 있는 포즈 특징을 사용했기 때문에 다른 포즈 모델과의 호환성이 제한적이었습니다. 저자들은 포즈의 표현을 SMPL 포즈 파라미터로 변경하고 그에 따라 PHALP 비용 함수를 조정했습니다. 또한 포즈 예측기가 SMPL 파라미터의 공간에서 작동하도록 조정했습니다.

특히 무작위 포즈 토큰을 마스킹하여 바닐라 트랜스포머 모델을 학습시킴으로써 미래의 포즈를 예측하고 누락된 감지를 완료할 수 있도록 했습니다. 이러한 변화를 통해 모든 메시 복구 방법을 통합하여 모든 비디오에 적용할 수 있었습니다.

그런 다음 저자들은 재구성과 추적을 모두 통합하는 결합 시스템을 도입하여 더 나은 포즈 재구성이 더 나은 추적 결과를 가져온다는 것을 보여주었습니다. 저자들은 이 시스템을 '4D휴먼'이라고 부르며, 이 시스템은 모든 동영상에서 작동할 수 있습니다.

### 5. Experiments

실험 설정: 이 시스템은 Human3.6M, MPI-INF3DHP, COCO, MPII, InstaVariety, AVA, AI Challenger와 같은 다양한 데이터 세트로 훈련되었습니다. 연구팀은 이 모델의 성능을 PyMAF, CLIFF, HMAR, PARE, PyMAF-X를 포함한 여러 이전 방법과 비교했습니다.

![HMR 2.0의 질적 평가. 각 예제에 대해 우리는 다음을 보여줍니다: a) 입력 이미지, b) 재구성 오버레이, c) 측면 뷰, d) 상단 뷰. HMR 2.0의 견고성을 보여주기 위해, 우리는 일반적이지 않은 자세(rows 1-4), 일반적이지 않은 시점(row 5) 및 시야가 나쁘거나, 극단적으로 잘려나가거나, 극단적으로 가려진 이미지(rows 6-8)에 대한 결과를 시각화합니다.](Humans%20in%204D%20Reconstructing%20and%20Tracking%20Humans%20wi%2000cb19ea5d0148c29dd637b3d9b04e48/Untitled%203.png)

HMR 2.0의 질적 평가. 각 예제에 대해 우리는 다음을 보여줍니다: a) 입력 이미지, b) 재구성 오버레이, c) 측면 뷰, d) 상단 뷰. HMR 2.0의 견고성을 보여주기 위해, 우리는 일반적이지 않은 자세(rows 1-4), 일반적이지 않은 시점(row 5) 및 시야가 나쁘거나, 극단적으로 잘려나가거나, 극단적으로 가려진 이미지(rows 6-8)에 대한 결과를 시각화합니다.

포즈 정확도: 3D 포즈 정확도는 표준 메트릭과 프로토콜, 특히 3DPW 테스트 분할과 Human3.6M val 분할에 대한 MPJPE 및 PA-MPJPE를 사용하여 평가되었습니다. 그 결과 HMR 2.0 모델이 이러한 지표에서 이전의 모든 기준선을 능가하는 것으로 나타났습니다. 그러나 이러한 벤치마크는 포화 상태이며 포즈 메트릭의 작은 차이는 그다지 중요하지 않다는 점에 주목했습니다. 또한 다양한 데이터 세트에서 생성된 포즈의 2D 이미지 정렬을 평가한 결과, HMR 2.0-b가 이전의 모든 접근 방식보다 일관되게 우수한 성능을 보였다고 밝혔습니다.

정성적 결과: 시각적 예시를 통해 HMR 2.0이 극단적인 포즈와 부분적인 오클루전에도 견고함을 확인할 수 있었습니다. 재구성된 이미지가 이미지와 잘 일치하며 새로운 관점에서 볼 때도 유효합니다. 특히 특이한 포즈의 경우 가장 근접한 경쟁사 모델보다 더 충실한 재구성을 반환한다고 언급했습니다.

추적: 수정된 PHALP의 다용도성은 추적이라는 다운스트림 작업에서 다양한 3D 포즈 추정기를 평가함으로써 입증되었습니다. 이 수정으로 대부분의 메시 복구 시스템에서 공유되는 SMPL 공간에서 작동할 수 있게 되어 적응성이 더욱 높아졌습니다. 테스트 결과, 이들의 시스템인 4D휴먼은 모든 트래킹 지표에서 기존 접근 방식보다 우수한 성능을 보였습니다. 또한 추적 성능이 우수하다는 것은 오클루전에 대한 견고함을 나타낼 수 있지만, 포즈의 미세한 차이를 구분하는 데는 도움이 되지 않는다는 점에 주목했습니다. 더 나은 바운딩 박스 디텍터인 ViTDet을 사용하면 성능을 더욱 향상시킬 수 있습니다.

동영상에서 동작을 인식하는 맥락에서, 특히 AVA 데이터세트에서 시스템을 평가합니다. 저자들은 이전 연구의 접근 방식을 비교 기준으로 사용했습니다. 이 접근 방식에서는 프레임별 3D 포즈 및 위치 추정치가 액션 레이블 예측을 위한 추가 기능으로 사용되었습니다. 또한 '포즈만' 기준선에 대한 결과도 보여주었습니다.

그런 다음 저자들은 이전 작업의 설정에 따라 SMPL 포즈를 기반으로 액션 레이블을 예측하도록 트랜스포머를 훈련시켰습니다. 각 기준선에 대해 이 작업을 수행했습니다.

비교 결과, HMR 2.0이 다양한 클래스 카테고리(OM, PI, PM)와 전반적으로 기준선보다 우수한 성능을 보였다는 사실을 발견했습니다. AVA 테스트 세트에서 평균 정밀도(mAP)는 22.3으로, 두 번째로 우수한 기준선보다 14% 더 높았습니다. 포즈에서 정확한 동작을 인식하려면 세밀한 포즈 추정이 필요하기 때문에 이는 매우 중요합니다. 즉, HMR 2.0은 기존 접근 방식보다 더 정확한 포즈를 예측할 수 있습니다.

![최첨단 메시 복구 방법의 질적 비교. HMR 2.0은 가장 가까운 경쟁자인 PyMAF-X [85]와 PARE [33]에 비해 특이한 자세에 대해 더 충실한 재구성을 반환합니다.](Humans%20in%204D%20Reconstructing%20and%20Tracking%20Humans%20wi%2000cb19ea5d0148c29dd637b3d9b04e48/Untitled%204.png)

최첨단 메시 복구 방법의 질적 비교. HMR 2.0은 가장 가까운 경쟁자인 PyMAF-X [85]와 PARE [33]에 비해 특이한 자세에 대해 더 충실한 재구성을 반환합니다.

또한 외모 특징과 결합했을 때 HMR 2.0은 AVA 동작 인식에서 42.3의 최첨단 mAP를 달성했습니다. 이 결과는 두 번째로 좋은 결과인 39.5 mAP보다 7% 더 나은 결과입니다. 이는 행동 인식에 있어 HMR 2.0 모델의 효율성을 보여줍니다.

![4DHumans의 질적 추적 결과. 우리는 헤드 마스크를 사용합니다(프레임 번호는 왼쪽 상단에 있음). 첫 번째 줄: 우리는 복잡한 자세와 무거운 가림막이 있는 얼음 위에서 스케이팅하는 사람들을 추적하며, 분당 영상에서는 신원을 바꾸지 않습니다. 두 번째 줄: 메인 사람은 다른 플레이어들과의 여러 상호작용을 통해 추적됩니다. 세 번째 줄: 관심 있는 사람은 장기간 가려짐을 통해 추적됩니다.](Humans%20in%204D%20Reconstructing%20and%20Tracking%20Humans%20wi%2000cb19ea5d0148c29dd637b3d9b04e48/Untitled%205.png)

4DHumans의 질적 추적 결과. 우리는 헤드 마스크를 사용합니다(프레임 번호는 왼쪽 상단에 있음). 첫 번째 줄: 우리는 복잡한 자세와 무거운 가림막이 있는 얼음 위에서 스케이팅하는 사람들을 추적하며, 분당 영상에서는 신원을 바꾸지 않습니다. 두 번째 줄: 메인 사람은 다른 플레이어들과의 여러 상호작용을 통해 추적됩니다. 세 번째 줄: 관심 있는 사람은 장기간 가려짐을 통해 추적됩니다.

### 6. Conclusion

HMR 2.0은 휴먼 메시 복구 분야의 일반적인 2D/3D 포즈 메트릭을 크게 개선한 완전히 '변환된' 네트워크 버전입니다. 또한 고급 비디오 트래커인 4DHumans의 중추 역할을 수행하여 추적에 대한 최첨단 결과를 보여주고 비디오 속 인물을 공동으로 재구성하고 추적하는 데 성공했습니다. 행동 인식에 HMR 2.0을 적용하여 이전의 포즈 기반 기준선을 인상적으로 개선했습니다.

그러나 저자들은 이 작업에 한계와 개선의 여지가 있음을 인정합니다. 예를 들어, SMPL 모델을 사용하면 손 포즈, 얼굴 표정, 피사체의 연령 변화와 같은 미묘한 측면이 제외되어 가능한 재구성 범위가 제한됩니다. 또한 이 시스템은 각 사람을 독립적으로만 고려하기 때문에 가까운 거리에 있는 사람을 정확하게 재구성하지 못합니다.

또 다른 한계는 카메라 프레임에 "살아있는" 재구성이라는 점입니다. 비디오에서 동작을 보다 포괄적으로 이해하려면 공통 세계 좌표 프레임에서 카메라 움직임에 대한 추론이 필요합니다.

마지막으로 저자들은 입력 해상도가 낮으면 재구성 품질에 영향을 미칠 수 있다고 언급합니다. 이 문제는 더 극단적인 해상도 증강을 통해 해결할 수 있습니다. 저자들은 이러한 영역을 향후 연구 방향으로 제시하여 동영상에서 3D 인체 재구성 및 추적 품질을 더욱 향상시킬 수 있습니다.