# Dynamic Facial Asset and Rig Generation from a Single Scan

[https://arxiv.org/abs/2010.00560](https://arxiv.org/abs/2010.00560)

[https://www.youtube.com/watch?v=yZac_9xjqKE&ab_channel=ICTVisionandGraphicsLab](https://www.youtube.com/watch?v=yZac_9xjqKE&ab_channel=ICTVisionandGraphicsLab)

1 INTRODUCTION

이 문서는 딥러닝을 사용하여 고품질의 개인화된 디지털 휴먼을 만드는 연구에 대한 소개입니다. 이 프로세스는 영화, 게임 제작, 가상현실 등 다양한 분야에 적용할 수 있습니다. 전통적으로 이러한 디지털 더블을 제작하려면 복잡한 장비와 상당한 수작업 후처리, 고도로 숙련된 팀이 필요합니다. 이 과정은 시간이 오래 걸리고 수개월이 걸리기도 합니다.

딥러닝 기반 방법은 캡처한 데이터에서 바로 사실적인 얼굴을 생성할 수 있어 완벽에 가까운 인간 복제품이 불안감이나 혐오감을 불러일으키는 '언캐니 밸리'를 극복하는 데 도움이 될 수 있다는 점에서 가능성을 보입니다. 하지만 현재 이러한 방법에는 재조명 기능과 미세 렌더링 제어 기능이 부족하여 가상 컴퓨터 그래픽 환경에 원활하게 통합하기 어렵습니다.

연구진은 3D 스캔을 입력으로 사용하는 새로운 접근 방식을 제안하여 개인화된 블렌드 셰이프(3D 모델을 변형하는 방법)와 동적인 물리 기반 텍스처 맵으로 완전히 리깅된 모델을 생성하는 것을 목표로 합니다. 이는 대량의 레이블이 지정된 데이터를 사용하여 개인화된 모델과 동적 변형을 학습함으로써 달성되며, 개인의 얼굴 모양과 외모에 고유한 주름과 같은 효과를 생성할 수 있습니다.

이 프레임워크는 단일 중립 지오메트리 모델과 알베도(빛 반사) 맵에서 고품질 페이셜 릭 에셋을 생성하는 프로세스를 자동화하고 간소화합니다. 이렇게 생성된 에셋은 전문 프로덕션 파이프라인에 바로 공급할 수 있습니다. 이 프레임워크는 개인화된 블렌드 셰이프를 생성하고 동적 피부 속성을 추론하는 두 가지 문제를 모두 해결합니다.

학습은 모공 수준의 디테일과 다양한 표정이 포함된 4000개 이상의 스캔이 포함된 고충실도 얼굴 스캔 데이터 세트를 사용하여 수행됩니다. 이 접근 방식은 단 한 번의 중립 스캔으로 개인화된 블렌드 쉐이프를 생성할 수 있습니다.

결론적으로, 저자들의 주요 공헌은 단 한 번의 중립 얼굴 스캔으로 고품질 얼굴 에셋과 릭을 자동으로 생성하는 엔드투엔드 프레임워크, 더 나은 개인화된 결과를 위한 새로운 자체 감독 딥러닝 접근 방식, 새로운 물리 기반 텍스처 합성 프레임워크, 추가 연구를 위해 코드, 모델, 데이터베이스를 공개하기로 결정한 점 등입니다.

2 RELATED WORK

얼굴 캡처와 얼굴 리깅은 사실적인 디지털 아바타를 생성하기 위한 중요한 연구 분야입니다. 얼굴 캡처는 일반적으로 통제된 환경에서 여러 대의 보정된 DSLR 카메라로 수행되며, 얼굴의 세밀한 디테일을 복원합니다. 리깅에는 주성분 분석을 사용하는 모퍼블 페이스 모델과 같은 다양한 방법을 사용하여 얼굴 애니메이션과 모델을 만드는 작업이 포함됩니다. 얼굴 표정을 선형 베이스 세트로 모델링하는 블렌드셰이프가 일반적으로 사용됩니다.

특정 개인의 얼굴 움직임을 모방할 수 있는 개인화된 블렌드쉐이프를 생성하기 위해 여러 가지 접근 방식이 사용되었습니다. 이러한 방법 중 상당수는 대규모 동작 단위 또는 일련의 표현을 입력으로 필요로 합니다. 최근에는 딥러닝 방법과 3D 형태 분석을 사용하여 비선형 3D 변형 가능한 모델을 학습하여 상세한 얼굴 텍스처와 형태를 생성합니다.

이미지를 한 도메인에서 다른 도메인으로 변환하는 이미지 간 변환은 3D 얼굴 또는 얼굴 텍스처를 생성하는 데 사용되는 또 다른 방법입니다. 생성기가 한 도메인에서 다른 도메인으로 이미지를 번역하고 판별기가 실제 이미지와 번역된 이미지를 구분하는 방식인 Pix2Pix와 Pix2PixHD가 이 접근 방식의 몇 가지 예입니다. 이 기술은 단일 입력 이미지에서 얼굴 반사율 맵을 추론하고, 임의의 표정과 텍스처를 합성하고, 기하학적 디테일을 추정하고, 베이스 메시의 변위 맵을 추론하는 데 사용되었습니다.

3 SYSTEM OVERVIEW

시스템은 알베도 맵이 포함된 중립적인 얼굴 지오메트리를 한 번 스캔하여 고품질의 물리 기반 렌더링에 적합한 페이스 릭 에셋과 텍스처 속성 세트를 생성합니다. 이 프로세스는 두 가지 주요 단계로 구성되며 계단식 방식으로 적용됩니다.

![시스템 개요. 중립 표정으로 단일 스캔에서 얻은 모델이 주어지면, 블렌드셰이프 생성 모듈이 먼저 개인화된 블렌드셰이프를 생성합니다. 그런 다음 개인화된 블렌드셰이프와 입력 중립 모델 그리고 그것의 알베도 맵을 사용하여 텍스쳐 생성 모듈이 알베도, 스펙큘러 강도, 디스플레이스먼트 맵을 포함한 고해상도 동적 텍스쳐 맵을 생성합니다. 이러한 자산이 준비되면, 우리는 개인화된 블렌드셰이프와 입력 중립 모델을 3D 모델로 조립하고, 템플릿 모델에서 다른 얼굴 구성 요소 (눈, 이, 잇몸, 혀)를 결합합니다. 최종 출력물은 블렌드셰이프 모델과 텍스쳐를 사용하여 렌더링된 완성된 얼굴 모델입니다.](Dynamic%20Facial%20Asset%20and%20Rig%20Generation%20from%20a%20Sin%20f7af534f59b24752a9427cc3a2dd56f5/Untitled.png)

시스템 개요. 중립 표정으로 단일 스캔에서 얻은 모델이 주어지면, 블렌드셰이프 생성 모듈이 먼저 개인화된 블렌드셰이프를 생성합니다. 그런 다음 개인화된 블렌드셰이프와 입력 중립 모델 그리고 그것의 알베도 맵을 사용하여 텍스쳐 생성 모듈이 알베도, 스펙큘러 강도, 디스플레이스먼트 맵을 포함한 고해상도 동적 텍스쳐 맵을 생성합니다. 이러한 자산이 준비되면, 우리는 개인화된 블렌드셰이프와 입력 중립 모델을 3D 모델로 조립하고, 템플릿 모델에서 다른 얼굴 구성 요소 (눈, 이, 잇몸, 혀)를 결합합니다. 최종 출력물은 블렌드셰이프 모델과 텍스쳐를 사용하여 렌더링된 완성된 얼굴 모델입니다.

블렌드 셰이프 생성: 시스템은 먼저 입력 피사체의 개인화된 블렌드셰이프 지오메트리 세트를 추정합니다. 블렌드셰이프 생성 네트워크는 중립적인 지오메트리를 활용하여 특정 피사체에 대해 다양한 표현을 나타내는 개인화된 블렌드셰이프를 생성합니다.

텍스처 생성: 블렌드 셰이프 생성에 이어 텍스처 생성 네트워크는 일련의 동적 맵을 추론하는 데 사용됩니다. 여기에는 알베도 맵, 스페큘러 강도 맵, 변위 맵이 포함되며, 고해상도의 사실적인 룩을 만드는 데 도움이 됩니다.

마지막 단계에서는 템플릿 모양 세트에서 얻은 치아, 잇몸, 눈과 같은 보조 얼굴 구성 요소를 모델에 추가합니다. 최종 결과물은 블렌드 셰이프 모델과 텍스처를 사용하여 렌더링된 완전한 얼굴 모델입니다.

이 두 가지 프로세스를 연쇄적으로 수행함으로써 시스템은 피사체의 얼굴을 중립적인 표정으로 한 번 스캔하여 사실적인 프로덕션 수준의 렌더링에 적합한 개인화된 고품질 3D 모델을 생성할 수 있습니다. 또한 얼굴의 정확한 물리적 렌더링에 필요한 다양한 텍스처 맵을 생성할 수도 있습니다.

4 BLENDSHAPE GENERATION

설명하는 프로세스는 머신 러닝과 심층 신경망을 사용하여 새로운 피사체의 중립적인 3D 얼굴에서 개인화된 블렌드 셰이프를 자동으로 생성합니다. 문제는 일반적으로 피사체의 다양한 표현이 필요한 피사체별 블렌드 셰이프를 생성하는 데 있습니다. 하지만 대규모 데이터 세트로 인해 표현식을 기반으로 이러한 블렌드 셰이프를 생성하는 방법을 학습하는 자가 감독 파이프라인을 제안합니다.

![두 단계의 자기 지도 학습 프레임워크. 중립 표정의 모델이 주어지면, 추정 단계는 먼저 초기 블렌드셰이프를 예측하고, 이것은 최종 개인화된 블렌드셰이프를 생성하기 위한 튜닝 단계의 입력으로 작동합니다. 추론 파이프라인은 실선으로 연결됩니다. 훈련 아키텍처도 재구성 손실을 계산하기 위해 점선으로 표시된 부분들을 포함합니다. 추정 단계에서 블렌드셰이프 생성기는 입력 중립 표정에서 초기 블렌드셰이프를 생성하는 방법을 배웁니다. 이것은 알려진 블렌딩 가중치와 결합하여 비중립 표정을 재구성합니다. 튜닝 단계에서 블렌딩 가중치 예측기가 개인화된 블렌드셰이프의 블렌딩 가중치를 예측하는 것이 추가됩니다. 이 가중치는 입력 표정을 재구성하는 데 사용됩니다.](Dynamic%20Facial%20Asset%20and%20Rig%20Generation%20from%20a%20Sin%20f7af534f59b24752a9427cc3a2dd56f5/Untitled%201.png)

두 단계의 자기 지도 학습 프레임워크. 중립 표정의 모델이 주어지면, 추정 단계는 먼저 초기 블렌드셰이프를 예측하고, 이것은 최종 개인화된 블렌드셰이프를 생성하기 위한 튜닝 단계의 입력으로 작동합니다. 추론 파이프라인은 실선으로 연결됩니다. 훈련 아키텍처도 재구성 손실을 계산하기 위해 점선으로 표시된 부분들을 포함합니다. 추정 단계에서 블렌드셰이프 생성기는 입력 중립 표정에서 초기 블렌드셰이프를 생성하는 방법을 배웁니다. 이것은 알려진 블렌딩 가중치와 결합하여 비중립 표정을 재구성합니다. 튜닝 단계에서 블렌딩 가중치 예측기가 개인화된 블렌드셰이프의 블렌딩 가중치를 예측하는 것이 추가됩니다. 이 가중치는 입력 표정을 재구성하는 데 사용됩니다.

제안된 시스템은 스캔한 표현식을 단위 블렌드 셰이프로 분리하는 아티스트의 프로세스를 모방할 수 있습니다. 이 작업은 사전 정의된 일반 템플릿 블렌드셰이프와 동일한 피사체에 대한 잘 정의된 여러 스캔 표현식을 사용하여 수행됩니다.

일반 템플릿 블렌드 셰이프 모델은 중립 표현식(𝑆0)과 덧셈 벡터 변위 집합(S = {𝑆1, ..., 𝑆𝑁})으로 구성됩니다. 이러한 표현식을 생성하고 새로운 피사체 𝑗에 대해 재구성 손실을 최소화하여 개인화된 블렌드 셰이프를 최적화할 수 있습니다.

![표정, 블렌드셰이프, 그리고 블렌드셰이프 오프셋 사이의 코사인 거리 맵의 시각화. (a)와 (b)는 표현 기하학에서의 절대 위치(Pj)(행 1), 중립 표정에서의 블렌드셰이프 오프셋(Sj)(행 2), 템플릿 블렌드셰이프에서의 오프셋(ΔSj)(행 3)으로 표현된 다른 주제들의 같은 표정을 보여줍니다. 행 1의 거리 맵이 거의 0으로 채워져 있다는 것에 주목하세요. 이는 같은 표정 사이의 평균 차이가 사람의 머리 크기보다 훨씬 작기 때문입니다.](Dynamic%20Facial%20Asset%20and%20Rig%20Generation%20from%20a%20Sin%20f7af534f59b24752a9427cc3a2dd56f5/Untitled%202.png)

표정, 블렌드셰이프, 그리고 블렌드셰이프 오프셋 사이의 코사인 거리 맵의 시각화. (a)와 (b)는 표현 기하학에서의 절대 위치(Pj)(행 1), 중립 표정에서의 블렌드셰이프 오프셋(Sj)(행 2), 템플릿 블렌드셰이프에서의 오프셋(ΔSj)(행 3)으로 표현된 다른 주제들의 같은 표정을 보여줍니다. 행 1의 거리 맵이 거의 0으로 채워져 있다는 것에 주목하세요. 이는 같은 표정 사이의 평균 차이가 사람의 머리 크기보다 훨씬 작기 때문입니다.

또한 추정 단계와 튜닝 단계로 구성된 자가 감독 2단계 학습 프레임워크를 도입합니다. 추정 단계는 초기 블렌드 셰이프를 예측한 다음 튜닝 단계에서 최종 개인화된 블렌드 셰이프를 생성하기 위한 입력으로 사용됩니다. 첫 번째 단계에서는 아이덴티티와 시맨틱을 최적으로 보존하고, 두 번째 단계에서는 캡처한 표현에 더 잘 맞도록 초기 블렌드 셰이프를 미세 조정합니다.

추정 단계는 표현식을 재구성하는 데 사용되는 개인화된 블렌드셰이프를 생성하는 방법을 학습하는 블렌드셰이프 생성기를 기반으로 구축됩니다. 여기서 목표는 대상 블렌드 셰이프가 템플릿 블렌드 셰이프와 의미적으로 일관성을 유지하도록 하는 것입니다. 블렌드셰이프 생성기는 아이덴티티 인코더와 블렌드셰이프 디코더로 구성된 2D 컨볼루션 신경망(CNN)입니다.

튜닝 단계에서는 블렌드쉐이프 생성기와 유사한 네트워크 아키텍처를 공유하는 블렌딩 가중치 예측기를 사용하여 입력 표현식으로부터 블렌딩 가중치를 예측합니다. 이 예측기는 또한 입력 표현식을 표현식 잠재 코드에 매핑하는 표현식 인코더와 블렌딩 가중치 디코더로 구성됩니다.

![추정 단계에서 단일-브랜치 네트워크와 두 개의 브랜치 네트워크로 생성된 두 블렌드셰이프 모델의 비교. GT 표정은 해당 블렌드셰이프와 가장 의미론적으로 비슷한 참조 FACS 표정을 나타냅니다. 단일 브랜치 결과에 비해 두 브랜치 결과는 일반적인 블렌드셰이프의 의미를 유지하면서 참조 FACS 표정과 더 비슷합니다.](Dynamic%20Facial%20Asset%20and%20Rig%20Generation%20from%20a%20Sin%20f7af534f59b24752a9427cc3a2dd56f5/Untitled%203.png)

추정 단계에서 단일-브랜치 네트워크와 두 개의 브랜치 네트워크로 생성된 두 블렌드셰이프 모델의 비교. GT 표정은 해당 블렌드셰이프와 가장 의미론적으로 비슷한 참조 FACS 표정을 나타냅니다. 단일 브랜치 결과에 비해 두 브랜치 결과는 일반적인 블렌드셰이프의 의미를 유지하면서 참조 FACS 표정과 더 비슷합니다.

블렌드쉐이프 생성기를 더 잘 훈련시키기 위해 모션 스케일에 따라 블렌드쉐이프를 두 가지 범주로 나누는 두 가지 분기 아키텍처가 제안되었습니다.

전체적인 프로세스는 머신러닝의 강점과 표현식 데이터의 풍부한 디테일을 결합하여 매우 사실적이고 개인화된 블렌드 셰이프를 생성하는 것으로 보입니다.

5 DYNAMIC TEXTURE GENERATION

이 섹션에서는 컴퓨터 그래픽에서 동적 텍스처 에셋을 효율적으로 표현하고 추론하는 새로운 방법, 특히 얼굴 표정을 렌더링하는 방법을 소개합니다. 이 방법은 두 가지 핵심 개념을 중심으로 전개됩니다: 압축 및 스트레치 맵과 인플루언스 맵입니다.

![추정 단계만을 이용한 두 표현의 재구성과 튜닝 단계의 추가를 통한 두 표현의 재구성 비교, 그리고 재구성된 표현과 지상 참값 표현 사이의 오차 맵. 튜닝 단계의 결과는 더 나은 재구성을 보여주고, 더 작은 적합 오차를 보여줍니다.](Dynamic%20Facial%20Asset%20and%20Rig%20Generation%20from%20a%20Sin%20f7af534f59b24752a9427cc3a2dd56f5/Untitled%204.png)

추정 단계만을 이용한 두 표현의 재구성과 튜닝 단계의 추가를 통한 두 표현의 재구성 비교, 그리고 재구성된 표현과 지상 참값 표현 사이의 오차 맵. 튜닝 단계의 결과는 더 나은 재구성을 보여주고, 더 작은 적합 오차를 보여줍니다.

![텍스쳐 생성 네트워크. 중립 표정의 입력 모델의 알베도 맵과 기하학 이미지 그리고 목표 표정 오프셋의 기하학 이미지가 주어지면, 첫 번째 네트워크는 pix2pixHD [Wang et al. 2018b]를 사용하여 표정의 알베도 맵을 생성합니다. 그런 다음 초기 입력과 예측된 알베도 맵을 결합하여, 두 번째 네트워크는 스펙큘러 강도, 저주파, 고주파 디스플레이스먼트 맵을 추론합니다.](Dynamic%20Facial%20Asset%20and%20Rig%20Generation%20from%20a%20Sin%20f7af534f59b24752a9427cc3a2dd56f5/Untitled%205.png)

텍스쳐 생성 네트워크. 중립 표정의 입력 모델의 알베도 맵과 기하학 이미지 그리고 목표 표정 오프셋의 기하학 이미지가 주어지면, 첫 번째 네트워크는 pix2pixHD [Wang et al. 2018b]를 사용하여 표정의 알베도 맵을 생성합니다. 그런 다음 초기 입력과 예측된 알베도 맵을 결합하여, 두 번째 네트워크는 스펙큘러 강도, 저주파, 고주파 디스플레이스먼트 맵을 추론합니다.

압축 및 스트레치 맵은 정적 텍스처를 사용할 때 손실되는 주름과 같은 얼굴 표정의 디테일을 보존하는 수단입니다. 얼굴의 미묘한 움직임과 표정을 모두 포착하는 고충실도 텍스처의 문제점은 상당한 메모리와 연산 능력이 필요하다는 점입니다. 이 문제를 해결하기 위해 압축 및 스트레치 맵을 사용하는 압축 표현이 제안되었습니다. 이 맵은 사용 가능한 모든 표정에서 국소적인 압축/신축 움직임으로 인한 두드러진 특징을 수집하므로 얼굴 움직임의 중요한 디테일을 잃지 않으면서 메모리 효율성을 보장합니다.

![압축 및 스트레치 맵의 시각화. 상단에서 하단으로: 중립 정적 맵, 압축 맵, 스트레치 맵. 왼쪽에서 오른쪽으로: 무광 알베도 맵, 스펙큘러 맵, 디스플레이스먼트 맵에서 계산된 노멀 맵 (탄젠트 공간)](Dynamic%20Facial%20Asset%20and%20Rig%20Generation%20from%20a%20Sin%20f7af534f59b24752a9427cc3a2dd56f5/Untitled%206.png)

압축 및 스트레치 맵의 시각화. 상단에서 하단으로: 중립 정적 맵, 압축 맵, 스트레치 맵. 왼쪽에서 오른쪽으로: 무광 알베도 맵, 스펙큘러 맵, 디스플레이스먼트 맵에서 계산된 노멀 맵 (탄젠트 공간)

![영향 맵의 시각화. (a). 다른 표정의 기하학에서 렌더링된 영향 값 (입 오른쪽, 미소, 입 퍼넬). (b). 블렌드셰이프의 한 세트와 동적 알베도와 그것의 해당 영향 맵이 있는 CheckSquint_L 블렌드셰이프의 선택된 영향 맵. 압축과 스트레치 영향 맵을 R과 G 채널로 저장하고 B 채널을 0으로 설정하는 것에 주목하세요.](Dynamic%20Facial%20Asset%20and%20Rig%20Generation%20from%20a%20Sin%20f7af534f59b24752a9427cc3a2dd56f5/Untitled%207.png)

영향 맵의 시각화. (a). 다른 표정의 기하학에서 렌더링된 영향 값 (입 오른쪽, 미소, 입 퍼넬). (b). 블렌드셰이프의 한 세트와 동적 알베도와 그것의 해당 영향 맵이 있는 CheckSquint_L 블렌드셰이프의 선택된 영향 맵. 압축과 스트레치 영향 맵을 R과 G 채널로 저장하고 B 채널을 0으로 설정하는 것에 주목하세요.

반면에 영향력 맵은 표정과 중립 얼굴 사이의 기하학적 변화를 기반으로 계산됩니다. 동적 텍스처를 블렌딩하고 추출하기 위한 가중치를 제공하여 동적 텍스처가 얼굴 움직임의 가능한 모든 디테일을 표현할 수 있도록 합니다.

압축 및 스트레치 맵 생성에는 딥러닝 모델을 사용하여 사전 정의된 표정의 텍스처 맵을 예측하는 작업이 포함됩니다. 이렇게 예측된 텍스처는 인플루언스 맵에 기반한 알고리즘을 사용하여 압축 및 스트레치 맵으로 블렌딩됩니다. 그런 다음 런타임에 이러한 맵을 사용하여 정적 중립 텍스처와 각 입력 표현식에 대해 계산된 블렌딩 가중치를 결합하여 동적 텍스처를 생성합니다.

![압축 맵 추출 시각화. 왼쪽: 네트워크에서 생성된 표현 텍스쳐. 오른쪽: 영향 맵에 기반한 블렌딩 표현 텍스쳐에서 추출된 압축 맵. 모든 표현에서 피부의 지역 압축에 의해 발생한 모든 동적 세부 사항을 최종 압축 맵이 모은다는 것을 참고하세요 (오렌지 원).](Dynamic%20Facial%20Asset%20and%20Rig%20Generation%20from%20a%20Sin%20f7af534f59b24752a9427cc3a2dd56f5/Untitled%208.png)

압축 맵 추출 시각화. 왼쪽: 네트워크에서 생성된 표현 텍스쳐. 오른쪽: 영향 맵에 기반한 블렌딩 표현 텍스쳐에서 추출된 압축 맵. 모든 표현에서 피부의 지역 압축에 의해 발생한 모든 동적 세부 사항을 최종 압축 맵이 모은다는 것을 참고하세요 (오렌지 원).

이 방법은 실시간 애플리케이션에서 계산 및 메모리 효율성이 높은 고충실도 얼굴 표정을 렌더링하는 데 유망한 접근 방식을 제공합니다. 특히 트래킹 및 애니메이션과 같은 애플리케이션에 적합한 것으로 보입니다.

6 ASSEMBLY

여기서 설명한 프로세스는 디테일하고 표현력이 풍부한 3D 얼굴 아바타를 만들기 위한 포괄적인 접근 방식입니다. 얼굴 지오메트리 및 텍스처와 같은 기본 구성 요소 외에도 안구, 눈물, 속눈썹, 치아 및 잇몸과 같은 보조 요소를 통합하여 보다 사실적인 모델을 만들 수 있습니다.

이를 위해 모든 기본 및 보조 부품에 일반 블렌드 셰이프 세트를 사용합니다. 블렌드 셰이프는 기본적으로 기본 3D 모델의 서로 다른 버전으로, 각각 다른 얼굴 표정을 표시합니다. 이러한 블렌드 셰이프 사이를 모핑하여 다양한 표정을 만들 수 있습니다.

네트워크에서 생성된 각 표정을 맞추기 위해 얼굴 영역의 해당 정점을 기반으로 선형 피팅을 사용합니다. 그런 다음 기본 부분을 기반으로 계산된 계수를 사용하여 보조 구성 요소를 구동함으로써 얼굴의 주요 특징과 함께 움직이도록 합니다(예: 속눈썹이 눈꺼풀과 함께 움직이도록).

모델을 완성하기 위해 장착된 보조 요소를 기본 얼굴 부분과 결합하여 통합된 얼굴 모델을 만듭니다. 눈알을 제외한 모든 보조 부품에 일반 텍스처를 사용하고 있습니다. 눈알의 경우 기존 눈알 에셋 데이터베이스를 사용하여 입력 피사체에 일치시킬 수 있는 다양한 눈 텍스처를 제공합니다.

이러한 수준의 디테일과 개인화를 통해 매우 사실적이고 개별화된 3D 아바타를 만들 수 있으며, 다양한 표정을 표현할 수 있습니다.

7 DATASET

여기서 설명한 프로세스에서 다양한 소스의 고해상도 얼굴 모델을 포함하는 풍부한 데이터 세트를 학습에 사용하고 있습니다. 이러한 소스는 다양한 얼굴 동작 코딩 시스템(FACS) 표현을 수행하는 다양한 범위의 개인을 제공합니다. 이를 통해 포괄적인 훈련 데이터 세트를 생성하여 다양하고 사실적인 표정을 생성할 수 있는 시스템의 기능을 향상시킬 수 있습니다.

![우리의 프레임워크로 생성된 얼굴 레깅 자산을 이용한 표현 재구성. 왼쪽에서 오른쪽으로: 열 1: 기하학과 알베도를 포함한 입력 중립. 열 2에서 열 4: 선택된 재구성 표현. 열 5에서 열 7: 선택된 블렌드 셰이프 유닛. 위에서 아래로: 행 1과 행 2: Triplegangers [Triplegangers 2019]에서 입력 중립, 행 3과 행 4: 온라인 자원 [3DScanstore 2019]에서 입력 중립, 행 5와 행 6: Light Stage 테스트 세트에서 입력 중립. 행 7: iPhone X Arkit에서 입력 중립. 마지막 예는 저품질 장치로 캡처된 데이터에도 우리의 방법이 적용될 수 있다는 것을 보여주며, 그러나 저해상도 입력 이미지는 결과 품질을 줄일 수 있다는 것을 참고하십시오.](Dynamic%20Facial%20Asset%20and%20Rig%20Generation%20from%20a%20Sin%20f7af534f59b24752a9427cc3a2dd56f5/Untitled%209.png)

우리의 프레임워크로 생성된 얼굴 레깅 자산을 이용한 표현 재구성. 왼쪽에서 오른쪽으로: 열 1: 기하학과 알베도를 포함한 입력 중립. 열 2에서 열 4: 선택된 재구성 표현. 열 5에서 열 7: 선택된 블렌드 셰이프 유닛. 위에서 아래로: 행 1과 행 2: Triplegangers [Triplegangers 2019]에서 입력 중립, 행 3과 행 4: 온라인 자원 [3DScanstore 2019]에서 입력 중립, 행 5와 행 6: Light Stage 테스트 세트에서 입력 중립. 행 7: iPhone X Arkit에서 입력 중립. 마지막 예는 저품질 장치로 캡처된 데이터에도 우리의 방법이 적용될 수 있다는 것을 보여주며, 그러나 저해상도 입력 이미지는 결과 품질을 줄일 수 있다는 것을 참고하십시오.

얼굴 형태를 학습하는 방법론을 안내하는 가정은 다음과 같습니다:

- 모든 표정에서 각 피사체의 두개골 모양에 대한 엄격한 변환을 찾을 수 있습니다.
- 공통 매개변수화를 사용할 수 있으려면 피사체 간에 드문 드문 대응이 필요합니다.
- 텍스처 맵을 사용하여 피부 변형의 작은 변화를 추적하려면 각 피사체에 대한 표현식 간의 밀도 높은 대응이 필요합니다.

얼굴 모델 등록의 경우, 스캔 피사체의 중립적인 얼굴에 맞게 변형 가능한 모델을 사용한 다음 비강체 기술과 표면 왜곡을 사용하여 디테일 재구성을 위해 변형합니다. 표현식 스캔을 등록하려면 템플릿 세트의 블렌드 셰이프 표현식을 사용하고 조밀하게 대응하는 표현식에 대해 라플라스 변형 단계를 도입합니다.

텍스처 데이터는 편광 구형 그라데이션 조명을 활용하여 생성되며, 이를 통해 피부 미세 구조와 확산 알베도 및 스페큘러와 같은 머티리얼 내재성을 계산할 수 있습니다.

블렌드 셰이프 모델은 눈썹 모양 비대칭을 허용하는 수정 사항과 함께 Apple의 ArKit 명명 규칙을 기반으로 합니다. 모든 피사체와 각 표현식에 대한 평균을 계산하여 선형적 독립성과 의미적 의미를 유지하면서 자기 교차점을 피하기 위해 예술적으로 분리할 수 있는 각 모양의 합리적인 평균을 찾을 수 있습니다.

이러한 접근 방식은 다양한 기술과 방법론을 통합하여 사실적인 3D 얼굴 아바타를 생성할 수 있는 강력한 프레임워크를 제공합니다.

8 RESULTS

이 논문은 피사체의 단일 스캔에서 동적 텍스처와 애니메이션이 포함된 상세한 3D 얼굴 모델을 생성하는 방법론에 대해 자세히 설명하는 것으로 보입니다. 이 논문은 훈련에 사용되는 데이터 세트와 얼굴 모델을 등록하는 접근 방식을 모두 설명합니다. 이 방법론에는 블렌드 셰이프 표현식 추정, 더 나은 표면 디테일을 위한 모델 변형, 텍스처 데이터 생성 등 여러 단계가 포함됩니다.

이 백서에서는 훈련 데이터를 훈련 세트와 테스트 세트로 분할하는 방법에 대해 설명합니다. 훈련 과정에는 추정 단계와 튜닝 단계의 두 단계가 포함됩니다. 블렌드 셰이프 생성 네트워크와 텍스처 생성 네트워크를 각각 훈련하기 위해 RMSProp과 Adam 옵티마이저를 사용했습니다.

이 논문에서는 프레임워크의 각 구성 요소에 대한 실행 시간 측면에서 이 방법의 성능에 대한 분석도 제공합니다. 블렌드 셰이프 생성을 위한 테스트는 NVIDIA GeForce RTX 2080 GPU에서, 텍스처 생성을 위한 테스트는 NVIDIA Tesla V100에서 수행되었다고 언급하고 있습니다.

저자는 다양한 실험과 비교를 통해 이 방법의 성능을 보여줍니다. 주름이나 접힌 부분과 같은 중간 주파수 디테일을 캡처하는 동적 텍스처를 생성한 모습을 보여줍니다. 또한 생성된 개인화된 블렌드 셰이프가 비강체 변형 시나리오에서 더 나은 성능을 발휘함을 보여줍니다.

![템플릿 블렌드 셰이프와 우리가 생성한 개인화된 블렌드 셰이프를 사용한 극단적인 표현 맞춤 비교. 왼쪽: 템플릿 블렌드 셰이프를 사용한 맞춤 결과. 가운데: 우리가 생성한 개인화된 블렌드 셰이프를 사용한 맞춤 결과. 오른쪽: 지상 진실 표현.](Dynamic%20Facial%20Asset%20and%20Rig%20Generation%20from%20a%20Sin%20f7af534f59b24752a9427cc3a2dd56f5/Untitled%2010.png)

템플릿 블렌드 셰이프와 우리가 생성한 개인화된 블렌드 셰이프를 사용한 극단적인 표현 맞춤 비교. 왼쪽: 템플릿 블렌드 셰이프를 사용한 맞춤 결과. 가운데: 우리가 생성한 개인화된 블렌드 셰이프를 사용한 맞춤 결과. 오른쪽: 지상 진실 표현.

![템플릿 일반 및 Li 등 [2010]과 함께 선택된 생성된 블렌드 셰이프 유닛 비교. 행 1: Sumner와 Popovió [2004]의 방법을 사용하여 일반적인 블렌드 셰이프에서 표현 전송으로 생성된 템플릿 블렌드 셰이프. 행 2: Li 등 [2010]의 방법으로 최적화된 블렌드 셰이프. 행 3: 우리의 방법. Li 등 [2010]에서 생성된 결과는 26개의 스캔 표현에서 나온 것이고, 우리의 결과는 단일 중립 입력에서 나온 것임을 주목하십시오.](Dynamic%20Facial%20Asset%20and%20Rig%20Generation%20from%20a%20Sin%20f7af534f59b24752a9427cc3a2dd56f5/Untitled%2011.png)

템플릿 일반 및 Li 등 [2010]과 함께 선택된 생성된 블렌드 셰이프 유닛 비교. 행 1: Sumner와 Popovió [2004]의 방법을 사용하여 일반적인 블렌드 셰이프에서 표현 전송으로 생성된 템플릿 블렌드 셰이프. 행 2: Li 등 [2010]의 방법으로 최적화된 블렌드 셰이프. 행 3: 우리의 방법. Li 등 [2010]에서 생성된 결과는 26개의 스캔 표현에서 나온 것이고, 우리의 결과는 단일 중립 입력에서 나온 것임을 주목하십시오.

결국, 이 방법은 애니메이션용 아바타를 생성하고 얼굴 추적 및 재구성과 같은 작업에 적합하다는 것을 보여줍니다. 또한 생성된 아바타를 다른 방법으로 생성된 아바타와 비교하여 자신들의 방법이 우수한 품질과 디테일을 제공한다는 점을 강조합니다.

9 CONCLUSION

요약하자면, 저자들은 한 번의 스캔으로 고품질의 개인화된 페이셜 리깅과 에셋 생성을 위한 엔드투엔드 프레임워크를 소개했습니다. 이 프레임워크는 개인화된 블렌드 셰이프, 물리 기반 동적 텍스처, 보조 얼굴 컴포넌트 세트를 생성할 수 있습니다. 이전 접근 방식과 달리 이 시스템은 단 한 번의 중립 스캔만 입력하면 피부 질감이나 주름과 같은 사람의 고유한 특성을 포착하는 고충실도 아바타를 생성할 수 있습니다.

이를 달성하기 위한 핵심은 고해상도 얼굴 스캔의 광범위한 데이터 세트를 기반으로 신원과 개인화된 블렌드 셰이프 간의 상관관계를 이해하는 모델을 개발하는 것이었습니다. 이 방법은 아티스트가 생성된 모델을 미세 조정하거나 군중의 보조 캐릭터로 직접 사용할 수 있기 때문에 실제 제작 파이프라인에 유리합니다.

하지만 모든 딥러닝 접근 방식과 마찬가지로 이 시스템의 효율성은 훈련 데이터의 다양성과 양에 따라 달라집니다. 현재 데이터 세트에는 젊은 피험자와 수염이나 턱수염이 있는 피험자가 부족하여 이러한 개인에 대한 성능이 약합니다. 향후에는 더 다양한 외모를 포함하도록 데이터베이스를 보강할 계획입니다.

이 프레임워크는 55개의 벡터로 구성된 블렌드 셰이프 모델을 사용하여 대부분의 일상 생활 표정을 복원할 수 있습니다. 향후 연구에서는 수백에서 수천 개의 표정을 포함하는 보다 정교한 블렌드셰이프 릭을 탐색하고 개인화된 눈과 치아를 생성하는 데 관심을 갖고 있습니다.

- 요약
    
    소개: 저자는 중립적인 얼굴을 단 한 번만 스캔하면 되는 보다 효율적인 고품질 얼굴 리깅 및 에셋 생성 프레임워크의 필요성을 제시합니다. 또한 여러 번의 스캔이 필요하거나 품질이 낮은 아바타만 생성하던 이전 방식과 이 접근 방식이 어떻게 다른지 강조합니다.
    
    방법: 저자는 고해상도 얼굴 스캔의 대규모 데이터 세트를 사용하여 신원과 개인화된 블렌드 셰이프 간의 상관관계를 모델링하는 프레임워크를 제안합니다. 생성된 동적 텍스처는 중간 주파수 주름부터 미세한 메조스코픽 모공 수준의 디테일까지 다양한 디테일을 캡처합니다.
    
    애플리케이션: 프레임워크로 생성된 고충실도 모델은 애니메이션 제작 파이프라인에서 아티스트의 추가 세분화를 위한 시작점이나 군중 장면의 보조 캐릭터로 바로 사용할 수 있습니다. 또한 이 방법은 가볍고 견고하며 빠르기 때문에 한 번의 스캔으로 즉각적인 결과를 얻을 수 있습니다.
    
    연구 결과: 저자는 신원이 개인화된 얼굴 모습과 역동적인 표정을 그럴듯하게 추론하는 데 충분한 것으로 보인다고 말합니다. 또한 개인화된 블렌드셰이프와 같은 지상 실측 데이터를 사용할 수 없는 경우를 처리하기 위한 새로운 자체 감독 딥러닝 학습 접근 방식을 소개합니다.
    
    제한 사항: 이 접근 방식의 성능은 학습 데이터의 다양성과 양에 따라 달라집니다. 현재 데이터 세트에는 젊은 피험자와 얼굴 털이 있는 피험자가 부족하여 이러한 영역의 성능에 영향을 미치는 등의 한계가 있습니다.
    
    향후 작업: 저자들은 더 많은 표현을 포함하도록 블렌드 셰이프 모델을 개선하고 학습 데이터의 다양성을 개선하는 데 관심을 표명했습니다. 또한 현재 제작된 아바타에서 일반적으로 사용되는 개인화된 눈과 치아를 생성하는 데에도 관심을 표명하고 있습니다.
    
    참고 문헌: 저자들은 관련 문헌을 인용하여 작업을 뒷받침하고 블렌드 셰이프 모델을 확장하고 개인화된 눈과 치아를 자동으로 생성하는 방법을 탐구하는 등 향후 연구를 위한 토대를 마련했습니다.
    
- [https://www.youtube.com/watch?v=yZac_9xjqKE&ab_channel=ICTVisionandGraphicsLab](https://www.youtube.com/watch?v=yZac_9xjqKE&ab_channel=ICTVisionandGraphicsLab)
    
    이 텍스트는 특히 얼굴 특징에 초점을 맞춘 고품질의 사실적인 가상 현실(VR) 아바타를 만드는 방법에 대한 설명입니다.
    
    "실사 위상 아바타는 VR 게임과 영화 산업에서 광범위하게 사용되고 있다": VR 게임과 영화에서 캐릭터(아바타)의 매우 사실적인 디지털 표현이 널리 사용되고 있다는 내용입니다.
    
    "고품질의 페이셜 릭 에셋을 확보하는 것은 어려운 문제": 이는 얼굴의 디테일하고 사실적인 3D 모델(페이셜 릭 에셋)을 만드는 것이 어렵다는 의미입니다.
    
    "대부분의 업계 방식은 한 사람에 대해 여러 스캔을 캡처한 후 지루한 수작업 처리에 의존한다": 이는 사람의 얼굴을 여러 번 스캔한 다음 수작업으로 3D 모델을 다듬는 기존의 모델 제작 방식을 설명합니다.
    
    "우리는 한 번의 중립 스캔을 입력으로 프로덕션 수준의 아바타 생성을 위한 좋은 이니셜을 자동으로 생성하는 프레임워크를 제안합니다." 저자들은 단 한 번의 얼굴 스캔으로 이러한 모델을 보다 효율적으로 생성할 수 있는 새로운 시스템을 제안합니다.
    
    "우리의 프레임워크는 4단계 리그 에셋을 생성할 수 있습니다." 이 시스템은 네 가지 유형의 3D 얼굴 모델을 생성할 수 있습니다.
    
    "우리의 파이프라인은 중립 지오메트리와 중립 알베도 맵을 입력으로 받아 중립 지오메트리를 블렌드 셰이프 생성 네트워크에 공급하여 일련의 블렌드 셰이프 지오메트리를 생성합니다." 기본 얼굴 모양과 빛이 얼굴에 반사되는 방식에 대한 맵(알베도 맵)을 다양한 얼굴 모양(블렌드 셰이프)을 생성하는 네트워크에 입력하는 것부터 시작하여 프로세스의 단계를 설명합니다.
    
    "26가지 사실 표현을 생성"합니다: 이 시스템은 26가지 얼굴 표정을 생성합니다.
    
    "텍스처 생성 네트워크는 표정 지오메트리와 중립 중재자를 입력으로 받아 스페큘러 및 변위 맵을 포함한 물리적 기반 텍스처 에셋을 생성합니다." 시스템의 또 다른 부분은 얼굴 표정과 베이스 페이셜 맵을 사용하여 사실적인 피부 텍스처를 생성합니다. 여기에는 스페큘러 맵(피부가 얼마나 반짝이는지)과 디스플레이스먼트 맵(피부 표면이 어떻게 변하는지)이 포함됩니다.
    
    "그런 다음 표현 지오메트리의 영향력 맵에 따라 표현 텍스처를 블렌딩하여 압축 및 스트레치 텍스처 에셋을 생성합니다." 그런 다음 얼굴 모양의 변화에 따라 표정 텍스처를 조정하여 추가 텍스처를 만듭니다.
    
    "전체 다이내믹 페이셜 에셋은 블렌드 셰이프 지오메트리와 사실적인 표정과 애니메이션을 렌더링하는 데 사용할 수 있는 압축 및 스트레치 텍스처로 구성됩니다." 최종 결과물은 3D 얼굴 모델과 피부 텍스처 세트로, VR에서 사실적이고 애니메이션이 적용된 얼굴을 만드는 데 사용할 수 있습니다.