# LightGlue: Local Feature Matching at Light Speed

[https://github.com/cvg/LightGlue](https://github.com/cvg/LightGlue)

[https://arxiv.org/pdf/2306.13643.pdf](https://arxiv.org/pdf/2306.13643.pdf)

### 1. Introduction

이 논문에서는 두 이미지를 일치시키기 위한 새로운 딥러닝 네트워크인 "LightGlue"를 소개하며, "SuperGlue"라는 이전 모델을 개선했습니다. 3D 매핑 및 카메라 추적과 같은 컴퓨터 비전 작업에서 중요한 부분인 이미지 매칭은 일반적으로 고차원 표현을 사용하여 드문 드문 관심 지점을 일치시키는 데 의존합니다. 그러나 견고성(다양한 조건에서 작동)과 고유성(일치하지 않는 매칭을 거부하는 기능) 사이의 절충점은 어려운 과제입니다.

![LightGlue는 SuperGlue와 같은 기존 접근 방식보다 더 빠르고 효과적으로 희소한 특징들을 매칭합니다. 그것의 적응적인 정지 메커니즘은 속도와 정확성 사이의 교환을 미세하게 조절합니다. 최종 최적화된 모델⋆는 보통 야외 조건에서 밀도가 높은 매처인 LoFTR에 가까운 정확성을 제공하면서 속도가 8배 빠릅니다.](LightGlue%20Local%20Feature%20Matching%20at%20Light%20Speed%20ab7a8e6890084e0fa11d024b37cb2866/Untitled.png)

LightGlue는 SuperGlue와 같은 기존 접근 방식보다 더 빠르고 효과적으로 희소한 특징들을 매칭합니다. 그것의 적응적인 정지 메커니즘은 속도와 정확성 사이의 교환을 미세하게 조절합니다. 최종 최적화된 모델⋆는 보통 야외 조건에서 밀도가 높은 매처인 LoFTR에 가까운 정확성을 제공하면서 속도가 8배 빠릅니다.

이전 모델인 슈퍼글루는 트랜스포머라는 딥러닝 아키텍처를 활용하여 두 이미지의 점을 동시에 일치시키고 거부하는 새로운 개념을 도입했습니다. 시각적 로컬라이제이션, 물체 자세 추정, 물고기 재식별과 같은 작업에서 뛰어난 성능을 보였음에도 불구하고 슈퍼글루는 계산 집약적이고 훈련하기 어렵다는 비판을 받았습니다.

라이트글루는 이러한 문제를 해결하여 보다 정확하고 효율적이며 사용자 친화적인 솔루션을 제공합니다. 트랜스포머의 최근 기술 발전을 바탕으로 저자들은 슈퍼글루의 설계 결정을 재평가하여 몇 가지 효과적인 아키텍처를 수정했습니다. 그 결과 모델은 더 빠르고 쉽게 훈련할 수 있으며, 더 적은 리소스로도 최고 수준의 정확도를 달성할 수 있습니다.

특히 LightGlue는 각 이미지 쌍의 난이도에 적응하여 각 계산 블록 후에 일련의 대응을 예측하고 더 많은 계산이 필요한지 여부를 결정합니다. 또한 일치하지 않는 점은 초기에 삭제하고 눈에 보이는 겹치는 부분에 집중합니다.

![깊이 적응성. LightGlue는 그것의 예측이 확신에 차 있을 때 더 이른 계층에서 멈출 수 있으므로 쉬운 이미지 쌍(상단)보다 어려운 이미지 쌍(하단)을 매칭하는데 더 빠릅니다.](LightGlue%20Local%20Feature%20Matching%20at%20Light%20Speed%20ab7a8e6890084e0fa11d024b37cb2866/Untitled%201.png)

깊이 적응성. LightGlue는 그것의 예측이 확신에 차 있을 때 더 이른 계층에서 멈출 수 있으므로 쉬운 이미지 쌍(상단)보다 어려운 이미지 쌍(하단)을 매칭하는데 더 빠릅니다.

결론적으로, LightGlue는 SuperGlue에 비해 크게 개선되어 더 짧은 시간에 강력한 이미지 매칭 기능을 제공하므로 동시 로컬라이제이션 및 매핑(SLAM) 또는 크라우드 소스 데이터에서 대규모 장면 재구성과 같이 짧은 지연 시간이 필요한 작업에 적합한 툴입니다. 저자들은 LightGlue 모델과 훈련 코드를 공개할 계획입니다.

### 2. Related work

동일한 장면이나 개체를 나타내는 이미지를 일치시키는 이미지 매칭은 일반적으로 로컬 특징에 따라 달라집니다. 로컬 피처는 각각 로컬 외관에 대한 설명과 연관된 희소 키포인트입니다. 기존 알고리즘은 수작업으로 만든 기준과 그라데이션 통계를 사용하지만, 최근의 접근 방식은 컨볼루션 신경망(CNN)을 활용하여 매칭의 정확성과 견고성을 향상시킵니다. 로컬 피처는 이제 다양한 형태로 제공되며, 더 나은 로컬라이제이션부터 신뢰할 수 없는 물체를 무시하는 기능까지 다양한 기능을 제공합니다.

![LightGlue 아키텍처. 입력 로컬 특징(d, p) 쌍이 주어지면, 각 계층은 위치 인코딩 ⊙을 가진 자기 및 교차 주의 단위를 기반으로 하는 컨텍스트로 시각적 설명자(•,•)를 증가시킵니다. 신뢰 분류자 c는 추론을 멈출지 결정하는데 도움이 됩니다. 만약 몇 개의 점이 확신에 차 있으면, 추론은 다음 계층으로 진행하지만, 확신적으로 매칭이 불가능한 점들은 제거합니다. 한 번에 확신에 차는 상태가 도달하면, LightGlue는 그들의 쌍대 유사성과 단항 매칭 가능성에 기초하여 점들 사이에 배정을 예측합니다.](LightGlue%20Local%20Feature%20Matching%20at%20Light%20Speed%20ab7a8e6890084e0fa11d024b37cb2866/Untitled%202.png)

LightGlue 아키텍처. 입력 로컬 특징(d, p) 쌍이 주어지면, 각 계층은 위치 인코딩 ⊙을 가진 자기 및 교차 주의 단위를 기반으로 하는 컨텍스트로 시각적 설명자(•,•)를 증가시킵니다. 신뢰 분류자 c는 추론을 멈출지 결정하는데 도움이 됩니다. 만약 몇 개의 점이 확신에 차 있으면, 추론은 다음 계층으로 진행하지만, 확신적으로 매칭이 불가능한 점들은 제거합니다. 한 번에 확신에 차는 상태가 도달하면, LightGlue는 그들의 쌍대 유사성과 단항 매칭 가능성에 기초하여 점들 사이에 배정을 예측합니다.

전통적으로 로컬 특징은 설명자 공간에서 가장 가까운 이웃 검색을 통해 매칭됩니다. 이 프로세스에는 일반적으로 휴리스틱 방법이나 기하학적 모델 피팅을 통해 일치할 수 없는 키포인트와 불완전한 설명자로 인한 잘못된 대응을 필터링하는 작업이 포함됩니다. 하지만 이 방법은 까다로운 조건에서는 실패할 수 있어 딥 매처를 개발하게 되었습니다.

딥 매처는 로컬 특징을 일치시키고 이상값을 거부하도록 학습된 딥 네트워크입니다. 이러한 최초의 시스템인 SuperGlue는 트랜스포머와 최적의 전송을 결합하여 부분 할당 문제를 해결합니다. 이러한 장점에도 불구하고 SuperGlue는 복잡하고 훈련하기 어렵습니다. 더 효율적으로 만들려는 시도는 특히 까다로운 조건에서 성능이 저하되는 경우가 많았습니다.

반면, LightGlue는 네트워크 크기를 동적으로 조정하여 성능 저하 없이 효율성을 개선합니다. 매칭을 위해 고밀도 그리드를 사용하고 더 많은 요소를 처리하기 때문에 속도가 느린 고밀도 매처와 달리, LightGlue는 희소 입력에서 작동하며 고밀도 매처와 경쟁하지만 실행 시간은 더 짧습니다.

트랜스포머는 언어 처리에서 성공을 거둔 이후 효율성에 중점을 두었습니다. 주요 제한 사항인 주의의 메모리 사용량을 줄이는 것은 선형 공식이나 병목 잠재 토큰을 사용하여 해결되었습니다. 일부 작업은 네트워크 깊이를 적응적으로 조절하여 토큰의 예측이 최종적인지 또는 추가 계산이 필요한지 예측합니다. 트랜스포머의 위치 인코딩도 정확도에 큰 영향을 미칩니다. LightGlue는 이러한 혁신 기술을 2D 피처 매칭에 적용하여 효율성과 정확성을 모두 개선합니다.

### 3. Fast feature matching

LightGlue는 SuperGlue 모델에 따라 이미지 A와 B에서 추출한 두 세트의 로컬 특징 사이의 부분 할당을 예측하도록 설계되었습니다. 로컬 피처는 2D 포인트 위치와 시각적 설명자로 구성되며, 이를 처리하여 일치하는 부분과 일치하지 않는 부분, 즉 오클루전 또는 반복 불가능성으로 인해 일치하는 부분과 일치하지 않는 부분으로 구성된 대응 집합을 출력합니다.

![포인트 프루닝. LightGlue는 컨텍스트를 집계함에 따라 일부 포인트(•)가 매칭할 수 없다는 것을 일찍 알아낼 수 있으며, 따라서 이들을 이후의 계층에서 배제할 수 있습니다. 다른, 반복 불가능한 포인트들은 이후 계층에서 배제됩니다: • → • → •. 이것은 추론 시간을 줄이고, 최종적으로 빠르게 좋은 매칭을 찾기 위한 검색 공간(•)을 줄입니다.](LightGlue%20Local%20Feature%20Matching%20at%20Light%20Speed%20ab7a8e6890084e0fa11d024b37cb2866/Untitled%203.png)

포인트 프루닝. LightGlue는 컨텍스트를 집계함에 따라 일부 포인트(•)가 매칭할 수 없다는 것을 일찍 알아낼 수 있으며, 따라서 이들을 이후의 계층에서 배제할 수 있습니다. 다른, 반복 불가능한 포인트들은 이후 계층에서 배제됩니다: • → • → •. 이것은 추론 시간을 줄이고, 최종적으로 빠르게 좋은 매칭을 찾기 위한 검색 공간(•)을 줄입니다.

LightGlue는 두 피처 세트를 공동으로 처리하는 동일한 레이어 스택으로 구성됩니다. 각 레이어에는 각 포인트의 표현을 업데이트하는 자체 및 교차 주의 단위가 포함되어 있습니다. 그런 다음 분류기가 각 레이어에서 추론을 중단할지 여부를 결정하여 불필요한 계산을 피합니다. 마지막으로 경량 헤드가 표현 집합에서 부분 할당을 계산합니다.

사용된 트랜스포머 백본은 이미지의 각 로컬 피처를 상태와 연결합니다. 상태는 해당 시각적 설명자로 초기화되고 이후 각 레이어에 의해 업데이트됩니다. 레이어는 하나의 자체 주의 단위와 하나의 교차 주의 단위의 연속으로 정의됩니다.

각 주의 단위에서 다중 레이어 퍼셉트론(MLP)은 소스 이미지에서 집계된 메시지가 주어지면 상태를 업데이트합니다. 메시지는 주의 메커니즘에 의해 소스 이미지의 모든 상태에 대한 가중치 평균으로 계산됩니다. 이 작업은 두 이미지의 모든 포인트에 대해 병렬로 수행됩니다.

셀프 어텐션에서는 각 포인트가 동일한 이미지의 포인트에서 정보를 가져옵니다. 각 포인트에 대해 현재 상태는 먼저 서로 다른 선형 변환을 통해 키와 쿼리 벡터로 분해됩니다. 그런 다음 포인트 사이의 상대적 위치를 회전 인코딩하여 주의 점수를 계산합니다. 위치 인코딩은 주의도에서 중요한 역할을 하며, 모델이 위치에 따라 다른 요소를 처리할 수 있게 해줍니다.

교차 주의에서는 한 이미지의 각 포인트가 다른 이미지의 모든 포인트에 주의를 기울입니다. 이 점수는 자기 주의 프로세스와는 다르게 계산되며, 양방향 메시지에 대해 유사성을 한 번만 계산하면 됩니다. 양방향 주의 전략은 이 단계의 복잡성을 고려할 때 상당한 계산 리소스를 절약하는 데 도움이 됩니다.

이미지 쌍에 대한 효율적인 특징 매칭 알고리즘인 LightGlue를 소개합니다. 이 알고리즘은 이전 이미지 매칭 방법인 SuperGlue를 여러 가지 면에서 개선했습니다. LightGlue는 이미지 쌍을 병렬로 처리할 수 있는 Transformer 백본을 사용합니다.

이 알고리즘은 이미지 A와 B에서 추출한 두 개의 로컬 특징 세트를 처리합니다. 각 로컬 특징은 2D 포인트 위치와 시각적 설명자로 구성됩니다. LightGlue는 이러한 특징으로부터 대응 집합을 생성합니다. 이러한 세트의 처리는 자체 및 교차 주의 단위로 구성된 레이어에서 이루어집니다.

트랜스포머 백본은 이미지의 각 로컬 피처를 상태와 연결하는 역할을 합니다. 이 상태는 각 레이어에서 업데이트됩니다. 자체 주의 단위는 동일한 이미지의 포인트에서 정보를 가져오고 교차 주의 단위는 다른 이미지에서 정보를 가져옵니다.

![훈련의 용이성. LightGlue 아키텍처는 합성 호모그래피에 대한 사전 훈련의 수렴 속도를 크게 개선합니다. 500만개의 이미지 쌍(오직 2 GPU-일) 후에, LightGlue는 최종 계층에서 -33%의 손실과 +4%의 매칭 회수율을 달성합니다. SuperGlue는 유사한 정확성에 도달하기 위해 7일 이상의 훈련이 필요합니다.](LightGlue%20Local%20Feature%20Matching%20at%20Light%20Speed%20ab7a8e6890084e0fa11d024b37cb2866/Untitled%204.png)

훈련의 용이성. LightGlue 아키텍처는 합성 호모그래피에 대한 사전 훈련의 수렴 속도를 크게 개선합니다. 500만개의 이미지 쌍(오직 2 GPU-일) 후에, LightGlue는 최종 계층에서 -33%의 손실과 +4%의 매칭 회수율을 달성합니다. SuperGlue는 유사한 정확성에 도달하기 위해 7일 이상의 훈련이 필요합니다.

섹션 3.2에서는 모든 레이어에서 업데이트된 상태로부터 대응을 예측하는 방법에 대해 설명합니다. 경량 헤드는 두 이미지의 점 사이의 쌍별 점수 매트릭스를 계산하여 각 쌍의 점의 대응에 대한 선호도를 반영합니다. 또한 각 점에는 다른 이미지에 해당 점이 있을 가능성을 나타내는 일치 가능성 점수가 할당됩니다.

백서의 다음 부분에서는 불필요한 계산을 피하기 위한 적응형 깊이와 너비에 대해 설명합니다. 또한 각 점의 예측된 할당에 대한 신뢰도를 결정하는 신뢰도 분류기를 소개합니다. 모든 점의 충분한 비율을 확신할 수 있는 경우 알고리즘이 중지되고, 확신이 없는 점은 폐기되어 계산을 더 절약할 수 있습니다.

마지막으로 LightGlue는 두 단계로 학습됩니다. 먼저 대응을 예측하도록 훈련한 다음 신뢰도 분류기를 훈련합니다. 훈련 과정은 투뷰 변환에서 추정된 실측 레이블을 사용하여 감독됩니다. 이 백서에서는 위치 인코딩, 예측 헤드, 심층 감독 측면에서 LightGlue가 제공하는 발전된 기능을 강조하면서 SuperGlue와의 비교로 마무리합니다.

### 4. Details that matter

이 섹션에서는 LightGlue 구현 및 훈련 프로세스에 대한 자세한 내용을 설명합니다. LightGlue는 처음에 1백만 개의 이미지에서 생성된 합성 호모그래피로 훈련됩니다. 이 사전 훈련 단계는 모델을 일반화하는 데 매우 중요하며, 특히 메가뎁스와 같은 실제 데이터 세트를 사용하여 미세 조정할 때 더욱 그렇습니다. 메가뎁스는 196개의 관광 랜드마크를 묘사한 100만 개의 크라우드 소싱 이미지로 구성되며, 카메라 보정 및 SfM(Structure from Motion)으로 복구된 포즈와 멀티뷰 스테레오를 통해 얻은 고밀도 심도로 완성됩니다.

LightGlue의 성능을 향상시키는 몇 가지 '트레이닝 트릭'이 있습니다. 여기에는 편극 오차가 큰 포인트를 일치할 수 없는 포인트로 표시하여 불완전한 깊이 맵을 처리하고, 학습 속도를 미세 조정 및 어닐링하여 정확도를 높이고, 훈련에 더 많은 포인트를 사용하고(이미지당 1k 대신 2k), 배치 크기를 효과적으로 관리하는 방법 등이 있습니다.

LightGlue의 아키텍처는 9개의 레이어로 구성되어 있으며, 각 주의 단위에는 4개의 헤드가 있습니다. 모든 표현의 크기는 256입니다. 런타임 성능을 위해 이 모델은 효율적인 셀프 어텐션 구현을 사용합니다.

마지막으로 LightGlue는 슈퍼포인트와 SIFT 로컬 피처로 학습되지만 모든 유형의 로컬 피처와 호환됩니다. 이미지 매칭 챌린지에 포함된 장면에 대한 학습을 피하기 위해 미세 조정 중에 Sun 등의 메가뎁스 데이터 분할이 사용됩니다.

### 5. Experiments

동형 추정, 상대 포즈 추정, 시각적 로컬라이제이션의 세 가지 작업에 대해 LightGlue 모델을 평가했습니다. 이 논문에서는 호모그래피 추정과 상대 포즈 추정에 대한 결과를 자세히 설명합니다.

호모그래피 추정 작업에서는 조명 또는 시점 변화에 따른 5개의 이미지 쌍 시퀀스로 구성된 HPatches 데이터 세트에서 LightGlue 모델을 테스트했습니다. 그 결과, LightGlue는 SuperGlue 및 SGMNet에 비해 더 높은 정밀도와 유사한 재현율을 제공했습니다. 이는 호모그래피 추정에 직접 선형 변환(DLT) 방법을 사용할 때 훨씬 더 정확한 추정값으로 이어져 DLT가 더 복잡하고 느린 MAGSAC 방법보다 경쟁력이 있다는 것을 보여주었습니다.

상대 포즈 추정 작업에는 강한 오클루전과 까다로운 조명 및 구조적 변화가 있는 야외 장면이 포함되었습니다. 두 곳의 유명 사진 관광지의 1500개 이미지 쌍이 포함된 MegaDepth-1500 데이터 세트의 테스트 세트에서 LightGlue를 평가했습니다. 그 결과, 일치 정확도와 추론 시간 측면에서 LightGlue가 SuperGlue나 SGMNet과 같은 기존 방법보다 월등히 뛰어난 성능을 보였습니다. 또한 LightGlue는 디스크 로컬 피처에 대한 매칭 정확도를 크게 향상시킬 수 있었으며, 더 나은 대응과 더 정확한 상대 포즈를 생성했습니다. 슈퍼글루와 SGM넷보다 빠르면서도 정확도가 더 높았기 때문에 정확도와 속도 간의 균형을 고려할 때 더 나은 선택이었습니다.

시각적 로컬라이제이션과 디자인 결정의 영향에 대한 자세한 내용은 이 섹션에서 제공하지 않았습니다.

대규모 아헨 주야간 벤치마크를 사용하여 실외 시각적 로컬라이제이션 작업에 대해 LightGlue 모델을 추가로 평가했습니다. 계층적 로컬라이제이션 프레임워크를 따랐으며 SuperGlue, SGMNet, ClusterGNN과 같은 방법과 성능을 비교했습니다. LightGlue는 SuperGlue와 정확도는 비슷하지만 처리량이 2.5배 더 높은 것으로 나타났습니다. 효율적인 자기 주의 메커니즘을 사용하는 최적화된 LightGlue 변형은 처리량을 4배 증가시켜 최대 4096개의 키포인트를 실시간으로 매칭할 수 있는 능력을 보여주었습니다.

![매칭 가능성의 이점. 매칭 가능성은 시각적으로 유사한 이상치(red)를 필터링하고, 오직 내부 상응성(green)만을 유지하는 데 도움이 됩니다.](LightGlue%20Local%20Feature%20Matching%20at%20Light%20Speed%20ab7a8e6890084e0fa11d024b37cb2866/Untitled%205.png)

매칭 가능성의 이점. 매칭 가능성은 시각적으로 유사한 이상치(red)를 필터링하고, 오직 내부 상응성(green)만을 유지하는 데 도움이 됩니다.

연구원들은 또한 LightGlue 모델의 설계 결정을 검증하기 위해 절제 연구를 수행했습니다. 슈퍼글루에 비해 라이트글루는 훨씬 더 빠르게 수렴하고 더 높은 리콜 및 정밀도 값을 달성했습니다. 또한 이 제거 연구에서는 일치성 분류기 및 학습된 절대 위치 인코딩 사용과 같은 특정 기능이 모델의 성능에 크게 기여한다는 사실을 입증했습니다.

또한 LightGlue는 케이스별로 포워드 패스 중에 계산을 적응적으로 줄일 수 있으며, 이는 다양한 범위의 시각적 중첩 상황에서 특히 유용하다는 것이 관찰되었습니다. 또한 LightGlue는 슈퍼글루와 SGMNet에 비해 실행 시간을 단축하여 특히 시각적 로컬라이제이션의 일반적인 설정인 이미지당 최대 2K 키포인트에 대해 향상된 효율성을 보여주었습니다. 이 연구는 적응형 가지치기가 모든 입력 크기에 대해 실행 시간을 더욱 단축한다는 것을 보여주었습니다.

### 6. Conclusion

이 논문의 저자들은 이미지 전반의 희박한 로컬 특징을 일치시키도록 설계된 LightGlue라는 심층 신경망을 발표했습니다. LightGlue는 주의 메커니즘, 트랜스포머의 혁신, 매칭 문제에 대한 고유한 이해를 활용하는 SuperGlue 모델의 확장판입니다. LightGlue의 주요 기능 중 하나는 각 이미지 쌍의 난이도에 따라 모델의 깊이와 폭을 조정하는 적응형 계산 방식입니다.

![적응적인 깊이와 너비의 시각화. 위에서 아래로, 우리는 쉬운, 중간, 어려운 이미지 쌍 세 개를 보여줍니다. 왼쪽 열은 LightGlue가 그 너비를 줄이는 방법을 보여줍니다: 일부 포인트(•)가 매칭할 수 없다는 것을 일찍 알아내고(주로 시각적 중첩에 의해), 나중 계층에서 반복 불가능한 포인트를 버립니다: • → • → •. 이것은 어려운 쌍에서 매우 효과적입니다. LightGlue는 줄어든 검색 공간(•)에서만 매칭을 찾습니다. 매칭 가능성 점수(중간 열, 매칭 불가능한 •에서 가능성 있는 매칭 •로),는 정확한 대응을 찾는 데 도움이 되며, 거의 이진적입니다. 오른쪽에서는 우리는 예측된 매칭을 에피폴라 내부 또는 외부로 시각화합니다. 우리는 각 쌍에 대한 실행 시간과 정지 계층을 보고합니다. 쉬운 샘플에서, LightGlue는 오직 2-3 계층 후에 멈추며, 거의 100 FPS로 실행합니다.](LightGlue%20Local%20Feature%20Matching%20at%20Light%20Speed%20ab7a8e6890084e0fa11d024b37cb2866/Untitled%206.png)

적응적인 깊이와 너비의 시각화. 위에서 아래로, 우리는 쉬운, 중간, 어려운 이미지 쌍 세 개를 보여줍니다. 왼쪽 열은 LightGlue가 그 너비를 줄이는 방법을 보여줍니다: 일부 포인트(•)가 매칭할 수 없다는 것을 일찍 알아내고(주로 시각적 중첩에 의해), 나중 계층에서 반복 불가능한 포인트를 버립니다: • → • → •. 이것은 어려운 쌍에서 매우 효과적입니다. LightGlue는 줄어든 검색 공간(•)에서만 매칭을 찾습니다. 매칭 가능성 점수(중간 열, 매칭 불가능한 •에서 가능성 있는 매칭 •로),는 정확한 대응을 찾는 데 도움이 되며, 거의 이진적입니다. 오른쪽에서는 우리는 예측된 매칭을 에피폴라 내부 또는 외부로 시각화합니다. 우리는 각 쌍에 대한 실행 시간과 정지 계층을 보고합니다. 쉬운 샘플에서, LightGlue는 오직 2-3 계층 후에 멈추며, 거의 100 FPS로 실행합니다.

LightGlue는 SuperGlue에 비해 속도, 정확도, 훈련 용이성이 개선되어 드롭인 대체 솔루션으로 유용하다는 것이 입증되었습니다. 저자들은 연구 커뮤니티의 이익을 위해 코드를 공개적으로 공개하겠다고 약속했습니다. 또한 저자들은 연구에 대한 귀중한 피드백을 제공한 Mihai Dusmanu, Remi Pautrat, Shaohui Liu에게 감사를 표했습니다.

### Appendix

부록에서는 2020년, 2021년, 2023년의 이미지 매칭 챌린지(IMC), 상대적 포즈 추정, 실외 및 실내 시각적 로컬라이제이션 작업에 대한 추가 테스트 등 다양한 환경에서의 LightGlue 모델에 대한 추가 실험 결과를 확인할 수 있습니다.

IMC 테스트 결과, 라이트글루는 슈퍼글루와 비교했을 때 경쟁적으로 더 빠른 결과를 제공했습니다. 또한 디스크 로컬 기능으로 훈련했을 때 LightGlue는 가장 가까운 이웃 매칭과 SuperPoint+LightGlue 모두에서 더 나은 성능을 보였습니다. 또한 IMC 2021 벤치마크에서 다른 모든 접근 방식을 능가하는 것으로 입증되었습니다. 다양한 장면에서 엔드 투 엔드 구조에서 모션까지를 중점적으로 테스트한 IMC 2023 챌린지에서는 LightGlue가 SuperPoint+SuperGlue에 비해 2.3% 더 나은 결과를 보였습니다.

메가뎁스를 사용한 상대적 포즈 추정 실험에서 라이트글루는 기존 스파스 매처보다 정확도가 높으면서도 더 빠른 성능을 보여주었습니다. 실외 및 실내 시각적 로컬라이제이션 작업에서 LightGlue는 다른 접근 방식과 비슷한 정확도를 제공하면서도 더 빠른 속도로 경쟁력을 유지했습니다. 실내 로컬라이제이션의 경우, 약간의 차이가 있긴 했지만 특정 임계값에서 LightGlue는 SuperGlue와 동등한 성능을 보였고 약간 더 나은 성능을 보였습니다.

그리고 제안한 모델인 LightGlue의 세부 구현을 제시합니다. 아키텍처의 세부 사항부터 다양한 특징 검출기와 설명자가 사용되는 방식에 이르기까지 다양한 논의가 이루어집니다.

구현에는 위치 인코딩과 그래프 신경망의 사용이 포함됩니다. GNN에는 자체 및 교차 주의 단위가 모두 포함된 9개의 트랜스포머 레이어가 포함되어 있다고 자세히 설명되어 있습니다. 구현의 주요 측면에는 선형 레이어와 시그모이드 활성화를 사용하여 신뢰 수준을 예측하는 신뢰도 분류기가 포함됩니다. 또 다른 중요한 구성 요소는 모델의 추론 프로세스를 최적화하는 데 사용되는 종료 기준과 포인트 가지치기입니다.

또한 SuperPoint, SIFT 및 DISK를 포함한 로컬 기능의 사용에 대해서도 설명합니다. 이러한 디텍터와 디스크립터는 이미지 인식 분야에서 널리 사용되고 잘 정립된 기술입니다. 또한 이 모델에는 메가뎁스 데이터 세트에 대한 호모그래피 사전 학습 및 미세 조정도 포함됩니다. 이 프로세스는 사전 학습을 위해 실제 이미지의 합성 호모그래피를 사용하고 미세 조정을 위해 의사 지상 실측 카메라 포즈와 깊이 이미지를 사용하여 모델의 성능을 향상시킵니다.

![LightGlue에 의해 생성된 다른 로컬 특징에 대한 특징 비교. 우리는 SIFT+LightGlue (왼쪽), SuperPoint+LightGlue (가운데) 및 DISK+LightGlue (오른쪽)의 결과를 비교합니다.](LightGlue%20Local%20Feature%20Matching%20at%20Light%20Speed%20ab7a8e6890084e0fa11d024b37cb2866/Untitled%207.png)

LightGlue에 의해 생성된 다른 로컬 특징에 대한 특징 비교. 우리는 SIFT+LightGlue (왼쪽), SuperPoint+LightGlue (가운데) 및 DISK+LightGlue (오른쪽)의 결과를 비교합니다.

다양한 시나리오를 고려하고 이러한 조건에서 모델의 성능을 최적화하는 메커니즘을 만들었습니다. 또한, 라이트글루는 효율적인 셀프 어텐션 메커니즘을 구현하여 IO 복잡성을 최적화하고 혼합 정밀도 컴퓨팅을 사용하여 런타임 및 메모리 요구 사항을 줄입니다.

Hpatches 데이터 세트를 사용한 동형성 추정을 통해 모델을 검증하고, 논문에서 추정된 동형성의 정확도를 평가하는 접근 방식을 제시합니다. 이 모든 실험은 10GB VRAM이 장착된 단일 RTX 3080에서 수행되며, 매칭 프로세스의 타이밍에만 초점을 맞추고 희소 특징 추출과 강력한 포즈 추정은 제외합니다.

마지막으로 라이트글루가 일치하지 않는 포인트를 삭제하는 방법과 쉬운, 중간, 어려운 쌍에 대한 조기 중지 메커니즘을 보여주는 정성적 결과가 제시됩니다. 이를 통해 실제 애플리케이션에서 모델의 효율성을 입증할 수 있습니다.

![InLoc [70]에서의 실패 사례. LightGlue는 때때로 강한 질감을 가진 장면에서 반복되는 객체를 매칭하며, 대신에 기하학적 구조를 매칭합니다.](LightGlue%20Local%20Feature%20Matching%20at%20Light%20Speed%20ab7a8e6890084e0fa11d024b37cb2866/Untitled%208.png)

InLoc [70]에서의 실패 사례. LightGlue는 때때로 강한 질감을 가진 장면에서 반복되는 객체를 매칭하며, 대신에 기하학적 구조를 매칭합니다.

![합성 호모그래피 예시. 우리는 원래의 이미지(왼쪽)와 강한 관점 변환과 극단적인 광학 증강을 결과로 하는 두 가지 증강 예시(중앙과 오른쪽)를 보여줍니다.](LightGlue%20Local%20Feature%20Matching%20at%20Light%20Speed%20ab7a8e6890084e0fa11d024b37cb2866/Untitled%209.png)

합성 호모그래피 예시. 우리는 원래의 이미지(왼쪽)와 강한 관점 변환과 극단적인 광학 증강을 결과로 하는 두 가지 증강 예시(중앙과 오른쪽)를 보여줍니다.