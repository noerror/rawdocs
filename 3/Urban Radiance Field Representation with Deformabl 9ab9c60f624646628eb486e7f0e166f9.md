# Urban Radiance Field Representation with Deformable Neural Mesh Primitives

[https://arxiv.org/abs/2307.10776](https://arxiv.org/abs/2307.10776)

- Jul 2023

![우리 방법의 기본 개념. 입력으로 제공된 불완전한 포인트클라우드를 처음에 보셀화하고, 각 보셀마다 Deformable Neural Mesh Primitive (DNMP)를 초기화합니다. 훈련하는 동안, DNMP의 형태는 기본적인 3D 구조를 모델링하기 위해 변형되고, DNMP의 발광 특징은 신경 렌더링을 위한 지역 발광 정보를 모델링하기 위해 학습됩니다. 우리의 표현을 기반으로, 우리는 도시 장면에 대해 효율적이고 사진처럼 리얼한 렌더링을 달성합니다.](Urban%20Radiance%20Field%20Representation%20with%20Deformabl%209ab9c60f624646628eb486e7f0e166f9/Untitled.png)

우리 방법의 기본 개념. 입력으로 제공된 불완전한 포인트클라우드를 처음에 보셀화하고, 각 보셀마다 Deformable Neural Mesh Primitive (DNMP)를 초기화합니다. 훈련하는 동안, DNMP의 형태는 기본적인 3D 구조를 모델링하기 위해 변형되고, DNMP의 발광 특징은 신경 렌더링을 위한 지역 발광 정보를 모델링하기 위해 학습됩니다. 우리의 표현을 기반으로, 우리는 도시 장면에 대해 효율적이고 사진처럼 리얼한 렌더링을 달성합니다.

## 1. Introduction

이 논문에서는 3D 장면의 사진 같은 이미지를 합성하는 것이 컴퓨터 비전 분야에서 오랜 기간 동안 중요한 연구 주제였음을 설명합니다. 특히 도시 외부 환경에서는 장면의 복잡성과 높은 컴퓨팅 자원 요구로 인해 많은 도전이 있습니다. 고품질 이미지 렌더링을 달성하기 위해 컴퓨터 그래픽스 커뮤니티는 점구름, 메쉬, 복셀, 암시적 함수 등 다양한 장면 표현 기술을 탐구했습니다. 이 중 메쉬 기반 표현이 현대 렌더링 파이프라인에서 널리 사용되지만, 도시 장면의 물밀폐(mesh-tight) 모델을 구축하는 것은 여전히 어려운 문제입니다. 또한, 고전적인 기술로는 텍스처와 조명을 현실적으로 복원하는 것이 어렵습니다.

최근 신경 렌더링 방법은 메쉬 구축 단계를 우회하고 장면을 암시적 신경 함수로 표현하여 이러한 문제를 해결하려고 시도했습니다. 특히 NeRF와 그 변형은 볼륨 내의 밀도와 발광 정보를 저장하고, 볼륨 렌더링을 사용하여 뷰를 합성하는 새로운 접근 방식을 제안했습니다. 이러한 방법은 주목할 만한 진전을 이루었지만, 암시적 함수를 수천 번 평가해야 하는 계산적인 집약성 때문에 여전히 많은 계산 자원이 낭비됩니다.

이에 더해, 연구자들은 신경 렌더링을 명시적 포인트클라우드 재구성과 결합하여 빈 공간을 뛰어넘어 렌더링하는 방법을 제안함으로써 계산 자원을 절약하는 방법을 모색했습니다. 이 방식에서는 뷰 레이와 포인트클라우드의 교차 지점 근처의 점들만 샘플링하여 특징을 집계합니다. 이러한 집계 메커니즘을 기반으로 사실적 렌더링을 위해 밀도 있고 완벽한 재구성이 필수적입니다. 그러나 현재의 재구성 알고리즘에서 재구성된 점들은 일반적으로 균일하게 분포되어 있지 않고, 누락된 영역도 흔하게 발생합니다.

이 연구에서는 대규모 환경에서 효율적인 발광 필드 표현을 제안하며, 효율적인 메쉬 기반 렌더링과 강력한 신경 표현을 결합합니다. Deformable Neural Mesh Primitive (DNMP)를 개발하여 전체 발광 필드를 이러한 기본 단위로 표현하고, 각 DNMP가 지역의 기하학과 발광을 매개변수화합니다.

## 2. Related Work

### **신경 렌더링**

- **초기 단계**: 초기의 신경 렌더링 기법은 3D 신호를 2D 이미지 평면에 직접 투영하고, 2D CNN을 사용하여 최종 이미지로 매핑하는 방식을 제안했습니다. 이 접근법은 CNN의 회귀 능력에만 의존하며, 3D 공간의 명시적인 물리 모델링이 없어 새로운 뷰를 합성하는 데 성능 한계가 있습니다.
- **볼륨 렌더링 기반 접근법**: 최근에는 장면의 밀도와 발광 정보를 암시적 신경 함수 내에 저장하고 볼륨 렌더링을 통해 새로운 뷰를 합성하는 방식이 등장했습니다. 이러한 방법은 초기 단계의 한계를 완화하며 일반적으로 좋은 렌더링 결과를 얻을 수 있습니다.

### **외부 NeRF**

- **NeRF의 확장**: 몇몇 연구자들은 NeRF를 도시 환경과 같은 외부 장면에 적용하려는 시도를 했습니다. NeRFW는 렌더링 파이프라인에 프레임별 코드를 통합하여 광도 변화와 일시적인 객체를 처리하는 등의 기능을 추가했습니다.
- **Block-NeRF**: Block-NeRF는 도시 장면을 블록 단위로 나누어 각각의 NeRF로 복합 장면을 구축하는 방법을 제안했습니다. 이러한 접근법은 여전히 복잡한 빈 공간에서 비효율적인 볼륨 샘플링에 의존합니다.

### **3D 형상 재구성**

- **클래식 파이프라인**: 카메라 자세를 구조에서 운동(Structure-from-Motion, SfM) 기반으로 추정한 후, 다중 뷰 스테레오(Multi-View Stereo, MVS) 기술로 조밀한 깊이를 복구하는 전통적인 3D 재구성 방법이 설명됩니다. 이러한 방법들은 이상적인 시나리오에서는 잘 작동하지만, 조명 변화나 텍스처가 없는 영역 등의 어려운 조건에서는 불완전한 재구성 결과를 생성할 수 있습니다.
- **암시적 필드 기반 방법**: 암시적 필드를 사용하는 방법은 일반적으로 더 강인하지만, 이후 메쉬를 추출하기 위해 비용이 많이 드는 이소 서페이싱 단계가 필요합니다.

이 챕터는 다양한 접근 방식의 장단점을 검토하고 이 논문에서 제안하는 방법이 기존 기술들의 한계를 어떻게 해결하고자 하는지 배경을 제공합니다.

## 3. Method

### **3.1 Deformable Neural Mesh Primitive (DNMP)**

![우리 프레임워크의 개요. 전체 장면은 포인트클라우드 재구성을 기반으로 보셀화되며, 각 보셀에는 지역의 기하학 및 발광을 매개변수화하기 위해 DNMP가 할당됩니다. 래스터화를 통해, 우리는 각 뷰 레이 r에 대해 교차하는 DNMPs에서 보간된 발광 특징 {fj |j = 0, 1, . . . J}를 얻을 수 있습니다. 이후 이 보간된 특징들과 뷰 의존적 임베딩 {γj |j = 0, 1, . . . , J}이 암시적 함수 Fθ로 전송되어 각 교차점의 발광 값 cj 및 불투명도 αj를 예측합니다. 마지막으로, 뷰 레이 r의 렌더링 색상 Cˆ (r)은 불투명도 {αj |j = 0, 1, . . . , J}에 따라 발광 값들을 혼합하여 얻어집니다.](Urban%20Radiance%20Field%20Representation%20with%20Deformabl%209ab9c60f624646628eb486e7f0e166f9/Untitled%201.png)

우리 프레임워크의 개요. 전체 장면은 포인트클라우드 재구성을 기반으로 보셀화되며, 각 보셀에는 지역의 기하학 및 발광을 매개변수화하기 위해 DNMP가 할당됩니다. 래스터화를 통해, 우리는 각 뷰 레이 r에 대해 교차하는 DNMPs에서 보간된 발광 특징 {fj |j = 0, 1, . . . J}를 얻을 수 있습니다. 이후 이 보간된 특징들과 뷰 의존적 임베딩 {γj |j = 0, 1, . . . , J}이 암시적 함수 Fθ로 전송되어 각 교차점의 발광 값 cj 및 불투명도 αj를 예측합니다. 마지막으로, 뷰 레이 r의 렌더링 색상 Cˆ (r)은 불투명도 {αj |j = 0, 1, . . . , J}에 따라 발광 값들을 혼합하여 얻어집니다.

- **DNMP 개발**: DNMP는 메쉬 기반의 표현 효율과 신경 특징의 강력한 발광 표현 능력을 결합합니다. DNMP는 변형 가능한 메쉬 꼭짓점들로 구성되어 각 꼭짓점에 발광 정보를 인코딩할 수 있는 학습 가능한 특징 벡터가 연결됩니다.
- **기하학적 모델링**: DNMP의 형태는 저차원의 잠재 코드로부터 디코딩되어 기하학적 정보를 모델링합니다. 잠재 공간은 크고 다양한 메쉬 데이터베이스로부터 학습됩니다.
- **발광 인코딩**: DNMP의 각 꼭짓점에 독립적인 학습 가능한 특징 벡터를 연결하여 발광 정보를 인코딩하고, 렌더링 시 관련 특징들을 효율적으로 얻기 위해 래스터화를 사용합니다.

### **3.2 DNMP 기반 장면 표현**

![식 (2)로 불완전한 깊이로 감독되더라도, DNMP는 방대한 수의 지역 3D 구조로부터 학습된 컴팩트한 잠재 공간 덕분에 일반적으로 기본 기하학을 반영하여 변형될 수 있습니다.](Urban%20Radiance%20Field%20Representation%20with%20Deformabl%209ab9c60f624646628eb486e7f0e166f9/Untitled%202.png)

식 (2)로 불완전한 깊이로 감독되더라도, DNMP는 방대한 수의 지역 3D 구조로부터 학습된 컴팩트한 잠재 공간 덕분에 일반적으로 기본 기하학을 반영하여 변형될 수 있습니다.

- **장면 최적화**: 주어진 장면을 먼저 보셀화하고, 각 보셀에 DNMP를 할당하여 지역의 구조와 발광 정보를 매개변수화합니다. DNMP의 형태는 훈련 과정에서 최적화됩니다.
- **계층적 표현**: 3D 재구성 결과가 부족한 영역을 커버하기 위해 장면을 계층적으로 모델링합니다. 각 계층에 대한 DNMP의 크기를 조정하고 각 계층의 DNMP 형태를 독립적으로 최적화합니다.

### **3.3 발광 모델링 및 뷰 합성**

- **래스터화 및 특징 보간**: 렌더링을 위해 관련 특징들을 래스터화를 통해 수집하고, 교차하는 메쉬 면의 꼭짓점 특징들로부터 발광 특징을 보간합니다.
- **렌더링 과정**: 발광 및 불투명도 값을 예측하기 위해 MLP를 사용하고, 뷰에 따라 조정되는 발광 값을 통해 최종 이미지를 합성합니다. 계층적 DNMP 결과를 혼합하여 결핍 지역에서도 만족스러운 렌더링을 달성합니다.

이 챕터는 DNMP를 사용하여 효율적이고 표현력 있는 3D 렌더링을 어떻게 달성하는지 구체적으로 설명하며, 이러한 방법이 실제 환경에서도 강력한 성능을 낼 수 있음을 보여줍니다.

## 4. Experiments

### **4.1 실험 설정**

![원시 형태 최적화 전략에 따른 뷰 합성 결과. 직접 형태 최적화 결과는 형태 최적화 없이 보다는 약간 더 나은 결과를 보여주지만, 우리의 DNMP 기반 형태 최적화와 비교하면 여전히 훨씬 덜 만족스럽습니다.](Urban%20Radiance%20Field%20Representation%20with%20Deformabl%209ab9c60f624646628eb486e7f0e166f9/Untitled%203.png)

원시 형태 최적화 전략에 따른 뷰 합성 결과. 직접 형태 최적화 결과는 형태 최적화 없이 보다는 약간 더 나은 결과를 보여주지만, 우리의 DNMP 기반 형태 최적화와 비교하면 여전히 훨씬 덜 만족스럽습니다.

- **구현 세부사항**: 계층적 표현을 위해 보셀화를 두 가지 크기(0.5m, 1m)로 수행했습니다. 렌더링 시 가장 가까운 4개의 교차점에 대한 발광 값을 혼합하여 사용합니다. 정점 특징 초기화를 위한 위치 인코딩의 빈도는 3으로 설정되었으며, 이는 21차원의 특징을 생성합니다.
- **데이터셋**: 실험은 KITTI-360과 Waymo Open Dataset 두 도시 데이터셋에서 수행되었습니다. KITTI-360은 약 73.7km의 도심 주행 거리에서 촬영된 83,000개의 이미지를 포함하며, Waymo 데이터셋은 주로 정적 객체를 포함하는 6개의 시퀀스로 구성됩니다.
- **평가 지표**: 평가는 피크 신호 대 잡음비(PSNR), 구조 유사성 지수(SSIM), 학습된 인식 이미지 패치 유사성(LPIPS) 지표를 사용하여 이루어졌습니다.

### **4.2 소거 연구**

![다른 전략으로 최적화된 장면 기하학의 시각화. 꼭짓점 매개변수를 직접 최적화하는 것과 비교했을 때, 우리의 DNMP 기반 형태 최적화는 더 강건합니다.](Urban%20Radiance%20Field%20Representation%20with%20Deformabl%209ab9c60f624646628eb486e7f0e166f9/Untitled%204.png)

다른 전략으로 최적화된 장면 기하학의 시각화. 꼭짓점 매개변수를 직접 최적화하는 것과 비교했을 때, 우리의 DNMP 기반 형태 최적화는 더 강건합니다.

![계층적 DNMP의 사용 유무에 따른 렌더링. 제안된 계층적 DNMP는 합성 이미지에서 누락된 영역을 효과적으로 완성합니다. 더 자세한 내용을 보려면 확대해 보세요.](Urban%20Radiance%20Field%20Representation%20with%20Deformabl%209ab9c60f624646628eb486e7f0e166f9/Untitled%205.png)

계층적 DNMP의 사용 유무에 따른 렌더링. 제안된 계층적 DNMP는 합성 이미지에서 누락된 영역을 효과적으로 완성합니다. 더 자세한 내용을 보려면 확대해 보세요.

- **DNMP의 형상 최적화**: DNMP 기반 형상 최적화의 효과를 보여주기 위해 두 가지 변형 실험을 수행했습니다. 하나는 잠재 코드에서 DNMP 꼭짓점을 디코딩하지 않고 학습 가능한 꼭짓점 오프셋 매개변수를 사용하여 구형 메쉬 템플릿을 직접 최적화하는 것이고, 다른 하나는 형상 최적화 없이 원래의 구형 메쉬 템플릿을 사용하는 것입니다.
- **렌더링 과정**: 교차점의 수(J)에 따른 렌더링 성능을 비교하였고, 발광 특징의 차원도 실험적으로 조절하여 최적의 설정을 찾았습니다.
- **계층적 DNMP**: 더 큰 DNMP 반경과 더 적은 수의 DNMP가 사용되는 경우의 성능을 분석하여, 자원 제약 상황에서의 용인 가능한 성능 저하를 평가했습니다. 계층 없이 DNMP만을 사용한 실험에서는 성능이 감소함을 확인했습니다.

### **4.3 상태-의-예술 방법과의 비교**

![Waymo 데이터셋에서 새로운 뷰 합성의 질적 비교. 자세한 내용을 강조하기 위해 잘라낸 패치들이 확대되었습니다. 명시적이고 정확한 표면 모델링 덕분에 제안된 방법은 기준 방법들을 크게 능가하며 텍스처 세부 정보를 효과적으로 복구합니다. 보다 많은 시각화 결과를 위해 우리의 보충 자료를 참조하세요.](Urban%20Radiance%20Field%20Representation%20with%20Deformabl%209ab9c60f624646628eb486e7f0e166f9/Untitled%206.png)

Waymo 데이터셋에서 새로운 뷰 합성의 질적 비교. 자세한 내용을 강조하기 위해 잘라낸 패치들이 확대되었습니다. 명시적이고 정확한 표면 모델링 덕분에 제안된 방법은 기준 방법들을 크게 능가하며 텍스처 세부 정보를 효과적으로 복구합니다. 보다 많은 시각화 결과를 위해 우리의 보충 자료를 참조하세요.

![훈련 세트와 크게 다른 뷰에서 새로운 뷰 합성의 질적 비교. MipNeRF와 Point-NeRF와 비교했을 때, 제안된 방법은 훨씬 적은 흐림과 아티팩트로 고품질의 결과를 생성할 수 있습니다. 더 자세한 내용을 보려면 확대해 보세요.](Urban%20Radiance%20Field%20Representation%20with%20Deformabl%209ab9c60f624646628eb486e7f0e166f9/Untitled%207.png)

훈련 세트와 크게 다른 뷰에서 새로운 뷰 합성의 질적 비교. MipNeRF와 Point-NeRF와 비교했을 때, 제안된 방법은 훨씬 적은 흐림과 아티팩트로 고품질의 결과를 생성할 수 있습니다. 더 자세한 내용을 보려면 확대해 보세요.

![장면 편집 샘플. 보다 많은 시각화 결과를 위해 우리의 보충 자료를 참조하세요.](Urban%20Radiance%20Field%20Representation%20with%20Deformabl%209ab9c60f624646628eb486e7f0e166f9/Untitled%208.png)

장면 편집 샘플. 보다 많은 시각화 결과를 위해 우리의 보충 자료를 참조하세요.

- **성능 비교**: 제안된 방법을 여러 최신 기법과 비교했습니다. 이들 중에는 NeRF, NeRF-W, Mip-NeRF, Instant-NGP 등이 포함되었으며, 특히 LPIPS 지표에서 더 낮은 값을 달성하여 더 사실적인 이미지를 합성할 수 있음을 보여주었습니다.

### **4.4 효율성 분석**

- **렌더링 시간 및 메모리 사용**: NVIDIA A100 GPU를 사용하여 렌더링 시간과 메모리 사용량을 분석했습니다. 이 연구의 방법은 명시적인 표면 모델링을 통해 뷰 레이와 교차하는 가장 가까운 표면 점들만을 평가함으로써 계산 비용을 크게 줄였습니다. 결과적으로, Mip-NeRF 360에 비해 약 5배 빠른 렌더링 속도와 훨씬 적은 메모리 소모를 달성했습니다.
- **렌더링 효율성**: Instant-NGP와 비교할 때, 비록 PyTorch를 사용한 일반적인 구현임에도 불구하고, 효율적인 래스터화 기반 렌더링과 적은 네트워크 평가 횟수로 인해 매우 경쟁력 있는 추론 속도를 보여주었습니다. 이는 특히 라이트웨이트 버전에서 더욱 빠른 속도를 보였으며, Instant-NGP보다 우수한 렌더링 품질을 유지했습니다.

### **4.5 장면 편집**

- **텍스처 편집 및 객체 조작**: DNMP 기반의 명시적 메쉬 표현 덕분에 장면 편집이 가능합니다. 특정 지역의 발광 특징을 수정하거나 DNMP를 추가/제거함으로써 텍스처 편집 및 객체의 삽입 및 제거가 가능했습니다. 이러한 편집 능력은 추가적인 시각화 결과와 함께 보충 자료에서 더 자세히 다루어졌습니다.

## 5. Conclusion

- **효과 및 응용 가능성**: 이 연구에서 제안된 Deformable Neural Mesh Primitives (DNMPs)는 고전적인 메쉬와 신경 특징의 표현 능력을 결합하여 효율적이고 표현력 있는 신경 장면 표현을 가능하게 합니다. 공개된 두 도시 데이터셋에서의 광범위한 실험을 통해 제안된 방법의 효과가 검증되었으며, 뛰어난 렌더링 품질과 자원 효율성을 달성했습니다. 또한, 이 방법은 현대 그래픽 렌더링 파이프라인에 쉽게 통합될 수 있으며, VR/AR과 같은 응용 분야에도 활용될 수 있는 가능성을 제시합니다.
- **향후 연구 방향**: 현재의 프레임워크는 정적 장면을 기반으로 하고 있지만, 앞으로는 움직이는 객체를 처리할 수 있는 방법으로 확장하고자 합니다. 이는 더 일반적인 응용 시나리오에 적용할 수 있게 할 것입니다.