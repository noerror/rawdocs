# TEDi: Temporally-Entangled Diffusion for Long-Term Motion Synthesis

*이 논문은 "Temporal Entangling Diffusion Inference" (TEDi)라는 새로운 모션 합성 방법을 제안합니다. TEDi는 운동의 시간 축을 확산 시간 축과 엮어서 사용하는 방식으로 긴 시퀀스의 동작을 생성할 수 있습니다. 이 방식은 U-Net 아키텍처를 사용하여 자동회귀 방식으로 동작을 생성합니다.*

*TEDi의 핵심 요소 중 하나는 "정지 모션 버퍼"입니다. 이 버퍼는 프레임을 계속 생성하면서 (즉, 확산 시간 축을 따라 진행하면서) 실제로 확산 시간을 증가시키지 않습니다. 이 과정이 TEDi 프레임워크가 강건하게 새로운 프레임을 지속적으로 생성할 수 있게 합니다.*

*또한, TEDi는 가이드 생성, 경로 제어 등의 유용한 기능을 제공하며, 비교 및 탈락 연구를 통해 다른 동작 생성 모델과 비교할 때 우수한 성능을 보입니다.*

*이 논문의 결과는 동작 생성 외에도 오디오, 비디오 등의 순차 데이터, 또는 이미지의 패치별 순서 등 순차 순서를 정의할 수 있는 다른 형식의 데이터에 대한 확산 모델의 활용을 시사합니다. 그러나 현재의 시스템에는 노이즈에서 깨끗한 프레임을 계산하는데 필요한 확산 제거 과정을 거쳐야 하는 등의 제한 사항이 있습니다. 이에 대해 미래의 연구에서는 DDIM 같은 아이디어를 활용하여 이러한 과정을 더 빠르게 수행할 수 있는 방법을 탐색할 계획입니다.*

[https://arxiv.org/abs/2307.15042](https://arxiv.org/abs/2307.15042)

- Jul 2023

### 1 INTRODUCTION

장기 모션 시퀀스 생성은 사실적이고 반복되지 않는 결과물을 목표로 하는 캐릭터 애니메이션 및 인간과 컴퓨터의 상호작용과 같은 분야에서 지속적으로 해결해야 할 과제입니다. 원래 이미지 합성용으로 설계된 노이즈 제거 확산 확률 모델(DDPM)은 모션 합성에 맞게 조정되었습니다. 그러나 이 방식을 적용한 고정 길이 출력은 짧은 시퀀스를 이어 붙이는 문제와 제한된 인터랙티브 제어로 인해 장기적인 모션 생성에 문제를 일으킵니다.

![확산 과정의 점진적 특성이 모션의 시간 축과 확산 과정의 시간 축을 얽히게 함으로써 (왼쪽), 우리의 접근법 (오른쪽)은 임의의 길이의 동작 시퀀스를 합성하는 새로운 메커니즘을 가능하게 합니다.](TEDi%20Temporally-Entangled%20Diffusion%20for%20Long-Term%20%2019f29fc8bd8e482a9197e1122961e3f4/Untitled.png)

확산 과정의 점진적 특성이 모션의 시간 축과 확산 과정의 시간 축을 얽히게 함으로써 (왼쪽), 우리의 접근법 (오른쪽)은 임의의 길이의 동작 시퀀스를 합성하는 새로운 메커니즘을 가능하게 합니다.

이 논문에서는 확산 프로세스의 각 단계에서 가변 노이즈 레벨을 주입하도록 DDPM 프레임워크를 조정하는 새로운 방법인 시간적으로 얽힌 확산(TEDi, Temporally-Entangled Diffusion)을 제안합니다. 이 방법은 시간에 따라 달라지는 디퓨전 프로세스의 특성을 활용하여 모션 시퀀스의 시간 축과 얽히게 함으로써 깨끗한 모션 프레임이 지속적으로 흐르도록 합니다.

'모션 버퍼'는 이 프로세스의 핵심 부분으로, 다양한 노이즈 레벨의 노이즈가 있는 미래의 모션 프레임을 포함합니다. 이 버퍼는 지속적으로 업데이트되어 마지막에 노이즈가 있는 프레임을 추가하고 처음에 깨끗한 프레임을 제거하여 스티칭 문제 없이 모션 시퀀스를 계속 생성할 수 있습니다.

이 방법을 사용하면 '안내 모션' 또는 클린 프레임을 도입할 수 있으므로 생성 프로세스를 더 잘 제어하고 계획할 수 있습니다. 실험 결과 TEDi는 다양한 긴 모션 시퀀스를 생성할 수 있으며 다른 장기 생성 모델에 비해 우수한 성능을 발휘하는 것으로 나타났습니다.

### 2 RELATED WORK

2.1 확산 모델
노이즈 제거 확산 모델(DDPM,Denoising Diffusion Probabilistic Models)은 이미지 생성 및 텍스트-이미지 합성, 이미지-이미지 변환, 3D 데이터 생성 등 다양한 애플리케이션에서 우수한 품질을 입증했습니다. 또한 모션을 이미지로 처리하고 모든 프레임의 노이즈를 동시에 제거하여 모션 생성에도 사용되었습니다. 그러나 이러한 접근 방식은 생성된 시퀀스의 길이를 제한하고 인터랙티브 제어를 제한합니다. 반면에 제안된 프레임워크는 임의 길이의 시퀀스를 위한 자동 회귀 생성 방식과 DDPM을 결합합니다.

2.2 딥 모션 합성
모션 합성의 초기 연구에서는 제한된 볼츠만 머신을 사용했고, 이후 연구에서는 컨볼루션 신경망(CNN)과 순환 신경망(RNN)을 사용했습니다. 이러한 신경망은 모션 예측, 인터랙티브 모션 생성, 음악 기반 모션 합성 등 다양한 작업에서 성공을 거두었습니다. 모션 합성을 위해 위상 함수 신경망(PFNN), 흐름 정규화 등의 다른 방법도 제안되었습니다. 심층 신경망은 모션 리타겟팅, 모션 스타일 전송, 키 프레임 기반 모션 생성 등과 같은 작업에서도 탁월한 성능을 발휘했습니다.

2.3 장기 모션 합성
장기 모션 합성을 위한 대부분의 딥러닝 모델은 자동 회귀 생성 및 애니메이션 프레임 간의 시간 종속성 캡처가 자연스럽게 가능한 RNN을 기반으로 합니다. 예측 품질을 개선하고 장기 생성 시 발생하는 오류 누적을 해결하기 위해 컨볼루션 LSTM, 네트워크 출력과 실측 데이터를 번갈아 입력하는 방식(acRNN)과 같은 기법이 제안되었습니다. 그러나 이러한 모델은 시간이 지남에 따라 메모리 구성 요소가 침식되기 때문에 매우 긴 동작을 생성하는 데 여전히 어려움을 겪고 있습니다. 이러한 모델과 달리 제안된 프레임워크는 확산 시간 축과 일치하는 컨텍스트 창 내의 프레임을 사용하여 작은 단위로 동작을 생성하므로 확산 프로세스의 성공적인 메커니즘과 일치합니다.

![. TEDi 훈련. 우리는 우리의 확산 기반 모델을 훈련시켜서 깨끗한 시퀀스에 적용되는 시간에 따라 변하는 노이즈를 제거합니다. 각 반복에서, 우리는 데이터셋으로부터 𝐾 프레임의 동작 시퀀스 [𝑓1, 𝑓2, . . . , 𝑓𝐾]를 가져오고, 그것에 노이즈 수준 일정 [𝛽𝑡1, 𝛽𝑡2, . . . , 𝛽𝑡𝐾 ]에 따라 노이즈를 적용하고, 우리의 네트워크를 (1)에 설명된대로 깨끗한 동작 시퀀스를 예측하도록 훈련합니다.](TEDi%20Temporally-Entangled%20Diffusion%20for%20Long-Term%20%2019f29fc8bd8e482a9197e1122961e3f4/Untitled%201.png)

. TEDi 훈련. 우리는 우리의 확산 기반 모델을 훈련시켜서 깨끗한 시퀀스에 적용되는 시간에 따라 변하는 노이즈를 제거합니다. 각 반복에서, 우리는 데이터셋으로부터 𝐾 프레임의 동작 시퀀스 [𝑓1, 𝑓2, . . . , 𝑓𝐾]를 가져오고, 그것에 노이즈 수준 일정 [𝛽𝑡1, 𝛽𝑡2, . . . , 𝛽𝑡𝐾 ]에 따라 노이즈를 적용하고, 우리의 네트워크를 (1)에 설명된대로 깨끗한 동작 시퀀스를 예측하도록 훈련합니다.

### 3 METHOD

이 논문에서는 확산 모델을 사용하여 긴 모션 시퀀스를 생성하는 새로운 접근 방식을 소개합니다. 이 기법은 확산 프로세스 중에 시간적으로 다양한 노이즈 레벨을 주입할 수 있는 표준 DDPM 프레임워크의 확장입니다. 이 혁신을 통해 모션 시퀀스의 시간 축과 확산 프로세스의 시간 축 사이에 직접적인 관계를 맺을 수 있습니다.

이 방법에서 모션 시퀀스는 일련의 포즈로 표현되며, 각 포즈는 루트 관절 변위, 관절 회전 및 발 접촉 레이블로 구성됩니다. 이 전체 표현은 M으로 표시됩니다.

저자는 확산 프로세스를 사용하여 간단한 샘플링 메커니즘을 생성하는 확산 노이즈 제거 확률론적 모델(DDPM)이라는 일종의 생성 모델을 사용합니다. 훈련 중에 모델은 데이터 세트의 깨끗한 모션 시퀀스로 시작하여 노이즈가 점진적으로 추가되어 노이즈가 있는 모션 시퀀스를 형성합니다. 결국 최종 노이즈 벡터는 거의 등방성 가우스 분포를 따르게 됩니다.

연구진은 확산 과정에서 시간에 따라 다양한 노이즈 레벨을 주입하는 새로운 접근 방식을 도입했습니다. 연구진은 무작위 스케줄과 단조로운 스케줄이라는 두 가지 노이즈 주입 방식을 제안하는데, 후자는 노이즈 레벨이 꾸준히 증가하는 방식입니다. 이 모델은 프레임에 걸쳐 다양한 노이즈 레벨을 가진 모션 시퀀스의 노이즈를 완전히 제거하는 방법을 학습하여 확산 프로세스의 시간 축과 모션의 시간 축 사이의 명시적인 상관관계를 파악할 수 있습니다.

![TEDi 재귀 생성. TEDi는 임의의 길이의 동작 시퀀스를 생성할 수 있습니다. 우선, 우리는 우리의 동작 버퍼를 점점 더 높은 수준의 노이즈가 적용된 동작 프레임의 집합으로 초기화합니다. 그리고 나서 (단계 1) 우리는 전체 동작 버퍼의 노이즈를 제거하고, (단계 2) 동작 버퍼의 시작 부분에 새로운 깨끗한 프레임을 팝하고, 그리고 나서 (단계 3) 동작 버퍼의 끝 부분에 노이즈를 푸시합니다. 이 과정은 재귀적으로 반복됩니다.](TEDi%20Temporally-Entangled%20Diffusion%20for%20Long-Term%20%2019f29fc8bd8e482a9197e1122961e3f4/Untitled%202.png)

TEDi 재귀 생성. TEDi는 임의의 길이의 동작 시퀀스를 생성할 수 있습니다. 우선, 우리는 우리의 동작 버퍼를 점점 더 높은 수준의 노이즈가 적용된 동작 프레임의 집합으로 초기화합니다. 그리고 나서 (단계 1) 우리는 전체 동작 버퍼의 노이즈를 제거하고, (단계 2) 동작 버퍼의 시작 부분에 새로운 깨끗한 프레임을 팝하고, 그리고 나서 (단계 3) 동작 버퍼의 끝 부분에 노이즈를 푸시합니다. 이 과정은 재귀적으로 반복됩니다.

모델 훈련에는 관절 회전의 오류를 설명하는 위치 손실과 발 관절의 오류에 불이익을 주는 발 접촉 손실 등 프로세스를 규칙화하는 데 도움이 되는 다양한 손실 함수가 포함됩니다.

추론하는 동안 모델은 노이즈 수준이 증가함에 따라 프레임 버퍼를 유지하는 타자기와 유사한 시스템을 사용합니다. 각 반복에서 모델은 모든 프레임을 처리하고 점진적으로 노이즈가 제거된 시퀀스를 생성합니다. 이제 완전히 깨끗한 시퀀스의 첫 번째 프레임이 버퍼에서 제거되고 노이즈가 있는 새로운 프레임이 추가됩니다. 이 프로세스를 통해 모션 시퀀스를 연속적으로 생성할 수 있습니다.

### 4 EXPERIMENTS

이 연구에서는 TEDi(모델의 실제 이름의 약자로 추정)라는 새로운 방법을 여러 장기 생성 작업에 사용하여 안내 생성 및 향후 모션 계획 기능과 같은 고유한 애플리케이션을 선보입니다. 저자들은 모델 구현에 대한 세부 사항, 사용된 데이터 세트, 장기 모션 생성 결과 등 실험 과정에 대한 철저한 리뷰를 제공합니다.

TEDi 모델은 NVIDIA A40 GPU에서 PyTorch를 사용하여 훈련되었으며, Adam이 옵티마이저로 참여했습니다. 훈련 데이터는 CMU 모션 데이터세트에서 가져와 120fps에서 30fps로 다운샘플링했습니다. 훈련 과정에는 약 50만 번의 반복이 포함되었으며 완료하는 데 약 3일이 걸렸습니다.

![장기 생성. 우리의 방법은 임의의 길이의 동작 시퀀스를 합성합니다. 위의 그림에서, 우리는 모션의 모든 100 프레임 (≈3 초)을 시각화함으로써 33초의 동작을 요약합니다. 우리의 모델은 전체 동작 시퀀스 동안 타당한 동작을 생성할 수 있습니다.](TEDi%20Temporally-Entangled%20Diffusion%20for%20Long-Term%20%2019f29fc8bd8e482a9197e1122961e3f4/Untitled%203.png)

장기 생성. 우리의 방법은 임의의 길이의 동작 시퀀스를 합성합니다. 위의 그림에서, 우리는 모션의 모든 100 프레임 (≈3 초)을 시각화함으로써 33초의 동작을 요약합니다. 우리의 모델은 전체 동작 시퀀스 동안 타당한 동작을 생성할 수 있습니다.

장기 생성 측면에서 TEDi 프레임워크는 깨끗한 프라이머 모션에 기반한 장기 모션을 생성할 수 있는 것으로 입증되었습니다. 반복 추론 전략은 임의로 긴 새 프레임 시퀀스를 생성할 수 있으며, 핵심 속성은 노이즈 프레임을 통해 장기 생성을 유지하고 모션 전체에서 프레임별 일관성을 보장하는 것입니다.

또한 연구진은 움직이는 캐릭터에 미리 정의된 모션 세트를 사용하는 가이드 생성도 시연했습니다. 이러한 모션은 노이즈 버전의 모션 가이드를 사용하여 모션 버퍼를 직접 수정함으로써 영향을 받아 현재 프레임 세트를 효과적으로 대체했습니다.

![다양한 동작. 우리의 방법은 다양한 종류의 장기 동작 시퀀스를 생성할 수 있습니다. 왼쪽에서 오른쪽으로: 복싱, 셔플링, 그리고 손 제스처.](TEDi%20Temporally-Entangled%20Diffusion%20for%20Long-Term%20%2019f29fc8bd8e482a9197e1122961e3f4/Untitled%204.png)

다양한 동작. 우리의 방법은 다양한 종류의 장기 동작 시퀀스를 생성할 수 있습니다. 왼쪽에서 오른쪽으로: 복싱, 셔플링, 그리고 손 제스처.

![동작 변형. 확산 모델의 확률적 특성 때문에, 우리의 방법은 동일한 동작 기본 입력을 사용하여 변형을 생성할 수 있습니다. 우리는 단일 기본 입력에서 생성된 네 가지 동작을 보여줍니다. 왼쪽에서 오른쪽으로, 우리는 시간이 지남에 따라 동작이 상당히 다르게 시작하는 것을 볼 수 있습니다.](TEDi%20Temporally-Entangled%20Diffusion%20for%20Long-Term%20%2019f29fc8bd8e482a9197e1122961e3f4/Untitled%205.png)

동작 변형. 확산 모델의 확률적 특성 때문에, 우리의 방법은 동일한 동작 기본 입력을 사용하여 변형을 생성할 수 있습니다. 우리는 단일 기본 입력에서 생성된 네 가지 동작을 보여줍니다. 왼쪽에서 오른쪽으로, 우리는 시간이 지남에 따라 동작이 상당히 다르게 시작하는 것을 볼 수 있습니다.

![안내된 생성. 주어진 동작 가이드 Q𝑖 (노란색으로 표시) 집합이 있으면, 우리는 원하는 시점에 순차적으로 그것들을 수행하면서 타당한 동작을 생성하는 프레임을 상호작용적으로 생성할 수 있습니다. 왼쪽 상단에서 오른쪽 하단까지, 우리의 방법은 원하는 동작 가이드와 상호작용적으로 합성된 동작을 포함하는 전체 동작 시퀀스를 생성합니다. 상호작용적으로 생성된 동작들은 다가오는 동작 가이드를 위해 "준비하고 계획"합니다. 보충 영상을 참조하세요.](TEDi%20Temporally-Entangled%20Diffusion%20for%20Long-Term%20%2019f29fc8bd8e482a9197e1122961e3f4/Untitled%206.png)

안내된 생성. 주어진 동작 가이드 Q𝑖 (노란색으로 표시) 집합이 있으면, 우리는 원하는 시점에 순차적으로 그것들을 수행하면서 타당한 동작을 생성하는 프레임을 상호작용적으로 생성할 수 있습니다. 왼쪽 상단에서 오른쪽 하단까지, 우리의 방법은 원하는 동작 가이드와 상호작용적으로 합성된 동작을 포함하는 전체 동작 시퀀스를 생성합니다. 상호작용적으로 생성된 동작들은 다가오는 동작 가이드를 위해 "준비하고 계획"합니다. 보충 영상을 참조하세요.

궤적 제어 영역에서는 추가 교육 없이 TEDi 프레임워크가 사용되었습니다. 연구진은 모션 버퍼를 조작하여 궤적 정보를 원하는 모션을 지시하는 프레임으로 대체했습니다.

![경로 제어. 안내된 생성과 유사하게, 주어진 경로 정보 P (노란색으로 표시)가 주어지면, 우리의 방법은 주어진 경로를 따르는 자연스러운 동작을 생성할 수 있습니다.](TEDi%20Temporally-Entangled%20Diffusion%20for%20Long-Term%20%2019f29fc8bd8e482a9197e1122961e3f4/Untitled%207.png)

경로 제어. 안내된 생성과 유사하게, 주어진 경로 정보 P (노란색으로 표시)가 주어지면, 우리의 방법은 주어진 경로를 따르는 자연스러운 동작을 생성할 수 있습니다.

또한 저자들은 TEDi를 ACRNN[Zhou 외. 2018] 및 인간 모션 확산 모델(MDM)[Tevet 외. 2022]을 포함한 다른 기준선과 비교했습니다. TEDi 방법은 붕괴에 강한 긴 시퀀스를 생성하는 데 있어 ACRNN보다 우수한 성능을 보였으며, MDM은 페인팅 내 경계를 따라 스티칭 아티팩트를 생성하는 것으로 나타났습니다.

마지막으로 생성된 모션의 인지된 다양성과 품질을 평가하기 위해 지각 연구를 수행했습니다. TEDi 방식은 MDM과 비교했을 때 동등하거나 더 나은 품질의 모션을 생성하는 동시에 다양성 측면에서 월등히 뛰어난 성능을 발휘하는 것으로 나타났습니다. 또한 절제 연구에서는 다양하고 안정적인 장거리 모션을 생성하는 데 있어 시간적으로 변화하는 노이즈의 중요성을 강조하면서 TEDi에서 사용하는 훈련 체계의 이점을 입증했습니다.

### 5 CONCLUSION

이 논문에서 저자들은 모션 합성을 위해 확산 모델을 새롭게 응용한 TEDi를 소개합니다. 이 방법은 시간축과 확산축을 얽혀서 U-Net 아키텍처를 사용하여 임의의 긴 모션 시퀀스를 합성할 수 있습니다.

TEDi의 특징은 고정 모션 버퍼입니다. 이 프레임워크는 확산 시간을 앞당기지 않고도 깨끗한 프레임(확산 시간 축을 따라 진행)을 생성합니다. 확산 축을 따라 모션을 생성하는 기능 덕분에 새 프레임을 강력하고 지속적으로 생성할 수 있습니다.

저자는 자동 회귀 방식으로 확산을 적용하는 이 접근 방식이 오디오, 비디오, 이미지의 패치별 순서와 같이 순차 순서를 정의할 수 있는 모달리티를 포함한 다른 유형의 순차 데이터에도 영향을 미칠 수 있다고 제안합니다.

하지만 TEDi 프레임워크에는 몇 가지 한계가 있습니다. 현재 순수한 노이즈로부터 깨끗한 프레임을 계산하려면 노이즈 제거 확산 과정을 거쳐야 합니다. 이 문제를 해결하기 위해 저자들은 DDIM의 아이디어를 활용하여 노이즈 제거 프로세스를 건너뛰어 지연 시간을 단축할 수 있는 방법을 모색할 계획입니다[송 외. 2020].

저자들은 또한 장기적인 텍스트 조건부 모션 생성에서 TEDi의 잠재적인 응용 분야를 탐구하고, 장기적인 생성 작업을 위해 높은 수준의 제어와 낮은 수준의 사용자 안내를 결합하는 데에도 관심이 있습니다. 이는 모션 합성 분야에서 향후 연구 및 개발의 흥미로운 길을 제시합니다.

- 모델의 입력과 출력
    
    모델인 TEDi (Temporal Entangling Diffusion Inference)의 주된 작업은 동작 생성이며, 이는 주로 동작 시퀀스를 생성하는 데 사용됩니다.
    
    입력: TEDi 모델에 대한 입력은 주로 '프라이머 모션'입니다. 이는 초기 동작 버퍼를 채우는 데 사용되는 깨끗한 동작 시퀀스를 의미합니다. 또한, 이 모델은 특정 동작을 생성하도록 가이드하기 위해 "동작 가이드"를 사용할 수도 있습니다. 이러한 가이드는 미래의 특정 시점에서 발생할 사전 정의된 동작 세트를 나타냅니다.
    
    출력: TEDi 모델의 출력은 임의의 길이의 새로운 동작 시퀀스입니다. 이 시퀀스는 모델이 입력으로 받은 프라이머 동작 시퀀스와 가이드를 기반으로 생성됩니다. 이 모델은 '모션 버퍼' 개념을 사용하여 시간이 지나면서 동작을 더 길게 생성할 수 있습니다.
    
    추가적으로, 모델은 '경로 제어'라는 능력을 가지며, 이는 출력 동작의 특정 특성을 조작하거나 제어하는 데 사용됩니다. 예를 들어, 경로 정보를 사용하여 생성된 동작의 루트 이동을 조정할 수 있습니다.
    
- 의의
    
    이 논문에서 제안하는 Temporal Entangling Diffusion Inference (TEDi) 모델은 이전 방식들과 몇 가지 핵심적인 차이점을 가지고 있습니다.
    
    1. **연속적인 긴 시퀀스 생성**: TEDi는 "정지 모션 버퍼" 개념을 도입하여 긴 시간동안 지속되는 동작 시퀀스를 생성할 수 있습니다. 이 기능은 확산 시간 축을 통해 지속적으로 새로운 프레임을 생성하게 합니다. 이런 방식은 일부 이전 방식들에서는 제한적이거나 불가능했던 것입니다.
    2. **가이드 생성**: TEDi는 미래의 특정 지점과 시간에서 수행될 예정인 미리 정의된 동작들을 수행하도록 캐릭터를 안내하는 기능을 제공합니다. 이를 통해 생성된 동작의 제어를 더욱 세밀하게 수행할 수 있습니다.
    3. **경로 제어**: TEDi는 추가적인 훈련 없이 추론 중에 경로를 제어하는 능력을 제공합니다. 이것은 모션 버퍼를 수정하는 'inpainting' 전략을 이용하여 구현되었습니다.
    4. **성능 및 다양성**: 비교 및 탈락 실험 결과 TEDi는 이전 방식들과 비교했을 때 우수한 성능을 보였습니다. 이전의 모델들(Auto-regressive Conditional Recurrent Networks, ACRNN과 Motion Diffusion Model, MDM)에 비해 TEDi는 더 긴 시간동안 안정적으로 동작을 생성하고, 동작이 붕괴되는 것을 피할 수 있으며, 동시에 다양한 동작 시퀀스를 생성하는 능력도 가지고 있습니다.
    
    이런 차별점들은 TEDi가 이전 방식들보다 긴 시퀀스의 동작을 생성하고, 동작의 제어를 개선하며, 동작의 다양성을 증가시킬 수 있도록 돕습니다.
    
- 확산모델
    
    확산 기법은 원래 이미지 생성 작업에 사용되었습니다. 이 방법은 주어진 데이터의 복잡한 분포를 단순한 노이즈 분포에서 시작하여 점차 원래 데이터의 분포로 변환하는 접근 방식입니다. 이 과정은 데이터 생성의 '역'과정으로 볼 수 있습니다. 각 단계에서, 모델은 노이즈를 제거하거나 추가하여 원래 데이터로 조금씩 다가가거나 또는 그것으로부터 멀어지게 됩니다. 이 기법은 특히 이미지 데이터에 대해 매우 효과적으로 작동하는 것으로 입증되었습니다.
    
    이 논문에서는 이러한 확산 기법을 모션 생성에 적용하고자 합니다. 이 경우, 모델의 목표는 일련의 동작 프레임을 생성하는 것입니다. 동작 데이터의 경우, 각 프레임은 시간에 따라 진행되므로, 이미지 생성에서 확산 시간 축에 해당하는 것이 모션 생성에서는 시간적 연속성을 가진 동작의 순서에 해당합니다.
    
    따라서, 원래 이미지 생성에서 확산 시간 축을 따라 움직이는 것을 시간적으로 연결된 동작의 생성으로 확장합니다. 이것은 모션 버퍼라는 개념을 통해 가능하게 되며, 이 모션 버퍼는 초기에 제공된 "primer" 동작으로 채워지고, 그 이후에는 모델이 생성한 새로운 동작으로 계속해서 갱신됩니다.
    
    이런 식으로, 확산 기법은 모델이 시간에 따라 펼쳐지는 동작 시퀀스를 생성할 수 있도록 해주고, 이미지 생성에서와 같은 방식으로 프레임 간의 일관성을 유지하며 새로운 동작을 탐색하는 데 사용됩니다.