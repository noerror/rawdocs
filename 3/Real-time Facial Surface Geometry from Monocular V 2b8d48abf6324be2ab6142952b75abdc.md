# Real-time Facial Surface Geometry from Monocular Video on Mobile GPUs

[https://arxiv.org/abs/1907.06724](https://arxiv.org/abs/1907.06724)

- Jul 2019

### 1. Introduction

이 논문에서는 컴퓨터 비전의 핵심 작업인 얼굴 형상 예측 문제에 대해 설명하며, 일반적으로 얼굴의 특정 주요 지점을 찾아서 수행합니다. 이 과정을 얼굴 정렬 또는 얼굴 등록이라고 합니다. 저자는 주성분 분석을 통해 바젤 얼굴 모델과 같은 3D 변형 가능 모델(3DMM)의 포즈, 스케일, 매개변수를 추정하는 대안을 제시합니다.

![Untitled](Real-time%20Facial%20Surface%20Geometry%20from%20Monocular%20V%202b8d48abf6324be2ab6142952b75abdc/Untitled.png)

그러나 바젤 얼굴 모델과 같은 3DMM은 더 많은 점으로 구성되지만, 모델에 캡처된 얼굴에 의해 표현할 수 있는 얼굴 유형의 다양성이 제한되기 때문에 한계가 있습니다. 예를 들어, 한쪽 눈을 감은 얼굴을 정확하게 묘사하는 데 어려움을 겪습니다.

저자는 각 정점을 독립적인 랜드마크로 취급하는 신경망을 사용하여 3D 메시 정점의 위치를 추정하는 방법을 제안합니다. 3D 메쉬는 고정된 쿼드로 배열된 468개의 점으로 구성됩니다. 이러한 포인트는 표현적인 증강 현실 효과, 가상 액세서리 시착, 메이크업 등 원하는 애플리케이션에 따라 선택되었습니다. 저자는 가변성이 높고 사람이 지각하는 중요도가 높은 영역일수록 포인트 밀도가 높도록 했습니다.

이 모델은 단일 RGB 카메라 프레임(또는 프레임 스트림)을 입력으로 사용하며 깊이 센서 정보가 필요하지 않습니다. 저자들은 다양한 디바이스 기능을 수용하기 위해 다양한 버전의 모델을 만들었는데, 강력한 GPU를 지원하는 디바이스를 위한 '전체' 모델과 CPU 처리에 의존하는 디바이스를 위한 '가장 가벼운' 모델이 있습니다.

### 2. Image processing pipeline

이 연구에서 제안한 이미지 처리 파이프라인은 다음 단계로 구성됩니다:

전체 카메라 프레임은 얼굴 경계 직사각형과 눈의 중심, 귓바퀴, 코끝과 같은 여러 랜드마크를 제공하는 경량 얼굴 감지기에 의해 처리됩니다. 이러한 랜드마크는 얼굴 직사각형을 회전하여 눈의 중심을 연결하는 선을 직사각형의 가로축과 정렬하는 데 도움이 됩니다.

![예측된 메시 토폴로지 (a) 그리고 3단계 Catmull-Clark 세분화 (b)](Real-time%20Facial%20Surface%20Geometry%20from%20Monocular%20V%202b8d48abf6324be2ab6142952b75abdc/Untitled%201.png)

예측된 메시 토폴로지 (a) 그리고 3단계 Catmull-Clark 세분화 (b)

첫 번째 단계에서 얻은 직사각형은 원본 이미지에서 잘라낸 후 메시 예측 신경망에 입력할 수 있도록 크기를 조정합니다. 이 크기는 전체 모델의 경우 256x256픽셀부터 가장 작은 모델의 경우 128x128까지 다양합니다. 이 모델은 3D 랜드마크 좌표 벡터를 생성한 다음 원본 이미지 좌표계로 다시 매핑합니다. 별도의 스칼라 네트워크 출력(얼굴 플래그)은 잘 정렬된 얼굴이 크롭에 존재할 확률을 생성합니다.

![초기 부트스트랩 과정에서 사용된 2D 의미적 윤곽선](Real-time%20Facial%20Surface%20Geometry%20from%20Monocular%20V%202b8d48abf6324be2ab6142952b75abdc/Untitled%202.png)

초기 부트스트랩 과정에서 사용된 2D 의미적 윤곽선

저자는 이미지 픽셀 좌표에 의해 주어진 대로 정점의 x 및 y 좌표가 2D 평면의 점 위치에 대응한다는 정책을 따릅니다. z 좌표는 메시의 질량 중심을 통과하는 기준 평면에 대한 깊이를 나타내며, x 좌표와 z 좌표의 스팬 사이에 고정 종횡비를 유지하도록 스케일이 조정됩니다.

파이프라인을 얼굴 추적에 비디오 입력과 함께 사용하는 경우, 이전 프레임 예측에서 이미 좋은 얼굴 크롭을 사용할 수 있으므로 얼굴 감지기가 중복됩니다. 이 경우 감지기는 첫 번째 프레임과 드물게 재획득하는 경우(얼굴 플래그가 예측한 확률이 특정 임계값 이하로 떨어질 때)에만 사용됩니다.

저자들은 얼굴이 두 번째 네트워크에 합리적으로 중앙에 배치되고 정렬된 입력을 제공하는 파이프라인이 상당한 회전과 이동이 있는 경우를 처리하는 데 사용될 수 있는 모델 표현 용량을 일부 절약한다고 주장합니다. 따라서 관련 증강의 양을 줄이면서 예측 품질을 개선할 수 있습니다.

### 3. Dataset, annotation, and training

이 연구에서 모델 학습은 다양한 센서를 사용하여 다양한 조명 조건에서 캡처한 약 30,000장의 모바일 카메라 사진으로 구성된 전 세계 데이터 세트를 활용합니다. 훈련 과정에서 이 데이터 세트는 표준 자르기 및 이미지 처리 기법과 카메라 센서 노이즈 모델링, 이미지 강도 히스토그램에 무작위 비선형 변환을 적용하여 다양한 조명 조건을 시뮬레이션하는 등 몇 가지 특수한 방법을 사용하여 보강됩니다.

468개의 3D 메시 포인트에 대한 지상 실측 데이터를 확보하는 것은 어려운 작업입니다. 이 프로세스를 간소화하기 위해 저자는 각 포인트에 수동으로 주석을 다는 대신 반복적인 절차를 사용합니다. 이 프로세스에는 다음 단계가 포함됩니다:

실제 사진의 얼굴 직사각형 위에 3D 변형 가능한 모델을 합성 렌더링하고 실제 '자연 상태' 데이터 세트에 주석이 달린 메시 정점의 작은 하위 집합에 해당하는 2D 랜드마크를 사용하여 초기 모델을 훈련합니다. 이 초기 모델을 학습한 후에는 데이터 세트의 이미지 중 최대 30%가 개선에 적합한 예측을 갖게 됩니다.

가장 최신 모델을 이미지에 적용하여 부트스트랩된 x 및 y 좌표를 반복적으로 개선하고 개선에 적합한 좌표를 필터링합니다. 반경을 조정할 수 있는 '브러시' 도구는 빠른 주석 세분화를 위해 사용되며, 다양한 포인트를 한 번에 이동할 수 있습니다. 마우스 커서 아래의 피벗 꼭지점으로부터의 거리에 따라 이동량이 기하급수적으로 감소합니다. 이 방법을 사용하면 어노테이터가 메쉬 표면의 부드러움을 유지하면서 로컬 세분화를 수행하기 전에 넓은 영역의 변위를 조정할 수 있습니다.

z 좌표는 변경되지 않고 그대로 유지되며, 앞서 언급한 합성 3D 렌더링이 이를 감독하는 유일한 소스입니다. 깊이 예측이 매우 정확하지는 않지만, 결과 메시가 얼굴에 사실적인 3D 텍스처 렌더링을 구동하거나 가상 액세서리 시착 경험의 일부로 3D 오브젝트를 정렬하는 등의 애플리케이션에 시각적으로 충분히 그럴듯하게 구현됩니다.

### 4. Model architecture

메시 예측 모델은 맞춤형이지만 상당히 간단한 잔류 신경망 아키텍처를 사용합니다. 이 모델 아키텍처는 초기 레이어에서 보다 공격적인 서브샘플링을 포함하며 네트워크의 얕은 부분에 대부분의 계산 리소스를 할당합니다.

뉴런의 수용 필드는 비교적 일찍 입력 이미지의 넓은 영역을 커버하기 시작합니다. 이러한 수용 필드가 이미지 경계에 도달하면 컨볼루션 패딩으로 인해 입력 이미지에서 상대적인 위치를 모델에서 암시적으로 사용할 수 있게 됩니다. 이를 통해 더 깊은 층의 뉴런이 입이나 눈과 같은 다양한 얼굴 특징을 구별할 수 있습니다.

이 모델은 약간 가려지거나 이미지 경계를 넘나드는 얼굴도 완성할 수 있습니다. 이는 모델이 고차원 및 저차원 메시 표현을 구성한 다음 네트워크의 최종 레이어에서만 좌표로 변환된다는 것을 의미합니다.

### 5. Filtering for temporal consistency in video

이 모델은 단일 프레임 수준에서 작동하므로 프레임 간에 전달되는 유일한 정보는 회전된 얼굴 경계 사각형과 얼굴 감지기로 재평가해야 하는지 여부뿐입니다. 후속 비디오 프레임에서 얼굴의 픽셀 수준 이미지 표현이 일관되지 않기 때문에(뷰의 작은 아핀 변환, 머리 자세 변화, 조명 변화, 카메라 센서 노이즈 등으로 인해) 개별 랜드마크의 궤적에 눈에 띄는 변동이나 시간적 지터가 발생합니다. 그러나 전체 메시 표면은 이 현상의 영향을 덜 받습니다.

이 문제를 해결하기 위해 저자는 예측된 각 랜드마크 좌표에 독립적으로 적용되는 1차원 시간 필터를 사용할 것을 제안합니다. 이 모델의 주요 적용 분야가 시각적으로 매력적인 렌더링이라는 점을 고려할 때, 저자는 인간과 컴퓨터의 상호 작용 방법, 특히 1유로 필터에서 영감을 얻었습니다. 1 유로 필터는 노이즈 감소와 위상 지연 제거의 균형을 맞출 때 인간은 파라미터가 크게 변하지 않을 때는 노이즈 감소(즉, 안정화)를, 변화율이 높을 때는 위상 지연 제거(즉, 지연 방지)를 선호하는 경향이 있다는 전제를 기반으로 합니다.

![응용 예시: 얼굴 텍스처 페인팅과 AR 객체 렌더링 (안경)](Real-time%20Facial%20Surface%20Geometry%20from%20Monocular%20V%202b8d48abf6324be2ab6142952b75abdc/Untitled%203.png)

응용 예시: 얼굴 텍스처 페인팅과 AR 객체 렌더링 (안경)

이 필터는 속도 추정을 위해 타임스탬프가 찍힌 몇 개의 샘플을 고정된 롤링 윈도우로 유지하며, 이 샘플은 비디오 스트림의 얼굴 크기 변화를 고려하기 위해 얼굴 크기에 따라 조정됩니다. 이 필터를 사용하면 눈에 띄는 지터 없이 동영상에서 시각적으로 만족스러운 예측 시퀀스를 얻을 수 있습니다.

### 6. Results

얼굴 지오메트리 예측 모델의 성능은 모델의 예측과 지상 실측 버텍스 위치 사이의 평균 절대 거리(MAD)를 사용하여 측정되며, 눈 중심 사이의 거리인 안구 간 거리(IOD)로 정규화됩니다. 이 정규화는 얼굴의 축척을 고려하지 않습니다.

메트릭의 기준선을 설정하기 위해 훈련된 11명의 어노테이터에게 58개의 이미지 세트에 주석을 달도록 요청했습니다. 동일한 이미지에 대한 주석 간의 IOD 정규화된 평균 절대 거리를 계산한 결과, 추정된 IOD MAD 오류는 2.56%였습니다.

이 모델은 다양한 1.7K 이미지 세트에서 평가되었습니다. 속도 추정치는 TensorFlow Lite GPU 프레임워크를 기반으로 했습니다. 세 가지 모델이 평가되었습니다:

Full 모델(256x256 입력)은 3.96%의 IOD MAD를 보였으며, iPhone XS에서 2.5ms, Pixel 3에서 7.4ms가 소요되었습니다.
라이트 모델(128x128 입력)의 IOD MAD는 5.15%였으며 iPhone XS에서 1ms, Pixel 3에서 3.4ms가 걸렸습니다.
가장 가벼운 모델(역시 128x128 입력)의 IOD MAD는 5.29%였으며 iPhone XS에서는 0.7ms, Pixel 3에서는 2.6ms가 걸렸습니다.
이러한 기술은 현재 휴대폰의 주요 증강 현실(AR) 자체 표현 애플리케이션과 AR 개발자 API를 주도하고 있으며, 다양한 렌더링 효과를 구현할 수 있게 해줍니다.