# Meta 3D AssetGen: Text-to-Mesh Generation with High-Quality Geometry, Texture, and PBR Materials

[https://ai.meta.com/research/publications/meta-3d-assetgen-text-to-mesh-generation-with-high-quality-geometry-texture-and-pbr-materials/](https://ai.meta.com/research/publications/meta-3d-assetgen-text-to-mesh-generation-with-high-quality-geometry-texture-and-pbr-materials/)

- 2024

## 1 Introduction

![우리는 물리 기반 렌더링 재질을 가진 3D 메쉬를 텍스트나 이미지 조건에 맞춰 생성하는 새로운 기술인 Meta 3D AssetGen을 소개합니다(상단). Meta 3D AssetGen은 세밀한 기하학과 고충실도의 텍스처를 가진 메쉬를 생성하며, 재질을 알베도, 금속성, 거칠기로 분해하여 새로운 환경에서도 객체를 현실적으로 재조명할 수 있게 합니다(하단 왼쪽 및 오른쪽).](Meta%203D%20AssetGen%20Text-to-Mesh%20Generation%20with%20High%20192519aacd6c473789712df4604b82fb/Untitled.png)

우리는 물리 기반 렌더링 재질을 가진 3D 메쉬를 텍스트나 이미지 조건에 맞춰 생성하는 새로운 기술인 Meta 3D AssetGen을 소개합니다(상단). Meta 3D AssetGen은 세밀한 기하학과 고충실도의 텍스처를 가진 메쉬를 생성하며, 재질을 알베도, 금속성, 거칠기로 분해하여 새로운 환경에서도 객체를 현실적으로 재조명할 수 있게 합니다(하단 왼쪽 및 오른쪽).

3D 객체를 텍스트 프롬프트나 이미지를 통해 생성하는 기술은 3D 그래픽스, 애니메이션, 게임 및 AR/VR 분야에서 큰 잠재력을 가지고 있습니다. 하지만 이미지와 비디오 생성에서의 놀라운 발전에도 불구하고, 3D 생성기의 품질은 여전히 전문가가 사용하기에 충분하지 않습니다. 일반적인 제한 사항으로는 느린 생성 속도와 생성된 3D 메쉬 및 텍스처에서 발생하는 결함이 있습니다. 많은 접근 방식이 외관을 알베도로 "굽는" 경향이 있어 3D 모델이 환경의 조명 변화에 어떻게 반응해야 하는지를 무시합니다. 이는 특히 반사 재질의 경우 새로운 환경에 배치될 때 시각적으로 매력적이지 않은 결과를 초래합니다.

이에 우리는 텍스트 조건 기반 3D 생성에서 중요한 발전을 이룬 Meta 3D AssetGen(AssetGen)을 소개합니다. AssetGen은 30초 이내에 자산을 생성하며, 이전 작업에 비해 생성된 3D 메쉬의 충실도와 품질, 특히 재질의 품질과 제어 측면에서 더 뛰어난 성능을 보입니다. AssetGen은 두 단계의 디자인을 사용합니다. 첫 번째 단계에서는 객체의 4개 표준 시점에서 이미지를 확률적으로 생성하고, 두 번째 단계에서는 이 시점을 바탕으로 객체의 3D 형상과 외관을 결정적으로 재구성합니다. 이 접근 방식은 속도와 견고성 면에서 기존의 기술들보다 뛰어나며, 단일 단계 3D 생성기보다 더 다양한 결과를 제공합니다.

AssetGen은 PBR(Physically-Based Rendering)을 사용하여 빛과 객체의 상호작용을 명확하게 모델링하며, 이는 3D 컴퓨터 그래픽스 응용 프로그램에 필수적입니다. 특히, 알베도, 금속성, 거칠기를 고려하여 환경 조명을 정확하게 반영하는 장면을 렌더링합니다. 또한, 메쉬를 출력 표현으로 사용하여 다양한 응용 프로그램에서의 활용과 PBR과의 호환성을 제공합니다.

우리의 첫 번째 기여는 PBR 정보를 생성하도록 두 단계를 확장한 것입니다. 이미지-3D 단계가 결정적이기 때문에 텍스트-이미지 단계에서 재질 할당의 모호성을 해결해야 합니다. 텍스트-이미지 모델을 세분화하여 필요한 PBR 채널을 직접 출력하도록 하는 것이 문제가 되었기 때문에, 대신 텍스트-이미지 모델이 음영과 알베도의 두 버전의 외관을 출력하도록 하여 이미지-3D 컴포넌트가 두 채널 간의 차이를 분석하여 PBR 재질을 정확하게 예측할 수 있도록 했습니다.

두 번째 혁신은 메쉬 생성 단계에 있습니다. 기존 작업은 3D 형상을 나타내기 위해 불투명도 필드를 출력하지만, 이는 메쉬 결함을 초래할 수 있습니다. 이를 해결하기 위해 AssetGen의 이미지-3D 단계인 MetaILRM은 불투명도 필드 대신 서명 거리 필드(SDF)를 직접 예측하여 더 높은 품질의 메쉬를 생성합니다. 또한, 이 표현 방식은 불투명도보다 쉽게 지도할 수 있습니다.

결론적으로, Meta 3D AssetGen은 텍스트 기반 3D 생성에서 중요한 진전을 이루었으며, PBR 재질을 지원하여 다양한 3D 그래픽 응용 프로그램에서 활용될 수 있는 고품질의 3D 자산을 신속하게 생성할 수 있습니다.

## 2 Related Work

텍스트를 기반으로 3D 객체를 생성하는 초기 접근 방식들은 텍스트-이미지 모델에 영감을 받아 캡션이 달린 3D 자산 데이터셋을 사용해 3D 확산 모델을 훈련했습니다. 그러나 3D 데이터의 제한된 크기와 다양성으로 인해 이 모델들은 개방형 어휘 프롬프트에 대한 일반화에 어려움을 겪었습니다. 최근 연구들은 수십억 개의 캡션이 달린 이미지를 기반으로 훈련된 텍스트-이미지 모델을 활용하여 이러한 문제를 해결하려 했습니다.

이러한 연구들 중 일부는 2D 확산 모델을 미세 조정하여 3D 표현을 출력하려 했으나, 2D와 3D 도메인 간의 큰 격차로 인해 품질에 한계가 있었습니다. 다른 접근 방식들은 크게 두 그룹으로 나뉩니다. 첫 번째 그룹은 DreamFusion이라는 획기적인 연구를 기반으로 하여 사전 훈련된 텍스트-이미지 모델의 신념과 일치시키기 위해 NeRF를 SDS 손실을 통해 최적화하여 3D 객체를 증류합니다. 이러한 방법들은 종종 다양한 3D 표현, SDS 개선, 단안 조건, 더 나은 기하학을 위해 추가 노멀이나 깊이를 예측하는 것을 포함합니다. 그러나 이러한 증류 방법들은 Janus 효과(객체 부분 복제)와 콘텐츠 드리프트 같은 문제에 취약하며, 이를 해결하기 위해 시각적 일관성을 확산 모델에 통합하는 것이 일반적인 해결책입니다. 또한, SDS 최적화는 느리고 자산당 몇 분에서 몇 시간이 소요되며, 이를 해결하기 위해 일부 연구는 SDS의 사전 계산을 시도했습니다.

두 번째 그룹은 텍스트-이미지 또는 -비디오 모델을 사용하여 객체의 여러 뷰를 생성한 후 NeRF 또는 3DGS를 사용하여 장면 최적화를 수행하는 빠른 두 단계 접근 방식을 포함합니다. 그러나 이러한 방법들은 일관성 있는 여러 뷰를 생성하는 데 어려움을 겪습니다. Instant3D는 4개의 뷰만을 생성하여 속도와 견고성을 개선했으며, LRM을 사용해 객체를 재구성합니다. 우리 AssetGen은 Instant3D 패러다임을 기반으로 하며, PBR 재질과 SDF 기반의 3D 형상을 출력하도록 LRM을 업그레이드했습니다.

이미지에서 3D로의 재구성 작업에서는 전통적인 다중 시점 스테레오(MVS) 방법이 장면의 밀집된 시점 세트에 접근할 수 있다고 가정합니다. 최근의 재구성 방법들은 NeRF를 사용하여 다중 시점 렌더링 손실을 최소화하여 3D 표현을 최적화합니다. 3D 표현은 명시적 표현(메쉬, 3D 포인트/가우시안)과 암묵적 표현(점유 필드, 방사 필드, 서명 거리 함수)으로 나뉩니다. 서명 거리 함수(SDF)는 점유 필드보다 표면 제약 조건 통합이 쉬워 장면 기하학을 개선할 수 있습니다. 우리 접근 방식은 SDF 공식을 채택하여 더 나은 기하학적 성능을 입증했습니다.

조밀한 다중 뷰가 없는 상태에서 3D 장면을 재구성하는 Sparse-view 재구성에서는 최적화 과정에서 2D 확산 모델을 활용하지만 이는 종종 느리고 견고하지 못합니다. 최근 연구들은 대규모 데이터셋을 사용하여 피드포워드 재구성기를 훈련하는 데 초점을 맞추고 있습니다. 특히, LRM은 트리플레인 표현을 사용하여 NeRF를 예측하는 대형 트랜스포머를 훈련합니다. 우리는 LRM을 기반으로 하되, 개선된 기하학을 위한 SDF 공식을 도입하고, 재조명을 위한 PBR 재질 예측, 그리고 더 나은 텍스처 디테일을 위한 텍스처 리파이너를 추가했습니다.

대부분의 3D 생성기들은 굽어진 조명을 포함한 3D 객체를 출력하지만 이는 환경 조명에 대한 모델의 반응을 무시하므로 제어된 조명을 사용하는 그래픽 파이프라인에 적합하지 않습니다. 물리 기반 렌더링(PBR)은 적절한 셰이더가 조명을 현실적으로 반영할 수 있도록 재질 속성을 정의합니다. 여러 연구들은 NeRF, SDF, 차별화 가능한 메쉬, 3DGS를 사용하여 PBR 재질을 추정하는 것을 고려했습니다. 생성 모델링에서는 텍스트-3D SDS 최적화를 PBR 모델과 결합하는 시도를 했습니다. 우리는 텍스트-3D 네트워크에서 PBR 모델링을 통합하여 텍스트 기반 3D 자산의 빠른 생성을 가능하게 했습니다.

## 3 Method

![텍스트 프롬프트가 주어지면, AssetGen은 두 단계로 PBR 재질을 가진 3D 메쉬를 생성합니다. 첫 번째 텍스트-이미지 단계(파란색)는 객체의 4개 시점을 셰이딩된 색상과 알베도 색상으로 나타낸 6채널 이미지를 예측합니다. 두 번째 이미지-3D 단계는 두 가지 단계로 구성됩니다. 첫 번째로, 3D 재구성기(MetaILRM라 명명됨)는 텍스처가 적용된 PBR 재질을 가진 메쉬로 변환되는 트리플레인 지원 SDF 필드를 출력합니다(주황색). 그 후, PBR 재질은 입력 뷰에서 누락된 세부 정보를 복원하는 텍스처 리파이너로 향상됩니다(녹색).](Meta%203D%20AssetGen%20Text-to-Mesh%20Generation%20with%20High%20192519aacd6c473789712df4604b82fb/Untitled%201.png)

텍스트 프롬프트가 주어지면, AssetGen은 두 단계로 PBR 재질을 가진 3D 메쉬를 생성합니다. 첫 번째 텍스트-이미지 단계(파란색)는 객체의 4개 시점을 셰이딩된 색상과 알베도 색상으로 나타낸 6채널 이미지를 예측합니다. 두 번째 이미지-3D 단계는 두 가지 단계로 구성됩니다. 첫 번째로, 3D 재구성기(MetaILRM라 명명됨)는 텍스처가 적용된 PBR 재질을 가진 메쉬로 변환되는 트리플레인 지원 SDF 필드를 출력합니다(주황색). 그 후, PBR 재질은 입력 뷰에서 누락된 세부 정보를 복원하는 텍스처 리파이너로 향상됩니다(녹색).

### 3.1 Text-to-image: Generating shaded and albedo images from text

텍스트-이미지 모듈의 목표는 생성된 3D 객체의 여러 시점을 생성하는 것입니다. 이를 위해 Emu와 유사한 아키텍처의 내부 텍스트-이미지 확산 모델을 사용하며, 수십억 개의 텍스트 주석이 달린 이미지로 사전 훈련되었습니다. 우리는 모델을 미세 조정하여 객체의 4개 표준 시점에서 이미지를 생성하도록 했습니다. 이 이미지는 객체의 셰이딩된 외형을 나타냅니다. PBR 매개변수를 텍스트-이미지 단계에서 직접 예측하려는 시도는 실패했으며, 대신 셰이딩된 외형과 알베도의 두 버전 이미지를 생성하도록 하여 모호성을 줄이고 PBR 매개변수 예측의 정확성을 높였습니다.

### 3.2 Image-to-3D: A PBR-based large reconstruction model

이미지-3D 단계에서는 새로운 PBR 인식 재구성 모델인 MetaILRM을 사용하여 N개의 포즈된 이미지로부터 객체를 재구성합니다. 우리는 4개의 고정된 시점에서 촬영된 6채널 이미지를 입력으로 사용하며, 출력으로는 객체의 3D 형상과 PBR 재질을 포함하는 서명 거리 필드(SDF)를 예측합니다. 중요한 학습 요소는 차별화 가능한 렌더링 연산자입니다. 이는 PBR 기반 반사 모델을 사용하여 객체의 외형을 예측합니다. 또한, 환경 조명을 고려하여 객체의 외형을 더욱 현실적으로 렌더링합니다. 우리는 훈련 중에 물리적으로 정확한 렌더링을 위해 지연 셰이딩을 사용하고, 손실 함수로는 MSE, LPIPS, SDF 손실 등을 사용하여 모델을 최적화합니다. 이 모델은 LightplaneLRM을 기반으로 하여 메모리와 계산 효율성을 높였으며, SDF 기반 렌더러와 SDF 손실을 추가하여 품질을 향상시켰습니다.

### 3.3 Mesh extraction and texture refiner

MetaILRM 모듈은 서명 거리 함수를 출력하여 객체 표면을 암묵적으로 정의합니다. 우리는 Marching Tetrahedra 알고리즘을 사용하여 이 표면을 추적하고 메쉬를 생성합니다. 그런 다음, xAtlas를 사용하여 UV 맵을 추출하고, 각 메쉬 포인트에 해당하는 5채널 PBR 텍스처 이미지를 생성합니다. 그러나 MetaILRM에서 추출된 텍스처는 해상도가 낮아 흐릿할 수 있습니다. 이를 해결하기 위해 텍스처 리파이너 모듈을 도입하여 원본 뷰에서 추출한 정보를 결합하여 텍스처 이미지를 더욱 선명하게 만듭니다. 이 모듈은 두 개의 U-Net을 사용하여 각 뷰의 정보를 병합하여 고해상도 텍스처 이미지를 생성합니다. 이 네트워크는 동일한 데이터셋에서 훈련되며, PBR 및 알베도 렌더링 손실을 사용하여 지도됩니다.

## 4 Experiments

우리의 훈련 데이터는 3D 아티스트들이 만든 다양한 주제의 140,000개의 메쉬로 구성되어 있습니다. 각 자산에 대해 무작위로 선택된 환경 맵으로 조명된 36개의 시점을 렌더링하고, 셰이딩된 이미지, 알베도, 금속성, 거칠기, 깊이 맵 및 전경 마스크를 각 시점에서 생성합니다. 텍스트-이미지 단계는 Emu와 유사한 내부 텍스트-이미지 모델을 기반으로 하며, 10,000개의 고품질 3D 샘플로 미세 조정되었습니다. 다른 단계는 전체 3D 데이터셋을 활용합니다.

평가는 PSNR과 LPIPS를 사용하여 시각적 품질을 측정하고, 기하학적 품질은 깊이 맵과 객체 실루엣의 L1 오차 및 IoU를 통해 측정합니다. 또한, 챔퍼 거리와 노멀 정확도를 20,000개의 샘플 포인트에서 계산합니다. 재질 분해는 알베도 이미지의 LPIPS와 PSNR, 금속성과 거칠기 채널의 PSNR로 평가합니다.

### 4.1 Sparse-view reconstruction

sparse-view 재구성 작업에서는 Google Scanned Objects(GSO)의 332개의 메쉬 서브셋을 사용하여 4개의 포즈된 이미지로부터 3D 메쉬를 예측합니다. 우리는 Instant3D-LRM, GRM, InstantMesh, 그리고 LightplaneLRM과 비교했습니다. 결과적으로 우리 방법은 모든 지표에서 기존 방법들보다 뛰어난 성능을 보였으며, 특히 기하학적 구조와 텍스처 품질에서 우수한 결과를 나타냈습니다.

우리는 또한 PBR 재질을 예측하는 sparse-view 재구성 작업을 내부 데이터셋에서 수행했으며, 기존 방법이 없기 때문에 실험적인 비교를 통해 우리의 접근 방식의 효용성을 입증했습니다. 추가적인 MLP 헤드를 사용한 재질 예측은 일부 개선을 제공했지만, 지연 셰이딩 손실과 텍스처 정제가 고품질 PBR 분해에 필수적임을 발견했습니다.

### 4.2 Text-to-3D generation

텍스트-3D 생성 작업에서는 GRM, InstantMesh, LightplaneLRM과 같은 기존의 빠른 생성 방법들과 비교했습니다. 우리 모델은 PBR 재질을 생성하는 반면, 다른 모델들은 조명을 베이킹합니다. 평가를 위해 우리는 우리의 출력에 평면 텍스처 셰이딩을 적용했습니다. 또한, Meshy v3와 LumaAI Genie 1.0과도 비교했으며, AssetGen의 메쉬가 시각적으로 더 매력적이고 재질 제어가 뛰어남을 확인했습니다.

![알베도 생성에 대한 질적 검토. 텍스트-3D 작업에서, 셰이딩된 RGB 색상과 함께 알베도 색상을 나타내는 4개의 시점을 생성하는 것이 우리의 3D 재구성기에서 재질 추정을 개선합니다. 두 입력을 모두 사용하면, 모델은 갑옷을 금속성 및 매끄럽게, 곰의 털을 거칠게 정확하게 예측합니다.](Meta%203D%20AssetGen%20Text-to-Mesh%20Generation%20with%20High%20192519aacd6c473789712df4604b82fb/Untitled%202.png)

알베도 생성에 대한 질적 검토. 텍스트-3D 작업에서, 셰이딩된 RGB 색상과 함께 알베도 색상을 나타내는 4개의 시점을 생성하는 것이 우리의 3D 재구성기에서 재질 추정을 개선합니다. 두 입력을 모두 사용하면, 모델은 갑옷을 금속성 및 매끄럽게, 곰의 털을 거칠게 정확하게 예측합니다.

![sparse-view 재구성에 대한 질적 비교. AssetGen은 기존 기술과 비교하여 더 나은 기하학(주황색으로 표시)과 더 높은 충실도의 텍스처(삽입된 부분)를 제공합니다. SDF 표현과 직접적인 SDF 손실을 함께 사용하면 점유 필드를 사용하는 기본 LightplaneLRM 모델(4, 5행)보다 더 나은 기하학을 제공합니다. 또한, 우리의 텍스처 리파이너는 텍스처 충실도를 크게 향상시킵니다(5, 6행).](Meta%203D%20AssetGen%20Text-to-Mesh%20Generation%20with%20High%20192519aacd6c473789712df4604b82fb/Untitled%203.png)

sparse-view 재구성에 대한 질적 비교. AssetGen은 기존 기술과 비교하여 더 나은 기하학(주황색으로 표시)과 더 높은 충실도의 텍스처(삽입된 부분)를 제공합니다. SDF 표현과 직접적인 SDF 손실을 함께 사용하면 점유 필드를 사용하는 기본 LightplaneLRM 모델(4, 5행)보다 더 나은 기하학을 제공합니다. 또한, 우리의 텍스처 리파이너는 텍스처 충실도를 크게 향상시킵니다(5, 6행).

정량적 평가를 위해 DreamFusion의 텍스트 프롬프트를 사용한 사용자 연구를 수행했으며, 사용자들은 생성된 메쉬의 3D 형상 품질과 텍스트 일치도를 평가했습니다. 총 11,080개의 응답에서 AssetGen의 메쉬가 다른 방법들보다 선호되었습니다.

![텍스트-3D에 대한 질적 비교. Meta 3D AssetGen과 기존의 최신 기법들로 생성된 3D 메쉬를 비교합니다. PBR 재질을 생성하는 방법들(Luma Genie 및 우리 Meta 3D AssetGen)의 경우 재질 분해를 포함합니다. 우리의 접근 방식은 더 잘 정의된 금속성과 거칠기, 그리고 알베도에서 조명 효과를 더 정확하게 분리하여 더 높은 품질의 재질을 생성합니다.](Meta%203D%20AssetGen%20Text-to-Mesh%20Generation%20with%20High%20192519aacd6c473789712df4604b82fb/Untitled%204.png)

텍스트-3D에 대한 질적 비교. Meta 3D AssetGen과 기존의 최신 기법들로 생성된 3D 메쉬를 비교합니다. PBR 재질을 생성하는 방법들(Luma Genie 및 우리 Meta 3D AssetGen)의 경우 재질 분해를 포함합니다. 우리의 접근 방식은 더 잘 정의된 금속성과 거칠기, 그리고 알베도에서 조명 효과를 더 정확하게 분리하여 더 높은 품질의 재질을 생성합니다.

![Meta 3D AssetGen에 의해 생성된 텍스트-3D 메쉬와 PBR 분해. Meta 3D AssetGen은 세밀한 알베도와 재질 속성을 제공하며, 플래터의 금속성(상단 오른쪽)과 금색 객체(마지막 행)에서 강조된 바와 같이 세부 사항이 잘 표현됩니다.](Meta%203D%20AssetGen%20Text-to-Mesh%20Generation%20with%20High%20192519aacd6c473789712df4604b82fb/Untitled%205.png)

Meta 3D AssetGen에 의해 생성된 텍스트-3D 메쉬와 PBR 분해. Meta 3D AssetGen은 세밀한 알베도와 재질 속성을 제공하며, 플래터의 금속성(상단 오른쪽)과 금색 객체(마지막 행)에서 강조된 바와 같이 세부 사항이 잘 표현됩니다.

결론적으로, 우리는 이중 채널 알베도+셰이딩 그리드를 생성하는 것이 알베도만 입력하는 것보다 PBR 분해에서 우수하다는 것을 발견했으며, 지연 셰이딩 손실의 효과를 입증했습니다. AssetGen은 sparse-view 재구성과 텍스트 기반 3D 생성에서 중요한 진전을 이루었으며, 고품질의 3D 메쉬와 PBR 재질을 신속하게 생성할 수 있습니다.

## 5 Conclusions

Meta 3D AssetGen은 고품질의 3D 메쉬와 PBR(Physically-Based Rendering) 재질을 신속하게 생성할 수 있습니다. 이를 위해 여러 주요 혁신을 도입했습니다: 셰이딩된 외형과 알베도 채널을 포함한 다중 뷰 그리드 생성, 이러한 정보를 활용해 PBR 재질을 예측하는 새로운 재구성 네트워크 도입, 지연 셰이딩을 사용한 네트워크 훈련, 새로운 확장 가능한 SDF(서명 거리 함수) 기반 렌더러와 SDF 손실을 통해 기하학적 품질 향상, 그리고 텍스처 정제 네트워크 도입을 통한 텍스처 디테일 개선이 그 예입니다.

종합적인 평가와 실험을 통해 이러한 설계 선택들이 얼마나 효과적인지, 그리고 기존의 방법들을 능가하는 성능을 제공하는지를 입증했습니다. AssetGen은 다양한 3D 그래픽 응용 프로그램에서 활용될 수 있는 고품질의 3D 자산을 빠르게 생성할 수 있는 기술적 돌파구를 제공합니다.