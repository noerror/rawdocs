# High-Resolution Image Synthesis with Latent Diffusion Models

[https://arxiv.org/pdf/2112.10752.pdf](https://arxiv.org/pdf/2112.10752.pdf)

[https://ommer-lab.com/research/latent-diffusion-models/](https://ommer-lab.com/research/latent-diffusion-models/)

[https://www.youtube.com/watch?v=7fBQDaJkcSU](https://www.youtube.com/watch?v=7fBQDaJkcSU)

### 1. Introduction

연구원들은 사전 훈련된 자동 인코더의 잠재 공간에서 확산 모델(DM)을 훈련하여 잠재 확산 모델(LDM)을 생성하는 방법을 시연합니다. 이 접근 방식은 훈련 및 샘플링의 계산 복잡성을 줄여 고해상도 이미지 합성을 더 쉽고 효율적으로 수행할 수 있게 해줍니다. 이 방법은 높은 시각적 충실도를 유지하고 고차원 데이터에 더 잘 확장할 수 있습니다.

LDM은 무조건 이미지 합성, 인페인팅, 확률론적 초해상도 등 여러 작업에서 경쟁력 있는 성능을 달성하는 동시에 픽셀 기반 DM에 비해 계산 비용을 크게 낮춥니다. 또한 추론 비용을 줄이고 메가픽셀 이미지의 고해상도 합성에도 적용할 수 있습니다.

연구진은 다중 모드 훈련을 위해 교차 주의에 기반한 범용 컨디셔닝 메커니즘을 설계하여 클래스 컨디셔닝, 텍스트-이미지, 레이아웃-이미지 모델을 가능하게 합니다. 제안된 방법은 충실한 재구성을 보장하고 잠재 공간의 정규화가 거의 필요하지 않아 이미지 합성의 다양한 작업에 효율적인 솔루션이 될 수 있습니다.

### 2. Related Work

이미지 합성을 위한 생성 모델은 이미지의 고차원적 특성으로 인해 어려움을 겪습니다. GAN은 고해상도 이미지의 효율적인 샘플링을 가능하게 하지만 최적화가 어렵고 전체 데이터 분포를 캡처하는 데 어려움을 겪습니다. VAE 및 흐름 기반 모델과 같은 확률 기반 방법은 더 나은 최적화를 제공하지만 샘플 품질이 낮습니다. 자동 회귀 모델은 강력한 밀도 추정을 수행하지만 계산 요구 사항과 순차적 샘플링 프로세스로 인해 제한이 있습니다.

확산 확률 모델(DM)은 최근 밀도 추정 및 샘플 품질에서 최첨단 결과를 달성했습니다. 그러나 픽셀 공간에서 이러한 모델을 평가하고 최적화하면 추론 속도가 느려지고 훈련 비용이 높아집니다.

이러한 한계를 해결하기 위해 연구자들은 서로 다른 생성 방법의 강점을 결합한 2단계 이미지 합성 접근법을 연구해 왔습니다. VQ-VAE와 VQGAN은 첫 번째 단계에서 자동 회귀 모델을 사용하지만, 훈련에 필요한 높은 압축률로 인해 전반적인 성능에 한계가 있습니다.

제안된 잠재 확산 모델(LDM)은 저차원의 압축된 잠재 공간에서 작업하여 이러한 단점을 극복하고, 합성 품질 저하를 최소화하면서 훈련 비용을 절감하고 추론 속도를 높입니다. LDM은 컨볼루션 백본으로 인해 더 높은 차원의 잠재 공간으로 더 잘 확장되므로 고충실도 재구성을 보장하는 최적의 압축 수준을 구현할 수 있습니다.

### 3. Method

고해상도 이미지 합성을 위한 확산 모델 훈련의 계산 수요를 줄이기 위해 저자는 압축 학습 단계와 생성 학습 단계를 분리하는 방법을 제안합니다. 자동 인코딩 모델을 사용하여 지각적으로 동등하지만 계산적으로 더 단순한 공간을 생성하여 계산 효율성 향상, 확산 모델의 귀납적 편향의 더 나은 활용, 다양한 애플리케이션을 위한 범용 압축 모델이라는 세 가지 이점을 제공합니다.

지각 압축 모델은 이전 연구를 기반으로 하며 지각 손실과 패치 기반 적대적 목표를 결합하여 이미지 재구성이 국소적 사실감을 유지하도록 합니다. 이 모델은 이미지를 잠재적 표현으로 인코딩함으로써 이전 작업보다 더 많은 디테일을 보존합니다.

![Untitled](High-Resolution%20Image%20Synthesis%20with%20Latent%20Diffus%200da4edf563324a8084192bd68de409dc/Untitled.png)

잠재 확산 모델(LDM)은 정규 분포 변수의 노이즈를 점진적으로 제거하여 데이터 분포를 학습합니다. LDM은 데이터의 중요하고 의미 있는 비트에 초점을 맞추고 더 낮은 차원의 더 효율적인 공간에서 학습합니다. 모델의 신경 백본은 시간 조건부 UNet으로 구현되며, 샘플은 디코더를 한 번만 통과하면 잠재 공간에서 이미지 공간으로 디코딩할 수 있습니다.

조건부 메커니즘은 텍스트, 시맨틱 맵 또는 기타 이미지 간 변환 작업과 같은 입력으로 합성 프로세스를 제어하는 데 사용할 수 있습니다. 저자들은 다양한 입력 양식을 전처리하기 위해 교차 주의 메커니즘과 도메인별 인코더로 UNet 백본을 보강합니다. 그런 다음 이미지 컨디셔닝 쌍을 기반으로 조건부 LDM을 학습합니다.

### 4. Experiments

이 연구에서는 지각적 압축과 개념적 압축 간의 상충 관계에 초점을 맞춰 이미지 합성을 위한 잠복 확산 모델(LDM)을 살펴봅니다. 저자는 LDM-4와 LDM-8이 효율성과 충실도 측면에서 이전 모델을 능가하는 고품질 합성 결과를 위한 최상의 조건을 제공한다는 사실을 발견했습니다. 또한 무조건 및 조건부 이미지 생성, 텍스트-이미지 합성, 이미지-이미지 번역 등 다양한 애플리케이션에서 LDM의 효과를 입증합니다. 또한 LDM은 시맨틱 합성, 초고해상도, 인페인팅과 같은 작업에서도 뛰어난 성능을 발휘하여 최대 메가픽셀 범위의 고해상도에서 고품질 이미지를 생성합니다.

이 연구에서는 잠복 확산 모델(LDM)을 초고해상도 및 인페인팅 작업에 효과적으로 사용할 수 있는 방법을 살펴봅니다. 초고해상도에서는 LDM이 경쟁적으로 성능을 발휘하여 FID 측면에서 SR3를 능가하는 반면 IS에서는 약간 낮은 성능을 보였습니다. 인페인팅의 경우, 저자들은 LDM이 픽셀 기반 모델에 비해 상당한 속도 향상을 제공하고 더 나은 FID 점수를 달성한다는 사실을 발견했습니다. 또한 이 모델은 다른 인페인팅 접근 방식에 비해 향상된 이미지 품질을 보여줍니다. 전반적으로 LDM은 초고해상도 및 인페인팅을 포함한 다양한 애플리케이션에서 효율성과 이미지 품질 측면에서 유망한 결과를 보여주며 그 잠재력을 입증하고 있습니다.

### 5. Limitations & Societal Impact

LDM은 GAN에 비해 순차적 샘플링 속도가 느리고 고정밀 작업에서 잠재적인 문제가 발생할 수 있는 등 한계가 있습니다. 이러한 모델은 창의적인 애플리케이션을 가능하게 하고 기술 액세스를 대중화할 수 있지만, 조작된 데이터, 잘못된 정보, 딥페이크에 대한 우려도 제기됩니다. 또한 생성 모델은 학습 데이터를 공개할 수 있으며, 데이터에 민감한 정보가 포함되어 있는 경우 문제가 될 수 있습니다. 또한 딥러닝 모델은 데이터에 존재하는 편견을 재생산하거나 악화시킬 수도 있습니다. LDM과 심층 생성 모델의 윤리적 영향과 한계를 전반적으로 이해하려면 추가 연구가 필요합니다.

### 6. Conclusion

우리는 간단하고 효율적인 방법인 잠재 확산 모델을 제시했습니다. 품질 저하 없이 노이즈 제거 확산 모델의 훈련 및 노이즈 제거 확산 모델의 품질 저하 없이 샘플링 효율성을 크게 향상시킬 수 있는 간단하고 효율적인 방법을 제시했습니다. 이 모델과 교차 주의 조절 메커니즘을 기반으로 한 실험을 통해 작업별 아키텍처 없이도 광범위한 조건부 이미지 합성 작업에서 최신 방법과 비교하여 유리한 결과를 얻을 수 있었습니다.

- Latent Diffusion
    
    잠상 확산은 일련의 노이즈 감소 단계를 통해 고품질 이미지를 생성하는 이미지 생성에 사용되는 기술입니다. 저품질의 노이즈가 많은 이미지로 시작하여 노이즈를 줄이고 디테일을 추가하여 점차적으로 이미지를 개선합니다. 이 과정은 최종 고품질 이미지를 얻을 때까지 각 단계에서 이미지를 다듬는 데 도움이 되는 학습된 신경망에 의해 안내됩니다.