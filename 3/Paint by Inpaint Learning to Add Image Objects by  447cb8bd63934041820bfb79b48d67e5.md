# Paint by Inpaint: Learning to Add Image Objects by Removing Them First

[https://arxiv.org/abs/2404.18212](https://arxiv.org/abs/2404.18212)

[https://rotsteinnoam.github.io/Paint-by-Inpaint/](https://rotsteinnoam.github.io/Paint-by-Inpaint/)

Apr 2024 

![제안된 모델의 시각적 결과](Paint%20by%20Inpaint%20Learning%20to%20Add%20Image%20Objects%20by%20%20447cb8bd63934041820bfb79b48d67e5/Untitled.png)

제안된 모델의 시각적 결과

## 1 Introduction

이미지 편집이 컴퓨터 비전 및 그래픽 커뮤니티에서 중요한 역할을 하며 다양한 분야에 응용될 수 있다고 언급합니다. 특히 이미지에 객체를 추가하는 작업은 복잡성이 높으며, 이는 단순히 현실적인 시각적 결과를 넘어서 이미지의 전반적인 맥락을 이해하고 적절히 반영하는 능력을 요구합니다. 객체의 위치, 크기, 스타일 등 다양한 요소들이 결과의 충실도에 영향을 미치며, 최근의 발전은 사용자가 직접 마스크를 제공하는 방식에서 벗어나 마스크 없는 접근 방식을 가능하게 하였습니다. 이러한 접근은 더욱 편리하고 현실적인 환경을 제공하지만, 여전히 여러 도전 과제를 가지고 있습니다.

논문은 'InstructPix2Pix'라는 방법을 소개하며, 이는 대규모의 데이터셋을 합성하여 편집 지시를 포함한 소스 및 타겟 이미지 쌍으로 모델을 훈련시키는 방식입니다. 그러나 이 방법은 합성된 훈련 데이터의 품질에 한계를 가지고 있어, 이를 개선하기 위한 새로운 자동화된 방법을 제안합니다. 이 방법은 기존의 이미지를 대상으로 하고 인페인트 처리된 이미지를 소스로 사용하여 데이터셋을 구성함으로써 원본과 편집된 이미지 간의 일관성을 자연스럽게 유지하는 데 중점을 둡니다.

![PIPE 데이터셋 구축. PIPE 데이터셋 생성 단계에서는 두 가지 과정이 사용됩니다: (i) 추가 지시문 생성. 그림에서는 VLM을 사용하여 시각적 객체 세부 정보를 추출하고, LLM의 도움으로 추가 지시문으로 구성하는 VLM-LLM 기반 지시문 생성 과정이 나타납니다. (ii) 입력 마스크는 원본 이미지와 결합되어 고정된 인페인팅 모델을 사용하여 이미지에서 객체를 제거합니다.](Paint%20by%20Inpaint%20Learning%20to%20Add%20Image%20Objects%20by%20%20447cb8bd63934041820bfb79b48d67e5/Untitled%201.png)

PIPE 데이터셋 구축. PIPE 데이터셋 생성 단계에서는 두 가지 과정이 사용됩니다: (i) 추가 지시문 생성. 그림에서는 VLM을 사용하여 시각적 객체 세부 정보를 추출하고, LLM의 도움으로 추가 지시문으로 구성하는 VLM-LLM 기반 지시문 생성 과정이 나타납니다. (ii) 입력 마스크는 원본 이미지와 결합되어 고정된 인페인팅 모델을 사용하여 이미지에서 객체를 제거합니다.

![편집 모델 훈련. 훈련 단계에서는 PIPE 데이터셋을 사용하여 모델을 훈련시켜 인페인팅 과정을 역으로 수행하고 이미지에 객체를 추가합니다.](Paint%20by%20Inpaint%20Learning%20to%20Add%20Image%20Objects%20by%20%20447cb8bd63934041820bfb79b48d67e5/Untitled%202.png)

편집 모델 훈련. 훈련 단계에서는 PIPE 데이터셋을 사용하여 모델을 훈련시켜 인페인팅 과정을 역으로 수행하고 이미지에 객체를 추가합니다.

마지막으로, 이 장은 데이터셋 구축에 사용된 마스크 기반 인페인팅과 다양한 필터링 및 정제 기술, 그리고 자연어 편집 지시문을 생성하기 위해 다중 모달 학습을 활용하는 방법을 간략히 소개합니다. 이러한 모든 요소들이 결합되어 'PIPE'라는 대규모 객체 추가 데이터셋을 형성하며, 이는 약 100만 개의 이미지 쌍과 1400개 이상의 다양한 클래스를 포함합니다.

## 2 Related Efforts

이미지 편집 분야의 연구 및 개발에 대한 관련 작업을 다루고 있습니다. 이 챕터는 크게 세 부분으로 나뉘어져 있습니다.

![시각적 비교. 주요 편집 모델과 비교하여 우리 모델의 지시에 대한 높은 충실도와 스타일, 크기, 위치 측면에서 정확한 객체 추가를 보여주며, 원본 이미지와의 더 높은 일관성을 유지합니다.](Paint%20by%20Inpaint%20Learning%20to%20Add%20Image%20Objects%20by%20%20447cb8bd63934041820bfb79b48d67e5/Untitled%203.png)

시각적 비교. 주요 편집 모델과 비교하여 우리 모델의 지시에 대한 높은 충실도와 스타일, 크기, 위치 측면에서 정확한 객체 추가를 보여주며, 원본 이미지와의 더 높은 일관성을 유지합니다.

### **2.1 이미지 편집**

이미지 편집은 컴퓨터 그래픽스와 비전 분야에서 오랫동안 탐구되어 왔으며, 특히 확산 기반 이미지 합성 모델의 출현으로 큰 발전을 이루었습니다. 이미지 편집은 크게 마스크 기반 편집과 마스크 없는 편집으로 나눌 수 있습니다.

- **마스크 기반 편집**: 이 접근 방식은 타겟 편집 영역을 아웃라인하는 마스크를 사용하는 인페인팅 작업으로 정의됩니다. 초기의 확산 기반 기술은 이미 훈련된 모델을 인페인팅에 사용했으며, 최근에는 특정 작업에 모델을 미세 조정하는 방식이 등장했습니다.
- **마스크 없는 편집**: 이 패러다임은 추가적인 마스크 없이 텍스트 조건을 사용하여 이미지 편집을 가능하게 합니다. 자연어를 직관적인 상호작용 도구로 사용하여, 전역 편집(예: 스타일 전송 또는 재조명)과 지역 편집의 일관성 유지에 도전합니다.

### **2.2 이미지 편집 데이터셋**

이미지 편집을 위한 데이터셋 생성은 특정 클래스를 포함하는 데이터셋 사용에서 시작되었습니다. 최근에는 자연 이미지와 그 편집된 버전을 포함하는 데이터셋을 마스크 없는 설정에서 생성하는 것이 불가능에 가깝다고 언급합니다. 이에 따라 다양한 합성 데이터셋이 제안되었으며, 그 중 'InstructPix2Pix'의 데이터셋이 인기를 끌고 있습니다. 또한, 새로운 데이터셋 생성 방법들이 계속해서 제안되고 있습니다.

### **2.3 객체 중심 편집**

특정 객체를 처리하는 데 확산 모델을 사용하는 연구가 최근 늘어나고 있습니다. 이 분야의 연구는 객체 마스크를 사용하여 해당 객체를 편집하는 기술을 개발하는 데 중점을 두고 있습니다. 특히, 'IP2P'와 'MagicBrush'와 같은 지시 기반 방법들은 이미지 객체를 삽입하는 능력을 크게 강조하며, 많은 부분을 이 목적에 할애하고 있습니다.

각 섹션은 다양한 접근 방식과 기술을 탐구하고 비교하면서, 특히 마스크 없는 편집과 객체 중심 편집의 발전에 주목합니다. 이러한 연구들은 최종적으로 객체 추가 데이터셋 'PIPE'의 개발로 이어지며, 이는 논문의 주된 기여 중 하나로 자리 잡고 있습니다.

## 3 PIPE Dataset

'PIPE' 데이터셋의 생성 방법과 그 특성에 대해 상세히 설명합니다. 이 데이터셋은 이미지 편집 모델의 효율성을 향상시키기 위해 설계되었으며, 객체 추가라는 복잡한 작업에 특화되어 있습니다.

![데이터셋 필터링 단계. PIPE를 구성하는 과정에서 여러 필터링 단계가 적용되어 인페인팅의 단점을 해결합니다. 첫 번째 행은 흐림과 저품질로 인한 비정상적인 객체 뷰를 대상으로 하는 사전 제거 필터를 보여줍니다. 두 번째와 세 번째 행은 제거 후 단계를 보여줍니다. 두 번째 행은 같은 이미지의 세 인페인팅 결과 사이에 CLIP 합의 부족을 나타내는 일관성 문제를 다룹니다. 이는 상당한 인페인팅 변동을 의미합니다. 세 번째 행은 원래 객체 이름과의 낮은 의미론적 유사성을 보장하기 위해 다중 모드 CLIP 필터링을 사용합니다. 마지막 행은 필터링이 필요 없는 성공적인 제거 결과를 보여줍니다.](Paint%20by%20Inpaint%20Learning%20to%20Add%20Image%20Objects%20by%20%20447cb8bd63934041820bfb79b48d67e5/Untitled%204.png)

데이터셋 필터링 단계. PIPE를 구성하는 과정에서 여러 필터링 단계가 적용되어 인페인팅의 단점을 해결합니다. 첫 번째 행은 흐림과 저품질로 인한 비정상적인 객체 뷰를 대상으로 하는 사전 제거 필터를 보여줍니다. 두 번째와 세 번째 행은 제거 후 단계를 보여줍니다. 두 번째 행은 같은 이미지의 세 인페인팅 결과 사이에 CLIP 합의 부족을 나타내는 일관성 문제를 다룹니다. 이는 상당한 인페인팅 변동을 의미합니다. 세 번째 행은 원래 객체 이름과의 낮은 의미론적 유사성을 보장하기 위해 다중 모드 CLIP 필터링을 사용합니다. 마지막 행은 필터링이 필요 없는 성공적인 제거 결과를 보여줍니다.

### **3.1 소스-타겟 이미지 쌍 생성**

PIPE 데이터셋의 생성은 크게 두 단계로 진행됩니다. 첫 번째 단계에서는 대규모 이미지 세분화 데이터셋을 활용합니다. 이들 데이터셋에는 COCO와 Open-Images가 포함되며, 이들은 세분화 마스크 주석이 풍부한 LVIS 데이터셋으로 풍부해집니다. 이를 통해 다양한 이미지와 1400개 이상의 유니크 클래스를 사용할 수 있습니다.

### **전처리-제거 단계**

- 마스크 필터링을 수행하여 객체 추가 작업에 적합한 객체만을 선택합니다.
- CLIP을 사용하여 세분화된 객체와 해당 클래스 이름 간의 유사성을 계산하고, 이를 필터링 기준으로 사용합니다.

### **객체 제거**

- 객체를 제거하기 위해 안정적인 확산 인페인팅 모델을 사용합니다. 이 과정에서는 긍정적 및 부정적 프롬프트를 사용하여 객체를 비-객체(예: 배경)로 대체하도록 모델을 유도합니다.

### **제거 후 처리**

- 여러 단계의 프로세스를 거쳐 인페인팅 결과를 필터링하고 정제합니다. 이는 소스 이미지와 그 인페인팅 출력 간의 일관성을 유지하는 데 중점을 둡니다.

### **3.2 객체 추가 지시문 생성**

이 데이터셋은 소스와 타겟 이미지 쌍 외에도 해당하는 편집 지시문을 자연어로 포함합니다. 여기서 세 가지 다른 전략을 사용하여 지시문을 향상시킵니다.

- **클래스 이름 기반**: 가장 간단한 형식으로 "add a <class>" 형식을 사용합니다.
- **VLM-LLM 기반**: 클래스 이름만으로는 부족할 수 있는 세부사항을 포함시키기 위해, 자세한 객체 속성을 설명하는 VLM을 사용하고, 이를 LLM을 통해 자연어 지시문으로 변환합니다.
- **수동 참조 기반**: 텍스트 객체 참조를 포함하는 데이터셋(예: RefCOCO)을 사용하여 더 풍부하고 구체적인 지시문을 생성합니다.

이러한 다양한 접근 방식을 통해 생성된 지시문은 PIPE 데이터셋에 1,879,919개의 다양한 객체 추가 지시문을 제공합니다. 이 데이터셋은 대규모 이미지 편집 작업에 사용될 수 있으며, 실제 이미지를 타겟으로 사용함으로써 기존의 합성 데이터셋과 차별화됩니다.

## 4 Model Training

PIPE 데이터셋을 사용하여 이미지 편집 확산 모델을 훈련시키는 방법론을 자세히 설명합니다.

![PIPE 데이터셋 예시.](Paint%20by%20Inpaint%20Learning%20to%20Add%20Image%20Objects%20by%20%20447cb8bd63934041820bfb79b48d67e5/Untitled%205.png)

PIPE 데이터셋 예시.

### **4.1 모델 구조**

모델은 SD 1.5 모델을 기반으로 하며, 이는 텍스트 조건부 확산 모델로, 사전 훈련된 변분 오토인코더와 U-Net을 사용하여 잠재 공간에서의 잡음 제거 과정을 담당합니다. 훈련 과정은 텍스트 지시문과 함께 시각적 표현을 통합하는 교차 주의 메커니즘에 의존합니다.

### **4.2 조건 설정**

이미지 편집 과정은 텍스트 지시문 **`cT`**에 조건을 두어 진행됩니다. 모델은 두 가지 유형의 조건, 즉 텍스트(**`cT`**) 및 입력 소스 이미지(**`cI`**)에 따라 다르게 반응합니다. 이중 조건 설정을 통해 모델은 보다 정확하게 대상 편집을 수행할 수 있습니다.

### **4.3 분류기-자유 안내 (CFG)**

분류기-자유 안내 기법을 사용하여 텍스트 지시문과의 일치성을 향상시킵니다. 이 기법은 조건부와 비조건부 점수 모두를 모델링함으로써, 편집 이미지가 지시문과 더 잘 일치하도록 합니다. 이를 통해 모델은 편집 과정 중에 텍스트 지시의 영향을 받아 특정 특징을 더욱 강조하거나 수정할 수 있습니다.

### **4.4 학습 및 추론 설정**

훈련 중에는 일부 확률로 텍스트(**`cT`**) 또는 이미지(**`cI`**) 조건을 제외시키며, 이는 모델이 더 강인하게 다양한 상황에 적응하도록 돕습니다. 추론 과정에서는 CFG를 이용하여, 지시문과 소스 이미지를 고려한 점수 추정을 계산합니다. 이 점수는 모델이 생성한 이미지가 지시문과 얼마나 잘 일치하는지를 나타냅니다.

### **4.5 세부 구현 및 하이퍼파라미터**

논문의 부록에서는 훈련과 관련된 추가적인 구현 세부사항과 하이퍼파라미터 설정을 제공합니다. 이 정보는 모델을 재현하거나 비슷한 작업에 적용할 때 유용할 수 있습니다.

이러한 방법론을 통해 PIPE 데이터셋에서 훈련된 모델은 이미지에 객체를 추가하는 복잡한 작업을 수행할 수 있으며, 훈련된 모델은 고도의 일관성과 정확성을 보여줍니다. 이는 PIPE 데이터셋의 다양한 편집 시나리오에 맞게 최적화된 결과를 제공하는 데 중요한 역할을 합니다.

## 5 Experiments

PIPE 데이터셋을 사용하여 훈련된 모델의 성능을 평가하는 다양한 실험에 대해 설명합니다. 이 장은 실험 설정, 정량적 평가, 정성적 예시, 인간 평가를 포함합니다.

### **5.1 실험 설정**

- **PIPE 테스트 세트**: PIPE에서 생성된 테스트 세트를 사용하여 모델의 객체 추가 기능을 평가합니다.
- **MagicBrush**: 이것은 합성 이미지 편집 벤치마크로, 특히 객체 추가 작업에 중점을 두어 필터링합니다.
- **OPA (Object Placement Assessment)**: 이 데이터셋은 객체 추가를 평가하기 위해 소스 및 타겟 이미지와 추가할 객체를 포함합니다.

### **5.2 정량적 평가**

모델의 성능을 평가하기 위해 여러 지표를 사용합니다:

- **L1 및 L2 거리**: 이 지표들은 타겟 이미지와 편집 결과 사이의 픽셀 수준 변경을 측정합니다.
- **CLIP 및 DINO**: 이러한 이미지 인코더는 편집된 이미지와 타겟 이미지 간의 의미론적 유사성을 평가합니다.
- **CLIP-T**: 이는 텍스트-이미지 정렬을 평가합니다.

모델은 PIPE 테스트 세트, MagicBrush, OPA 데이터셋에서 성능을 평가하며, 주요 경쟁 모델과 비교하여 일관되게 높은 성능을 보입니다.

### **5.3 정성적 예시**

실험 결과는 모델이 자연스럽고 일관성 있는 방식으로 이미지에 객체를 추가하는 능력을 시각적으로 보여줍니다. 예시 이미지들은 모델이 훈련 클래스를 넘어 다양한 객체를 성공적으로 통합할 수 있음을 보여줍니다.

### **5.4 인간 평가**

인간 평가를 통해 모델의 편집 품질과 지시에 따른 정확성을 평가합니다. 100개의 이미지에 대해 합리적인 추가 지시문을 제공받고, 두 모델(IP2P와 비교)의 편집 결과를 평가받습니다. 평가 결과, 우리 모델은 편집 지시에 대한 충실도와 이미지 품질 모두에서 높은 선호도를 보였습니다.

## 6 Leveraging PIPE for General Editing

6장 'Leveraging PIPE for General Editing'에서는 PIPE 데이터셋을 사용하여 일반 이미지 편집 작업에 어떻게 적용할 수 있는지를 탐구합니다. 이 장은 PIPE 데이터셋이 객체 추가에 국한되지 않고, 더 넓은 범위의 이미지 편집 성능을 향상시키는 방법에 초점을 맞춥니다.

### **6.1 데이터셋 통합**

- PIPE 데이터셋은 IP2P 일반 편집 데이터셋과 통합되어, 보다 다양한 이미지 편집 작업에 활용됩니다. 이러한 통합은 두 데이터셋의 강점을 결합하여, 모델이 더 광범위한 편집 작업을 수행할 수 있게 합니다.

### **6.2 모델 훈련 및 평가**

- PIPE와 결합된 데이터셋을 사용하여 확산 모델을 다시 훈련합니다. 이 과정에서, 모델은 일반 편집 작업에 대해 미세 조정되어, MagicBrush 테스트 세트 전체를 사용하여 평가됩니다. 이 평가는 모델이 일반 편집 작업에서 어떻게 성능을 발휘하는지를 보여줍니다.

### **6.3 성능 평가**

- 모델은 IP2P 모델과의 비교를 통해 평가되며, MagicBrush 훈련 세트로 미세 조정된 버전과 비교하여 평가됩니다. 결과적으로, 우리의 모델은 일반 편집 작업에서 새로운 최고 기록을 설정합니다. 이는 PIPE 데이터셋이 다양한 편집 시나리오에서 모델의 성능을 개선하는 데 기여함을 보여줍니다.

### **6.4 결과의 재현성 및 공정성**

- 모든 실험은 동일한 시드를 사용하여 실행되어, 결과의 재현성과 공정성을 확보합니다. 평가는 제공된 스크립트와 공식 모델을 사용하여 수행되며, 이는 결과가 더 신뢰할 수 있도록 합니다.

### **종합적으로**

이 장은 PIPE 데이터셋이 단순히 객체 추가에만 국한되지 않고, 전반적인 이미지 편집 작업에서도 성능 향상을 이끌어낼 수 있음을 보여줍니다. 또한, 다양한 데이터셋과의 통합을 통해 일반 편집 작업의 성능을 높이고, 모델의 범용성을 확장하는 방법을 제시합니다. 이러한 접근 방식은 이미지 편집 기술의 전반적인 발전에 기여할 수 있는 잠재력을 지니고 있습니다.

## 7 Discussion

### **7.1 연구 결과의 요약**

- **Paint by Inpaint 프레임워크**: 이 프레임워크는 이미지에 객체를 추가하는 것이 기본적으로 객체를 제거하는 과정의 역임을 식별하고 활용합니다. 이는 PIPE 데이터셋의 개발로 이어져, 대규모 고품질의 객체 추가 데이터셋을 구축하는 데 기여했습니다.
- **확산 모델의 성능**: PIPE 데이터셋을 사용하여 훈련된 확산 모델은 객체를 이미지에 추가하는 작업에서 최고의 성능을 보였습니다. 이는 복잡한 객체 추가 작업을 위한 새로운 표준을 설정합니다.
- **일반 편집 작업의 향상**: PIPE 데이터셋을 다른 편집 데이터셋과 통합함으로써, 일반 편집 작업의 전반적인 성능이 향상되었습니다. 이는 PIPE의 유용성을 넘어 다양한 편집 작업에 적용될 수 있는 잠재력을 시사합니다.

### **7.2 한계점 및 개선 방향**

- **객체 제거 단계의 강건성**: 데이터 취득 파이프라인이 객체 제거 단계에서 상당한 강건성을 보이지만, 여전히 오류에 완전히 면역되지는 않습니다. 이는 추가 개선이 필요한 영역으로, 더 정교한 알고리즘 개발이 요구됩니다.
- **지시문 생성의 효과**: 다양한 방법으로 생성된 편집 지시문의 효과는 VLMs와 LLMs가 인간처럼 자연스러운 지시문을 생성하는 능력에 의존합니다. 이 분야에서의 기술 발전이 지시문의 질을 더욱 향상시킬 수 있습니다.
- **범용적 적용 가능성**: 연구 결과를 다양한 이미지 편집 작업에 적용하는 것이 논문의 주된 목표 중 하나이지만, 실제 적용에서의 일관성과 정확성을 더욱 보장하기 위한 추가 연구가 필요합니다.

### **7.3 향후 연구 방향**

- 논문은 이러한 한계를 극복하기 위한 구체적인 향후 연구 방향을 제시하지 않았지만, 연구 결과를 바탕으로 기술 개발과 데이터셋 확장, 모델 최적화 등이 포함될 것으로 예상됩니다. 또한, 새로운 기술의 통합으로 모델의 일관성과 범용성을 더욱 강화할 수 있을 것입니다.

## **부록**

### **A. 추가 모델 출력**

- Fig. 7에서는 다양한 객체 추가 결과를 보여주며, PIPE 데이터셋만을 사용한 모델과 MagicBrush 훈련 세트에서 미세 조정된 모델의 결과를 비교 제시합니다.
    
    ![제안된 모델의 추가 객체 추가 결과. 처음 세 줄은 PIPE 데이터셋만을 사용하여 훈련된 모델의 결과를 보여줍니다. 마지막 줄은 Sec. 5.2에 자세히 설명된 바와 같이 MagicBrush 훈련 세트에서 미세 조정된 동일 모델의 결과를 보여줍니다.](Paint%20by%20Inpaint%20Learning%20to%20Add%20Image%20Objects%20by%20%20447cb8bd63934041820bfb79b48d67e5/Untitled%206.png)
    
    제안된 모델의 추가 객체 추가 결과. 처음 세 줄은 PIPE 데이터셋만을 사용하여 훈련된 모델의 결과를 보여줍니다. 마지막 줄은 Sec. 5.2에 자세히 설명된 바와 같이 MagicBrush 훈련 세트에서 미세 조정된 동일 모델의 결과를 보여줍니다.
    

### **B. PIPE 데이터셋**

- **B.1 소스-타겟 이미지 쌍 생성**: 제거 후 과정에서, 객체의 클래스 이름과 인페인트된 영역 간의 CLIP 유사도를 평가하여 객체 제거의 품질을 평가합니다. 배경의 영향을 줄이기 위해 배경색을 이미지의 평균 색상과 일치시키는 조정을 포함합니다.
- **B.2 VLM-LLM 기반 지시문**: 객체의 클래스 이름을 자세한 자연어 지시문으로 변환합니다. CogVLM을 사용하여 객체의 주요 특성을 기술하고, 이 정보를 LLM에 제공하여 명확한 지시문을 생성합니다.
- **B.3 지시문 유형 통합**: 세 가지 접근 방식(클래스 이름 기반, VLM-LLM 기반, 수동 참조 기반)을 사용하여 최종 데이터셋을 구성합니다.
    
    ![PIPE 데이터셋 예시.](Paint%20by%20Inpaint%20Learning%20to%20Add%20Image%20Objects%20by%20%20447cb8bd63934041820bfb79b48d67e5/Untitled%207.png)
    
    PIPE 데이터셋 예시.
    

### **C. 구현 세부사항**

- **C.1 MagicBrush 하위 집합**: 객체 추가 작업에 초점을 맞추기 위해 MagicBrush 데이터셋에서 자동 필터링 과정을 적용합니다.
- **C.2 평가**: 모델을 주요 지시문 따르는 이미지 편집 모델과 비교 평가합니다. 비교 평가는 고정된 시드를 사용하여 일관성을 유지합니다.

### **D. 인간 평가**

- 정량적 지표와 함께 인간 평가 설문을 통해 편집 결과에 대한 인간의 만족도를 평가합니다. 이 설문은 요청된 편집의 실행과 결과 이미지의 전반적인 품질에 관한 질문을 포함합니다.
    
    ![Untitled](Paint%20by%20Inpaint%20Learning%20to%20Add%20Image%20Objects%20by%20%20447cb8bd63934041820bfb79b48d67e5/Untitled%208.png)
    
    ![인간 평가 예시. 질적 설문조사의 예시와 응답 분포(우리 방법은 빨간색, 기준선은 파란색)를 함께 보여줍니다. 예시에는 모델의 성공적인 경우와 실패한 경우가 모두 포함됩니다. 상단의 처음 세 예시는 편집 완성도에 초점을 맞춘 질문과 관련이 있고, 하단의 세 예시는 결과 이미지의 품질에 관한 것입니다.](Paint%20by%20Inpaint%20Learning%20to%20Add%20Image%20Objects%20by%20%20447cb8bd63934041820bfb79b48d67e5/Untitled%209.png)
    
    인간 평가 예시. 질적 설문조사의 예시와 응답 분포(우리 방법은 빨간색, 기준선은 파란색)를 함께 보여줍니다. 예시에는 모델의 성공적인 경우와 실패한 경우가 모두 포함됩니다. 상단의 처음 세 예시는 편집 완성도에 초점을 맞춘 질문과 관련이 있고, 하단의 세 예시는 결과 이미지의 품질에 관한 것입니다.
    

### **E. 지시문 효과 평가**

- VLM-LLM 파이프라인을 사용하여 생성된 자세한 지시문의 효과를 '짧은 지시문'과 비교합니다. 이 평가는 MagicBrush 및 OPA 데이터셋에서 수행되며, 자세한 지시문이 모델 성능을 크게 향상시킴을 보여줍니다.
    
    ![지시문 효과 평가. '짧은' 템플릿 기반 지시문과 VLM-LLM 파이프라인을 통해 생성된 '긴' 지시문에 대해 훈련된 모델 성능의 질적 비교입니다. 후자에 훈련된 모델은 복잡한 지시문을 해석하고 편집 요청에 맞춰 객체를 추가하는 데 더 우수한 성능을 보여줍니다.](Paint%20by%20Inpaint%20Learning%20to%20Add%20Image%20Objects%20by%20%20447cb8bd63934041820bfb79b48d67e5/Untitled%2010.png)
    
    지시문 효과 평가. '짧은' 템플릿 기반 지시문과 VLM-LLM 파이프라인을 통해 생성된 '긴' 지시문에 대해 훈련된 모델 성능의 질적 비교입니다. 후자에 훈련된 모델은 복잡한 지시문을 해석하고 편집 요청에 맞춰 객체를 추가하는 데 더 우수한 성능을 보여줍니다.
    

### **F. 일반 편집 예시**

- 일반 편집 작업에서의 모델 성능을 시각적으로 비교하며, PIPE 데이터셋이 다양한 편집 작업에서 성능을 향상시키는 방법을 보여줍니다.
    
    ![Untitled](Paint%20by%20Inpaint%20Learning%20to%20Add%20Image%20Objects%20by%20%20447cb8bd63934041820bfb79b48d67e5/Untitled%2011.png)
    
    일반 편집 작업에 대한 시각적 비교. 전체 MagicBrush 테스트 세트에서 평가된 일반 편집 작업에 대해 PIPE 데이터셋과 IP2P 데이터셋이 결합된 기여도입니다. 비교는 이러한 병합된 데이터셋에서 훈련된 모델과 IP2P 데이터셋만으로 훈련된 모델 간에 이루어지며, 두 모델 모두 MagicBrush 훈련 세트에서 미세 조정되었습니다. 결과는 PIPE 데이터셋이 객체 추가 지시문에만 초점을 맞추었음에도 불구하고 다양한 편집 작업에서 성능을 향상시킴을 보여줍니다.
    

### **G. 사회적 영향 및 윤리적 고려**

- PIPE 사용이나 해당 모델 훈련은 이미지에 객체를 추가하는 능력을 크게 향상시키지만, 잘못 사용될 경우 오해를 불러일으키거나 해로운 이미지를 생성할 수 있는 위험이 있습니다. 따라서 사용자는 연구 결과를 책임감 있고 윤리적으로 사용할 것을 권장합니다.